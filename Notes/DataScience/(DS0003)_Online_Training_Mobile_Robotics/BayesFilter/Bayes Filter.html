<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style.css">
    <title>Bayes Filter</title>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Bayes Filter"><h1 id="Bayes Filter" class="header"><a href="#Bayes Filter">Bayes Filter</a></h1></div>

<hr>

<ol>
<li>
<a href="Bayes Filter.html#Bayes Filter-State Estimation">State Estimation</a>

</li><li>
<a href="Bayes Filter.html#Bayes Filter-Recursive State Estimation">Recursive State Estimation</a>

</li><li>
<a href="Bayes Filter.html#Bayes Filter-Recursive Bayes Filter">Recursive Bayes Filter</a>

<ol>
<li>
<a href="Bayes Filter.html#Bayes Filter-Recursive Bayes Filter-Intuition">Intuition</a>

</li><li>
<a href="Bayes Filter.html#Bayes Filter-Recursive Bayes Filter-Derivation">Derivation</a>

</li><li>
<a href="Bayes Filter.html#Bayes Filter-Recursive Bayes Filter-Prediction and Correction Step">Prediction and Correction Step</a>

</li><li>
<a href="Bayes Filter.html#Bayes Filter-Recursive Bayes Filter-Implementation">Implementation</a>

</li></ol>
</li><li>
<a href="Bayes Filter.html#Bayes Filter-Popular Filters">Popular Filters</a>

</li><li>
<a href="Bayes Filter.html#Bayes Filter-Model Examples">Model Examples</a>

</li></ol>
<hr>

<div id="Bayes Filter-State Estimation"><h2 id="State Estimation" class="header"><a href="#Bayes Filter-State Estimation">State Estimation</a></h2></div>

<p>
State Estimation means we want to estimate the state of the system based on sensor measurements and control commands.
</p>

<p>
Thus, given observations \(z\) and control commands \(u\), estimate the current state \(x\) at time \(t\):
</p>

\[
p(x_t|z_{1:t}, u_{1:t})
\]

<div id="Bayes Filter-Recursive State Estimation"><h2 id="Recursive State Estimation" class="header"><a href="#Bayes Filter-Recursive State Estimation">Recursive State Estimation</a></h2></div>

<p>
Recursive State Estimation means we want to update our belief based on the observation that comes in reusing the previous distribution that we had.
</p>

<p>
Therefore, using the previous definition of the current state, we would introduce recursion by computing \(x_t\) based on the current measurement \(z_t\), the current control command \(u_t\) and the previous state \(x_{t-1}\). The latter is in itself also defined recursively.
</p>

<div id="Bayes Filter-Recursive Bayes Filter"><h2 id="Recursive Bayes Filter" class="header"><a href="#Bayes Filter-Recursive Bayes Filter">Recursive Bayes Filter</a></h2></div>

<div id="Bayes Filter-Recursive Bayes Filter-Intuition"><h3 id="Intuition" class="header"><a href="#Bayes Filter-Recursive Bayes Filter-Intuition">Intuition</a></h3></div>

<p>
We start with no knowledge of the environment, so our state is described by a uniform distribution, indicating we could be located at any point in space.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/belief.png" alt="Initial Belief">
</p>

<p>
After receiving a measurement \(z\), we update our belief. In this case we have sensed a door, and we know there are three doors in our map. Therefore the probability of obtaining the measurement \(z\) given we are in front of that door is larger than in the other possible positions. So if we combine our previous belief with this measurement's probability distribution, our belief becomes:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/belief_after_measurement.png" alt="Belief After Measurement">
</p>

<p>
Now we move forward, so we also have to shift our belief forward. Note, however, that our movement is not exact, there is also a level of uncertainty, so we describe it by using a distribution. Hence, when combining our previous belief with the probability distribution for the motion our certainty about our state decreases, and our belief becomes:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/belief_after_motion.png" alt="Belief After Motion">
</p>

<p>
We receive yet another measurement \(z\), again we have that \(p(z|x)\) is larger on the locations where there is a door, because this measurement has sensed a door. So if we combine this probability distribution for this measurement with our previous state we increase our certainty about our current state. Therefor, our belief becomes:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/belief_after_second_measurement.png" alt="Belief After Second Measurement">
</p>

<div id="Bayes Filter-Recursive Bayes Filter-Derivation"><h3 id="Derivation" class="header"><a href="#Bayes Filter-Recursive Bayes Filter-Derivation">Derivation</a></h3></div>

<p>
The belief at time \(t\) is given by:
</p>

\[
bel(x_t) = p(x_t | z_{1:t}, u_{1:t})
\]

<p>
That is, where am I at moment \(t\), given all previous observations \(z_{1:t}\) and control commands \(u_{1:t}\). We now apply Bayes rule, to swap \(x_t\) and \(z_t\) on the conditional probability:
</p>

\[
= \eta \cdot p(z_t | x_t, z_{1:t-1}, u_{1:t}) \cdot p(x_t|z_{1:t-1}, u_{1:t})
\]

<p>
Where \(\eta\) is a normalization constant. Now, let's pay attention to \(p(z_t | x_t, z_{1:t-1}, u_{1:t})\). By the Markov assumption we are going to assume that the current state \(x_t\) and the previous observations and control commands are conditionally independent. That is, they do not give any information about the likelihood of the observation \(z_t\). Thus, we drop them from the equation:
</p>

\[
= \eta \cdot p(z_t | x_t) \cdot p(x_t|z_{1:t-1}, u_{1:t})
\]

<p>
For \(p(x_t|z_{1:t-1}, u_{1:t})\) we are going to use the law of Total Probability to add a new variable, so we integrate over this new variable. More concretely to add \(x_{t-1}\), which will allow us to introduce recursion to our expression:
</p>


\[
= \eta \cdot p(z_t | x_t) \cdot \int p(x_t | x_{t-1}, z_{1:t-1}, u_{1:t}) \cdot p(x_{t-1}|z_{1:t-1},u_{1:t}) dx_{t-1}
\]

<p>
We could interpret this rewritten expression as:
</p>

<p>
For each previous state \(x_{t-1}\) we multiply
</p>

<ul>
<li>
\(p(x_t | x_{t-1}, z_{1:t-1}, u_{1:t})\), the probability of being in the new state \(x_t\) given the previous state \(x_{t-1}\), observations \(z_{1:t-1}\) and control commands \(u_{1:t}\)

</li><li>
by \(p(x_{t-1}|z_{1:t-1},u_{1:t})\), the probability of being in the state \(x_{t-1}\) given the previous observations \(z_{1:t-1}\) and control commands \(u_{1:t}\)

</li></ul>
<p>
Once again we apply the Markov assumption over \(p(x_t | x_{t-1}, z_{1:t-1}, u_{1:t})\), because knowing where I am at moment \(t-1\), we assume the observations \(z_{1:t-1}\) do not add any information. However note the control command does indeed hold valuable information, as it tells us action last executed that moved us from \(x_{t-1}\) to \(x_t\). So we simplify the expression as follows:
</p>

\[
= \eta \cdot p(z_t | x_t) \cdot \int p(x_t | x_{t-1}, u_{1:t}) \cdot p(x_{t-1}|z_{1:t-1},u_{1:t}) dx_{t-1}
\]

<p>
We now suppose that knowing what action or command is executed in the future does not tell us anything about the present. Hence we ignore the latest control command \(u_t\), so the expression becomes:
</p>

\[
= \eta \cdot p(z_t | x_t) \cdot \int p(x_t | x_{t-1}, u_{1:t}) \cdot p(x_{t-1}|z_{1:t-1},u_{1:t-1}) dx_{t-1}
\]

<p>
Note that we have finally derived a recursive expression for our belief, given:
</p>

\[
bel(x_{t-1}) = p(x_{t-1}|z_{1:t-1}, u_{1:t-1})
\]

<p>
We substitute this expression in the belief at time \(t\):
</p>

\[
= \eta \cdot p(z_t | x_t) \cdot \int p(x_t | x_{t-1}, u_{1:t}) \cdot bel(x_{t-1}) dx_{t-1}
\]

<div id="Bayes Filter-Recursive Bayes Filter-Prediction and Correction Step"><h3 id="Prediction and Correction Step" class="header"><a href="#Bayes Filter-Recursive Bayes Filter-Prediction and Correction Step">Prediction and Correction Step</a></h3></div>

<p>
Usually the Bayes Filter is broken up into:
</p>

<ul>
<li>
Prediction step: estimates where the future state is based on the control command at time \(t\) and makes use of the motion model.

<ul>
<li>
Motion model: \(p(x_t | x_{t-1}, u_{1:t})\)
\[
\hat{bel}(x_t) = \int p(x_t | x_{t-1}, u_{1:t}) \cdot bel(x_{t-1}) dx_{t-1}
\]

</li></ul>
</li><li>
Correction step: we get an observation that we use to correct potential mistakes we make in the prediction step. This correction is made using the observation or measurement model.

<ul>
<li>
Observation model: \(p(z_t | x_t)\)
\[
bel(x_t) = \eta \cdot p(z_t | x_t) \cdot \hat{bel}(x_t)
\]

</li></ul>
</li></ul>
<div id="Bayes Filter-Recursive Bayes Filter-Implementation"><h3 id="Implementation" class="header"><a href="#Bayes Filter-Recursive Bayes Filter-Implementation">Implementation</a></h3></div>

<p>
In order to implement a Bayes Filter we need to define certain things:
</p>

<ul>
<li>
Specify the motion model

</li><li>
Specify the observation model

</li><li>
Specify the belief

</li><li>
How do we move from one state to the next (i.e. linear model, non-linear model)

</li></ul>
<div id="Bayes Filter-Popular Filters"><h2 id="Popular Filters" class="header"><a href="#Bayes Filter-Popular Filters">Popular Filters</a></h2></div>

<ul>
<li>
Kalman Filters and EFK

<ul>
<li>
Use Gaussians to represent the belief, motion model and observation model 

</li><li>
They use linear or linearized models

</li></ul>
</li><li>
Particle Filter

<ul>
<li>
The can use arbitrary models to represent state, motion model and observation model

</li></ul>
</li></ul>
<div id="Bayes Filter-Model Examples"><h2 id="Model Examples" class="header"><a href="#Bayes Filter-Model Examples">Model Examples</a></h2></div>

<div id="Bayes Filter-Model Examples-Motion model"><h3 id="Motion model" class="header"><a href="#Bayes Filter-Model Examples-Motion model">Motion model</a></h3></div>

<p>
Given a current state \(x_t\), the motion model could look like:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/example_motion_model.png" alt="Example of Motion model">
</p>

<p>
In the first case, let's suppose a point represents the next state \(x_{t+1}\) after the control command is applied. If we execute our system \(n\) times, we get \(n\) estimations that are illustrated by the \(n\) points in the graph. They represent an approximation of the distribution that describes our predicted state (illustrated by the graph in the upper left corner). This distribution is our motion model at time \(t+1\).
</p>

<p>
For the two middle graphs, we can deduce that our system is certain about the angle of motion, however it shows more uncertainty about the distance. Finally in the last two graphs we see the opposite. The system knows how much we moved, that is the distance, but is uncertain about the angle of movement.
</p>

<div id="Bayes Filter-Model Examples-Measurement model"><h3 id="Measurement model" class="header"><a href="#Bayes Filter-Model Examples-Measurement model">Measurement model</a></h3></div>

<p>
Suppose we have a sensor that tell us the distance between us and the closest obstacle in front of us. We know that this sensor is noisy, so to mimic that noise we can describe the measurement model as a normal distribution.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/example_measurement_model.png" alt="Example of Measurement model">
</p>

<p>
In the previous image, the star represents the closest obstacle, and we use the Gaussian distribution to describe how likely it is of obtaining a given measurement. Observe that the further we move away from the actual obstacle the lower is the probability of that measurement taking place.
</p>
</div>
  
  <script type="text/javascript">
    $("pre").each(function (index, item) {
      $(item).html("<code>" + $(item).html() + "</code>");
    });
    hljs.initHighlightingOnLoad();
  </script>

<script src="https://albamr09.github.io/js/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script src="https://albamr09.github.io/js/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script src="https://albamr09.github.io/js/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script src="https://albamr09.github.io/js/search.js" id="search" data-description="Library to perform search"></script></body></html>