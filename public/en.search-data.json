{"/notes/":{"data":{"":" Computer Science Data Science Math Music Web Development Other "},"title":"Notes"},"/notes/cs/":{"data":{"":"","computer-architecture#Computer Architecture":" The Elements of Computer Systems ","computer-graphics#Computer Graphics":" 3D Graphics with WebGL 2 ","programming#Programming":" Clean Code "},"title":"Computer Science"},"/notes/cs/cc/":{"data":{"":" Meaningful Names Functions Comments Formatting Objects and Data Structures Error Handling Boundaries Unit Tests Classes Systems Emergence Concurrency Smells and Heuristics "},"title":"Clean Code"},"/notes/cs/cc/01/":{"data":{"":" Use intention revealing names: the name of a variable, function or class should answer why it exists, what it does and how it is used. Let’s avoid:\nList\u003cint\u003e list1; Make meaningful distinctions: if variable names are different then they must mean something different, and that difference has to be easily understood. Let’s avoid:\nchar[] a1; char[] a2; Use pronounceable names: use common words for names, instead of gibberish. Let’s avoid:\nclass DtaRcRd102 { private Date genymdhms; } Use searchable names: if a variable is used on several places on your code it should be easy to seach, so avoid numbers and single letter variables. Class names: should be nouns or noun-like words. Method names: should have verb or verb phrases as names. Pick one word per concept: avoid having different namings for something that is fundamentally the same. For example, avoid having fetch, retrieve and get as different method names that do the “same”. Use solution domain names: use algorithm names, pattern names, math names and so forth. Use problem domain names: if no solution domain name is suitable, go ahead and use the name from the problem domain. Add meaninful context: few names are meaningul in and of themselves, so it is always helpful when they are declared under well named classes, methods, namespaces, etc. "},"title":"Meaningful Names"},"/notes/cs/cc/02/":{"data":{"":"","how-functions-should-be-defined#How Functions Should be Defined":"Lets consider the following code:\npublic static String testableHtml( PageData pageData, boolean includeSuiteSetup ) throws Exception { WikiPage wikiPage = pageData.getWikiPage(); StringBuffer buffer = new StringBuffer(); if (pageData.hasAttribute(\"Test\")) { if (includeSuiteSetup) { WikiPage suiteSetup = PageCrawlerImpl.getInheritedPage( SuiteResponder.SUITE_SETUP_NAME, wikiPage ); if (suiteSetup != null) { WikiPagePath pagePath = suiteSetup.getPageCrawler().getFullPath(suiteSetup); String pagePathName = PathParser.render(pagePath); buffer.append(\"!include -setup .\") .append(pagePathName) .append(\"\\n\"); } } WikiPage setup = PageCrawlerImpl.getInheritedPage(\"SetUp\", wikiPage); if (setup != null) { WikiPagePath setupPath = wikiPage.getPageCrawler().getFullPath(setup); String setupPathName = PathParser.render(setupPath); buffer.append(\"!include -setup .\") .append(setupPathName) .append(\"\\n\"); } } buffer.append(pageData.getContent()); if (pageData.hasAttribute(\"Test\")) { WikiPage teardown = PageCrawlerImpl.getInheritedPage(\"TearDown\", wikiPage); if (teardown != null) { WikiPagePath tearDownPath = wikiPage.getPageCrawler().getFullPath(teardown); String tearDownPathName = PathParser.render(tearDownPath); buffer.append(\"\\n\") .append(\"!include -teardown .\") .append(tearDownPathName) .append(\"\\n\"); } if (includeSuiteSetup) { WikiPage suiteTeardown = PageCrawlerImpl.getInheritedPage( SuiteResponder.SUITE_TEARDOWN_NAME, wikiPage ); if (suiteTeardown != null) { WikiPagePath pagePath = suiteTeardown.getPageCrawler().getFullPath (suiteTeardown); String pagePathName = PathParser.render(pagePath); buffer.append(\"!include -teardown .\") .append(pagePathName) .append(\"\\n\"); } } } pageData.setContent(buffer.toString()); return pageData.getHtml(); } This is quite a convoluted function from which we can extract a few keypoints of things we should enforce when defining functions.\nThe first rule of functions is that they should be small. The indent level should not be greater than 1 or 2. A function should do one thing and one thing only. We say the function does one thing by abstracting all of the inner steps. The statements within a function should be all on the same level of abstraction. Every function should be defined so the program can be read from top to bottom. That is: 1 To print a string I have to create the string, show the string on the screen. 1.1 To create a string i have to create an array of characters and append each character 1.1.1 To create an array of characters i have to allocate memory 1.1.2 To append a character i have to find on memory the place i want to save it to and save its ascii 1.2. To show a string on the screen i have to show each character on the screen 1.2.1. To show a character on the screen i need to know its bitmap and print it on the screen ... Use descriptive names that say exactly what the function does. A function should have zero arguments. They take a lot of conceptual power as they are on a different level of abstraction and they also make testing harder. Output arguments are harder to understand than input arguments as we usually do not expect arguments to be modified, so it is best to steer clear of them. If your function must change the state of something, have it change the state of its owning object. Avoid flag arguments as these booleans make the function do one thing if they are true and another if they are false. That is now our function does two things. Use the keyword form of a function name, where we encode the names of the arguments into the function name. For example instead of assertEquals we define assertExpectedEqualsActual. Avoid having side effects, where the function seems to do one thing but is also does some other hidden thing (e.g. updating an instance variable). Apply the Command Query Separation: functions should either change the state of an object, or it should return some information about that object. Doing both often leads to confusion. Prefer returning exceptions to error codes: When you return an error code, you create the problem that the caller must deal with the error immediately. Try/catch blocks confuse the structure of the code and mix error processing with normal processing. Functions should do one thing. Error handing is one thing. So it is better to extract the bodies of the try and catch blocks out into functions of their own. public void delete(Page page) { try { deletePageAndAllReferences(page); } catch (Exception e) { logError(e); } } private void deletePageAndAllReferences(Page page) throws Exception { deletePage(page); registry.deleteReference(page.name); configKeys.deleteKey(page.name.makeKey()); } ","switch-statements#Switch Statements":"Switch statements it violates our previous rule about functions doing only one thing, most usually swith function do as many things as clauses it has. Also they may grow whenever a new case is added. In order to avoid this it is recommended swith statements be buried low on the abstraction hierarchy.\nFor example, instead of creating a function that computes the pay with regards of the type of employee:\npublic Money calculatePay(Employee e) throws InvalidEmployeeType { switch (e.type) { case COMMISSIONED: return calculateCommissionedPay(e); case HOURLY: return calculateHourlyPay(e); case SALARIED: return calculateSalariedPay(e); default: throw new InvalidEmployeeType(e.type); } } We, instead, define an abstract factory that creates one type of employee or another, and where each type of employee decides how calculatePay is computed with polymorphism.\npublic abstract class Employee { public abstract boolean isPayday(); public abstract Money calculatePay(); public abstract void deliverPay(Money pay); } public interface EmployeeFactory { public Employee makeEmployee(EmployeeRecord r) throws InvalidEmployeeType; } public class EmployeeFactoryImpl implements EmployeeFactory { public Employee makeEmployee(EmployeeRecord r) throws InvalidEmployeeType { switch (r.type) { case COMMISSIONED: return new CommissionedEmployee(r) ; case HOURLY: return new HourlyEmployee(r); case SALARIED: return new SalariedEmploye(r); default: throw new InvalidEmployeeType(r.type); } } } "},"title":"Functions"},"/notes/cs/cc/03/":{"data":{"":"","bad-comments#Bad Comments":" Redundant Comments: comments that are not more informative than the code itself. Misleading Comments: that say half truths and may confuse future maintainers. Mandated Comments: It is just plain silly to have a rule that says that every function must have a javadoc, or every variable must have a comment. Journal Comments: Sometimes people add a comment to the start of a module every time they edit it. They are no longer necessary as we already have version control. Position Markers: A banner is startling and obvious if you don’t see banners very often. So use them very sparingly, and only when the benefit is significant. If you overuse banners, they’ll fall into the background noise and be ignored. // Actions ////////////////////////////////// Closing Brace Comments: Sometimes programmers will put special comments on closing braces. It serves only to clutter the kind of small and encapsulated functions that we prefer. Attributions and Bylines: Source code control systems are very good at remembering who added what, when. /** Added by Rick **/ Commented-Out Code: Others who see that commented-out code won’t have the courage to delete it. They’ll think it is there for a reason and is too important to delete. Nonlocal Information: If you must write a comment, then make sure it describes the code it appears near. Don’t offer systemwide information in the context of a local comment. Too Much Information: Don’t put interesting historical discussions or irrelevant descriptions of details into your comments. Inobvious Connection: The connection between a comment and the code it describes should be obvious. Function Headers: Short functions don’t need much description. A well-chosen name for a small function that does one thing is usually better than a comment header. API Docs in Nonpublic Code: Generating javadoc pages for the classes and functions inside a system is not generally useful. ","good-comments#Good Comments":" Legal Comments: For example, copyright and authorship statements are necessary and reasonable things to put into a comment at the start of each source file. Informative Comments: they are sometimes useful, but it is better to use the name of the function to convey the information where possible // format matched kk:mm:ss EEE, MMM dd, yyyy Pattern timeMatcher = Pattern.compile( \"\\\\d**:\\\\d**:\\\\d** \\\\w**, \\\\w** \\\\d**, \\\\d*\"); Explanation of Intent: comments that provide the intent behind a decision. //This is our best attempt to get a race condition //by creating large number of threads. for (int i = 0; i \u003c 25000; i++) { WidgetBuilderThread widgetBuilderThread = new WidgetBuilderThread(widgetBuilder, text, parent, failFlag); Thread thread = new Thread(widgetBuilderThread); thread.start(); } Clarification: In general it is better to find a way to make that argument or return value clear in its own right; but when its part of the standard library, or in code that you cannot alter, then a helpful clarifying comment can be useful. Warning of Consequences: Sometimes it is useful to warn other programmers about certain consequences. // Don't run unless you // have some time to kill. public void _testWithReallyBigFile() { ... } TODO Comments: Still, you don’t want your code to be littered with TODOs. Amplification: used to amplify the importance of something that may otherwise seem inconsequential. String listItemContent = match.group(3).trim(); // the trim is real important. It removes the starting // spaces that could cause the item to be recognized // as another list. Docs in Public APIs: If you are writing a public API, then you should certainly write good javadocs for it. "},"title":"Comments"},"/notes/cs/cc/04/":{"data":{"":"","horizontal-formatting#Horizontal Formatting":"Programmers clearly prefer short lines (80 to 120 characters).\nHorizontal Openness and Density We use horizontal white space to associate things that are strongly related and disassociate things that are more weakly related.\nHorizontal Alignment Using horizontal alignment to accentuate certain structures is not useful:\npublic class FitNesseExpediter implements ResponseSender { private Socket socket; private InputStream input; private OutputStream output; private Request request; private Response response; private FitNesseContext context; protected long requestParsingTimeLimit; private long requestProgress; private long requestParsingDeadline; private boolean hasError; Indentantion A source file is a hierarchy rather like an outline. Each level of this hierarchy is a scope into which names can be declared and in which declarations and executable statements are interpreted. And each level of hierarchy is differentiated using indentantion. This allows readers to quickly hop over scopes.\nBreaking indentation: It is sometimes tempting to break the indentation rule for short if statements, short while loops, or short functions. However it is preferable to expand and indent those scopes.","team-rules#Team Rules":"A team of developers should agree upon a single formatting style.","the-purpose-of-formatting#The Purpose of Formatting":"The coding style and readability set precedents that continue to affect maintainability and extensibility long after the original code has been changed beyond recognition.","vertical-formatting#Vertical Formatting":"How big should a source file be? Small files are usually easier to understand than large files are.\nThe Newspaper Metaphor We would like a source file to be like a newspaper article. The name should be simple but explanatory. Detail should increase as we move downward.\nVertical Openness Between Concepts Each blank line is a visual cue that identifies a new and separate concept\npackage fitnesse.wikitext.widgets; import java.util.regex.*; public class BoldWidget extends ParentWidget { public static final String REGEXP = \"'''.+?'''\"; private static final Pattern pattern = Pattern.compile(\"'''(.+?)'''\", Pattern.MULTILINE + Pattern.DOTALL ); public BoldWidget(ParentWidget parent, String text) throws Exception { super(parent); Matcher match = pattern.matcher(text); match.find(); addChildWidgets(match.group(1)); } public String render() throws Exception { StringBuffer html = new StringBuffer(\"\u003cb\u003e\"); html.append(childHtml()).append(\"\u003c/b\u003e\"); return html.toString(); } } Vertical Density Vertical density implies close association. So lines of code that are tightly related should appear vertically dense.\nVertical Distance Concepts that are closely related should be kept vertically close to each other to avoid forcing our readers to hop around through our source files and classes.\nVariable declarations: Variables should be declared as close to their usage as possible. Instance variables: should all be declared in one well-known place (e.g. at the top of the class, at then end of the class). Dependent functions: If one function calls another, they should be vertically close, and the caller should be above the callee, if at all possible. Vertical Ordering In general we want function call dependencies to point in the downward direction. That is, a function that is called should be below a function that does the calling.\nAlso, we expect the most important concepts to come first."},"title":"Formatting"},"/notes/cs/cc/05/":{"data":{"":"","conclusion#Conclusion":"Objects expose behavior and hide data. This makes it easy to add new kinds of objects without changing existing behaviors. It also makes it hard to add new behaviors to existing objects. Data structures expose data and have no significant behavior. This makes it easy to add new behaviors to existing data structures but makes it hard to add new data structures to existing functions.","data-abstraction#Data Abstraction":"Hiding implementation is not just a matter of putting a layer of functions between the variables. Hiding implementation is about abstractions! For example on the following excerpt we do not know how the Point is defined, if by rectangular coordinates or by polar coordintes.\npublic interface Point { double getX(); double getY(); void setCartesian(double x, double y); double getR(); double getTheta(); void setPolar(double r, double theta); } ","data-transfer-objects#Data Transfer Objects":"The quintessential form of a data structure is a class with public variables and no functions. This is sometimes called a data transfer object, or DTO. They are useful when communicating with databases or parsing messages from sockets, and so on and one should avoid adding business logic to these type of objects.\nActive Record Active Records are special forms of DTOs. They are data structures with public variables; but they typically have navigational methods like save and find. Typically these Active Records are direct translations from database tables, or other data sources.\nWe should treat the Active Record as a data structure and to create separate objects that contain the business rules and that hide their internal data.","dataobject-anti-symmetry#Data/Object Anti-Symmetry":"Objects hide their data behind abstractions and expose functions that operate on that data. Data structure expose their data and have no meaningful functions. They are virtual opposites.\nProcedural Shape\npublic class Square { public Point topLeft; public double side; } public class Rectangle { public Point topLeft; public double height; public double width; } public class Circle { public Point center; public double radius; } public class Geometry { public final double PI = 3.141592653589793; public double area(Object shape) throws NoSuchShapeException { if (shape instanceof Square) { Square s = (Square)shape; return s.side * s.side; } else if (shape instanceof Rectangle) { Rectangle r = (Rectangle)shape; return r.height * r.width; } else if (shape instanceof Circle) { Circle c = (Circle)shape; return PI ** c.radius ** c.radius; } throw new NoSuchShapeException(); } } Polymorphic Shapes\npublic class Square implements Shape { private Point topLeft; private double side; public double area() { return side*side; } } public class Rectangle implements Shape { private Point topLeft; private double height; private double width; public double area() { return height * width; } } public class Circle implements Shape { private Point center; private double radius; public final double PI = 3.141592653589793; public double area() { return PI ** radius ** radius; } } This exposes the fundamental dichotomy between objects and data structures: Procedural code (code using data structures) makes it easy to add new functions without changing the existing data structures. OO code, on the other hand, makes it easy to add new classes without changing existing functions.\nIn any complex system there are going to be times when we want to add new data types rather than new functions. For these cases objects and OO are most appropriate. On the other hand, there will also be times when we’ll want to add new functions as opposed to data types. In that case procedural code and data structures will be more appropriate.","hybrids#Hybrids":"The are structures that are hybrid structures which are half object and half data structure. They have functions that do significant things, and they also have either public variables or public accessors and mutators that make the private variables public.\nSuch hybrids make it hard to add new functions but also make it hard to add new data structures.","the-law-of-demeter#The Law of Demeter":"The Law of Demeter says a module should not know about the innards of the objects it manipulates. More precisely, the Law of Demeter says that a method f of a class C should only call the methods of these:\nC An objects created by f An Object passed as an argument to f An object held in an instance variable of C That is, the method should not invoke methods on objects that are returned by any of the allowed functions."},"title":"Objects and Data Structures"},"/notes/cs/cc/06/":{"data":{"":"","conclusion#Conclusion":"Clean code is readable, but it must also be robust. These are not conflicting goals. We can write robust clean code if we see error handling as a separate concern, something that is viewable independently of our main logic. To the degree that we are able to do that, we can reason about it independently, and we can make great strides in the maintainability of our code.","define-exception-classes-in-terms-of-a-callers-needs#Define Exception Classes in Terms of a Caller\u0026rsquo;s Needs":"","dont-pass-null#Don\u0026rsquo;t Pass Null":"Use Exceptions Rather Than Return Codes The problem with using return codes is that they clutter the caller. The caller must check for errors immediately after the call. Unfortunately, it’s easy to forget. For this reason it is better to throw an exception.\nThe code is better because two concerns that were tangled, the algorithm for device shutdown and error handling, are now separated.\nWrite Your Try-Catch-Finally Statement First One of the most interesting things about exceptions is that they define a scope within your program. Your catch has to leave your program in a consistent state, no matter what happens in the try. For this reason it is good practice to start with a try-catch-finally statement when you are writing code that could throw exceptions. This helps you define what the user of that code should expect.\nUse Unchecked Exceptions With Unchecked Exceptions the signature of every method would list all of the exceptions that it could pass to its caller. These exceptions were part of the type of the method. Your code wouldn’t compile if the signature didn’t match what your code could do.\nThe price of checked exceptions is an Open/Closed Principle1 violation. If you throw a checked exception from a method in your code and the catch is three levels above, you must declare that exception in the signature of each method between you and the catch. This means that a change at a low level of the software can force signature changes on many higher levels.\nIn general application development the dependency costs outweigh the benefits.\nProvide Context with Exceptions Each exception that you throw should provide enough context to determine the source and location of an error by using informative error messages.\nDefine Exception Classes in Terms of a Caller’s Needs Wrapping third-party APIs is a best practice. When you wrap a third-party API, you minimize you dependencies upon it. Wrapping also makes it easier to mock out third-party calls when you are testing your own code. One final advantage of wrapping is that you aren’t tied to a particular vendor’s API design choices.\nDon’t Return Null If you are tempted to return null from a method, consider throwing an exception or returning a SPECIAL CASE object instead. If you are calling a null-returning method from a third-party API, consider wrapping that method with a method that either throws an exception or returns a special case object. You will minimize the chance of NullPointerExceptions and your code will be cleaner.\nDon’t Pass Null You should avoid passing null in your code whenever possible. In most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.","dont-return-null#Don\u0026rsquo;t Return Null":"","provide-context-with-exceptions#Provide Context with Exceptions":"","use-exceptions-rather-than-return-codes#Use Exceptions Rather Than Return Codes":"","use-unchecked-exceptions#Use Unchecked Exceptions":"","write-your-try-catch-finally-statement-first#Write Your Try-Catch-Finally Statement First":""},"title":"Error Handling"},"/notes/cs/cc/07/":{"data":{"":"","clean-boundaries#Clean Boundaries":"Good software designs accommodate change without huge investments and rework. We manage third-party boundaries by having very few places in the code that refer to them. We may wrap them as we did with Map, or we may use an ADAPTER to convert from our perfect interface to the provided interface.","exploring-and-learning-boundaries#Exploring and Learning Boundaries":"We could write some tests to explore our understanding of the third-party code (learning tests). We call the third-party API, as we expect to use it in our application. Not only are learning tests free, they have a positive return on investment. When there are new releases of the third-party package, we run the learning tests to see whether there are behavioral differences.","using-code-that-does-not-yet-exist#Using Code That Does Not Yet Exist":"There is another kind of boundary, one that separates the known from the unknown. There are often places in the code where our knowledge seems to drop off the edge.\nFor example, there was a subsystem, the “Transmitter,” that we knew little about, and the people responsible for the subsystem had not gotten to the point of defining their interface. So we defined our own interface, this was the interface we wished we had.\nThis design also gives us a very convenient seam3 in the code for testing.","using-third-party-code#Using Third-Party Code":"There is a natural tension between the provider of an interface and the user of an interface. Providers: which strive for broad applicability and users: which are want an interface focused on their particular needs.\nLet’s look at java.util.Map as an example. If our application needs a Map of Sensors, you might find the sensors set up like this:\nMap sensors = new HashMap(); Then, when some other part of the code needs to access the sensor, you see this code:\nSensor s = (Sensor)sensors.get(sensorId); The readability of this code can be greatly improved by using generics, as shown below:\nMap\u003cSensor\u003e sensors = new HashMap\u003cSensor\u003e(); ... Sensor s = sensors.get(sensorId ); However, this doesn’t solve the problem that Map\u003cSensor\u003e provides more capability than we need. Also there will be a lot of places to fix if the interface to Map ever changes. A cleaner way to use Map might look like the following.\npublic class Sensors { private Map sensors = new HashMap(); public Sensor getById(String id) { return (Sensor) sensors.get(id); } } So the interface at the boundary (Map) is hidden. This interface is also tailored and constrained to meet the needs of the application. It results in code that is easier to understand and harder to misuse."},"title":"Boundaries"},"/notes/cs/cc/08/":{"data":{"":"","a-dual-standard#A Dual Standard":"The code within the testing API does have a different set of engineering standards than production code. It must still be simple, succinct, and expressive, but it need not be as efficient as production code.\nThat is the nature of the dual standard. There are things that you might never do in a production environment that are perfectly fine in a test environment.","clean-tests#Clean Tests":"What makes a clean test? Readability. What makes tests readable? The same thing that makes all code readable: clarity, simplicity, and density of expression.","domain-specific-testing-language#Domain-Specific Testing Language":"Rather than using the APIs that programmers use to manipulate the system, we build up a set of functions and utilities that make use of those APIs and that make the tests more convenient to write and easier to read. These functions and utilities become a specialized API used by the tests. They are a testing language.","first#F.I.R.S.T.":"Clean tests follow five other rules:\nFast Tests: should be fast. They should run quickly. When tests run slow, you won’t want to run them frequently and you won’t find problems early enough to fix them. Independent: Tests should not depend on each other. One test should not set up the conditions for the next test. Repeatable: Tests should be repeatable in any environment. If your tests aren’t repeatable in any environment, then you’ll always have an excuse for why they fail. Self-Validating: The tests should have a boolean output. Either they pass or fail. Timely: The tests need to be written in a timely fashion. Unit tests should be written just before the production code that makes them pass. ","keeping-tests-clean#Keeping Tests Clean":"Tests must change as the production code evolves. So, the dirtier the tests, the harder they are to change. Therefore test code is just as important as production code, it must be kept as clean as production code.","one-assert-per-test#One Assert per Test":"There is a school of thought4 that says that every test function in a JUnit test should have one and only one assert statement. Unfortunately, sometimes you might have to split the tests which results in a lot of duplicate code.\nThe single assert rule is a good guideline, but you may need to break it sometimes.","single-concept-per-test#Single Concept per Test":"Perhaps a better rule is that we want to test a single concept in each test function.","tests-enable-the--ilities#Tests Enable the -ilities":"No matter how flexible your architecture is, no matter how nicely partitioned your design, without tests you will be reluctant to make changes because of the fear that you will introduce undetected bugs. But with tests that fear virtually disappears. So if your tests are dirty, then your ability to change your code is hampered.","the-tree-laws-of-tdd#The Tree Laws of TDD":" First Law: You may not write production code until you have written a failing unit test. Second Law: You may not write more of a unit test than is sufficient to fail, and not compiling is failing. Third Law: You may not write more production code than is sufficient to pass the currently failing test. The tests and the production code are written together, with the tests just a few seconds ahead of the production code. If we work this way, we will write a lot of tests, the sheer bulk of those tests, which can rival the size of the production code itself, can present a daunting management problem."},"title":"Unit Tests"},"/notes/cs/cc/09/":{"data":{"":"","class-organization#Class Organization":"Following the standard Java convention, a class should begin with a list of variables. Public static constants, if any, should come first. Then private static variables, followed by private instance variables. There is seldom a good reason to have a public variable\nPublic functions should follow the list of variables. We like to put the private utilities called by a public function right after the public function itself.","classes-should-be-small#Classes Should Be Small!":"The first rule of classes is that they should be small. How small? We count in reposibilities. The name of a class should describe what responsibilities it fulfills. In fact, naming is probably the first way of helping determine class size. If we cannot derive a concise name for a class, then it’s likely too large.","cohesion#Cohesion":"Classes should have a small number of instance variables. In general the more variables a method manipulates the more cohesive that method is to its class. A class in which each variable is used by each method is maximally cohesive.","encapsulation#Encapsulation":"We like to keep our variables and utility functions private (or protected when accessed by a test).","isolating-from-change#Isolating from Change":"Needs will change, therefore code will change. A client class depending upon concrete details is at risk when those details change. We can introduce interfaces and abstract classes to help isolate the impact of those details.\nBy minimizing coupling in this way, our classes adhere to another class design principle known as the Dependency Inversion Principle (DIP). In essence, the DIP says that our classes should depend upon abstractions, not on concrete details.","maintaining-cohesion-results-in-many-small-classes#Maintaining Cohesion Results in Many Small Classes":"Consider a large function with many variables declared within it. Let’s say you want to extract one small part of that function into a separate function. Must you pass all four of those variables into the new function as arguments? Not at all! If we promoted those four variables to instance variables of the class, then we could extract the code without passing any variables at all.\nUnfortunately, this also means that our classes lose cohesion because they accumulate more and more instance variables. But, if there are a few functions that want to share certain variables, doesn’t that make them a class in their own right? Of course it does. When classes lose cohesion, split them!\nThe first thing you might notice is that the program gets a lot longer.","organizing-for-change#Organizing for Change":"For most systems, change is continual. Every change subjects us to the risk that the remainder of the system no longer works as intended. In a clean system we organize our classes so as to reduce the risk of change. In an ideal system, we incorporate new features by extending the system, not by making modifications to existing code.\nOpen-Closed Principle, or OCP: Classes should be open for extension but closed for modification. ","the-single-responsibility-principle#The Single Responsibility Principle":"The Single Responsibility Principle (SRP)2 states that a class or module should have one, and only one, reason to change."},"title":"Classes"},"/notes/cs/cc/10/":{"data":{"":"","cross-cutting-concerns#Cross-Cutting Concerns":"Note that concerns like persistence tend to cut across the natural object boundaries of a domain. You want to persist all your objects using generally the same strategy. Using persistence as an example, you would declare which objects and attributes (or patterns thereof) should be persisted and then delegate the persistence tasks to your persistence framework. The behavior modifications are made noninvasively8 to the target code by the AOP framework.\nAn optimal system architecture consists of modularized domains of concern, each of which is implemented with Plain Old Java (or other) Objects. The different domains are integrated together with minimally invasive Aspects or Aspect-like tools. This architecture can be test-driven, just like the code.","dependency-injection#Dependency Injection":"A powerful mechanism for separating construction from use is Dependency Injection (DI), the application of Inversion of Control (IoC) to dependency management.3 Inversion of Control moves secondary responsibilities from an object to other objects that are dedicated to the purpose, thereby supporting the Single Responsibility Principle. In the context of dependency management, an object should not take responsibility for instantiating dependencies itself. Instead, it should pass this responsibility to another “authoritative” mechanism, thereby inverting the control.\nThe class takes no direct steps to resolve its dependencies; it is completely passive. Instead, it provides setter methods or constructor arguments (or both) that are used to inject the dependencies. During the construction process, the DI container instantiates the required objects (usually on demand) and uses the constructor arguments or setter methods provided to wire together the dependencies. Which dependent objects are actually used is specified through a configuration file or programmatically in a special-purpose construction module.\nBut what about the virtues of LAZY-INITIALIZATION? This idiom is still sometimes useful with DI. First, most DI containers won’t construct an object until needed. Second, many of these containers provide mechanisms for invoking factories or for constructing proxies, which could be used for LAZY-EVALUATION and similar optimizations.","factories#Factories":"Sometimes we need to make the application responsible for when an object gets created. In this case we can use the ABSTRACT FACTORY pattern to give the application control of when to build the objct, but keep the details of that construction separate from the application code.","optimize-decision-making#Optimize Decision Making":"Modularity and separation of concerns make decentralized management and decision making possible. The agility provided by a POJO system with modularized concerns allows us to make optimal, just-in-time decisions, based on the most recent knowledge. The complexity of these decisions is also reduced.","scaling-up#Scaling Up":"It is a myth that we can get systems “right the first time.” Instead, we should implement only today’s stories, then refactor and expand the system to implement new stories tomorrow. This is the essence of iterative and incremental agility. Test-driven development, refactoring, and the clean code they produce make this work at the code level.\nSoftware systems are unique compared to physical systems. Their architectures can grow incrementally, if we maintain the proper separation of concerns.","separate-constructing-a-system-from-using-it#Separate Constructing a System from Using It":"The separation of concerns is one of the oldest and most important design techniques in our craft.\nOne way to separate construction from use is simply to move all aspects of construction to main, or modules called by main, and to design the rest of the system assuming that all objects have been constructed and wired up appropriately. (See Figure 11-1)","systems-need-domain-specific-languages#Systems Need Domain-Specific Languages":"In software, there has been renewed interest recently in creating Domain-Specific Languages (DSLs), which are separate, small scripting languages or APIs in standard languages that permit code to be written so that it reads like a structured form of prose that a domain expert might write.","use-standards-wisely-when-they-add-demonstrable-value#Use Standards Wisely, When They Add Demonstrable Value":"Standards make it easier to reuse ideas and components, recruit people with relevant experience, encapsulate good ideas, and wire components together. However, the process of creating standards can sometimes take too long for industry to wait, and some standards lose touch with the real needs of the adopters they are intended to serve."},"title":"Systems"},"/notes/cs/cc/11/":{"data":{"":"","getting-clean-via-emergent-design#Getting Clean via Emergent Design":"What if by following some rules it waseasier to apply principles such as SRP and DIP? What if these rules facilitated the emergence of good designs?\nA design is “simple” if it follows these rules:\nRuns all the tests Contains no duplication Expresses the intent of the programmer Minimizes the number of classes and methods ","minimal-classes-and-methods#Minimal Classes and Methods":"Even concepts as fundamental as elimination of duplication, code expressiveness, and the SRP can be taken too far. In an effort to make our classes and methods small, we might create too many tiny classes and methods. So this rule suggests that we also keep our function and class counts low.\nRemember, however, that this rule is the lowest priority of the four rules of Simple Design. So, although it’s important to keep class and function count low, it’s more important to have tests, eliminate duplication, and express yourself.","simple-design-rule-1-runs-all-the-tests#Simple Design Rule 1: Runs All the Tests":"A system that is comprehensively tested and passes all of its tests all of the time is a testable system. Systems that aren’t testable aren’t verifiable. Arguably, a system that cannot be verified should never be deployed.\nFortunately, making our systems testable pushes us toward a design where our classes are small and single purpose. Whilst tight coupling makes it difficult to write tests.","simple-design-rules-2-refactoring#Simple Design Rules 2: Refactoring":"Once we have tests, we are empowered to keep our code and classes clean. We do this by incrementally refactoring the code. For each few lines of code we add, we pause and reflect on the new design. Did we just degrade it? If so, we clean it up and run our tests to demonstrate that we haven’t broken anything.","simple-design-rules-3-expresiveness#Simple Design Rules 3: Expresiveness":"In order to minimize the potential for defects as we introduce change, it’s critical for us to be able to understand what a system does. As systems become more complex, they take more and more time for a developer to understand, and there is an ever greater opportunity for a misunderstanding. Therefore, code should clearly express the intent of its author.\nYou can express yourself by choosing good names. You can also express yourself by keeping your functions and classes small. You can also express yourself by using standard nomenclature. By using the standard pattern names, such as COMMAND or VISITOR, in the names of the classes that implement those patterns, you can succinctly describe your design to other developers. Well-written unit tests are also expressive. A primary goal of tests is to act as documentation by example.","simple-design-rules-3-no-duplication#Simple Design Rules 3: No Duplication":"Duplication is the primary enemy of a well-designed system. It represents additional work, additional risk, and additional unnecessary complexity."},"title":"Emergence"},"/notes/cs/cc/12/":{"data":{"":"","beware-dependencies-between-synchronized-methods#Beware Dependencies Between Synchronized Methods":"There will be times when you must use more than one method on a shared object. When this is the case, there are three ways to make the code correct:\nClient-Based Locking—Have the client lock the server before calling the first method and make sure the lock’s extent includes code calling the last method. Server-Based Locking—Within the server create a method that locks the server, calls all the methods, and then unlocks. Have the client call the new method. Adapted Server—create an intermediary that performs the locking. ","challenges#Challenges":"What makes concurrent programming so difficult? Consider the following trivial class:\npublic class X { private int lastIdUsed; public int getNextId() { return ++lastIdUsed; } Let’s say we create an instance of X, set the lastIdUsed field to 42, and then share the instance between two threads. Now suppose that both of those threads call the method getNextId(). Then one possible outcome is that thread one gets the value 43, thread two gets the value 43 and lastIdUsed is 43.\nThis surprising result occurs when the two threads step on each other. This happens because there are many possible paths that the two threads can take through that one line of Java code, and some of those paths generate incorrect results.","concurrency-defense-principles#Concurrency Defense Principles":"What follows is a series of principles and techniques for defending your systems from the problems of concurrent code.\nSingle Responsibility Principle Concurrency design is complex enough to be a reason to change in it’s own right and therefore deserves to be separated from the rest of the code. Here are a few things to consider:\nConcurrency-related code has its own life cycle of development. Concurrency-related code has its own challenges Recommendation: Keep your concurrency-related code separate from other code.\nLimit the Scope of the Data As we saw, two threads modifying the same field of a shared object can interfere with each other, causing unexpected behavior. It is important to restrict the number of such critical sections.\nRecommendation: Take data encapsulation to heart; severely limit the access of any data that may be shared.\nUse Copies of Data A good way to avoid shared data is to avoid sharing the data in the first place. If there is an easy way to avoid sharing objects, the resulting code will be far less likely to cause problems. You might be concerned about the cost of all the extra object creation. It is worth experimenting to find out if this is in fact a problem. However, if using copies of objects allows the code to avoid synchronizing, the savings in avoiding the intrinsic lock will likely make up for the additional creation and garbage collection overhead.\nThreadds Should Be as Independent as Possible Consider writing your threaded code such that each thread exists in its own world, sharing no data with any other thread.\nRecommendation: Attempt to partition data into independent subsets than can be operated on by independent threads, possibly in different processors.","keep-synchronized-sections-small#Keep Synchronized Sections Small":"Locks are expensive because they create delays and add overhead. So we want to design our code with as few critical sections as possible.\nRecommendation: Keep your synchronized sections as small as possible.","know-your-execution-models#Know Your Execution Models":"We need to understand some basic definitions.\nBound resources: Resources of a fixed size or number used in a concurrent environment. Mutual exclusion: Only one thread can access shared data or a shared resource at a time. Starvation: One thread or a group of threads is prohibited from proceeding for an excessively long time or forever. Deadlock: Two or more threads waiting for each other to finish. Each thread has a resource that the other thread requires and neither can finish until it gets the other resource. Livelock: Threads in lockstep, each trying to do work but finding another “in the way.” Threads in lockstep, each trying to do work but finding another “in the way.”\nProducer-Consumer One or more producer threads create some work and place it in a buffer or queue. One or more consumer threads acquire that work from the queue and complete it. The queue between the producers and consumers is a bound resource.\nReaders-Writers Coordinating readers so they do not read something a writer is updating and vice versa is a tough balancing act. Writers tend to block many readers for a long period of time, thus causing throughput issues.\nA simple strategy makes writers wait until there are no readers before allowing the writer to perform an update. If there are continuous readers, however, the writers will be starved. On the other hand, if there are frequent writers and they are given priority, throughput will suffer. Finding that balance and avoiding concurrent update issues is what the problem addresses.\nDining Philosofers Imagine a number of philosophers sitting around a circular table. A fork is placed to the left of each philosopher. There is a big bowl of spaghetti in the center of the table. The philosophers spend their time thinking unless they get hungry. Once hungry, they pick up the forks on either side of them and eat. A philosopher cannot eat unless he is holding two forks.\nReplace philosophers with threads and forks with resources and this problem is similar to many enterprise applications in which processes compete for resources. Unless carefully designed, systems that compete in this way can experience deadlock, livelock, throughput, and efficiency degradation.","myths-and-misconceptions#Myths and Misconceptions":"Consider these common myths and misconceptions:\nConcurrency always improves performance: only when there is a lot of wait time that can be shared between multiple threads or multiple processors. Design does not change when writing concurrent program: the design of a concurrent algorithm can be remarkably different from the design of a single-threaded system. Understanding concurrency issues is not important when working with a container Here are a few more balanced sound bites regarding writing concurrent software:\nConcurrency incurs some overhead, both in performance as well as writing additional code. Correct concurrency is complex, even for simple problems. Concurrency bugs aren’t usually repeatable, so they are often ignored as one-offs instead of the true defects they are. Concurrency often requires a fundamental change in design strategy. ","testing-threaded-code#Testing Threaded Code":"Recommendation: Write tests that have the potential to expose problems and then run them frequently, with different programatic configurations and system configurations and load. If tests ever fail, track down the failure. Don’t ignore a failure just because the tests pass on a subsequent run.\nHere are a few more fine-grained recommendations:\nTreat spurious failures as candidate threading issues. Get your nonthreaded code working first Make your threaded code pluggable. Make your threaded code tunable. Run with more threads than processors. Run on different platforms. Instrument your code to try and force failures. Make Your Threaded Code Pluggable Write the concurrency-supporting code such that it can be run in several configurations:\nOne thread, several threads, varied as it executes Threaded code interacts with something that can be both real or a test double. Execute with test doubles that run quickly, slowly, variable. Configure tests so they can run for a number of iterations. Run with More Threads Than Processors Things happen when the system switches between tasks. To encourage task swapping, run with more threads than processors or cores.\nRun on Different Platforms Different operating systems have different threading policies, each of which impacts the code’s execution. Multithreaded code behaves differently in different environments. You should run your tests in every potential deployment environment.\nInstrument Your Code to Try and Force Failures It is normal for flaws in concurrent code to hide. Simple tests often don’t expose them. Indeed, they often hide during normal processing. How might you increase your chances of catching such rare occurrences? You can instrument your code and force it to run in different orderings.\nThere are two options for code instrumentation:\nHand-coded Automated Hand-coded You can insert calls to wait(), sleep(), yield(), and priority() in your code by hand. Here is an example of doing just that:\npublic synchronized String nextUrlOrNull() { if(hasNext()) { String url = urlGenerator.next(); Thread.yield(); // inserted for testing. updateHasNext(); return url; } return null; } The inserted call to yield() will change the execution pathways taken by the code and possibly cause the code to fail where it did not fail before. There are many problems with this approach:\nYou have to manually find appropriate places to do this. How do you know where to put the call and what kind of call to use? Leaving such code in a production environment unnecessarily slows the code down. You may or may not find flaws. What we need is a way to do this during testing but not in production. We also need to easily mix up configurations.\nAutomated You could use tools like an Aspect-Oriented Framework to programmatically instrument your code. For example, you could use a class with a single method:\npublic class ThreadJigglePoint { public static void jiggle() { } } You can add calls to this in various places within your code:\npublic synchronized String nextUrlOrNull() { if(hasNext()) { ThreadJiglePoint.jiggle(); String url = urlGenerator.next(); ThreadJiglePoint.jiggle(); updateHasNext(); ThreadJiglePoint.jiggle(); return url; } return null; } Now you use a simple aspect that randomly selects among doing nothing, sleeping, or yielding. Or imagine that the ThreadJigglePoint class has two implementations. The first implements jiggle to do nothing and is used in production. The second generates a random number to choose between sleeping, yielding, or just falling through. If you run your tests a thousand times with random jiggling, you may root out some flaws.","why-concurrency#Why Concurrency?":"Concurrency is a decoupling strategy. It helps us decouple what gets done from when it gets done.","writing-correct-shut-down-code-is-hard#Writing Correct Shut-Down Code Is Hard":"Writing a system that is meant to stay live and run forever is different from writing something that works for awhile and then shuts down gracefully. Graceful shutdown can be hard to get correct. Common problems involve deadlock, with threads waiting for a signal to continue that never comes.\nRecommendation: Think about shut-down early and get it working early."},"title":"Concurrency"},"/notes/cs/cc/17/":{"data":{"":"","comments#Comments":"Innapropiate Information\nIt is inappropriate for a comment to hold information better held in a different kind of system such as your source code control system, your issue tracking system, or any other record-keeping system. Comments should be reserved for technical notes about the code and design.\nObsolete Comment\nA comment that has gotten old, irrelevant, and incorrect is obsolete. If you find an obsolete comment, it is best to update it or get rid of it as quickly as possible.\nRedundant Comment\nA comment is redundant if it describes something that adequately describes itself. Comments should say things that the code cannot say for itself.\nPoorly Written Comment\nA comment worth writing is worth writing well. Be brief.\nCommented-Out Code\nWhen you see commented-out code, delete it! Don’t worry, the source code control system still remembers it.","environment#Environment":"Build Requires More Than One Step\nYou should not need a sequence of arcane commands or context dependent scripts in order to build the individual elements. You should be able to check out the system with one simple command and then issue one other simple command to build it.\nTests Require More Than One Step\nYou should be able to run all the unit tests with just one command.","functions#Functions":"Too Many Arguments\nFunctions should have a small number of arguments.\nOutput Arguments\nOutput arguments are counterintuitive. Readers expect arguments to be inputs, not outputs.\nFlag Arguments\nBoolean arguments loudly declare that the function does more than one thing. They are confusing and should be eliminated.\nDead Function\nMethods that are never called should be discarded, your source code control system still remember it.","general#General":"Multiple Languages in One Source File\nThe ideal is for a source file to contain one, and only one, language. Realistically, we will probably have to use more than one. But we should take pains to minimize both the number and extent of extra languages in our source files.\nObvious Behaviour Is Unimplemented\nFollowing “The Principle of Least Surprise”, any function or class should implement the behaviors that another programmer could reasonably expect.\nIncorrect Behaviour at the Boundaries\nIt seems obvious to say that code should behave correctly. The problem is that we seldom realize just how complicated correct behavior is. Don’t rely on your intuition. Look for every boundary condition and write a test for it.\nOverriden Safeties\nIt is risky to override safeties. Turning off failing tests and telling yourself you’ll get them to pass later is bad.\nDuplication\nEvery time you see duplication in the code, it represents a missed opportunity for abstraction. Abide by the DRY principle (Don’t Repeat Yourself).\nCode at Wrong Level of Abstraction\nIt is important to create abstractions that separate higher level general concepts from lower level detailed concepts. We need to make sure that the separation is complete. We want all the lower level concepts to be in the derivatives and all the higher level concepts to be in the base class.\nGood software design requires that we separate concepts at different levels and place them in different containers. We don’t want lower and higher level concepts mixed together.\nBase Classes Depending on Their Derivatives\nThe most common reason for partitioning concepts into base and derivative classes is so that the higher level base class concepts can be independent of the lower level derivative class concepts. Therefore, when we see base classes mentioning the names of their derivatives, we suspect a problem. In general, base classes should know nothing about their derivatives.\nToo Much Information\nWell-defined modules have very small interfaces that allow you to do a lot with a little.\nGood software developers learn to limit what they expose at the interfaces of their classes and modules. The fewer methods a class has, the better. The fewer variables a function knows about, the better. The fewer instance variables a class has, the better.\nDead Code\nDead code is code that isn’t executed. Dead code is not completely updated when designs change. It still compiles, but it does not follow newer conventions or rules. Delete it.\nVertical Separation\nVariables and function should be defined close to where they are used. Local variables should be declared just above their first usage and should have a small vertical scope. Private functions should be defined just below their first usage.\nInconsistency\nIf you do something a certain way, do all similar things in the same way.\nArtificial Coupling\nThings that don’t depend upon each other should not be artificially coupled. In general an artificial coupling is a coupling between two modules that serves no direct purpose. It is a result of putting a variable, constant, or function in a temporarily convenient, though inappropriate, location. This is lazy and careless.\nFeature Envy\nWhen a method uses accessors and mutators of some other object to manipulate the data within that object, then it envies the scope of the class of that other object. It wishes that it were inside that other class so that it could have direct access to the variables it is manipulating.\nSelector Arguments\nNot only is the purpose of a selector argument difficult to remember, each selector argument combines many functions into one. Selector arguments are just a lazy way to avoid splitting a large function into several smaller functions.\nOf course, selectors need not be boolean. They can be enums, integers, or any other type of argument that is used to select the behavior of the function. In general it is better to have many functions than to pass some code into a function to select the behavior.\nObscured Intent\nWe want code to be as expressive as possible. Run-on expressions, Hungarian notation, and magic numbers all obscure the author’s intent. It is worth taking the time to make the intent of our code visible to our readers.\nMisplaced Responsibility\nOne of the most important decisions a software developer can make is where to put code. The principle of least surprise comes into play here. Code should be placed where a reader would naturally expect it to be.\nUse Explanatory Variables\nOne of the more powerful ways to make a program readable is to break the calculations up into intermediate values that are held in variables with meaningful names.\nFunction Names Should What They Do\nIf you have to look at the implementation (or documentation) of the function to know what it does, then you should work to find a better name or rearrange the functionality so that it can be placed in functions with better names.\nUnderstand the Algorithm\nLots of very funny code is written because people don’t take the time to understand the algorithm. Before you consider yourself to be done with a function, make sure you understand how it works. It is not good enough that it passes all the tests. You must know that the solution is correct. Often the best way to gain this knowledge and understanding is to refactor the function into something that is so clean and expressive that it is obvious how it works.\nMake Logical Dependencies Physical\nIf one module depends upon another, that dependency should be physical, not just logical. The dependent module should not make assumptions (in other words, logical dependencies) about the module it depends upon. Rather it should explicitly ask that module for all the information it depends upon.\nPrefer Polymorphism to If/Else or Switch/Case\nMost people use switch statements because it’s the obvious brute force solution, not because it’s the right solution for the situation. So this heuristic is here to remind us to consider polymorphism before using a switch. Also the cases where functions are more volatile than types are relatively rare. So every switch statement should be suspect.\nFollow Standard Conventions\nEvery team should follow a coding standard based on common industry norms. This coding standard should specify things like where to declare instance variables; how to name classes, methods, and variables; where to put braces; and so on.\nReplace Magic Numbers with Named Constants\nIn general it is a bad idea to have raw numbers in your code. You should hide them behind well-named constants. The term “Magic Number” does not apply only to numbers. It applies to any token that has a value that is not self-describing.\nBe Precise\nWhen you make a decision in your code, make sure you make it precisely. Know why you have made it and how you will deal with any exceptions. Ambiguities and imprecision in code are either a result of disagreements or laziness. In either case they should be eliminated.\nStructure over Convention\nEnforce design decisions with structure over convention.\nEncapsulate Conditionals\nExtract functions that explain the intent of the conditional.\nAvoid Negative Conditionals\nNegatives are just a bit harder to understand than positives. So, when possible, conditionals should be expressed as positives.\nFunctions Should Do One Thing\nFunctions that do more than one thing should be converted into many smaller functions, each of which does one thing.\nHidden Temporal Couplings\nTemporal couplings are often necessary, but you should not hide the coupling. Structure the arguments of your functions such that the order in which they should be called is obvious.\nDon’t Be Arbitrary\nHave a reason for the way you structure your code, and make sure that reason is communicated by the structure of the code.\nEncapsulate Boundary Conditions\nBoundary conditions are hard to keep track of. Put the processing for them in one place. Don’t let them leak all over the code.\nFunctions Should Descend Only One Level of Abstraction\nThe statements within a function should all be written at the same level of abstraction, which should be one level below the operation described by the name of the function.\nKeep Configurable Data at High Levels\nIf you have a constant such as a default or configuration value that is known and expected at a high level of abstraction, do not bury it in a low-level function.\nAvoid Transitive Navigation\nIn general we don’t want a single module to know much about its collaborators. More specifically, if A collaborates with B, and B collaborates with C, we don’t want modules that use A to know about C. (For example, we don’t want a.getB().getC().doSomething();). Rather we want our immediate collaborators to offer all the services we need.\nThis is sometimes called the Law of Demeter. The Pragmatic Programmers call it “Writing Shy Code.”","names#Names":"Choose Descriptive Names\nNames in software are 90 percent of what make software readable. You need to take the time to choose them wisely and keep them relevant. Names are too important to treat carelessly. The power of carefully chosen names is that they overload the structure of the code with description.\nChoose Names at the Appropriate Level of Abstraction\nDon’t pick names that communicate implementation; choose names the reflect the level of abstraction of the class or function you are working in.\nUse Standard Nomenclature Where Possible\nNames are easier to understand if they are based on existing convention or usage.\nUnambiguous Names\nChoose names that make the workings of a function or variable unambiguous.\nUse Long Names for Long Scopes\nThe length of a name should be related to the length of the scope. You can use very short variable names for tiny scopes, but for big scopes you should use longer names. Variables and functions with short names lose their meaning over long distances. So the longer the scope of the name, the longer and more precise the name should be.\nAvoid Encodings\nNames should not be encoded with type or scope information. Prefixes such as m_ or f are useless in today’s environments.\nNames Should Describe Side-Effects\nNames should describe everything that a function, variable, or class is or does. Don’t hide side effects with a name.","tests#Tests":"Insufficient Tests\nA test suite should test everything that could possibly break. The tests are insufficient so long as there are conditions that have not been explored by the tests or calculations that have not been validated.\nUse A Coverage Tool\nCoverage tools reports gaps in your testing strategy. They make it easy to find modules, classes, and functions that are insufficiently tested.\nDon’t Skip Trivial Tests\nThey are easy to write and their documentary value is higher than the cost to produce them.\nTest Boundary Conditions\nTake special care to test boundary conditions. We often get the middle of an algorithm right but misjudge the boundaries.\nExhaustively Test Near Bugs\nBugs tend to congregate. When you find a bug in a function, it is wise to do an exhaustive test of that function.\nPatterns of Failure Are Revealing\nSometimes you can diagnose a problem by finding patterns in the way the test cases fail. This is another argument for making the test cases as complete as possible. Complete test cases, ordered in a reasonable way, expose patterns.\nTest Covertage Patterns Can Be Revealing\nLooking at the code that is or is not executed by the passing tests gives clues to why the failing tests fail.\nTests Should Be Fast\nA slow test is a test that won’t get run."},"title":"Smells and Heuristics"},"/notes/cs/ecs/":{"data":{"":" Boolean Logic Boolean Arithmetic Memory Machine Language Computer Architecture Assembler Virtual Machine I: Processing Virtual Machine II: Control Compiler I: Syntax Compiler II: Code Generation Operating System "},"title":"Elements of Computer Systems"},"/notes/cs/ecs/01/":{"data":{"":"","boolean-algebra#Boolean Algebra":"Boolean algebra manipulates two-state binary values. On Figure 1.1 we present three commonly used Boolean functions, also known as Boolean operators. These functions are named And, Or, and Not.\nFigure 1.2 begs the question: What makes And, Or, and Not more interesting? A deeper answer is that various subsets of logical operators can be used for expressing any Boolean function, and {And, Or, Not} is one such subset. Also, any one of these three basic operators can be expressed using Nand gates only.\nEvery Boolean function can be defined using two alternative representations: truth tables or boolean expressions. Given a Boolean function of n variables represented by a Boolean expression, we can always construct from it the function’s truth table and vice-versa.\nNote that every Boolean function can be represented by many different yet equivalent Boolean expressions. So the ability to simplify a Boolean expression is the first step toward hardware optimization.","hardware-construction#Hardware Construction":"Today, hardware designers design the chip architecture using a formalism called Hardware Description Language, or HDL by writing an HDL program. While the tests are carried out using computer simulation.\nThe hardware designer will typically be interested in a variety of parameters such as speed of computation, energy consumption and the overall cost implied by the implementation. All these parameters can be simulated.\nAfter all tests and optimizations have been performed the final version of the HDL program can become the blueprint for the physical chip.\nFigure 1.7, shows brief introduction to HDL, using an Xor gate example.","logic-gates#Logic Gates":"A gate is a physical device that implements a simple Boolean function. Gates can be realized with any alternative technology permitting switching and conducting capabilities. Many hardware implementations of Boolean functions were created, including magnetic, optical, biological, hydraulic, pneumatic, quantum-based, and even domino-based mechanisms.\nToday, gates are typically implemented as transistors etched in silicon, packaged as chips.\nThis means computer scientists don’t have to worry about physical artifacts and can be content with the abstract notions of Boolean algebra and gate logic, trusting blissfully that someone else will realize them in hardware.\nPrimitive and Composite Gates Since all logic gates have the same input and output data types (0’s and 1’s), they can be combined, creating composite gates of arbitrary complexity. The right side of figure 1.5 gives the gate’s internal architecture, or implementation, whereas the left side shows its interface.\nNote that the interface of any given gate is unique, however it can be realized in many different ways. From an efficiency standpoint, the general rule is to try to use as few gates as possible.\nTo sum up, the art of logic design can be described as follows: Given a gate abstraction (also referred to as specification, or interface), find an efficient way to implement it using other gates that were already implemented.","specification#Specification":"Not: this gate outputs the opposite value of its input’s value.\nAnd: Returns 1 when both its inputs are 1, and 0 otherwise\nOr: Returns 1 when at least one of its inputs is 1, and 0 otherwise\nXor: Also known as exclusive or, this gate returns 1 when exactly one of its inputs is 1, and 0 otherwise\nNand: realizes the following Boolean function:\nMultiplexer: A multiplexer is a three-input gate (see figure 1.9). The multiplexer uses sel to select and output the value of either $a$ or $b$.\nDemultiplexer: takes a single input value and routes it to one of two possible outputs, according to a selector bit (see Figure 1.10).\nMulti-Bit Versions of Basic Gates Computer hardware is often designed to process multi-bit values—for example 16-bit inputs.\nMulti-bit Not: An n-bit Not gate applies the Boolean operation Not to every one of the bits in its n-bit input.\nMulti-bit And: An n-bit And gate applies the Boolean operation And to every respective pair in its two n-bit inputs\nMulti-bit Or: An n-bit Or gate applies the Boolean operation Or to every respective pair in its two n-bit inputs\nMulti-bit multiplexer: An n-bit multiplexer operates exactly the same as a basic multiplexer, except that its inputs and output are n-bits wide\nMulti-Way Versions of Basic Gates These are logic gates that can operate on more than two inputs, for example:\nMulti-way Or: An m-way Or gate outputs 1 when at least one of its m input bits is 1, and 0 otherwise.\nMulti-way/Multi-bit multiplexer: An $m$-way $n$-bit multiplexer selects one of its $m$ $n$-bit inputs, and outputs it to its $n$-bit output. The selection is specified by a set of $k$ selection bits, where $k = \\log_2 m$. For example, a $4$-way multiplexer is shown on the following image:"},"title":"Boolean Logic"},"/notes/cs/ecs/02/":{"data":{"":"","adders#Adders":"Half Adders: adds two bits, outputs two bits.\nFull adder: adds three bits, outputs two bits.\nAdder: adds two $n$-bit numbers.\nIncrementer: adds $1$ to a given number (Spoiler: This will enable fetching the next instruction from memory, after executing the current one).","binary-addition#Binary Addition":"A pair of binary numbers can be added bitwise from right to left by adding the two rightmost bits (lest significant bits or LSB). Next, we add the resulting carry bit to the sum of the next pair of bits. We continue until the two left most significan bits (MSB) are added.\nIf the most significant bitwise addition generates a carry of 1, we have what is known as overflow.","signed-binary-numbers#Signed Binary Numbers":"We use two’s complement (also known as radix complement) for representing signed numbers in binary code. Given a word size of $n$ bits, the two’s complement for negative $x$ is given by the binary code of $2^n - x$.\nThe two’s complement representation has the following attractive properties:\nThe system codes signed numbers, ranging from $-(2^{n-1})$ to $2^{n-1} - 1$ The code of any nonnegative number begins with a $0$. The code of any negative number begins with a $1$. To obtain the binary code of $-x$ flip all the bits of x and add 1 to the result. Subtraction is handled as a special case of addition. ","the-arithmetic-logic-unit#The Arithmetic Logic Unit":"An Arithmetic Logic Unit is a chip designed to compute a set of arithmetic and logic operations. Exactly which operations an ALU should feature is a design decision. This ALU design is unique to the computer built in Nand to Tetris, named Hack.\nAs seen in figure 2.5a, the Hack ALU operates on two $16$-bit two’s complement integers, denoted $x$ and $y$, and on six $1$-bit inputs, called control bits. These control bits tell the ALU which function to compute. The exact specification is given in figure 2.5b.\nNote that each one of the six control bits is associated with a standalone, conditional micro-action. The six directives are to be performed in order:\nWe either set the $x$ and $y$ inputs to $0$, or not We either negate the resulting values, or not We compute either $+$ or $\u0026$ on the preprocessed values We either negate the resulting value, or not. All these settings, negations, additions, and conjunctions are $16$-bit operations.\nNote that the ALU actually computes a total of sixty-four functions, since six control bits code that many possibilities. We’ve decided to focus on, and document, only eighteen of these possibilities, since these will suffice for supporting the instruction set of our target computer system"},"title":"Boolean Arithmetic"},"/notes/cs/ecs/03/":{"data":{"":"","counter#Counter":"The Counter is a chip that knows how to increment its value by 1 each time unit, aslo known as Program Counter or PC (see figure 3.8).","memory-devices#Memory Devices":"A data flip flop (DFF) is a time-dependent logic gate that can flip and flop between two stable states: representing $0$ and $1$. DFFs are used as low-level chip-parts embedded deep within other memory devices (see Figure 3.1.).\nDFFs can be used to create $1$-bit registers and $n$ such registers can be lashed together to create an $n$-bit register. Next, a RAM device is constructed using an arbitrary number of such registers.","random-access-memory#Random Access Memory":"A direct-access memory unit, also called Random Access Memory, or RAM, is an aggregate of $n$ Register chips (see figure 3.7).","sequential-logic#Sequential Logic":"On any operation outputs are always delayed, due to at least two reasons:\nThe signal that represent the inputs travel from the outputs of other chips, which takes time. The computations that chips perform also take time. Thus, time is an issue we must deal with. As seen at the top of figure 3.2, time is viewed as an arrow that progresses relentlessly forward. This progression is taken to be continuous: between every two time-points there is another time-point, and changes in the world can be infinitesimally small.\nInstead of viewing time as a continuous progression, we break it into fixed-length intervals, cycles. Where cycles are atomic and indivisible: changes in the world occur only during cycle transitions; within cycles, the world stands still.\nThis discrete view of time serves two design objectives:\nIt can be used for neutralizing the randomness associated with communications and computation time delays. Second, it can be used for synchronizing the operations of different chips across the system. Let’s focus on the bottom part of figure 3.2, which tracks how a Not gate (used as an example) responds to arbitrarily chosen inputs. When we feed the gate with $1$, it takes a while before the gate’s output stabilizes on $0$. However, since the cycle duration is—by design—longer than the time delay, when we reach the cycle’s end, the gate output has already stabilized on $0$.\nTherefore the cycle’s length must be longer than the maximal time delays that can occur in the system. In practice, we design our hardware such that the cycle is sufficiently long to contain any possible time delay taking into acount that, the shorter the cycle, the faster the computer. To sum up, the cycle length is chosen to be slightly longer than the maximal time delay in any chip in the system.\nTypically, the cycles are realized by an oscillator that alternates continuously between two phases labeled $0$−$1$, low-high, or ticktock. Using the hardware’s circuitry, the same master clock signal is simultaneously broadcast to every memory chip in the system. In every such chip, the clock input is funneled to the lower-level DFF gates.\nFlip-flops The low-level devices that facilitate the memory/storage abstraction are named flip-flop gates, in our case, data flip-flop or DFF, whose interface includes a single-bit data input and a single-bit data output.\nIn addition, the DFF has a clock input that feeds from the master clock’s signal. Taken together, the data input and the clock input enable the DFF to implement the following behaviour $out(t) = in(t - 1)$\nCombinational and Sequential Logic The most fundamental sequential gate is the DFF, and any chip that includes it is also said to be sequential.\nAs shown in figure 3.4, these sequential chips may also interact with combinational chips. In combinational chips, the introduction of feedback loops is problematic, because the output would depend on itself. However, if the feedback loop goes through a DFF gate: the DFF introduces an inherent time delay so that the output at time $t$ does not depend on itself but rather on the output at time $t - 1$.\nThe time dependency of sequential chips has an important side effect that serves to synchronize the overall computer architecture.\nSuppose we instruct the ALU to compute $x + y$, because of physical constraints the electric signals representing $x$ and $y$ will likely arrive at the ALU at different times. It will take some time before the ALU’s output stabilizes to the correct result. Until then, the ALU will generate garbage."},"title":"Memory"},"/notes/cs/ecs/04/":{"data":{"":"","overview#Overview":"Hardware Elements A machine language can be viewed as an agreed-upon formalism designed to manipulate a memory using a processor and a set of registers.\nMemory: refers to the collection of hardware devices that store data and instructions. It is a continuous sequence of cells, also referred to as locations or memory registers, each having a unique address. Processor: The processor, Central Processing Unit, or CPU, is a device capable of performing a fixed set of primitive operations: arithmetic, locical operation, memory access operations and control (branching) operations. It consists of an ALU, a set of registers, and gate logic that enables it to parse and execute binary instructions. Registers: moving data from the memory to the processor is relatively slow. For this reason, processors are normally equipped with several onboard registers inside the processor’s chip that serves as high-speed local memory. These registers fall into two categories: data registers, which hold data values, and address registers, which hold values that can be interpreted either as data values or as memory addresses.\nLanguages Machine language programs can be written in two ways: binary and symbolic. Symbolic machine languages are called assembly languages, and the programs that translate them into binary code are called assemblers.\nThe syntax of an assembly language is tightly related to the low-level details of the target hardware: the available ALU operations, number and type of registers, memory size, and so on.\nInstructions Arithmetic and logical operations: Every machine language features instructions for performing basic arithmetic operations:\nMemory access: Every machine language features means for accessing and manipulating selected memory locations. This is typically done using an address register, $A$. For example, suppose we wish to set memory location $17$ to the value $1$. We can decide to do so using the two instructions load A,17 followed by load M,1, where, by convention, $M$ stands for the memory register selected by $A$.\nFlow control: To facilitate branching actions, machine languages feature several variants of conditional and unconditional goto instructions, as well as label declaration statements that mark the goto destinations (see Figure 4.1).\nSymbols: code that uses symbolic references is much easier to write, debug and maintain. Also low-level code that mentions no physical addresses is said to be relocatable.","the-hack-machine-language#The Hack Machine Language":"Background Hack is a $16$-bit computer, meaning that the CPU and the memory units are designed to process, move, and store, chunks of $16$-bit values.\nMemory: the Hack platform uses two distinct memory units: a data memory and an instruction memory.\nThe data memory (which we also call RAM) is a read/write device. So hack instructions can read data from, and write data to, selected RAM registers. The current data register is referred as $M$.\nThe instruction memory (which we also call ROM) is a read-only device, and programs are loaded into it. The current instruction register is referred as the current instruction.\nRegisters: Hack instructions are designed to manipulate three $16$-bit registers: a data register, denoted D, an address register, denoted A, and a selected data memory register, denoted M.\nAddresing: The Hack instruction @xxx sets the A register to the value xxx. This has two side effects:\nIt makes the RAM register whose address is xxx the selected memory register It makes the value of the ROM register whose address is xxx the selected instruction Which action to pursue is determined by the subsequent Hack instruction.\nBranching: For example jo jump to instruction number $29$ we would use these two instructions: @29, 0;JMP. The first instruction selects the ROM[29] register and the second one realizes an unconditional jump to execute said instruction. The Hack language also features conditional branching.\nVariables: The xxx in the Hack instruction @xxx can be either a constant or a symbol. The use of symbols endows Hack assembly programs with the ability to use variables. For example let x = 17 translates to:\n@17 D=A @x Which basically selects the RAM register whose address is the value that is bound to the symbol x, and set this register to $17$. We assume that there is an agent who knows how to bind the symbols to addresses (the assembler).\nOn the following figure the show an example of the tranlation of pseudocode to our assembly language:\nThe Hack Language Specification The Hack machine language consists of two instructions, specified in figure 4.5.\nThe A-instruction The A-instruction sets the A register to some $15$-bit value. The binary version consists of two fields: an operation code (op-code), which is $0$, followed by fifteen bits that code a nonnegative binary number.\nThe A-instruction is used for three different purposes:\nIt’s the only way to enter a constant into the computer. Sets the stage for a subsequent C-instruction that manipulates a selected RAM register. Sets the stage for a subsequent C-instruction that specifies a jump. The C-instruction The C-instruction answers three questions:\nWhat to compute (an ALU operation, denoted comp) Where to store the computed value (dest) What to do next (jump) In the binary version, the leftmost bit is the C-instruction’s op-code, which is $1$. The next two bits are not used, and are set by convention to $1$.\nComputation specification (comp) The computed function is specified by the a-bit and the six c-bits comprising the instruction’s comp field. This $7$-bit pattern can potentially code $128$ different calculations, of which only the twenty-eight listed in figure 4.5.\nIn the ALU the first input feeds from the D register, while the second ALU input feeds either from the A register (when the a-bit is $0$) or from M, the selected data memory register (when the a-bit is $1$).\nDestination specification (dest) The ALU output can be stored in zero, one, two, or three possible destinations, simultaneously. The first and second d-bits code whether to store the computed value in the A register and in the D register, respectively. The third d-bit codes whether to store the computed value in M, the currently selected memory register.\nJump directive (jump) The jump field of the C-instruction specifies what to do next. There are two possibilities:\nFetch and execute the next instruction in the program, the default. Fetch and execute some other instruction. In the latter case, we assume that the A register was already set to the address of the target instruction.\nWhether or not to jump is determined jointly by the three j-bits. This gives eight possible jump conditions, listed on figure 4.5.\nSymbols Assembly instructions can specify memory locations (addresses) using either constants or symbols.\nPredefined symbols R0, R1, …, R15: bound to the values $0$ to $15$. SP, LCL, ARG, THIS, THAT: bound to the values $0$, $1$, $2$, $3$, and $4$, respectively SCREEN, KBD: bound, respectively, to the values $16384$ and $24576$. Which are the base addresses of the screen memory map and the keyboard memory map. Layer symbols The syntax (xxx) binds the symbol xxx to the address of the next instruction in the program.\nVariable symbols Any symbol xxx appearing in a Hack assembly program that is not predefined and is not declared elsewhere using (xxx) is treated as a variable and is bound to a unique running number starting at $16$.\nInput/Output Handling The Hack hardware platform can be connected to two peripheral I/O devices: a screen and a keyboard.\nScreen: the computer interacts with a black-and-white screen organized as $256$ rows of $512$ pixels per row. So it is associated to a memory map stored in an $8$K memory block of $16$-bit words, starting at RAM address $16384$. Each row in the physical screen, starting at the screen’s top-left corner, is represented in the RAM by $32$ consecutive $16$-bit words.\nNote that we cannot access individual pixels/bits directly, we must fetch a complete $16$-bit word ($16$ pixels).\nKeyboard: the computer can interact with a standard physical keyboard via a single-word memory map located at RAM address $24576$. When a key is pressed on the physical keyboard, its $16$-bit character code appears at RAM[KBD]. When no key is pressed, the code $0$ appears."},"title":"Machine Language"},"/notes/cs/ecs/05/":{"data":{"":"","computer-architecture-fundamentals#Computer Architecture Fundamentals":"A computer is based on a fixed hardware platform capable of executing a fixed repertoire of simple instructions which serves as building blocks. Moreover the logic of these programs is temporarily stored in the computer’s memory, like data.\nThe von Neumann architecture, shown in figure 5.1, is based on a Central Processing Unit (CPU), interacting with a memory device, receiving data from some input device, and emitting data to some output device.\nThe term Random Access Memory derives from the important requirement that each randomly selected memory register can be reached instantaneously, that is, within the same cycle.\nData memory: High-level programs are designed to manipulate abstract artifacts like variables, arrays, and objects. Yet at the hardware level, these data abstractions are realized by binary values stored in memory registers.\nIntruction memory: Before a high-level program can be executed on a target computer, it must first be translated into the machine language of the target computer. Each high-level statement is translated into one or more low-level instructions, which are then written as binary values to a file called the binary, or executable, version of the program. Before running a program, we must first load its binary version into the computer’s instruction memory.\nCentral Processing Unit The Central Processing Unit (CPU) is in charge of executing the instructions of the program using three main elements: An Arithmetic Logic Unit (ALU), a set of registers, and a control unit.\nArithmetic Logic Unit: performs all the low-level arithmetic and logical operations.\nRegisters: stores interim values temporarily. It the processor’s immediate memory. These registers serve various purposes:\nData registers store interim values Address registers store values that are used to address the RAM Program Counter tores the address of the instruction that should be fetched and executed nex Instruction register stores the current instruction. Control: A computer instruction is a structured package of micro-codes: sequences of one or more bits designed to tell different devices what to do. Before an instruction can be executed, it must first be decoded into its micro-codes. Next, each micro-code is routed to its designated hardware device (ALU, registers, memory).\nFetch-Execute: In each cycle of the program’s execution, the CPU fetches a binary machine instruction from the instruction memory, decodes it, and executes it. It also figures out which instruction to fetch and execute next. This is called the fetch-execute cycle.\nInput and Output Computers interact with a great variety of input and output (I/O) devices. So we use a key element: memory-mapped I/O. This mapping is done by allocating, for each I/O device, a designated area in the computer’s memory that acts as its memory map. Then low-level computer programs can access any I/O device by manipulating its designated memory map.\nGiven the multitude of computer platforms, I/O devices, and different hardware and software vendors standars play a crucial role to realize these low-level interactions between the computer and the external devices.\nAnother necessary element is a device driver program, which is added to the computer’s operating system. This program controls the way this data is actually rendered on, or generated by, the physical I/O device using the memory map.","the-hack-hardware-platform-specification#The Hack Hardware Platform: Specification":"The Hack CPU consists of the ALU built in project 2 and three registers named Data register (D), Address register (A), and Program Counter (PC).\nThe D register is used solely for storing data values The A register serves one of three different purposes: Storing a data value Selecting an address on the instruction memory Selecting an address on the data memory Central Processing Unit The Hack CPU interface is shown in figure 5.2. The CPU expects to be connected to an instruction memory, from which it fetches instructions for execution, and to a data memory, from which it can read, and into which it can write, data values.\nIf the instruction input is an A-instruction, the CPU loads the $16$-bit instruction value into the A register.\nIf instruction is a C-instruction, then:\nThe CPU causes the ALU to perform the computation specified by the instruction The CPU causes this value to be stored in the any of the A,D, or M destination registers specified by the instruction. If one of the destination registers is M, the CPU’s outM output is set to the ALU output, and the CPU’s writeM output is set to $1$. Otherwise, writeM is set to $0$.\nAs long as the reset input is $0$, the CPU uses the ALU output and the jump bits of the current instruction to decide which instruction to fetch next. If reset is $1$, the CPU sets pc to $0$. This realizes the fetch step on the fetch-execute cycle.\nThe following figure shows its implementation:\nComputer When the user sets the reset bit to $1$ and then to $0$, the computer starts executing the currently loaded program. This is referred as “booting the computer.” (see Figure 5.7).\nFor example, when you boot up a PC or a cell phone, the device is set up to run a ROM-resident program. This program, in turn, loads the operating system’s kernel (also a program) into the RAM and starts executing it.\nThe following figure shows the Computer implemetation:"},"title":"Computer Architecture"},"/notes/cs/ecs/06/":{"data":{"":"","the-hack-machine-language-specification#The Hack Machine Language Specification":"We distinguish two programs:\nBinary Hack program: A binary Hack program is a sequence of text lines, each consisting of sixteen 0 and 1 characters. Contains the instruction data we load onto the CPU to execute.\nAssembly Hack program: An assembly Hack program is a sequence of text lines, each being one of thre:\nAssembly instruction: A symbolic A-instruction or a symbolic C-instruction. Label declaration: A line of the form (xxx), where xxx is a symbol. Comment: A line beginning with two slashes (//) is considered a comment and is ignored. See Figure 4.5 for the specification of the Hack instruction set:\nHandling Instructions For each assembly instruction, the assembler\nParses the instruction into its underlying fields. For each field, generates the corresponding bit-code, as specified in figure 4.5. If the instruction contains a symbolic reference, resolves the symbol into its numeric value. Assembles the resulting binary codes into a string of sixteen $0$ and $1$ characters. Writes the assembled string to the output file. Handling Symbols A common solution is to develop a two-pass assembler.\nThe assembler creates a symbol table and initializes it with all the predefined symbols and their pre-allocated values. In the first pass, the assembler builds a symbol table, adds all the label symbols to the table, and generates no code In the second pass, the assembler handles the variable symbols and generates binary code, using the symbol table. "},"title":"Assembler"},"/notes/cs/ecs/07/":{"data":{"":"","implementation#Implementation":"The VM abstraction has only one data type: a signed integer. This type is implemented on the Hack platform as a two’s complement $16$-bit value. The VM Boolean values true and false are represented as $-1$ and $0$, respectively.\nThe host Hack RAM consists of $32$K $16$-bit words. VM implementations should use the top of this address space as follows:\nWhere some slots are already allocated:\nNote that deciding where to locate virtual memory segments in the host RAM is a delicate issue. How can we ensure that these open-ended memory segments will not overflow into each other and into other reserved RAM areas? We will deal with this on the next chapter.\nVM implementations manipulate these virtual segments symbolically, using the pointer names. For example, suppose we want to push the value of the D register onto the stack. This operation can be implemented using the logic which can be expressed in Hack assembly\n// Selects RAM[SP] so we obtain the base address of the top of the stack @SP // Sets A to be the value under M, RAM[SP] (address of the top of the stack), // So now the selected register (M) will be RAM[RAM[SP]] -\u003e value of the element on top // of the stack A=M // Update M to equal D, RAM[RAM[SP]] = M M=D // Selects RAM[SP] as the selected memory register, M = RAM[SP] @SP // As we pushed a new element on the stack, we augment the pointer M=M+1 Memory Segments Mapping Local, argument, this, that: the base addresses of these segments are stored in the registers LCL, ARG, THIS, and THAT, respectively. Therefore, any access to the i-th entry of a virtual segment (in the context of a VM push/pop segmentName i command) should be translated into assembly code that accesses address in the RAM.\nPointer: the pointer segment contains exactly two values and is mapped directly onto RAM locations $3$ and $4$. These RAM locations are also called, respectively, THIS and THAT. Any access to pointer $0$ should result in accessing the THIS pointer, and any access to pointer $1$ should result in accessing the THAT pointer.\nTemp: This $8$-word segment is also fixed and mapped directly on RAM locations $5$–$12$.\nConstant: This virtual memory segment is truly virtual, as it does not occupy any physical RAM space. Instead, the VM implementation handles any access to constant $i$ by simply supplying the constant $i$.\nStatic: are mapped on addresses $16$ to $255$ of the host RAM. Each reference to static i in a VM program stored in file Foo.vm can be translated to the assembly symbol Foo.i. the Hack assembler will map these symbolic variables on the host RAM, starting at address $16$. We note in closing that since the stack begins at address $256$, the implementation limits the number of static variables in a Jack program to $255 - 16 + 1 = 240$.","stach-machine#Stach Machine":"The centerpiece of the stack machine is the stack, which is a sequential storage space that grows and shrinks as needed. The push operation adds a value to the top of the stack, and pop operation removes the stack’s top value. Note that the push/pop logic results in a last-in-first-out (LIFO) access logic.\nStack Arithmetic Consider the generic operation $x \\text{op} y$, where the operator $\\text{op}$ is applied to the operands $x$ and $y$. In a stack machine, this operation is carried out as follows:\nThe operands $x$ and $y$ are popped off the top of the stack. The value of $x \\text{op} y$ is computed. The computed value is pushed onto the top of the stack. For example, consider the expression $d = (2 - x) + (y + 9)$ shown in figure 7.3a.\nVirtual Memory Segments High-level languages feature symbolic variables like $x, y, sum, count$, these can be a classlevel static variable, an instance-level field of an object, or a method-level local or argument variable.\nIn virtual machines there are no symbolic variables, instead, variables are represented as entries in virtual memory segments like static, this, local, and argument. The compiler maps the first, second, third, … static variable found in program onto static 0, static 1, static 2, and so on. The other variable kinds are mapped on the segments this, local, and argument.\nOur VM model features eight memory segments, whose names and roles are listed in figure 7.4.","vm-specification-part-i#VM Specification, Part I":"A VM program is a sequence of VM commands that fall into four categories:\nPush / pop commands Arithmetic-logical commands Branching commands Function commands Push / Pop Commands Arithmetic-Logical Commands Arithmetic commands: add, sub, neg Comparison commands: eq, gt, lt Logical commands: and, or, not The commands add, sub, eq, gt, lt, and, and or have two implicit operands. We mean that the operand is not part of the command syntax since the command is designed to always operate on the two top stack values, there is no need to specify them."},"title":"Virtual Marchine I: Processing"},"/notes/cs/ecs/08/":{"data":{"":"","branching#Branching":"The VM language supports two forms of branching:\nUnconditional branching is effected using a goto symbol command, which means: jump to execute the command just after the label symbol command in the code.\nConditional branching is effected using the if-goto symbol command, whose semantics is:\nPop the topmost value off the stack. If it’s not false, jump to execute the command just after the label symbol command. Otherwise, execute the next command in the code. Consider a function that receives two arguments, $x$ and $y$, and returns the product $xy$. This can be done by adding $x$ repetitively to a local variable, say $\\text{sum}$, $y$ times, and then returning sum’s value (see Figure 8.1.)\nNotice how the Boolean condition !(i \u003c y) implemented as:\npush i push y lt ng Is pushed onto the stack just before the if-goto WHILE_END command.","functions#Functions":"The only difference between applying a primitive operation and invoking a function is the keyword call preceding the latter. Both require the caller to set the stage by pushing arguments onto the stack, both operations are expected to consume their arguments, and both operations are expected to push return values onto the stack\nFigure 8.2 shows a VM program that computes the function $\\sqrt{x^2 + y^2}$.\nThe bottom part of figure 8.2 shows that during run-time, each function sees a private world, consisting of its own working stack and memory segments.\nWe use the term calling chain to refer, conceptually, to all the functions that are currently involved in the program’s execution. Each function in the calling chain waits for the function that it called to return. Thus, the only function that is truly active in the calling chain is the last one.\nFunctions normally use local and argument variables. These variables are temporary: the memory segments that represent them must be allocated when the function starts executing and can be discarded when the function returns. This memory management task is complicated by the requirement that function calling is allowed to be arbitrarily nested, as well as recursive.\nThe property that makes this housekeeping task tractable is the linear nature of the call-and-return logic. Assume that the current function is foo. Suppose that at some point foo wants to call another function, bar, for its effect. At this point we have to put foo’s execution on hold until bar will terminate its execution. Now, putting foo’s working stack on hold is not a problem: because the stack grows only in one direction, the working stack of bar will never override previously pushed values.\nBut how can we save foo’s memory segments? If we wish to put these segments on hold, we can push their pointers onto the stack and pop them later. We use the term frame to refer, collectively, to the set of pointer values needed for saving and reinstating the function’s state.\nAs shown in figure 8.3, when handling the call functionName command, the VM implementation pushes the caller’s frame onto the stack. At the end of this housekeeping, we are ready to jump to executing the callee’s code. We use the function’s name to create a unique symbolic label that marks where the function starts. Thus we can generate assembly code that effects a goto functionName.\nReturning from the callee to the caller when the former terminates can be done by:\nSaving the return address just before control is transferred to executing the caller. Retrieving the return address and jumping to it just after the callee returns. But where shall we save the return address? We can have the VM translator plant a label right after the instruction call foo and push this label onto the stack. When we later encounter a return command in the VM code, we can pop the previously saved return address off the stack—let’s call it returnAddress— and effect the operation goto returnAddress .\nWe now turn to give a step-by-step illustration of how the VM implementation supports the function call-andreturn action in Figure 8.4.\nEach call operation is implemented by saving the frame of the caller on the stack and jumping to execute the callee.\nEach return operation is implemented by\nUsing the most recently stored frame for getting the return address within the caller’s code and reinstating its memory segments. Copying the topmost stack value (the return value) onto the stack location associated with argument 0 Jumping to execute the caller’s code from the return address onward. Figure 8.5. shows the steps taken when calling and returning from a function:","high-level-magic#High Level Magic":"Whenever one function calls a function, someone must take care of the following:\nSave the return address, which is the address within the caller’s code to which execution must return after the callee completes its execution; Save the memory resources of the caller Allocate the memory resources required by the callee Make the arguments passed by the caller available to the callee’s code Start executing the callee’s code When the callee terminates and returns a value, someone must take care of the following:\nMake the callee’s return value available to the caller’s code Recycle the memory resources used by the callee Reinstate the previously saved memory resources of the caller Retrieve the previously saved return address Resume executing the caller’s code, from the return address onward. ","vm-specification-part-ii#VM Specification, Part II":"Branching Commands label LABEL: Labels the current location in the function’s code. Only labeled locations can be jumped to.\ngoto LABEL: Effects an unconditional goto operation, causing execution to continue from the location marked by the label.\nif-goto LABEL: Effects a conditional goto operation. The stack’s topmost value is popped; if the value is not zero, execution continues from the location marked by the label; otherwise, execution continues from the next command in the program.\nFunction Commands function functionName nVars: Marks the beginning of a function named functionName.\ncall functionName nArgs: Calls the named function.\nreturn: Transfers execution to the command just following the call command."},"title":"Virtual Marchine II: Control"},"/notes/cs/ecs/10/":{"data":{"":"","background#Background":"A compiler is a program that translates programs from a source language into a target language. The translation process, known as compilation, is conceptually based on two distinct tasks:\nSyntax analysis: usually divided further into two substages Tokenizing: grouping of input characters into language atoms called tokens. Parsing: grouping of tokens into structured statements that have a meaning. Code generation Figure 10.1 shows these steps:\nGiven grammar—the set of rules that define the syntax of a programming language, parsing a program means to determine the exact correspondence between the program’s text and the grammar’s rules. To do so, we must first transform the program’s text into a list of tokens.\nLexical Analysis The first step in analyzing the program’s syntax is grouping the characters into tokens, as defined by the language lexicon, while ignoring white space and comments. This task is called lexical analysis, scanning, or tokenizing.\nFigure 10.2 presents the Jack language lexicon and illustrates the tokenization of a typical code segment.\nGammars A grammar is written in a meta-language: a language describing a language. Terminals are tokens, nonterminals are names of other rules, and qualifiers are represented by the five symbols |, *, ?, (, and ). See figure 10.3 for an example.\nWe see that the grammar of a programming language can be used to ascertain, without ambiguity, whether given inputs are accepted or rejected. As a side effect of this parsing act, the parser produces an exact correspondence between the given input, on the one hand, and the syntactic patterns admitted by the grammar rules, on the other. The correspondence can be represented by a data structure called a parse tree, also called a derivation tree, like the one shown in figure 10.4a.\nHow can we represent parse trees textually? See figure 10.4b for an example.\nParser A parser is an agent that operates according to a given grammar. The parser accepts as input a stream of tokens and attempts to produce as output the parse tree associated with the given input.\nThere are several algorithms for constructing parse trees. The top-down approach, also known as recursive descent parsing, attempts to parse the tokenized input recursively, using the nested structures admitted by the language grammar.\nRecursive parsing algorithms are simple and elegant. If the language is simple, a single token lookahead is all that it takes to know which parsing rule to invoke next. Grammars that have this lingual property are called LL (1). These grammars can be handled simply and elegantly by recursive descent algorithms, without backtracking.\nThe term LL comes from the observation that the grammar parses the input from left to right, performing leftmost derivation of the input. The (1) parameter informs that looking ahead $1$ token.","specification#Specification":"The complete Jack grammar is specified in figure 10.5."},"title":"Compiler I: Syntax Analysis"},"/notes/cs/ecs/11/":{"data":{"":"","code-generation#Code Generation":"We have to figure out how to systematically translate expressions, statements, subroutines, and the handling of variables, objects, and arrays into sequences of stack-based VM commands that execute the desired semantics on the target virtual machine.\nHandling Variables One of the basic tasks of compilers is mapping the variables declared in the source high-level program onto the host RAM of the target platform. In Nand to Tetris there are no mapping complications: all the primitive types in Jack are 16-bit wide, and so are the addresses and words of the Hack RAM. Thus, every Jack variable, including pointer variables holding 16-bit address values, can be mapped on exactly one word in memory.\nThe second challenge faced by compilers is that variables of different kinds have different life cycles. Class-level static variables are shared globally by all the subroutines in the class. Therefore, a single copy of each static variable should be kept alive during the complete duration of the program’s execution.\nThe good news is that we’ve already handled all these difficulties. In our two-tier compiler architecture, memory allocation and deallocation are delegated to the VM level. All we have to do now is map Jack static variables on static 0, static 1, static 2, …; field variables on this 0, this 1, …; local variables on local 0, local 1, …; and argument variables on argument 0, argument 1, ….\nThe variable properties can be managed conveniently using a symbol table. When a static, field, local, or argument variable is declared in the source code, the compiler allocates it to the next available entry in the corresponding static, this, local, or argument VM segment. To enable separate namespaces, each identifier is implicitly associated with a scope. Jack compilers can realize the scope abstractions by managing two separate symbol tables as seen in figure 11.2.\nWhen the compiler fails to find the variable in the table associated with the current scope, it looks it up outward.\nCompiling Expressions In Jack, expressions are written using infix notation. In contrast, our compilation’s target language is postfix. We need an algorithm that knows how to parse an infix expression and generate from it as output postfix code. Figure 11.4 presents one such algorithm.\nFigure 11.5 gives the complete grammatical definition of Jack expressions, along with several examples of actual expressions consistent with this definition.\nCompiling Strings Each time a string constant comes up in a high-level statement or expression, the compiler generates code that calls the String constructor. Next, the compiler initializes the new object with the string characters by generating a sequence of calls to the String method appendChar, one for each character.\nCompiling Statements The Jack programming language features five statements: let, do, return, if, and while.\nReturn First, we call the compileExpression routine, which generates VM code designed to evaluate and put the expression’s value on the stack. Next, we generate the VM command return.\nLet Since parsing is a left-to-right process, we begin by remembering the varName. Next, we call compileExpression, which puts the expression’s value on the top of the stack. Finally, we generate the VM command pop varName, (where varName is for example, local 3, static 1, and so on). With this we store the top value of the stack onto varName.\nDo Here we discuss the compilation of function calls of the form do className.functionName (exp1, exp2, ..., expn). The do abstraction is designed to call a subroutine for its effect, ignoring the return value. To compile it we call compileExpression and then get rid of the topmost stack element (the expression’s value) by generating a command like pop temp 0.\nIf/While One of the challenges faced by compiler developers is expressing the semantics of high-level control flow statements using nothing more than goto primitives. Figure 11.6 shows how this gap can be bridged systematically.\nThe compiler starts by calling compileExpression, which generates VM commands designed to compute and push the expression’s value onto the stack. The compiler then generates the VM command not, designed to negate the expression’s value. Next, the compiler creates a label, say L1, and uses it for generating the VM command if-goto L1.\nHandling Objects Each object is implemented physically as a memory block. The reference variable, also known as an object variable, or pointer, contains the memory block’s base address. The heap is used as a memory pool from which memory blocks are carved, as needed, for representing new objects. When an object is no longer needed, its memory block can be freed.\nAny methodis designed to operate on a placeholder known as the current object, or this. When VM commands make references to this 0, this 1, this 2, and so on, they should effect the fields of the current object. How do we align the this segment with the current object?\nAccording to the VM specification, the pointer THIS (referred to as pointer 0) is designed to hold the base address of the memory segment this. Thus, to align the this segment with the current object, we can push its value (which is an address) onto the stack and then pop it into pointer 0.\nVersions of this initialization technique are used conspicuously in the compilation of constructors and methods.\nCompiling Constructors Compiling constructor calls: First, one declares a variable of some class type. At a later stage, one can instantiate the object by calling a class constructor, for example, let p = Point.new(2,3). On this second step first, the constructor allocates a memory block of the required size. Second, when the constructorterminates its execution, it returns to the caller the base address of the allocated memory block. Figure 11.7 shows how this abstraction can be realized.\nThe physical addresses $6012$ and $9543$ are irrelevant; the high-level code as well as the compiled VM code have no idea where the objects are stored in memory; the references to these objects are strictly symbolic, via p1 and p2 in the high-level code and local 0 and local 1 in the compiled code.\nCompiling constructors: note that a constructor is a subroutine what makes the compilation of a constructor special is that in addition to treating it as a regular subroutine, the compiler must also generate code that (i) creates a new object and (ii) makes the new object the current object (also known as this) (see Figure 11.8).\nThe creation of a new object requires finding a free RAM block sufficiently large to accommodate the new object’s data and marking the block as used. These tasks are delegated to the host operating system.\nBefore calling Memory.alloc, the compiler determines the size of the required memory block. This can be readily computed from the class-level symbol table. For example:\npush constant 2 call Memory.alloc pop pointer 0 This VM code allocates a total of two words of memory and saves the base address returned by Memory.alloc on this (or pointer 0).\nAccording to the Jack language specification, every constructor must end with a return this statement. This convention forces the compiler to end the constructor’s compiled version with push pointer 0 and return so the object’s base address is on top of the stack.\nCompiling Methods We’ll describe how to compile method calls and then how to compile the methods themselves.\nCompiling method calls: Unlike functions, methods are subroutines that always operate on a given object, and it’s the caller’s responsibility to specify this object. The compiler handles object-oriented method calls like p1.distance (p2) as if they were procedural calls like distance(p1, p2). Specifically, it translates p1.distance(p2) into push p1, push p2, call distance.\nTo compile the method call varName.methodName(exp1, exp2, ..., expn), we start by generating the command push varName. If the method call mentions no varName, we push the symbol table mapping of this. Next, we call compileExpressionList, that generates code for all the expressions defined for arguments. Finally, we generate the command call className.methodName n+1 informing that$n$ arguments were pushed onto the stack. See figure 11.9 for an example.\nCompiling methods: any is designed to operate on the current object, represented by the built-in identifier this. One can write an entire method without ever mentioning this. So how does the Jack compiler handle expressions like x – other.getx()? First, it looks up x in the symbol tables and finds that it represents the first field in the current object. Which, according to the method call contract, it must be the first argument that was passed by the method’s caller. Therefore, from the callee’s perspective, the current object must be the object whose base address is the value of argument 0. See figure 11.10 for the details.\nTurning our attention to the compiled version, note that the code starts with push argument 0, followed by pop pointer 0. These commands set the method’s THIS pointer to the value of argument 0, which contains the base address of the object on which the method was called to operate (p1). Thus, from this point onward, the method’s this segment is properly aligned with the base address of the target object.\nCompiling Arrays Arrays are similar to objects. In Jack, arrays are implemented as objects, concretely as instances of an Array class, which is part of the operating system. With the difference that the array abstraction allows accessing array elements using an index.\nUsing pointer notation, observe that arr[i] can be written as *(arr + i) that is, memory address arr + i. To compute the physical address of arr[i], we execute push arr, push i, add, which results in pushing the target address onto the stack. Next, we execute pop pointer 1. According to the VM specification, this action stores the target address in the method’s THAT pointer, which has the effect of aligning the base address of the virtual segment that with the target address. See figure 11.11 for the details.\nIt doesn’t work for a[i] = b[j]. The good news is that this flawed compilation strategy can be easily fixed to compile correctly any instance of let arr[expression1] = expression2.\nWe generate the command push arr, calling compileExpression, and generating the command add. This sequence puts the target address (arr + expression1) at the stack’s top. We call compileExpression, which will end up putting at the stack’s top the value of expression2. We save this value (pop temp 0). This operation has the nice side effect of making (arr + expression1) the top stack element. Thus we can now pop pointer 1 (set THAT to the value of (arr + expression1)), push temp 0(saves the value of expression2 on the stack), and pop that 0 (sets the value under address (arr + expression1) to expression2). "},"title":"Compiler II: Code Generation"},"/notes/cs/ecs/12/":{"data":{"":"","mathematical-operations#Mathematical Operations":"Normally, addition is implemented in hardware, at the ALU level, and subtraction is gained freely, using two’s complement method. Other arithmetic operations can be handled either by hardware or by software, depending on cost/performance considerations.\nAs a rule, we seek algorithms whose running time is a polynomial function of the input’s word size $n$. Algorithms whose running time depends on the values of $n$-bit numbers are unacceptable, since these values are exponential in $n$.\nMultiplication On decimal notation, To compute $356$ times $73$, we line up the two numbers one on top of the other, right-justified. Next, we multiply $356$ by $3$. Next, we shift $356$ to the left one position, and multiply $3560$ by $7$. The binary version of the multiplication procedure is illustrated in figure 12.1.\nFor each $i$-th bit of $y$, we shift $x$ $i$ times to the left (same as multiplying $x$ by $2^i$). We look at the $i$-th bit of $y$: If it is $1$, we add the shifted $x$ to an accumulator; otherwise, we do nothing. Note that $2 * shiftedx$ can be computed either by left-shifting the bitwise representation of $shiftedx$ or by adding $shiftedx$ to itself. Either operation lends itself to primitive hardware operations.\nThe multiplication algorithm performs $n$ iterations, where $n$ is the bit width of the $y$ input. In the Hack platform, the bit width of all data types is $16$. If we assume that each iteration of the multiplication algorithm entails about ten Hack machine instructions, it follows that each multiplication operation will require at most $160$ clock cycles\nDivision We can try to subtract large chunks of $y$’s from $x$ in each iteration. For example, suppose we have to divide $175$ by $3$. We start by asking: What is the largest number $x = (90, 80, \\cdots, 10)$, so that $3 \\cdot x \\leq 175$. The answer is $50$. This accelerated subtraction leaves a remainder of $175 - 3 \\cdot 50 = 25$. Moving along, we now ask: What is the largest number $x = (9, 8, \\cdots, 1)$, so that $3 \\cdot x \\leq 25$? We perform this steps until the remainder is less than $3$. This technique is the rationale behind the dreaded school procedure known as long division.\nThe binary version of this algorithm is identical, except that instead of accelerating the subtraction using powers of $10$ we use powers of $2$. Figure 12.2 presents another division algorithm which is as efficient, but more elegant and easier to implement.\nSuppose we have to divide $480$ by $17$. The algorithm shown in figure 12.2 is based on the insight and so on. The depth of this recursion is bounded by the number of times $y$ can be multiplied by $2$ before reaching $x$. This also happens to be, at most, the number of bits required to represent $x$.\nSquare Root The square root function has two attractive properties.\nIt is monotonically increasing. Its inverse function, is a function that we already know how to compute efficiently, multiplication. Taken together, these properties imply that we have all we need to compute square roots efficiently, using a form of binary search. Figure 12.3 gives the details.\nSince the number of iterations in the binary search that the algorithm performs is bound by $\\frac{n}{2}$ where $n$ is the number of bits in $x$, the algorithm’s running time is $O(n)$.\nStrings Typically, the string abstraction is supplied by a String class that is part of the standard class library that supports the language.\nThe more challenging String methods are those that convert integer values to strings and strings of digit characters to integer values.\nString representation of numbers: When numbers are captured from an input device like a keyboard they are cast as strings of characters, each representing one of the digits $0$ to $9$. The subset of relevant characters is:\nThe integer value of character $c$, where $48 \\leq c \\leq 57$ is $c - 48$. Conversely, the character code of the integer $x$, where $0 \\leq x \\leq 9$ is $x + 48$. These conversion algorithms can be based on either iterative or recursive logic, so figure 12.4 presents one of each.\nMemory Management Each time a program creates a new array or a new object, a memory block of a certain size must be allocated for representing the new array or object. And when the array or object is no longer needed, its RAM space may be recycled. These chores are done by two classical OS functions called alloc and deAlloc.\nThe memory blocks for representing arrays and objects are carved from, and recycled back into, a designated RAM area called a heap.\nThe agent responsible for managing this resource is the operating system. When the OS starts running, it initializes a pointer named heapBase, containing the heap’s base address in the RAM (in Jack, the heap starts just after the stack’s end, with heapBase=2048). We’ll present two heap management algorithms: basic and improved.\nBasic Memory Allocation Algorithm The data structure that this algorithm manages is a single pointer, named free, which points to the beginning of the heap segment that was not yet allocated. See figure 12.5a for the details.\nThe basic heap management scheme is clearly wasteful, as it never reclaims any memory space.\nImproved Memory Allocation Algorithm This algorithm manages a linked list of available memory segments, called freeList (see figure 12.5b). Each segment in the list begins with two housekeeping fields: the segment’s length and a pointer to the next segment in the list.\nWhen asked to allocate a memory block of a given size, the algorithm has to search the freeList for a suitable segment. There are two heuristics for doing this search.\nBest-fit: finds the shortest segment that is long enough for representing the required size First-fit: finds the first segment that is long enough Next, the length of this segment is updated in the freeList, reflecting the length of the part that remained after the allocation. If no memory was left in the segment, or if the remaining part is practically too small, the entire segment is eliminated from the freeList.\nWhen asked to reclaim the memory block of an unused object, the algorithm appends the deallocated block to the end of the freeList.\nDynamic memory allocation algorithms like the one shown in figure 12.5b may create block fragmentation problems. Hence, a defragmentation operation should be considered, that is, merging memory areas that are physically adjacent in memory but logically split into different segments in the freeList. The defragmentation can be done each time an object is deallocated, when alloc() fails to find a block of the requested size, or according to some other, periodical ad hoc condition.\nWe end the discussion of memory management with two simple OS functions that have nothing to do with resource allocation. Memory.peek(addr) returns the value of the RAM at address addr, and Memory.poke(addr,value) sets the word in RAM address addr to value. These functions play a role in various OS services that manipulate the memory.\nGraphical Output Modern computers render graphical output like animation and video on high-resolution color screens, using optimized graphics drivers and dedicated graphical processing units (GPUs). In Nand to Tetris we abstract away most of this complexity, focusing instead on fundamental graphicsdrawing algorithms and techniques.\nWe assume that the computer is connected to a physical black-and-white screen arranged as a grid of rows and columns, and at the intersection of each lies a pixel. By convention, the columns are numbered from left to right and the rows are numbered from top to bottom. Thus pixel $(0,0)$ is located at the screen’s top-left corner.\nWe assume that the screen is connected to the computer system through a memory map—a dedicated RAM area in which each pixel is represented by one bit. The screen is refreshed from this memory map many times per second by a process that is external to the computer.\nThe most basic operation that can be performed on the screen is drawing an individual pixel specified by $(x,y)$ coordinates. This is done by turning the corresponding bit in the memory map on or off. Other operations like drawing a line and drawing a circle are built on top of this basic operation. The graphics package maintains a current color that can be set to black or white. All the drawing operations use the current color. Since the RAM is an $n$-bit device, this operation requires reading and writing an n-bit value. See figure 12.6.\nOn the next code section we show how a pixel is drawn on our OS:\nfunction int setPixelOnWord(int x, int idx) { var int mask; // Avoid getting warning of integer constant too big let mask = powersOfTwo[idx]; if (drawBlack) { // or operation over 000000001000000 // where there is a 1 on the idx-th position // this ensures the idx-th bit is 1 let x = x | mask; } else { // and operation over 111111101111111 // where there is a 0 on the idx-th position // this ensures the idx-th bit is 0 let x = x \u0026 -mask; } return x; } /*** Draws the (x,y) pixel, using the current color. **/ function void drawPixel(int x, int y) { var int screenAddress, screenValue, wordIdx; var int col, row; let col = x; let row = y; let screenAddress = baseScreenMemory + (32 * row) + (col / 16); // Computes the index on the 16-bit word by performing col % 16 let wordIdx = col - ((col / 16) * 16); let screenValue = Memory.peek(screenAddress); let screenValue = Screen.setPixelOnWord(screenValue, wordIdx); do Memory.poke(screenAddress, screenValue); return; } When asked to render a continuous “line” between two “points” on a grid made of discrete pixels, the best that we can possibly do is approximate the line by drawing a series of pixels along the imaginary line connecting the two points. The procedure for drawing a line from $(x1,y1)$ to $(x2,y2)$ starts by drawing the $(x1,y1)$ pixel and then zigzagging in the direction of $(x2,y2)$ until that pixel is reached. See figure 12.7.\nThe following code realizes this algorithm:\n/*** Draws a line from pixel (x1,y1) to pixel (x2,y2), using the current color. **/ function void drawLine(int x1, int y1, int x2, int y2) { var int a, b; var int dx, dy, da, db; var int xDirection, yDirection; let dx = Math.abs(x2 - x1); let dy = Math.abs(y2 - y1); let a = 0; let b = 0; let da = 0; let db = 0; // Vertical line if (dx = 0) { do Screen.drawVerticalLine(x1, Math.min(y1, y2), dy); return; } // Horizontal line if (dy = 0) { do Screen.drawHorizontalLine(Math.max(x1, x2), y1, dx); return; } // If y1 \u003e y2 we have to always go up, that is we have to decrement y1 if (y1 \u003e y2) { let yDirection = -1; } else { // Else we have to always go down, that is we have to increment y1 let yDirection = 1; } // If x1 \u003e x2 we have to always go left, that is we have to decrement x1 if (x1 \u003e x2) { let xDirection = -1; } else { // Else we have to always go right, that is we have to increment x1 let xDirection = 1; } while (((da = dx) | (da \u003c dx)) \u0026 ((db = dy) | (db \u003c dy))) { do Screen.drawPixel(x1 + a, y1 + b); // (da, db) is, let's say the current dx and dy. They store // how many times we have gone (up-down)/(right-left). da being the units to the // \"right-left\" and db being the units \"up-down\". if ((db ** dx) \u003c (da ** dy)) { // If the b/a ratio, that is the slope of our current line, m1, is below the // slope of the line to be painted (dx / dy), then we should readjust the // next pixel to draw so we augment m1. That means we need to modify the height b. // Go up/down let b = b + yDirection; } else { // Else we need to decrement the slope m1 by modifying the x-coordinate of // the endpoint of our current line, that is a // Go right/left let a = a + xDirection; } let da = Math.abs(a); let db = Math.abs(b); } return; } Figure 12.8 presents an algorithm that uses three routines that we’ve already implemented: multiplication, square root, and line drawing.\nThe algorithm is based on drawing a sequence of horizontal lines (like the typical line $ab$ in the figure), one for each row in the range $y - r$ to $y + r$. Since $r$ is specified in pixels, the algorithm ends up drawing a line in every row along the circle’s north-south diameter, resulting in a completely filled circle. A simple tweak can cause this algorithm to draw only the circle’s outline, if so desired.\nAnd finally the next funcion shows how to implement the algorithm to draw the circle:\n/*** Draws a filled circle of radius r\u003c=181 around (x,y), using the current color. **/ function void drawCircle(int x, int y, int r) { var int dy, dx, rSquare, dySquare, ySum, yDiff; let dy = 0; let rSquare = r * r; while (dy \u003c (r + 1)) { let dySquare = dy * dy; // y coordinate is computed using original y +- an offset of dy, which takes values in [0, r] let ySum = y + dy; let yDiff = y - dy; // x coordinate is computed using pythagorean theorem, where the triangle's // hypothenuses length is equal to the radious (r) we also know the length of // one of the cathetus equals dy, therefore dx = +-sqrt(r^2 - dy^2) let dx = Math.sqrt(rSquare - dySquare); // Avoid redrawing middle part of circle if (~(dy = 0)) { // Draw upper part do Screen.drawLine(x - dx, yDiff, x + dx, yDiff); } // Draw lower part do Screen.drawLine(x - dx, ySum, x + dx, ySum); let dy = dy + 1; } return; } Character Output The character sets that computers use are divided into printable and non-printable subsets. For each printable character in the Hack character set, an 11-row-by-8-column bitmap image was designed. Taken together, these images are called a font. To handle character spacing, each character image includes at least a $1$-pixel space before the next character in the row and at least a $1$-pixel space between adjacent rows (the exact spacing varies with the size and squiggles of individual characters). Figure 12.9 shows how our font renders the uppercase letter N.\nOn our OS the pixel representation for the characters are stored on a map, indexed by the int value assigned to each character:\n// Initializes the character map array function void initMap() { var int i; let charMaps = Array.new(127); // Black square, used for displaying non-printable characters. do Output.create(0,63,63,63,63,63,63,63,63,63,0,0); // Assigns the bitmap for each character in the charachter set. // The first parameter is the character index, the next 11 numbers // are the values of each row in the frame that represents this character. do Output.create(32,0,0,0,0,0,0,0,0,0,0,0); // do Output.create(97,0,0,0,14,24,30,27,27,54,0,0); // a do Output.create(98,3,3,3,15,27,51,51,51,30,0,0); // b do Output.create(99,0,0,0,30,51,3,3,51,30,0,0); // c do Output.create(100,48,48,48,60,54,51,51,51,30,0,0); // d do Output.create(101,0,0,0,30,51,63,3,51,30,0,0); // e do Output.create(102,28,54,38,6,15,6,6,6,15,0,0); // f do Output.create(103,0,0,30,51,51,51,62,48,51,30,0); // g do Output.create(104,3,3,3,27,55,51,51,51,51,0,0); // h ... } // Creates the character map array of the given character index, using the given values. function void create(int index, int a, int b, int c, int d, int e, int f, int g, int h, int i, int j, int k) { var Array map; let map = Array.new(11); let charMaps[index] = map; let map[0] = a; let map[1] = b; let map[2] = c; let map[3] = d; let map[4] = e; let map[5] = f; let map[6] = g; let map[7] = h; let map[8] = i; let map[9] = j; let map[10] = k; return; } The resulting font is a collection of ninetyfive rectangular bitmap images, each representing a printable character. For each printable character, we define an array that holds the character’s bitmap. The array consists of 11 elements, each corresponding to a row of 8 pixels. Specifically, we set the value of each array entry j to an integer value whose binary representation (bits) codes the 8 pixels appearing in the j-th row of the character’s bitmap. So for example, the number $4$, whose binary representation in $8$ bits is $00000100$, would just color black the third column for the $j$th row.\nCharacters are usually displayed one after the other, from left to right, until the end of the line is reached. The character-writing package maintains a global cursor that keeps track of the screen location where the next character should be drawn. The cursor information consists of column and row counts, say, cursor.col and cursor.row.\nAfter a character has been displayed, we do cursor.col++. At the end of the row we do cursor.row++ and cursor.col = 0. When the bottom of the screen is reached, there is a question of what to do next. Two possible actions are effecting a scrolling operation or clearing the screen and starting over by setting the cursor to $(0,0)$.\nKeyboard Input Detecting which key is presently pressed is a hardware-specific operation that depends on the keyboard interface. In the Hack computer, the keyboard continuously refreshes a $16$-bit memory register whose address is kept in a pointer named KBD. If a key is currently pressed on the keyboard, that address contains the key’s character code; otherwise, it contains $0$. This contract is used for implementing the keyPressed function shown in figure 12.10.\nThe elapsed time between the key pressed and the subsequent key released events is unpredictable. Hence, we have to write code that neutralizes this uncertainty. Also, when users press keys on the keyboard, we want to give feedback as to which keys have been pressed. Typically, we want to display some graphical cursor at the screen location where the next input goes, and, after some key has been pressed, we want to echo the inputted character by displaying its bitmap on the screen at the cursor location. All these actions are implemented by the readChar function.\nA multicharacter input typed by the user is considered final after the ENTER key has been pressed, yielding the newLine character. Until the ENTER key is pressed, the user should be allowed to backspace, delete, and retype previously typed characters. All these actions are accommodated by the readLine function.\nOur input-handling solutions are based on a cascading series of abstractions: The high-level program relies on the readLine abstraction, which relies on the readChar abstraction, which relies on the keyPressed abstraction, which relies on the Memory.peek abstraction, which relies on the hardware."},"title":"Operating System"},"/notes/cs/rtgw/":{"data":{"":" Gettings Started Rendering Lights Camera Animations Colors, Depth Testing, and Alpha Blending Textures Picking "},"title":"Real-Time 3D Graphics with WebGL 2"},"/notes/cs/rtgw/01/":{"data":{"":"","accessing-the-webgl-context#Accessing the WebGL Context":"A WebGL context is an object through which we can access WebGL functions and attributes.\n\u003cscript type=\"text/javascript\"\u003e \"use strict\"; function init() { const canvas = document.getElementById(\"webgl-canvas\"); // Ensure we have a canvas if (!canvas) { console.error(\"Sorry! No HTML5 Canvas was found on this page\"); return; } const gl = canvas.getContext(\"webgl2\"); } // Call init once the document has loaded window.onload = init; \u003c/script\u003e A WebGL context can be understood as a state machine: once you modify attributes, the modifications persist until later modifications. For example:\nconst color = gl.getParameter(gl.COLOR_CLEAR_VALUE); Here gl.COLOR_CLEAR_VALUE is one of the WebGL context attributes.","elements-in-a-webgl-application#Elements in a WebGL Application":"Some of these common elements include:\ncanvas: the placeholder where our scene is rendered. Objects: the 3D entities that make up the scene. Lights Camera ","retained-and-immediate-mode-rendering#Retained and Immediate Mode Rendering":"In th retained-mode the graphics library maintains a scene model in memory, To change what is rendered, the application issues a command to update the scene.\nIn the inmediate-mode each time a new frame is drawn the application issues all drawing commands required to describe the entire scene.\nRetained-mode rendering can be simpler to use, because the API does more of the work for you, such as initialization, state maintenance, and cleanup. However, it is often less flexible since the API forces its own particular scene model; it can also have higher memory prerequisites.\nImmediate-mode rendering, on the other hand, as offered with WebGL, is much more flexible and can implement targeted optimizations.","server-and-client-based-rendering#Server and Client Based Rendering":"The second distinction to make is whether the rendering process is happening locally or remotely. When the image that needs to be rendered is too complex, the render will most likely occur remotely. We call this server-based rendering.\nThe opposite of this approach takes place when rendering occurs locally. We call this client-based rendering.\nWebGL offers a client-based rendering approach: the processing required to obtain an image is all performed locally using the client’s graphics hardware.\nWebGL presents several advantages\nJavaScript programming Automatic memory management Pervasiveness Performance Zero compilation ","software-and-hardware-based-rendering#Software and Hardware Based Rendering":"The first distinction we should make is whether we are using any special graphics hardware. On one hand, we can talk about software-based rendering for cases where all required calculations to render 3D scenes are performed using the computer’s Central Processing Unit (CPU).\nOn the other hand, as is the case with WebGL, we use the term hardware-based rendering for scenarios where there is a GPU performing 3D graphics computations.\nHardware-based rendering is much more efficient than software-based rendering, because the former involves dedicated hardware handling the necessary operations."},"title":"Getting Started"},"/notes/cs/rtgw/02/":{"data":{"":"","drawelements-modes#\u003ccode\u003edrawElements\u003c/code\u003e Modes":"WebGL Rendering Pipeline WebGL runs on the GPU on your computer. As such, you need to provide code that runs on that GPU. This code is comprised by two functions called vertex shader and fragment shader, written in a very strictly-typed C/C++-like language called GLSL, GL Shader Language. Together, they are called a program.\nA vertex shader’s job is to compute vertex attributes, it outputs values that can be used to rasterize various kinds of primitives, including points, lines, and triangles.\nA fragment shader’s job is to compute a color for each pixel of the primitive currently being drawn.\nLet’s examine what WebGL’s rendering pipeline. The following is a diagram of a simplified version of WebGL’s rendering pipeline:\nVertex Buffer Objects (VBOs) VBOs contain the data that is used to describe the geometry to be rendered. Vertex coordinates, are usually stored and processed in WebGL as VBOs.\nIndex Buffer Objects (IBOs) IBOs contain information about the relationship of the vertices. It uses the index of each vertex in the vertex buffer as a value.\nVertex Shader The vertex shader is called on each vertex. The shader manipulates per-vertex data.\nFragment Shader Each surface element (pixel) is called a fragment. The main goal of the fragment shader is to calculate the color of individual pixels.\nFramebuffer The framebuffer is a two-dimensional buffer contains the fragments that have been processed by the fragment shader.\nAttributes Attributes are input variables that are used in the vertex shader.\nFor example, you may put three dimensional $32$-bit vectors in a buffer. You would tell a particular attribute which buffer to pull the vectors out of, what type of data it should pull out ($3$-component, $32$-bit floating point numbers), what offset in the buffer the positions start at, and how many bytes to get from one position to the next.\nUniform Uniforms are input variables that are available to both the vertex shader and the fragment shader. Unlike attributes, uniforms are constant during a rendering cycle.\nTextures Textures are arrays of data that can be accessed in your shader program. Image data is the most common thing to put in a texture.\nVaryings Varyings are used to pass data from the vertex shader to the fragment shader. The values set on a varying by a vertex shader will be interpolated while executing the fragment shader.\nRendering in WebGL There are two data types that are fundamental: vertices and indices. Vertices are the points that define the corners of 3D objects. Each vertex is represented by three floating-point numbers that correspond to the x, y, and z coordinates of the vertex.\nIndices are numeric labels for the vertices in a given 3D scene. Indices allow us to tell WebGL how to connect vertices in order to produce a surface.\nBoth vertices and indices are stored on a javascript array and passed to WebGL’s rendering pipeline.\nDefining a Geometry Using JavaScript Arrays As you can see from the preceding illustration, we have placed the coordinates sequentially in the vertex array and then indicated how these coordinates are used to draw the trapezoid in the index array.\nTriangles in the index array are usually, but not necessarily, defined in counter-clockwise order. It’s important to pick one approach and keep it consistent because programs may use the clockwise/counter-clockwise order to determine whether a face is facing forward or backward for culling and rendering purposes.\nIn computer graphics, back-face culling determines whether a polygon of a graphical object is visible.\nCreating WebGL Buffers Let’s render a square. We define the vertices, and create the respective buffer. These vertices are defined in clipspace coordinates, because WebGL only deals with clipspace coordinates. Clipspace coordinates always go from $-1$ to $+1$.\nconst vertices = [-0.5, 0.5, 0, -0.5, -0.5, 0, 0.5, -0.5, 0, 0.5, 0.5, 0]; const positionBuffer = gl.createBuffer(); Now, when positionBuffer is made the currently-bound WebGL buffer any subsequent buffer operation will be executed on this buffer until it is unbound, or another buffer is made the current one.\ngl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer); The first parameter is the type of buffer we are creating:\ngl.ARRAY_BUFFER: Vertex data gl.ELEMENT_ARRAY_BUFFER: Index data Once we have bound a buffer, we need to pass along its contents.\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW); The last argument is the type, which is a performance hint for WebGL. The accepted values for type are as follows:\nSTATIC_DRAW: Data in the buffer will not be changed (specified once and used many times) DYNAMIC_DRAW: Data will be changed frequently (specified many times and used many times) STREAM_DRAW: Data will change on every rendering cycle (specified once and used once) WebGL requires JavaScript typed array so that the buffer data can be processed in its native binary form with the objective of speeding up geometryprocessing performance. The typed arrays used by WebGL include Int8Array, Uint8Array, Int16Array, Uint16Array, Int32Array, Uint32Array, Float32Array, and Float64Array.\nIt’s important to note that vertex coordinates can be float, but indices are always integers. Finally, it is a good practice to unbind the buffer.\ngl.bindBuffer(gl.ARRAY_BUFFER, null); All this same process applies for the index buffer.\nAssociating Attributes to VBOs Once we have created the VBOs, we need to associate these buffers to vertex shader attributes. Each vertex shader attribute will refer to one and only one buffer. We can achieve this by following these steps:\nBind a VBO gl.bindBuffer(gl.ARRAY_BUFFER, myBuffer); Point an attribute to the currently-bound VBO gl.vertexAttribPointer(index, size, type, normalize, stride, offset); index: attribute’s index that we are bounding the currently-bound buffer to (i.e. aVertexPosition) size: number of values per vertex that are stored in the currently-bound buffer. type: data type of the values stored in the current buffer (FIXED, BYTE, UNSIGNED_BYTE, FLOAT, SHORT, UNSIGNED_SHORT) normalize: beyond scope (set to false) stride: If stride is 0, then we are indicating that elements are stored sequentially in the buffer. offset: The position in the buffer from which we will start reading values for the corresponding attribute. Generally $0$. Enable the attribute gl.enableVertexAttribArray(positionAttributeLocation); Unbind gl.bindBuffer(gl.ARRAY_BUFFER, null); Rendering Drawing Functions The drawArrays and drawElements functions are used for writing to the framebuffer.\ndrawArrays uses vertex data in the order in which it is defined in the buffer to create the geometry. In contrast, drawElements uses indices to access the vertex data buffers and create the geometry. Both drawArrays and drawElements will only use enabled arrays.\nUsing drawArrays We will call drawArrays when information about indices is not available. In most cases, drawArrays is used when the geometry is simple enough that defining indices is overkill.\nWhen we want to render a triangle or a rectangle. In that case, WebGL will create the geometry in the order in which the vertex coordinates are defined in the VBO. If you have contiguous triangles (as we did in the trapezoid example), you will have to repeat these coordinates in the VBO.\nIf you need to repeat many vertices to create the geometry, drawArrays is not the optimal method. The more vertex data you duplicate, the more calls you will have on the vertex shader, one per vertex.\nThe signature for drawArrays is as follows:\ngl.drawArrays(mode, first, count); Where:\nmode: the type of primitive that we are going to render: gl.POINTS, gl.LINE_STRIP, gl.LINE_LOOP, gl.LINES, gl.TRIANGLE_STRIP, gl.TRIANGLE_FAN, and gl.TRIANGLES. first: the starting element in the enabled arrays. count: the number of elements rendered. Using drawElements drawElements allows us to use the IBO to tell WebGL how to render the geometry. Therefore, vertices are only processed once, and can be used as many times as they are defined in the IBO. This feature reduces both the memory and processing required on the GPU.\nWhen we use drawElements, we need at least two buffers: a VBO and an IBO. As the vertex shader gets executed on each vertex, the rendering pipeline assembles the geometry into triangles using the IBO.\nThe signature for drawElements is as follows:\ngl.drawElements(mode, count, type, offset); Where:\nmode: the type of primitive that we are going to render: gl.POINTS, gl.LINE_STRIP, gl.LINE_LOOP, gl.LINES, gl.TRIANGLE_STRIP, gl.TRIANGLE_FAN, and gl.TRIANGLES. count: the number of elements rendered. type: the type of the values in indices: UNSIGNED_BYTE or UNSIGNED_SHORT. offset: which element in the buffer will be the starting point for rendering. Rendering a Square We first, compile each shader as follows:\n/** * Compiles the vertex or fragment shader */ export const compileShader = ( gl: WebGL2RenderingContext, type: PROGRAM_TYPE, source: string ) =\u003e { let shader; if (type === PROGRAM_TYPE.VERTEX) { shader = gl.createShader(gl.VERTEX_SHADER); } else { shader = gl.createShader(gl.FRAGMENT_SHADER); } if (!shader) return; gl.shaderSource(shader, source); gl.compileShader(shader); if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) { console.error(gl.getShaderInfoLog(shader)); return null; } return shader; }; We use this utility function to create the program:\n/** * Creates a program that is made up of a vertex shader and a fragment shader */ export const createProgram = ( gl: WebGL2RenderingContext, vertexShaderSource: string, fragmentShaderSource: string ) =\u003e { // Obtain the shaders const vertexShader = compileShader( gl, PROGRAM_TYPE.VERTEX, vertexShaderSource ); const fragmentShader = compileShader( gl, PROGRAM_TYPE.FRAGMENT, fragmentShaderSource ); // Create a program const program = gl.createProgram(); if (!program || !vertexShader || !fragmentShader) { throw \"Could no create program\"; } // Attach the shaders to this program gl.attachShader(program, vertexShader); gl.attachShader(program, fragmentShader); gl.linkProgram(program); if (!gl.getProgramParameter(program, gl.LINK_STATUS)) { throw \"Could not initialize shaders\"; } // Use this program instance gl.useProgram(program); return program; }; Once the program has been created, we populate our buffers:\n/** Draws square on center of clipspace x in (-1, 1), y in (-1, 1) * 0-\u003e(-0.5, 0.5) 3-\u003e(0.5, 0.5) * | / | * | / | * | / | * | / | * 1-\u003e(-0.5, -0.5) 2-\u003e(0.5, -0.5) * */ // Define vertices for position on space: the depth (z) is not important for now const vertices = [-0.5, 0.5, 0, -0.5, -0.5, 0, 0.5, -0.5, 0, 0.5, 0.5, 0]; // Define indices for identifying triangles that make up the geometry // Using counter-clock wise order // First triangle is made up from the vertices 0, 1, and 2, the second triangle // is made up of vertices 1, 2 and 3 indices = [0, 1, 3, 1, 2, 3]; // Set up VBO verticesBuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, verticesBuffer); gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW); // Set up IBO indicesBuffer = gl.createBuffer(); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indicesBuffer); gl.bufferData( gl.ELEMENT_ARRAY_BUFFER, new Uint16Array(indices), gl.STATIC_DRAW ); // Unbind buffers gl.bindBuffer(gl.ARRAY_BUFFER, null); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null); Now, in order to draw, we bind our buffers again and the we bind and enable the attributes:\n// Clear the scene gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT); gl.viewport(0, 0, gl.canvas.width, gl.canvas.height); // Bind the vertex buffer with an attribute gl.bindBuffer(gl.ARRAY_BUFFER, verticesBuffer); // Obtain attribute instance const vertexPositionAttr = gl.getAttribLocation(program, \"aVertexPosition\"); // Bind attibute to buffer and set some metadata gl.vertexAttribPointer(vertexPositionAttr, 3, gl.FLOAT, false, 0, 0); // Enable attribute gl.enableVertexAttribArray(vertexPositionAttr); // Bind IBO gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indicesBuffer); // Draw to the scene using triangle primitives gl.drawElements(gl.TRIANGLES, indices.length, gl.UNSIGNED_SHORT, 0); // Unbind buffers gl.bindBuffer(gl.ARRAY_BUFFER, null); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null); Vertex Array Objects Vertex array objects (VAOs) allow you to store all of the vertex/index binding information for a set of buffers in a single, easy to manage object.\nThis is an important feature that should always be used, since it significantly reduces rendering times.\nWhen not using VAOs, all attributes data is in global WebGL state, which means that calling functions such as gl.vertexAttribPointer, gl.enableVertexAttribArray, and gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer) manipulates the global state. This leads to performance loss, because before any draw call, we would need to set up all vertex attributes and set the ELEMENT_ARRAY_BUFFER where indexed data is being used. with VAOs, we would set up all attributes during our application’s initialization and simply bind the data at render, yielding much better performance.\nSo how would we use a VAO. There are two steps that change, firstly when we populate our data we create a VAO object alongside our VBO and IBO. And we also create create and enable here our vertex attributes.\n// Define vertices for position on space: the depth (z) is not important for now const vertices = [-0.5, 0.5, 0, -0.5, -0.5, 0, 0.5, -0.5, 0, 0.5, 0.5, 0]; // Define indices for identifying triangles that make up the geometry // Using counter-clock wise order // First triangle is made up from the vertices 0, 1, and 2, the second triangle // is made up of vertices 1, 2 and 3 indices = [0, 1, 3, 1, 2, 3]; // Set up VAO VAO = gl.createVertexArray(); gl.bindVertexArray(VAO); // Set up VBO (used inside VAO) const verticesBuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, verticesBuffer); gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW); // Tell VAO how to use the current bound buffer (vertices buffer!) // Refer to 01_square.html and see how now the definition of how the data should // be retrived is done now on initialization instead of on render. // Obtain attribute instance const vertexPositionAttr = gl.getAttribLocation(program, \"aVertexPosition\"); gl.enableVertexAttribArray(vertexPositionAttr); gl.vertexAttribPointer(vertexPositionAttr, 3, gl.FLOAT, false, 0, 0); // Set up IBO indicesBuffer = gl.createBuffer(); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indicesBuffer); gl.bufferData( gl.ELEMENT_ARRAY_BUFFER, new Uint16Array(indices), gl.STATIC_DRAW ); // Unbind buffers gl.bindVertexArray(null); gl.bindBuffer(gl.ARRAY_BUFFER, null); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null); And, in order to draw we simply bind our VAO and our IBO to be used with drawElements.\n// Clear the scene gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT); gl.viewport(0, 0, gl.canvas.width, gl.canvas.height); // Bind VAO gl.bindVertexArray(VAO); // Bind IBO gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indicesBuffer); // Draw to the scene using triangle primitives gl.drawElements(gl.TRIANGLES, indices.length, gl.UNSIGNED_SHORT, 0); // Unbind buffers gl.bindVertexArray(null); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null); drawElements Modes TRIANGLES: WebGL will use the first three indices defined in your IBO to construct the first triangle, the next three to construct the second triangle, and so on. LINES: will instruct WebGL to take each consecutive pair of indices defined in the IBO and draw lines by taking the coordinates of the corresponding vertices. POINTS: WebGL will not generate surfaces. Instead, it will render the vertices that we had defined using the index array. LINES_LOOP: draws a closed loop connecting the vertices defined in the IBO to the next one. LINE_STRIP: is similar to LINE_LOOP. The difference is that WebGL does not connect the last vertex to the first one. TRIANGLE_STRIP: draws connected triangles. Every vertex is specified after the first three. TRIANGLE_FAN: FAN creates triangles in a similar way to TRIANGLE_STRIP. However, the first vertex defined in the IBO is taken as the origin of the fan (the only shared vertex among consecutive triangles). ","rendering#Rendering":"","rendering-a-square#Rendering a Square":"","rendering-in-webgl#Rendering in WebGL":"","vertex-array-objects#Vertex Array Objects":"","webgl-as-a-state-machine-buffer-manipulation#WebGL as a State Machine: Buffer Manipulation":"When dealing with buffers for the getParameter, getBufferParameter, and isBuffer functions, new information about the state of the rendering pipeline becomes available to us.\ngetParameter(parameter), we use parameter to retrieve a reference to the currently-bound VBO (parameter=ARRAY_BUFFER_BINDING) or to retrieve a reference to the currently-bound IBO (parameter=ELEMENT_ARRAY_BUFFER_BINDINGS).\nWe can also query the size and the usage of the currently-bound VBO and IBO using getBufferParameter(type, parameter), where type can have the following values:\nARRAY_BUFFER: To refer to the currently-bound VBO\nELEMENT_ARRAY_BUFFER: To refer to the currently-bound IBO\nAnd parameter can have the following values:\nBUFFER_SIZE: Returns the size of the requested buffer\nBUFFER_USAGE: Returns the usage of the requested buffer\nFinally, isBuffer(object) will return true if the object is a WebGL buffer, or false with an error when the buffer is invalid.","webgl-rendering-pipeline#WebGL Rendering Pipeline":""},"title":"Rendering"},"/notes/cs/rtgw/03/":{"data":{"":"","goraud-shading-with-lambertian-reflection-model#Goraud Shading with Lambertian Reflection Model":"The Lambertian reflection model only considers the interaction of diffuse material and diffuse light properties. In short, we assign the final color as follows:\n$$ \\begin{aligned} F_d = C_lC_m (-L \\circ N) = C_lC_m (|-L||N| \\cos \\emptyset) = C_l C_m (\\cos \\emptyset) \\end{aligned} $$Where:\nuLightDiffuse is $C_l$ uMaterialDiffuse is $C_m$ aVertexNormal is $N$ uLightDirection is $L$ These can be translated onto a vertex shader as follows:\n#version 300 es precision mediump float; uniform mat4 uModelViewMatrix; uniform mat4 uProjectionMatrix; uniform mat4 uNormalMatrix; uniform vec3 uLightDirection; uniform vec3 uLightDiffuse; uniform vec3 uMaterialDiffuse; in vec3 aVertexPosition; in vec3 aVertexNormal; out vec4 vVertexColor; void main(void) { // Calculate the normal vector vec3 N = normalize(vec3(uNormalMatrix * vec4(aVertexNormal, 1.0))); // Normalized light direction vec3 L = normalize(uLightDirection); // Dot product of the normal product and negative light direction vector float lambertTerm = dot(N, -L); // Calculating the diffuse color based on the Lambertian reflection model vec3 Id = uMaterialDiffuse ** uLightDiffuse ** lambertTerm; vVertexColor = vec4(Id, 1.0); // Setting the vertex position gl_Position = uProjectionMatrix ** uModelViewMatrix ** vec4(aVertexPosition, 1.0); } And the fragment shader simply outputs the color computed on the vertex shader:\n#version 300 es precision mediump float; // Expect the interpolated value fro, the vertex shader in vec4 vVertexColor; // Return the final color as fragColor out vec4 fragColor; void main(void) { // Simply set the value passed in from the vertex shader fragColor = vVertexColor; } Note that the uModelViewMatrix matrix contains the Model-View transformation matrix. We will see how all this works in Chapter 4, Cameras. For now, suffice to say that this matrix allows us to update vertices’ positions, and in this example, the light’s position as well.","goraud-shading-with-phong-reflection-model#Goraud Shading with Phong Reflection Model":"Different from the Lambertian reflection model, the Phong reflection model considers three properties: the ambient, diffuse, and specular, and ultimately yields a more realistic reflection. So now both light and material have three properties: the ambient, diffuse, and specular colors.\nVertex Shader Let’s cover a sample vertex shader. In this example we are applying Goraud Shading (we compute the color on the vertex shader and the pass it as a varying to the fragment shader). And in order to compute the color we use the Phong reflection model. That is the color is computed as follows:\n$$ \\begin{aligned} F_s = C_lC_m (R \\circ E) = C_lC_m (|R||E| \\cos \\emptyset) = C_l C_m (\\cos \\emptyset)^n \\end{aligned} $$Where:\nuLightDiffuse is $C_l$ uMaterialDiffuse is $C_m$ eyeVector is $E$ reflect(uLightDirection, N) is $R$ So the final colo is computed as follows:\nfinalVertexColor = Ia + Id + Is; // Ambient Ia = lightAmbient * materialAmbient; // Diffuse (following lambertian model) Id = lightDiffuse ** (materialDiffuse ** lambertCoefficient); // Specular Is = lightSpecular ** (materialSpecular ** specularCoefficient); And based on our knowledge of the Phong reflection model (the final equation we saw above):\nfloat specular = pow(max(dot(lightReflection, eyeVector), 0.0), shininess); And we output the computed color vVertexColor to the fragment shader. Note that not all logic is shown on this code:\n#version 300 es precision mediump float; uniform mat4 uModelViewMatrix; uniform mat4 uProjectionMatrix; uniform mat4 uNormalMatrix; // Light and materials uniform vec3 uLightDirection; uniform vec4 uLightAmbient; uniform vec4 uLightDiffuse; uniform vec4 uLightSpecular; in vec3 aVertexPosition; in vec3 aVertexNormal; out vec4 vVertexColor; void main(void) { // Normal vec3 N = vec3(uNormalMatrix * vec4(aVertexNormal, 1.0)); // Light direction vec3 light = vec3(uModelViewMatrix * vec4(uLightDirection, 0.0)); vec3 L = normalize(light); // Eye vector -\u003e vector between camera and vector vec3 eyeVector = -vectex.xyz; // Ambient colors vec4 Ia = uMaterialDiffuse * uLightAmbient; float lambertTerm = dot(N,-L); // If this value is positive the cos between the surface normal and the negative light direction is positive, that is the angle is between 0º and 90º or between 270º and 360º // which means the surface is facing the light if (lambertTerm \u003e 0.0) { // Diffuse colors vec4 Id = uMaterialDiffuse ** uLightDiffuse ** lambertTerm; // Specular colors: note we retrieve the positive value for the dot product between R and E float specular = pow(max(dot(lightReflection, eyeVector), 0.0), shininess); vec4 Is = uMaterialDiffuse ** uLightSpecular ** specular; } // Combine ambient and diffuse vVertexColor = vec4(vec3(Ia + Id + Is), 1.0); gl_Position = uProjectionMatrix ** uModelViewMatrix ** vec4(aVertexPosition, 1.0); } Light Reflection Negative light contributions are not physically realistic. Light does not contribute negatively to the color intensity; it either contributes positively or not at all. When the surface is concave, some parts of the surface might face away from the light source. The light direction vector (pointing from the surface to the light source) and the normal vector (pointing out from the surface) will form an obtuse angle:\nThe dot product between these two vectors ($N \\circ L$, where $N$ is the normal and $L$ is the light direction) will be negative because the cosine of an obtuse angle is negative. To ensure the Lambertian term contributes positively to the diffuse reflection, we clamp the dot product to the range $[0, 1]$ using the clamp function. By clamping to zero, we discard these unrealistic negative values.\nAlso note how we check for $\\cos (\\theta)$ to be positive where $\\theta$ is the angle between the negative light direction $-L$ and the surface normal $N$. As we have said on the example this means the surface faces the light. If the surface does not face the light it should not contribute to the diffuse reflection nor specular component of the lighting.\nFragment Shader The fragment shader is very simple. We just assign the vVertexColor varying to the fragColor output variable.\n#version 300 es // Fragment shaders don't have a default precision so we need // to pick one. mediump is a good default. It means \"medium precision\" precision mediump float; // Computed color coming from the vertex shader in vec4 vVertexColor; // We need to declare an output for the fragment shader out vec4 fragColor; void main() { fragColor = vVertexColor; } Remember that the value of the vVertexColor varying will be different from the one calculated in the vertex shader since WebGL will interpolate it by taking the corresponding calculated colors for the vertices surrounding the correspondent fragment (pixel).","how-to-create-a-program#How To Create a Program":"We need to take a look at how we create a program using our WebGL context. Let’s take a look at the structure of the web apps we have developed so far:\nIn this section, we will take a closer look at the initProgram function which allows us to create and compile an ESSL program.\nLet’s take a step-by-step look at initProgram:\nconst initProgram = () =\u003e { gl.clearColor(0.5, 0.5, 0.5, 1); gl.enable(gl.DEPTH_TEST); program = createProgram(gl, vertexShaderSource, fragmentShaderSource); }; Where createProgram is defined as follows:\n/** * Creates a program that is made up of a vertex shader and a fragment shader */ export const createProgram = ( gl: WebGL2RenderingContext, vertexShaderSource: string, fragmentShaderSource: string ) =\u003e { // Obtain the shaders const vertexShader = compileShader( gl, PROGRAM_TYPE.VERTEX, vertexShaderSource ); const fragmentShader = compileShader( gl, PROGRAM_TYPE.FRAGMENT, fragmentShaderSource ); // Create a program const program = gl.createProgram(); if (!program || !vertexShader || !fragmentShader) { throw \"Could no create program\"; } // Attach the shaders to this program gl.attachShader(program, vertexShader); gl.attachShader(program, fragmentShader); gl.linkProgram(program); if (!gl.getProgramParameter(program, gl.LINK_STATUS)) { throw \"Could not initialize shaders\"; } // Use this program instance gl.useProgram(program); return program; }; We use compileShader function to retrieve the contents of the vertex shader and the fragment shader, both source codes are compiled inside this function. The program’s creation is done by calling createProgram, attachShader and linkProgram.\n/** * Compiles the vertex or fragment shader */ export const compileShader = ( gl: WebGL2RenderingContext, type: PROGRAM_TYPE, source: string ) =\u003e { let shader: WebGLShader | null; if (type === PROGRAM_TYPE.VERTEX) { shader = gl.createShader(gl.VERTEX_SHADER); } else { shader = gl.createShader(gl.FRAGMENT_SHADER); } if (!shader) return; gl.shaderSource(shader, source); gl.compileShader(shader); if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) { console.error(gl.getShaderInfoLog(shader)); return null; } return shader; }; WebGL Function Description createProgram() Creates a new program (program) attachShader(program, shader) Attaches a shader to the current program linkProgram(program) Creates executable versions of the vertex and fragment shaders that are passed to the GPU. getProgramParameter(program, parameter) It allows you to query the program parameters. We use this function to verify whether the program has been successfully linked useProgram(program) It will load the program onto the GPU if the program contains valid code (that is, it has been successfully linked) We also create a mapping for the attributes and the uniforms:\nprogram.aPosition = gl.getAttribLocation(program, \"aPosition\"); program.aNormal = gl.getAttribLocation(program, \"aNormal\"); program.uModelViewMatrix = gl.getUniformLocation(program, \"uModelViewMatrix\"); program.uProjectionMatrix = gl.getUniformLocation(program, \"uProjectionMatrix\"); program.uNormalMatrix = gl.getUniformLocation(program, \"uNormalMatrix\"); program.uMaterialAmbientColor = gl.getUniformLocation( program, \"uMaterialAmbientColor\" ); program.uMaterialDiffuseColor = gl.getUniformLocation( program, \"uMaterialDiffuseColor\" ); program.uMaterialSpecularColor = gl.getUniformLocation( program, \"uMaterialSpecularColor\" ); program.uLightAmbientColor = gl.getUniformLocation( program, \"uLightAmbientColor\" ); program.uLightDiffuseColor = gl.getUniformLocation( program, \"uLightDiffuseColor\" ); program.uLightSpecularColor = gl.getUniformLocation( program, \"uLightSpecularColor\" ); program.uLightDirection = gl.getUniformLocation(program, \"uLightDirection\"); program.uShininess = gl.getUniformLocation(program, \"uShininess\"); Here, we have used the following WebGL API functions:\nWebGL Function Description getAttribLocation(program, name) This function receives the current program object and a string that contains the name of the attribute that needs to be retrieved. This function then returns a reference to the respective attribute. getUniformLocation(program, name) This function receives the current program object and a string that contains the name of the uniform that needs to be retrieved. This function then returns a reference to the respective uniform. We can use the layout qualifier to look up resource locations. So instead of using getAttribLocation:\nconst vertexPosition = gl.getAttribLocation(program, \"aVertexPosition\"); gl.enableVertexAttribArray(vertexPosition); We define the attribute’s index:\nconst vertexPosition = 0; gl.enableVertexAttribArray(vertexPosition); const colorLocation = 1; gl.enableVertexAttribArray(colorLocation); And so the vertex shader becomes:\n#version 300 es layout (location=0) in vec4 aVertexPosition; layout (location=1) in vec3 aVertexColor; out vec3 vVertexColor; void main() { vVertexColor = aVertexColor; gl_Position = aVertexPosition; } ","materials#Materials":"In WebGL, the material of an object can be modeled by several parameters, including its color and texture. Material colors are usually modeled as triplets in the RGB (red, green, blue) space. Textures, on the other hand, correspond to images that are mapped onto the surface of the object. This process is usually called texture mapping.","normals#Normals":"Normals are vectors that are perpendicular to the surface we want to illuminate. Normals represent the orientation of the surface.\nBy definition, the cross-product of vectors $A$ and $B$ will be a vector perpendicular to both vectors $A$ and $B$.\nWhat about the vertices that are shared by more than one triangle? Each shared vertex normal will receive a contribution from each of the triangles in which the vertex appears.\nFor example, say that the p1 vertex is shared by the #1 and #2 triangles, and that we have already calculated the normals for the vertices of the #1 triangle. Then, we need to update the $p_1$ normal by adding up the calculated normal for $p_1$ on the #2 triangle. This is a vector sum.","opengl-es-shading-language-essl#OpenGL ES Shading Language (ESSL)":"The OpenGL ES Shading Language (ESSL) is the language we’ll use to write our shaders.\nStorage Qualifier Variable declarations may have a storage qualifier specified in front of the type: atrribute, uniform, varying or const.\nTypes Here is a non-exhaustive list of the most common ESSL types:\nvoid: For functions that do not return a value or for an empty parameter list bool: A conditional type, taking on values of true or false int: A signed integer float: A single floating-point scalar vec2: A two-component floating-point vector vec3: A three-component floating-point vector vec4: A four-component floating-point vector bvec2: A two-component Boolean vector bvec3: A three-component Boolean vector bvec4: A four-component Boolean vector ivec2: A two-component integer vector ivec3: A three-component integer vector ivec4: A four-component integer vector mat2: A 2×2 floating-point matrix mat3: A 3×3 floating-point matrix mat4: A 4×4 floating-point matrix sampler2D: A handle for accessing a 2D texture sampler3D: A handle for accessing a 3D texture samplerCube: A handle for accessing a cube-mapped texture struct: Used to declare custom data structures based on standard types Vector Components We can refer to each one of the components of an ESSL vector by its index. However, we can also refer to each component by a letter, as demonstrated in the following table:\nIt’s also possible to use the vector component notation to refer to subsets inside a vector:\nvec4 v4; v4.rgba; // is a vec4 and the same as just using v4 v4.rgb; // is a vec3 v4.b; // is a float v4.xy; // is a vec2 v4.xgba; // is illegal - the component names do not come from the same set Operators and Functions One of the major advantages of GLSL and ESSL are the powerful built-in mathematical operators. Let’s see a few examples of these operations:\n-x: The negative of the $x$ vector. It produces the same vector in the exact opposite direction. x + y: Sum of the $x$ and $y$ vectors. Both vectors need to have the same number of components. x - y: Subtraction of the $x$ and $y$ vectors. Both vectors need to have the same number of components. x * y: If $x$ and $y$ are both vectors, this operator yields a component-wise multiplication. Multiplication applied to two matrices returns a linear algebraic matrix multiplication, not a component-wise multiplication. matrixCompMult(matX, matY): Component-wise multiplication of matrices. They need to have the same dimensions. x / y: The division operator behaves similarly to the multiplication operator. dot(x, y): Returns the dot product (scalar) of two vectors. They need to have the same dimensions. cross(vecX, vecY): Returns the cross product (vector) of two vectors. They must both be vec3. normalize(x): Returns a vector in the same direction but with a length of $1$. reflect(t, n): Reflects the $t$ vector along the $n$ vector. ","parallelism-and-the-difference-between-attributes-and-uniforms#Parallelism and the Difference Between Attributes and Uniforms":"When a draw call is invoked (using drawArrays or drawElements), the GPU will launch several copies of the vertex shader in parallel. Each copy will receive a different set of attributes. All of the copies of the vertex shaders will receive the same uniforms.","phong-shading-with-phong-lighting-in-practice#Phong Shading with Phong Lighting in Practice":"The Phong interpolation calculates the final color for every fragment. This means that the calculation of the ambient, diffuse, and specular terms in the Phong model are performed in the fragment shader instead of the vertex shader.\nThis is computationally more intensive than performing a simple interpolation like with Goraud shading. However, we obtain a scene that seems more realistic.\nWhereas before we had a normal per vertex, now we need to generate a normal for every pixel so that we can calculate the Lambert coefficient for each fragment. We do so by interpolating the normals that we pass to the fragment shader.\nNow, let’s take a look at the vertex shader under Phong shading:\n#version 300 es precision mediump float; uniform mat4 uModelViewMatrix; uniform mat4 uProjectionMatrix; uniform mat4 uNormalMatrix; in vec3 aVertexPosition; in vec3 aVertexNormal; out vec3 vNormal; out vec3 vEyeVector; void main(void) { vec4 vertex = uModelViewMatrix * vec4(aVertexPosition, 1.0); vNormal = vec3(uNormalMatrix * vec4(aVertexNormal, 1.0)); // Eye vector -\u003e vector between camera and vector vEyeVector = -vec3(vertex.xyz); gl_Position = uProjectionMatrix ** uModelViewMatrix ** vec4(aVertexPosition, 1.0); } We are using two varyings to pass information to the fragment shader. Next we look at the fragment shader, where we can see that it is very similar to the vertex shader for the Phong lighting model.\n#version 300 es precision mediump float; uniform float uShininess; uniform vec3 uLightDirection; uniform vec4 uLightAmbient; uniform vec4 uLightDiffuse; uniform vec4 uLightSpecular; uniform vec4 uMaterialAmbient; uniform vec4 uMaterialDiffuse; uniform vec4 uMaterialSpecular; in vec3 vNormal; in vec3 vEyeVector; out vec4 fragColor; void main(void) { vec3 L = normalize(uLightDirection); vec3 N = normalize(vNormal); float lambertTerm = dot(N, -L); vec4 Ia = uLightAmbient * uMaterialAmbient; vec4 Id = vec4(0.0, 0.0, 0.0, 1.0); vec4 Is = vec4(0.0, 0.0, 0.0, 1.0); if (lambertTerm \u003e 0.0) { Id = uLightDiffuse ** uMaterialDiffuse ** lambertTerm; vec3 E = normalize(vEyeVector); vec3 R = reflect(L, N); float specular = pow( max(dot(R, E), 0.0), uShininess); Is = uLightSpecular ** uMaterialSpecular ** specular; } fragColor = vec4(vec3(Ia + Id + Is), 1.0); } ","positional-lights#Positional Lights":"Now, we are going to consider a case where the light source is relatively close to the object it needs to illuminate.\nWhen working with positional lights, we need to know the location of the light. We can represent it by using a uniform that we will name uLightPosition. We need to calculate each light ray separately. We will do this by using a varying that we will name vLightRay.\nSo on the following program we intent to create a positional light source using the Phong Shading model alongside the Phong Light model. The vertex shader is very similar to the vertex shader we showed for the Phong Shading model. But now we also compute a vLightRay, that is simply the vector between the vertex (transformed by uModelViewMatrix) and the light position (transformed by uModelViewMatrix). Note that now we use uLightPosition instead of uLightDirection.\n#version 300 es uniform mat4 uModelViewMatrix; uniform mat4 uNormalMatrix; uniform mat4 uProjectionMatrix; uniform vec3 uLightPosition; in vec3 aPosition; in vec3 aNormal; out vec3 vNormal; out vec3 vLightRay; out vec3 vEyeVector; void main(void) { // Obtains transformed vertex position vec4 vertex = uModelViewMatrix * vec4(aPosition, 1.0); // Obtains transformed light position vec4 light = uModelViewMatrix * vec4(uLightPosition, 1.0); // Obtains transformed normal (use normal matrix) vNormal = vec3(uNormalMatrix * vec4(aNormal, 1.0)); // Light ray -\u003e vector between vertex and light vector vLightRay = vertex.xyz - light.xyz; // Eye vector -\u003e vector between camera and vector vEyeVector = -vec3(vertex.xyz); gl_Position = uProjectionMatrix ** uModelViewMatrix ** vec4(aPosition, 1.0); } Let’s now look at the fragment shader. It is identical to the fragment shader shown for the Phong Shading model with the difference that now we use vLightRay instead of uLightDirection. This basically means that we do not define infinite light sources that have the direction given by uLightDirection, but now we define a single light source that is defined by vLightRay.\n#version 300 es precision highp float; uniform vec4 uMaterialDiffuseColor; uniform vec4 uMaterialSpecularColor; uniform vec4 uMaterialAmbientColor; uniform vec4 uLightDiffuseColor; uniform vec4 uLightAmbientColor; uniform vec4 uLightSpecularColor; uniform float uShininess; in vec3 vNormal; in vec3 vLightRay; in vec3 vEyeVector; out vec4 fragColor; void main(void) { vec3 L = normalize(vLightRay); vec3 N = normalize(vNormal); vec4 Ia = uMaterialAmbientColor * uLightAmbientColor; vec4 Id = vec4(0.0, 0.0, 0.0, 1.0); vec4 Is = vec4(0.0, 0.0, 0.0, 1.0); float lambertTerm = dot(N, -L); if (lambertTerm \u003e 0.0) { Id = uLightDiffuseColor ** uMaterialDiffuseColor ** lambertTerm; vec3 E = normalize(vEyeVector); vec3 R = reflect(L, N); float specular = pow(max(dot(R, E), 0.0), uShininess); Is = uLightSpecularColor ** uMaterialSpecularColor ** specular; } fragColor = vec4(vec3(Ia + Id + Is), 1.0); } Thanks to the interpolation of varyings that is provided by ESSL, we automatically obtain all the light rays per pixel in the fragment shader:","positional-versus-directional-lights#Positional Versus Directional Lights":"Light sources can be positional or directional. A light source is called positional when its location will affect how the scene is lit. Directional lights are lights that produce the same luminous result, regardless of their position. Directional lighting assumes that the light is coming uniformly from one direction.","shading-methods-and-light-reflection-models#Shading Methods and Light-Reflection Models":"Shading refers to the type of interpolation that is performed to obtain the final color for every fragment in the scene.\nThe lighting model determines how the normals, materials, and lights need to be combined to produce the final color.\nShading/Interpolation Methods Goraud Interpolation: calculates the final color in the vertex shader. The vertex normals are used to perform this calculation. Then, using a varying variable, the final color for the vertex is passed to the fragment shader.\nPhong Interpolation: calculates the final color in the fragment shader. Each vertex normal is passed from the vertex shader to the fragment shader using a varying.\nDue to the automatic interpolation of varyings provided by the rendering pipeline, each fragment will have a color that is the result of interpolating the colors of the enclosing triangle for each fragment for goraud interpolation or its own normal in the case of phong interpolation.\nThe following diagram summarizes the two interpolation models:\nThe shading only specifies where (vertex or fragment shader) and the type of interpolation (vertex colors or vertex normals) to be used.\nGoraud Versus Phong Shading Goraud shading is considered to be faster since the performed calculations are computed per vertex, whereas Phong shading is calculated per fragment. The speed in performance does come at the cost of accurate or more realistic interpolation.\nLight-Reflection Models Lambertian Reflection Model Lambertian reflections are commonly used in computer graphics as a model for diffuse reflections, which are the kinds of reflections where an incident light ray is reflected in many angles instead of just one angle, as is the case for specular reflections:\nThe Lambertian reflection is usually calculated as the dot product between the surface normal (vertex or fragment normal, depending on the interpolation method used) and the negative of the light-direction vector. Then, the number is multiplied by the material and light source colors.\nThe light-direction vector is the vector that starts on the surface and ends on the light source position. It is essentially the vector that maps the light’s position to the surface of the geometry.\n$$ \\begin{aligned} F = C_lC_m(-L \\circ N) \\end{aligned} $$Where $F$ is the final diffuse color, $C_l$ is the light diffuse color and $C_m$ is the material diffuse color. Given:\n$$ \\begin{aligned} -L \\cot N = |-L||N| \\circ \\emptyset \\end{aligned} $$If $L$ and $N$ are normalized then $|-L| = |N| = 1$, thus:\n$$ \\begin{aligned} -L \\cot N = \\cos \\emptyset \\end{aligned} $$And the final color is computed as:\n$$ \\begin{aligned} F = C_lC_m(\\cos \\emptyset) \\end{aligned} $$Phong Reflection Model The Phong reflection model describes the way a surface reflects the light as the sum of three types of reflection.\nAmbient: accounts for the scattered light present in the scene, independent of any light source. Diffuse: corresponds to diffuse reflections. A Lambertian model is typically used for this component. Specular: provides mirror-like reflections. The specular reflection reaches its maximum when we look at the object at an angle that is equal to the reflected light-direction vector. The specular term is modeled by the dot product of two vectors, the eye vector and the reflected light-direction vector. The eye vector originates in the fragment and terminates in the view position (camera). The reflected light-direction vector is obtained by reflecting the light-direction vector upon the surface normal vector. When this dot product equals $1$ (by working with normalized vectors), our camera will capture the maximum specular reflection.\nSo the specular color is computed as follows:\n$$ \\begin{aligned} F_s = C_lC_m (R \\circ E)^n \\end{aligned} $$where $F_s$ is the final specular color, $C_l$ is the light specular color, $C_l$ is the material specular color, and $n$ is the shininess factor.\nIf $R$ and $E$ are normalized, then $R \\circ E = \\cos \\emptyset$:\n$$ \\begin{aligned} F_s = C_lC_m (\\cos \\emptyset)^n \\end{aligned} $$We know that the maximum value of $\\cos \\theta$ is $1$, and it is reached when $\\theta = 0$, that is when $R$ and $E$ have the same direction.\nSummary ","using-lights-normals-and-materials-in-the-pipeline#Using Lights, Normals, and Materials in the Pipeline":"Let’s revisit the pipeline and see where lights, normals, and materials fit in:\nNormals are defined on a vertex-per-vertex basis; therefore, normals are modeled as a VBO and are mapped using an attribute, as shown in the preceding diagram.\nLights and materials are passed as uniforms. Uniforms are available to both the vertex shader and the fragment shader, we can calculate how the light is reflected on a vertex-by-vertex basis (vertex shader) or on a fragment-per-fragment basis (fragment shader)."},"title":"Lights"},"/notes/cs/rtgw/04/":{"data":{"":"Even though we have a camera within our 3D application, there is no camera object in the WebGL API—only matrices. That is because having matrices instead of a camera object gives WebGL the flexibility to represent complex projections and animations.","webgl-does-not-have-cameras#WebGL Does Not Have Cameras":"WebGL does not have a camera object that you can manipulate. However, we can assume that what we render in the canvas is what our camera captures.\nEvery time we move our camera around, we need to update the objects according to the new camera position. So, we need to transform each vertex. Similarly, we need to make sure that the object normals and light directions are still consistent after the camera has moved. In summary, we need to analyze two different types of transformations:\nvertex (points) and normal (vectors) Transformations The Model, View and Projection matrices Normal Transform Camera Matrix "},"title":"Camera"},"/notes/cs/rtgw/04/01_transformations/":{"data":{"":"","transposing-transformation-or-projection-matrices#Transposing Transformation or Projection Matrices":"It can be confusing to determine whether you should transpose your matrix before passing it to the graphics pipeline. According to the WebGL specifications, matrices are conventionally written in column-major order. Row-major order is what is conventionally used on mathematics to define matrices, and throughout all this chapter we define the matrices on row-major order, therefore to avoid this before passing them to WebGL we need to transpose them, either we do it manually, or we can use:\ngl.uniformMatrix4fv(uModelViewMatrix, true, modelViewMatrix.toFloatArray()); Where the second argument determines whether we want to transpose the matrix or not.","vertex-transformations#Vertex Transformations":"Each transformation is encoded by a $4$x$4$ matrix. We multiply vertices that have three components, $(x, y, z)$, by this $4$x$4$ matrix by adding a fourth component to each vertex called the Homogeneous coordinate.\nThis article has a great visualization for each space:\nWorld Space Camera Space Clip Space Homogeneous Coordinates Until now, we only considered 3D vertices as a $(x,y,z)$ triplet. Let’s introduce $w$. Homogeneous coordinates make it possible to represent affine transformations (such as rotation, scaling, shear, and translation) and projective transformations as $4$x$4$ matrices.\nIn Homogeneous coordinates, vertices have four components: $x, y, z$, and $w$. The first three components are the vertex coordinates in Euclidian Space. The fourth is the perspective component. So $(x, y, z, w)$ take us to a new space: the Projective Space.\nThis will be more clear soon, but for now, just remember this:\nIf $w == 1$, then the vector $(x,y,z,1)$ is a position in space. If $w == 0$, then the vector $(x,y,z,0)$ is a direction.\nWhat difference does this make? Well, for a rotation, it doesn’t change anything. When you rotate a point or a direction, you get the same result. However, for a translation (when you move the point in a certain direction), things are different. What could mean “translate a direction”? Not much. Homogeneous coordinates allow us to use a single mathematical formula to deal with these two cases.\nHomogeneous coordinates make it possible to solve a system of linear equations where each equation represents a line that is parallel with all the others in the system. Remember that in Euclidian Space, a system like that does not have solutions, because there are no intersections. However, in Projective Space, this system has a solution—the lines will intersect at infinity. This fact is represented by the perspective component having a value of $0$.\nIt’s easy to convert from Homogeneous coordinates to non-Homogeneous, old-fashioned, Euclidean coordinates by dividing each coordinate by $w$:\n$$ \\begin{aligned} h(x, y, z, w) = v(\\frac{x}{w}, \\frac{y}{w}, \\frac{z}{w}) \\end{aligned} $$Consequently, if you want to go from Euclidean to Projective space, you add the fourth component, $w$, and make it $1$:\n$$ \\begin{aligned} v(x, y, z) = h(x, y, z, 1) \\end{aligned} $$In fact, this is what we’ve been doing throughout the first three chapters:\n#version 300 es precision mediump float; uniform mat4 uModelViewMatrix; uniform mat4 uProjectionMatrix; uniform mat4 uNormalMatrix; in vec3 aVertexPosition; void main(void) { gl_Position = uProjectionMatrix ** uModelViewMatrix ** vec4(aVertexPosition, 1.0); } There is one more thing to note about Homogeneous coordinates: while vertices have a Homogeneous coordinate, $w = 1$, vectors have a Homogeneous coordinate, $w = 0$. This is because in the Phong vertex shader, the line that processes the normals looks like this:\nvVertexNormal = vec3(uNormalMatrix * vec4(aVertexNormal, 0.0)); Transformations Translation Matrices These are the most simple tranformation matrices to understand. A translation matrix look like this:\n$$ \\begin{aligned} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 X \\\\ 0 \u0026 1 \u0026 0 \u0026 Y \\\\ 0 \u0026 0 \u0026 1 \u0026 Z \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\end{aligned} $$where $X,Y,Z$ are the values that you want to add to your position.\nSo if we want to translate the vector $(10,10,10,1)$ of $10$ units in the X direction, we get:\n$$ \\begin{aligned} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 10 \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} * \\begin{bmatrix} 10 \\\\ 10 \\\\ 10 \\\\ 1 \\\\ \\end{bmatrix} = \\begin{bmatrix} 1 ** 10 + 0 ** 10 + 0 ** 10 + 10 ** 1 \\\\ 0 ** 10 + 1 ** 10 + 0 ** 10 + 0 ** 1 \\\\ 0 ** 10 + 0 ** 10 + 1 ** 10 + 0 ** 1 \\\\ 0 ** 10 + 0 ** 10 + 0 ** 10 + 1 ** 1 \\\\ \\end{bmatrix} = \\begin{bmatrix} 20 \\\\ 10 \\\\ 10 \\\\ 1 \\\\ \\end{bmatrix} \\end{aligned} $$and we get a $(20,10,10,1)$ homogeneous vector! Remember, the $1$ means that it is a position, not a direction. So our transformation didn’t change the fact that we were dealing with a position, which is good.\nScaling matrices Scaling matrices are quite easy too:\n$$ \\begin{aligned} \\begin{bmatrix} x \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 y \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 z \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\end{aligned} $$So if you want to scale a vector (position or direction, it doesn’t matter) by $2.0$ in all directions:\n$$ \\begin{aligned} \\begin{bmatrix} 2 \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 2 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 2 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} * \\begin{bmatrix} x \\\\ y \\\\ z \\\\ w \\\\ \\end{bmatrix} = \\begin{bmatrix} 2 ** x + 0 ** y + 0 ** z + 0 ** w \\\\ 0 ** x + 2 ** y + 0 ** z + 0 ** w \\\\ 0 ** x + 0 ** y + 2 ** z + 0 ** w \\\\ 0 ** x + 0 ** y + 0 ** z + 1 ** w \\\\ \\end{bmatrix} = \\begin{bmatrix} 2x \\\\ 2y \\\\ 2z \\\\ w \\\\ \\end{bmatrix} \\end{aligned} $$Rotation Matrices TBC\nCumulating transformations So now we know how to rotate, translate, and scale our vectors. It would be great to combine these transformations. This is done by multiplying the matrices together:\nTransformedVector = TranslationMatrix * (RotationMatrix * ScaleMatrix) * OriginalVector; This actually performs the scaling FIRST, and THEN the rotation, and THEN the translation. This is how matrix multiplication works."},"title":"Transformations"},"/notes/cs/rtgw/04/02_model_view/":{"data":{"":"","clipping#Clipping":"Up to this point, we are still working with Homogeneous coordinates. Projection matrices actually transform points from the camera space to the homogeneous clip space, not to NDC (Normalized Device Coordinate) space.\nBecause WebGL doesn’t know anything about the coordinate space it requires that when all of the transformations are done, things should be in normalized device coordinates. Normalized device coordinates are obtained by dividing the clipping coordinates by the $w$ component. This is why this step is known as perspective division. In the NDC space, the $x$ and $y$ coordinates represent the location of your vertices on a normalized 2D screen, while the z-coordinate encodes depth information, which is the relative location of the objects with respect to the near and far planes.\nBasically the homogeneous coordinates have four components: $x$, $y$, $z$, and $w$. The clipping is done by comparing the $x$, $y$, and $z$ components against the Homogeneous coordinate, $w$. If any of them is more than, $+w$, or less than, $-w$, then that vertex lies outside the frustum and is discarded.\nThe clipping coordinates now range from $-1$ to $+1$ on each axis, regardless of the shape or size of the actual screen. The bottom left corner will be at $(-1, -1)$, and the top right corner will be at (1, 1). WebGL will then map these coordinates onto the viewport that was configured with glViewport.","recap#Recap":"The following diagram shows the theory we have learned so far, along with the relationships between the steps in the theory and the implementation in WebGL.\nThe five transformations that we apply to object coordinates to obtain viewport coordinates are:\nThe Model-View matrix that groups the model and view transform in one single matrix. When we multiply our vertices by this matrix, we end up in the camera space with homogeneous coordinates. The Projection matrix as a result, we end up in the homogeneous clip space. Clipping: transforms the homogeneous coordinates on cartesian coordinates by leaving out all vertices ouside of the range $[-w, w]$. This leaves us on the clip space. Perspective Division: after we apply perspective division, so now our coordinates are on the NDC space. GL Viewport: internal transform to move to the raster space. An extra transformation matrix is defined specially for the normals. This is the Normal matrix, which is obtained by inverting and transposing the Model-View matrix. This matrix is applied to normal vectors to ensure that they continue to be perpendicular to the surface.","references#References":" Model View Projection Projection Matrices ","the-model-matrix#The Model Matrix":"A model is defined by a set of vertices. The $X,Y,Z$ coordinates of these vertices are defined relative to the object’s center: that is, if a vertex is at $(0,0,0)$, it is at the center of the object.\nWe’d like to be able to move this model (you just learnt to do so: translation**rotation**scale, and done. You apply this matrix to all your vertices at each frame and everything moves. Something that doesn’t move will be at the center of the world.\nYour vertices are now in World Space. We went from Model Space (all vertices defined relatively to the center of the model) to World Space (all vertices defined relatively to the center of the world). See figure below:","the-model-view-matrix#The Model-View Matrix":"The Model-View matrix allows us to perform affine transformations in our scene. Affine is a mathematical name that describes transformations that do not change the structure of the object undergoing such transformations. In our 3D world scene, such transformations are rotation, scaling, reflection shearing, and translation. Let’s take a look at how the Model-View matrix is constructed.\nSpatial Encoding of the World By default, when you render a scene, you are looking at it from the origin of the world in the negative direction of the z-axis. As shown in the following diagram, the z-axis is coming out of the screen:\nRotation Matrix The intersection of the first three rows with the first three columns defines the 3x3 Rotation matrix. This matrix contains information about rotations around the standard axis.\n$$ \\begin{aligned} \\begin{bmatrix} m_1 \u0026 m_2 \u0026 m_3 \\\\ m_5 \u0026 m_6 \u0026 m_7 \\\\ m_9 \u0026 m_{10} \u0026 m_{11} \\end{bmatrix} \\end{aligned} $$Translation Vector The intersection of the first three rows with the last column defines a three-component Translation vector.\n$$ \\begin{aligned} \\begin{bmatrix} m_{13} \u0026 m_{14} \u0026 m_{15} \\end{bmatrix} \\end{aligned} $$The Mysterious Fourth Row The fourth row does not have any special meaning.\nThe $m_4$, $m_8$, and $m_{12}$ elements are always $0$. The $m_{16}$ element (the Homogeneous coordinate) will always be $1$. ","the-projection-matrix#The Projection Matrix":"Projection matrices are specialized $4$x$4$ matrices designed to transform a 3D point in camera space into its projected counterpart on the canvas. Essentially, when you multiply a 3D point by a projection matrix, you determine its 2D coordinates on the canvas within NDC (Normalized Device Coordinates) space (we’ll see what these are later). Points in NDC space fall within the range $[-1, 1]$.\nIt’s crucial to remember that projection matrices are intended for transforming vertices or 3D points, not vectors. The workaround involves treating points as $1\\times 4$ vectors, enabling their multiplication by a $4\\times 4$ matrix. The result is another $1\\times 4$ matrix, or 4D points with homogeneous coordinates. These coordinates are only directly applicable as 3D points if their fourth component is $1$, allowing the first three components to represent a standard 3D Cartesian point.\nThis operation determines how much of the view space will be rendered and how it will be mapped onto the computer screen. This region is known as the frustum and it is defined by six planes (near, far, top, bottom, right, and left planes), as shown in the following diagram:\nThese six planes are encoded in the Projection matrix. Any vertices lying outside the frustum after applying the transformation are clipped out and discarded from further processing. Therefore, the frustum defines clipping coordinates, and the Projection matrix that encodes the frustum produces clipping coordinates.\nIf the far and near planes have the same dimensions, the frustum will then determine an orthographic projection. Otherwise, it will be a perspective projection.\nWe went from Camera Space (all vertices defined relatively to the camera) to Homogeneous Space (all vertices defined in a small cube. Everything inside the cube is onscreen).\nBefore projection, we’ve got our blue objects, in Camera Space, and the red shape represents the frustum of the camera: the part of the scene that the camera is actually able to see.\nMultiplying everything by the Projection Matrix has the following effect:\nPerspective or Orthogonal Projection A perspective projection assigns more space to details that are closer to the camera than details that are farther away. In other words, the geometry that is close to the camera will appear larger than the geometry that is farther from it.\nIn contrast, an orthogonal projection uses parallel lines; this means that lines will appear to be the same size, regardless of their distance to the camera.\nPerspective Matrix The Projection matrix determines the field of view (FOV) of the camera. Which is how much of the 3D space will be captured by the camera. It is a measure given in degrees, and the term is used interchangeably with the term angle of view.\nPerspective Matrix Orthographic Matrix Orthographic Matrix ","the-view-matrix#The View Matrix":"It you want to view a moutain from another angle, you can either move the camera… or move the mountain.\nSo initially your camera is at the origin of the World Space. In order to move the world, you simply introduce another matrix. Let’s say you want to move your camera of $3$ units to the right ($+X$). This is equivalent to moving your whole world $3$ units to the left ($-X$).\nWe went from World Space (all vertices defined relatively to the center of the world, as we made so in the previous section) to Camera Space (all vertices defined relatively to the camera). The figure below shows how we go from model/object coordinates to world coordinates and finally to camera coordinates."},"title":"Model, View and Projection Transform"},"/notes/cs/rtgw/04/02_model_view/02_01_perspective/":{"data":{"":"","derivation#Derivation":"We need to figure out how $P_{sx}$ and $P_{sy}$ correlate with the WebGL perspective matrix. The purpose of a projection matrix is to remap the values projected onto the image plane to a unit cube (defined by minimum $(-1, -1, -1)$ and maximum $(1, 1, 1)$).\nProjected X Once the point $P$ is projected onto the image plane (near clipping plane), is considered visible if its and coordinates fall within the range $[left, right]$ for $x$ and $[bottom, top]$ for $y$, as depicted in Figure 2.\nSuch that:\n$$ \\begin{aligned} l \\leq P_{sx} \\leq r \\end{aligned} $$where $l$ and $r$ are the left and right coordinates respectively. Our objective is to remap so that its final value resides within the range $[-1, 1]$:\n$$ \\begin{aligned} 0 \\leq P_{sx} - l \\leq r - l \\end{aligned} $$normalizing by dividing by $r - l$ gives:\n$$ \\begin{aligned} 0 \\leq \\frac{P_{sx} - l}{r - l} \\leq 1 \\end{aligned} $$multiplying all terms by $2$:\n$$ \\begin{aligned} 0 \\leq 2 \\frac{P_{sx} - l}{r - l} \\leq 2 \\end{aligned} $$substracting $1$ from all terms results in:\n$$ \\begin{aligned} -1 \\leq 2 \\frac{P_{sx} - l}{r - l} - 1 \\leq 1 \\end{aligned} $$Now the central term on the inequality is defined to exist on the range $[-1, 1]$, which is what we wanted. With some further rearrangement:\n$$ \\begin{aligned} -1 \\leq 2 \\frac{P_{sx} - l}{r - l} - \\frac{r - l}{r - l} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2P_{sx} - 2l - r + l}{r - l}\\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2P_{sx} - r - l}{r - l}\\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2P_{sx}}{r - l} - \\frac{r + l}{r - l}\\leq 1 \\end{aligned} $$The two central terms are quite similar to the first two terms of the first row in the WebGL perspective projection matrix. If we replace $P_{sx}$ from the previous equation with\n$$ \\begin{aligned} P_{sx} = \\frac{n P_x}{-P_z} \\end{aligned} $$we get:\n$$ \\begin{aligned} -1 \\leq \\frac{2nP_x}{-P_z(r - l)} - \\frac{r + l}{r - l}\\leq 1 \\end{aligned} $$We can encode this equation in matrix form if we replace the first and third coefficients of the matrix’s first row with the first and second term of this formula:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2n}{r - l} \u0026 0 \u0026 \\frac{r + l}{r - l} \u0026 0 \\\\ \\cdots \u0026 \\cdots \u0026 \\cdots \u0026 \\cdots \\\\ \\cdots \u0026 \\cdots \u0026 \\cdots \u0026 \\cdots \\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\end{aligned} $$So computing $P_{sx}$ yields:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2n}{r - l} \u0026 0 \u0026 \\frac{r + l}{r - l} \u0026 0 \\\\ \\cdots \u0026 \\cdots \u0026 \\cdots \u0026 \\cdots \\\\ \\cdots \u0026 \\cdots \u0026 \\cdots \u0026 \\cdots \\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\cdot \\begin{bmatrix} P_x \\\\ P_y \\\\ P_z \\\\ P_w \\\\ \\end{bmatrix} \\end{aligned} $$such that:\n$$ \\begin{aligned} P_{sx} = \\frac{2n}{r - l} P_x + \\frac{r + l}{r - l} P_z \\end{aligned} $$And since $P_{sx}$ will be divided at the end of the process by $-P_z$ when we convert from homogeneous to Cartesian coordinates, we get:\n$$ \\begin{aligned} P_{sx} = \\frac{\\frac{2n}{r - l} P_x}{-P_z} + \\frac{\\frac{r + l}{r - l} P_z}{-P_z} = \\frac{2nP_x}{-P_z(r - l)} - \\frac{r + l}{r - l} \\end{aligned} $$This is the first coordinate of the projected point $P_{s}$ computed using the WebGL perspective matrix.\nProjected Y The derivation for $P_{sy}$ is analogous, replacing $l$ and $r$ with and $b$ and $t$, such that:\n$$ \\begin{aligned} b \\leq P_{s_y} \\leq t \\end{aligned} $$$$ \\begin{aligned} 0 \\leq P_{s_y} - b \\leq t - b \\end{aligned} $$$$ \\begin{aligned} 0 \\leq \\frac{P_{s_y} - b}{t - b} \\leq 1 \\end{aligned} $$We multiply by $2$:\n$$ \\begin{aligned} 0 \\leq 2\\frac{P_{s_y} - b}{t - b} \\leq 2 \\end{aligned} $$And we substract $1$:\n$$ \\begin{aligned} -1 \\leq 2\\frac{P_{s_y} - b}{t - b} - 1 \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq 2\\frac{P_{s_y} - b}{t - b} - \\frac{t - b}{t - b} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2P_{s_y} - 2b - t + b}{t - b} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2P_{s_y} - b - t}{t - b} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2P_{s_y}}{t - b} - \\frac{t + b}{t - b} \\leq 1 \\end{aligned} $$Given we know that:\n$$ \\begin{aligned} P_{s_y} = \\frac{n P_y}{-P_z} \\end{aligned} $$then:\n$$ \\begin{aligned} -1 \\leq \\frac{2n P_y}{-P_z(t - b)} - \\frac{t + b}{t - b} \\leq 1 \\end{aligned} $$Therefore, now our projection matrix has the following shape:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2n}{r - l} \u0026 0 \u0026 \\frac{r + l}{r - l} \u0026 0 \\\\ 0 \u0026 \\frac{2n}{t - b} \u0026 \\frac{t + b}{t - b} \u0026 0 \\\\ \\cdots \u0026 \\cdots \u0026 \\cdots \u0026 \\cdots \\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\end{aligned} $$Computing $P_{s_y}$ using this matrix gives:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2n}{r - l} \u0026 0 \u0026 \\frac{r + l}{r - l} \u0026 0 \\\\ 0 \u0026 \\frac{2n}{t - b} \u0026 \\frac{t + b}{t - b} \u0026 0 \\\\ \\cdots \u0026 \\cdots \u0026 \\cdots \u0026 \\cdots \\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ w \\\\ z \\\\ \\end{bmatrix} \\end{aligned} $$$$ \\begin{aligned} P_{s_y} = 0 \\cdot x + \\frac{2n}{t - b} P_y + \\frac{t + b}{t - b}P_z + 0 \\end{aligned} $$and after the divsion by $-P_z$:\n$$ \\begin{aligned} P_{s_y} = \\frac{\\frac{2n}{t - b}P_y}{-P_z} + \\frac{\\frac{t + b}{t - b}P_z}{-P_z} \\end{aligned} $$$$ \\begin{aligned} = \\frac{2n P_y}{-P_z(t - b)} - \\frac{t + b}{t - b} \\end{aligned} $$Projected Z All that’s left to do to complete it is find a way to remap the z-coordinate of the projected points to the range $[-1,1]$\nWe know that the $x$ and $y$ coordinates of $P$ don’t contribute to the calculation of the projected point’s z-coordinate. Thus, the first and second coefficients of the matrix’s third row are necessarily zero. We are left with the following matrix:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2n}{r - l} \u0026 0 \u0026 \\frac{r + l}{r - l} \u0026 0 \\\\ 0 \u0026 \\frac{2n}{t - b} \u0026 \\frac{t + b}{t - b} \u0026 0 \\\\ 0 \u0026 0 \u0026 A \u0026 B \\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\end{aligned} $$If we write the equation to compute $P_{s_z}$ using this matrix, we get:\n$$ \\begin{aligned} P_{s_z} = \\frac{0 \\cdot P_x + 0 \\cdot P_y + A \\cdot P_z + B \\cdot P_w}{P_{s_w} = - P_z} \\end{aligned} $$$$ \\begin{aligned} \\frac{A \\cdot P_z + B}{P_{s_w} = -P_z} \\end{aligned} $$Note that we are dividing $P_{s_z}$ by $P_{s_w}$ when the point is converted from homogeneous to Cartesian coordinates, and that $P_w = 1$.\nWe need to find the values of $A$ and $B$. We know that when $P_z$ is on the near clipping plane, $P_{s_z}$ needs to be remapped to $-1$, and when $P_z$ is on the far clipping plane, $P_{s_z}$needs to be remapped to $1$.\nSo, when $P_z$ is on the near plane, the previous equation is as follows:\n$$ \\begin{aligned} \\frac{A \\cdot (P_z = -n) + B}{(-P_z = -(-n) = n)} = -1 \\end{aligned} $$$$ \\begin{aligned} \\frac{A \\cdot -n + B}{n} = -1 \\end{aligned} $$$$ \\begin{aligned} -nA + B = -n \\end{aligned} $$And when $P_z$ is on the far plane:\n$$ \\begin{aligned} \\frac{A \\cdot (P_z = -f) + B}{(-P_z = -(-f) = f)} = 1 \\end{aligned} $$$$ \\begin{aligned} \\frac{A \\cdot -f + B}{f} = 1 \\end{aligned} $$$$ \\begin{aligned} -fA + B = f \\end{aligned} $$These two equations form the following system of equations:\n$$ \\begin{aligned} \\begin{cases} -nA + B = -n \\\\ -fA + B = f \\end{cases} \\end{aligned} $$We solve the first equation for $B$:\n$$ \\begin{aligned} B = -n + An \\end{aligned} $$And we substitute on the second equation:\n$$ \\begin{aligned} -fA + (-n + An) = f \\end{aligned} $$$$ \\begin{aligned} A (n - f) = f + n \\end{aligned} $$$$ \\begin{aligned} A= -\\frac{f + n}{f - n} \\end{aligned} $$Finding $B$ is straightforward. We just replace $A$ in the first equation:\n$$ \\begin{aligned} B = -n + (-\\frac{f + n}{f - n})n \\end{aligned} $$$$ \\begin{aligned} B = -n(1 + \\frac{f + n}{f - n}) \\end{aligned} $$$$ \\begin{aligned} B = -n(\\frac{f + n + f - n}{f - n}) \\end{aligned} $$$$ \\begin{aligned} B = -n(\\frac{2f}{f - n}) \\end{aligned} $$$$ \\begin{aligned} B = -\\frac{2fn}{f - n} \\end{aligned} $$We can replace the solutions we found for A and B in our matrix, and we finally get:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2n}{r - l} \u0026 0 \u0026 \\frac{r + l}{r - l} \u0026 0 \\\\ 0 \u0026 \\frac{2n}{t - b} \u0026 \\frac{t + b}{t - b} \u0026 0 \\\\ 0 \u0026 0 \u0026 -\\frac{f + n}{f - n}\u0026 -\\frac{2fn}{f - n} \\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\end{aligned} $$","fundamentals#Fundamentals":"Let’s now examine how points are projected in OpenGL (or WebGL). A line is drawn from the camera’s origin to the point $P$ that we want to project, and the intersection of this line with the image plane determines the position of the projected point $P_s$. It’s important to note that in OpenGL, the image plane is situated on the near clipping plane.\nThe triangles $\\Delta ABC$ and $\\Delta DEF$ are similar. Thus, we can express:\n$$ \\begin{aligned} \\frac{AB}{DE} = \\frac{BC}{EF} \\end{aligned} $$By substituting $AB$ with $n$ (the near clipping plane), $DE$ with $P_z$ (the z-coordinate of $P$), and $EF$ with $P_y$ (the y-coordinate of $P$), we can rewrite this equation as:\n$$ \\begin{aligned} \\frac{n}{-P_z} = \\frac{BC}{P_y} \\end{aligned} $$And solving for $BC$ we obtain:\n$$ \\begin{aligned} BC = P_{sy} \\frac{n \\cdot P_y}{-P_z} \\end{aligned} $$Note that since the camera is oriented along the negative z-axis, $P_z$ is negative, so, to maintain the sign of the y-coordinate, we negate $P_z$. Following the same logic, we derive the x-coordinate of the projected point with the following equation:\n$$ \\begin{aligned} P_{s_x} = \\frac{n \\cdot P_x}{-P_z} \\end{aligned} $$Following the same reasoning for $P_y$, we obtain:\n$$ \\begin{aligned} P_{s_y} = \\frac{n \\cdot P_y}{-P_z} \\end{aligned} $$","note#Note":"This section is kinda important, up until now we have define this projection matrix on what we call row-major order. However, WebGL expects us to use matrices defined on column-major order. See Transposing Transformation or Projection Matrices on how to correctly defined these matrices.","references#References":" The Perspective Projection Matrix ","the-field-of-view-and-image-aspect-ratio#The Field of View and Image Aspect Ratio":"The field of view and the image aspect ratio are somehow related to the projection process. The construction of the matrix relies on six parameters: the left, right, bottom, and top coordinates, as well as the near and far clipping planes. The user provides the values for the near and far clipping planes, but how about the left, right, bottom, and top coordinates? What are these, where do they come from, and how do we calculate them?\nObserving the following figure, you can see that these coordinates correspond to the lower-left and upper-right corners of the frustum front face, where the image of the 3D scene is projected:\nThe angle of view can either be defined vertically or horizontally. OpenGL tends to define the field-of-view as vertical (hence the Y in FOVY).\nComputing the Coordinates To compute the top coordinate, we look at the right-angled triangle $ABC$ on the following image.\nThe angle between by $AB$ and $AC$ is half the FOV. Also, the adjacent side of the triangle is the value for the near-clipping plane. Using trigonometry, we can express this as:\n$$ \\begin{aligned} \\tan(\\frac{FOVY}{2}) = \\frac{opposite}{adyacent} = \\frac{BC}{AB} = \\frac{top}{near} \\end{aligned} $$Therefore:\n$$ \\begin{aligned} top = \\tan(\\frac{FOVY}{2}) \\cdot near \\end{aligned} $$And since the bottom half of the camera is symmetrical to the upper half, we can state that:\n$$ \\begin{aligned} bottom = -top \\end{aligned} $$\nIn Figure 5, two scenarios are considered: the image can either be square or rectangular. For a square camera, it’s straightforward: the left and bottom coordinates are the same, the right and top coordinates are also the same. Therefore:\n$$ \\begin{aligned} top = \\tan(\\frac{FOVY}{2}) \\cdot near \\end{aligned} $$$$ \\begin{aligned} left = bottom = -top \\end{aligned} $$$$ \\begin{aligned} right = top \\end{aligned} $$For a non-square camera, as shown in the right inside of figure 5, the bottom and top coordinates remain the same, but the left and right coordinates are scaled by the aspect ratio, defined as the image width over the image height. The general formulas for computing the left, right, and bottom coordinates are:\n$$ \\begin{aligned} aspect ratio = \\frac{width}{heigth} \\end{aligned} $$$$ \\begin{aligned} top = \\tan(\\frac{FOVY}{2}) \\cdot near \\end{aligned} $$$$ \\begin{aligned} bottom = -top \\end{aligned} $$$$ \\begin{aligned} right = top \\cdot aspect ratio \\end{aligned} $$$$ \\begin{aligned} left = bottom \\cdot aspect ratio \\end{aligned} $$"},"title":"Perspective Matrix"},"/notes/cs/rtgw/04/02_model_view/02_02_orthographic/":{"data":{"":"","derivation#Derivation":"We will refer to these screen coordinates as $l$, $r$, $t$, and $b$, which stand for left, right, top, and bottom, respectively.\nProjection of $x$ Now, we need to remap the left and right screen coordinates $(l, r)$ to $-1$ and $1$, and apply the same remapping to the top and bottom coordinates $(t, b)$. Assuming $x$ is any point within the range $[l ,r]$, we can state:\n$$ \\begin{aligned} l \\leq x \\leq r \\end{aligned} $$$$ \\begin{aligned} 0 \\leq x - l \\leq r - l \\end{aligned} $$$$ \\begin{aligned} 0 \\leq \\frac{x - l}{r - l} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} 0 \\leq 2\\frac{x - l}{r - l} \\leq 2 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq 2\\frac{x - l}{r - l} -1 \\leq 1 \\end{aligned} $$Now, the middle term falls within the range $[-1, 1]$, successfully remapping it. To further develop this formula:\n$$ \\begin{aligned} -1 \\leq \\frac{2x - 2l - r + l}{r - l} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2x - l - r}{r - l} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2x}{r - l} - \\frac{r + l}{r - l} \\leq 1 \\end{aligned} $$This yields the transformation formula for $x$:\n$$ \\begin{aligned} x' = \\frac{2x}{r - l} - \\frac{r + l}{r - l} \\end{aligned} $$To represent this transformation in matrix form:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2}{r - l} \u0026 0 \u0026 0 \u0026 -\\frac{r + l}{r - l} \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\end{aligned} $$So:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2}{r - l} \u0026 0 \u0026 0 \u0026 -\\frac{r + l}{r - l} \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{2x}{r - l} - \\frac{r + l}{r - l} \\\\ y \\\\ z \\\\ 1 \\\\ \\end{bmatrix} \\end{aligned} $$Projection of $y$ The process for the y-coordinate is the same. You just need to replace $r$ and $l$ with $t$ and $b$ (top and bottom).\n$$ \\begin{aligned} b \\leq y \\leq t \\end{aligned} $$$$ \\begin{aligned} 0 \\leq y - b \\leq t - b \\end{aligned} $$$$ \\begin{aligned} 0 \\leq \\frac{y - b}{t - b} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} 0 \\leq 2\\frac{y - b}{t - b} \\leq 2 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq 2\\frac{y - b}{t - b} - 1 \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2y - 2b - t + b}{t - b} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2y - b - t}{t - b} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{2y}{t - b} - \\frac{t + b}{t - b} \\leq 1 \\end{aligned} $$So the transformation formula for $y$ is as follows:\n$$ \\begin{aligned} y' = \\frac{2y}{t - b} - \\frac{t + b}{t - b} \\end{aligned} $$Which yields the following transformation matrix:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2}{r - l} \u0026 0 \u0026 0 \u0026 -\\frac{r + l}{r - l} \\\\ 0 \u0026 \\frac{2}{t - b} \u0026 0 \u0026 -\\frac{t + b}{t - b} \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\end{aligned} $$So:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2}{r - l} \u0026 0 \u0026 0 \u0026 -\\frac{r + l}{r - l} \\\\ 0 \u0026 \\frac{2}{t - b} \u0026 0 \u0026 -\\frac{t + b}{t - b} \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{2x}{r - l} - \\frac{r + l}{r - l} \\\\ \\frac{2y}{t - b} - \\frac{t + b}{t - b} \\\\ z \\\\ 1 \\\\ \\end{bmatrix} \\end{aligned} $$Projection of $z$ And finally, to complete our orthographic projection matrix, we need to remap the z-coordinates from $-1$ to $1$. We start with the following condition:\n$$ \\begin{aligned} n \\leq -z \\leq f \\end{aligned} $$Don’t forget that the $z$-coordinates of all points visible to the camera are negative, which is why we use $-z$ instead of $z$.\n$$ \\begin{aligned} 0 \\leq -z - n\\leq f - n \\end{aligned} $$$$ \\begin{aligned} 0 \\leq \\frac{-z - n}{f - n} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} 0 \\leq 2\\frac{-z - n}{f - n} \\leq 2 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq 2\\frac{-z - n}{f - n} - 1 \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{-2z - 2n -f + n}{f - n} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{-2z - n - f}{f - n} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{-2z}{f - n} - \\frac{n + f}{n - f}{f - n} \\leq 1 \\end{aligned} $$Now we add this to the matrix:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2}{r - l} \u0026 0 \u0026 0 \u0026 -\\frac{r + l}{r - l} \\\\ 0 \u0026 \\frac{2}{t - b} \u0026 0 \u0026 -\\frac{t + b}{t - b} \\\\ 0 \u0026 0 \u0026 -\\frac{2}{f - n} \u0026 -\\frac{n + f}{n - f} \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\end{aligned} $$So:\n$$ \\begin{aligned} \\begin{bmatrix} \\frac{2}{r - l} \u0026 0 \u0026 0 \u0026 -\\frac{r + l}{r - l} \\\\ 0 \u0026 \\frac{2}{t - b} \u0026 0 \u0026 -\\frac{t + b}{t - b} \\\\ 0 \u0026 0 \u0026 -\\frac{2}{f - n} \u0026 -\\frac{n + f}{n - f} \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{2x}{r - l} - \\frac{r + l}{r - l} \\\\ \\frac{2y}{t - b} - \\frac{t + b}{t - b} \\\\ \\frac{-2z}{f - n} - \\frac{f + n}{f - n} \\\\ 1 \\\\ \\end{bmatrix} \\end{aligned} $$","intro#Intro":"In this chapter, we will explore how to construct a matrix that projects a point from camera space onto the image plane of an orthographic camera.\nThe aim of the orthographic projection matrix is to remap all coordinates within a specific 3D space bounding box to the canonical viewing volume. For that we need to know the scene’s bounding box, that is the bounding box that encompasses all the objects on the scene. The orthographic matrix then aims to remap this box to a canonical view volume, defined by minimum and maximum extents of $(-1, -1, -1)$ and $(1, 1, 1)$.\nOnce we have computed the scene bounding box, we need to project the minimum and maximum extents of this bounding box onto the image plane of the camera. The $x$- and $y$-coordinates of any point expressed in camera space and the $x$- and $y$-coordinates of the same points projected onto the image plane remain identical. It may be necessary to adjust the projection of the bounding box’s minimum and maximum extents onto the screen to ensure the screen window is either square or maintains the same aspect ratio as the image.","note#Note":"This section is kinda important, up until now we have define this projection matrix on what we call row-major order. However, WebGL expects us to use matrices defined on column-major order. See Transposing Transformation or Projection Matrices on how to correctly defined these matrices.","references#References":" Orthographic Matrix "},"title":"Orthografic Matrix"},"/notes/cs/rtgw/04/03_normal_transform/":{"data":{"":"","#":"Calculating the Normal Matrix Two vectors are perpendicular if their dot product is $0$. In our example\n$$ \\begin{aligned} = 0 \\end{aligned} $$Here, $S$ is the surface vector and can be calculated as the difference of two vertices. Let $M$ be the Model-View matrix. We can use $M$ to transform $S$ as follows:\n$$ \\begin{aligned} S' = MS \\end{aligned} $$We want to find a matrix, $K$, that allows us to transform normals in a similar way. For the $N$ normal, we want the following:\n$$ \\begin{aligned} N' = KN \\end{aligned} $$For the scene to be consistent after obtaining $N’$ and $S’$, these two need to keep the perpendicularity that the original vectors $N$ and $S$ had.\n$$ \\begin{aligned} "},"title":"Normal Transform"},"/notes/cs/rtgw/04/04_camera/":{"data":{"":"","basic-camera-types#Basic Camera Types":"So far, we’ve learned how to generate rotations and translations in either world or camera coordinates. In both cases, however, we are always generating the rotations around the center of the world. This may be ideal when we’re orbiting around a 3D object. We will refer to this type of camera as an orbiting camera.\nIf we are able to look left and right (rotations) and then move in the direction in which our camera is pointing (translation), then this camera type can be designated as a first-person camera and it is generally known as a tracking camera.\nWhen applying transformation the order of the operations affects the result. It is not the same to rotate around the origin and then translate away from it (orbiting camera), as compared to translating the origin and then rotating around it (tracking camera).\nWith an orbiting camera, the camera will always look toward the center of the world. Therefore, we will always use the z-axis to move to and from the object we are examining. However, with a tracking camera, since the rotation occurs at the camera location, we can end up looking to any position in the world. Thus, we need to know the direction in which the camera is pointing in world coordinates (camera axis).","camera-translation#Camera Translation":"Let’s move the camera to $[0, 0, 4]$ in world coordinates. This means four units from the origin on the positive z-axis. If we applied:\nmat4.translate(modelViewMatrix, modelViewMatrix, [0, 0, 4]); In such a case, the world would be translated 4 units on the positive z-axis, and since the camera position has not been changed, it would be located at $[0, 0, -4]$, which is exactly the opposite of what we want. Now, say that we applied the translation in the opposite direction:\nmat4.translate(modelViewMatrix, modelViewMatrix, [0, 0, -4]); In such a case, the world would be moved 4 units on the negative z-axis and then the camera would be located at $[0, 0, 4]$ in the new world-coordinate system.\nThe Camera matrix transformation is the inverse of the Model-View matrix transformation.","interpreting-transformations-using-the-model-view-matrix#Interpreting Transformations Using the Model-View Matrix":"\nAs we’ve just seen, understanding the rotation matrix (the $3 \\times 3$ upper-left corner of the Model-View matrix) is simple: the first $3$ columns always tell us where the axis is.","the-camera-model#The Camera Model":"Just like the Model-View matrix, the Camera matrix encodes information about the camera orientation. As we can see in the following diagram, the upper-left $3 \\times 3$ matrix corresponds to the camera axes:\nThe first column corresponds to the x-axis of the camera. We will call it RightVector. The second column is the y-axis of the camera. This will be UpVector. The third column determines the vector in which the camera can move back and forth. This is the z-axis of the camera and we will call it CameraAxis. Because the Camera matrix is the inverse of the Model-View matrix, the upper-left $3 \\times 3$ rotation matrix contained in the Camera matrix gives us the orientation of the camera axes in world space. This means that we can tell the orientation of our camera in world space just by looking at the columns of this $3 \\times 3$ rotation matrix."},"title":"Camera Matrix"},"/notes/cs/rtgw/05/":{"data":{"":"","animating-a-3d-scene#Animating a 3D scene":"Animating a scene is nothing more than applying the appropriate local transformations to the objects in the scene. For instance, if we want to move a cone and a sphere, each one of them will have a corresponding local transformation that will describe its location, orientation, and scale.\nWe should address when to apply these transforms. If we calculate the position to apply to the cone and sphere in our example every time we call the render function, this would imply that the animation rate would depend on the speed of our rendering cycle. A slow rendering cycle would produce choppy animations and too fast a rendering cycle would create the illusion of objects jumping from one side to the other without smooth transitions.\nThe requestAnimationFrame Function One of the advantages of leveraging this function is that it is designed to call the rendering function (whatever function we indicate) only when the browser/tab window is in focus.","interpolation#Interpolation":"Interpolation greatly simplifies a 3D objects’ animation. Unlike parametric curves, it is not necessary to define the position of the object as a function of time. When interpolation is used, we only need to define control points or knots. The set of control points describes the path that a particular animate object will follow.\nLinear Interpolation This method requires that we define the starting and ending points of the location of our object, along with the number of interpolating steps. The object will move on the line determined by the starting and ending point:\nPolynomial Interpolation This method allows us to determine as many control points as we want. The object will move from the starting point to the ending point and will pass through each one of the control points in between\nWhile using polynomials, an increasing number of control points can produce undesired oscillations on the object’s path described by this technique. This is known as Runge’s phenomenon.\nB-Splines This method is similar to polynomial interpolation with the difference that the control points are outside of the object’s path. In other words, the object does not pass through the control points as it moves. B-splines also respond better to Runge’s phenomenon:","matrix-stacks#Matrix Stacks":"A matrix stack provides a way to apply local transforms to individual objects in our scene while preserving global transforms.\nThe matrix stack works at each rendering cycle, it requires calculating the scene matrices to react to camera movements. The update is done in the following steps:\nGlobal Transform: Update the model-view matrix for each object and push it to the stack. This allows us to recover the original matrix once we’ve applied local transforms. Local Transform: Update Model-View matrix for each object in the scene by multiplying the original Model-View matrix by a matrix that represents the rotation, translation, and/or scaling of each object in the scene. Recover the original matrix for the stack. Repeat the process for each object on the scene. The following diagram shows this procedure for one object:","optimizing-batch-performance#Optimizing Batch Performance":"WebGL 2 adds some interesting features, such as geometry-instancing. This feature allows us to render the same instance of a single mesh with differing shader attributes using instancing and only one render call. Though instancing is limited, as it’s based on the same mesh only, it’s still a great way to improve performance if you have to draw the same meshes multiple times, especially if combined with shaders.","parametric-curves#Parametric Curves":"There are many situations where we don’t know the exact position of an object at a given time, but we do know an equation that describes its movement. These equations are known as parametric curves. The following diagram shows the parametric equation that describes the free-fall motion:\n$$ \\begin{aligned} h = H_0 + V_0t - \\frac{1}{2}gt^2 \\end{aligned} $$where $g$ is the gravity at $9.8 m/s$, $V_0$ is the initial velocity, $H_0$ is the initial position, $t$ is the time and $h$ is the position at $t$.","scene-graph#Scene graph":"This is a data structure, commonly used by vector-based graphics-editing applications and modern computer games, that arranges the logical and often spatial representation of a graphical scene. A scene graph is a collection of nodes in a graph or tree structure.","webgl-matrix-naming-conventions#WebGL Matrix Naming Conventions":"Before we go any further, let’s take a moment to quickly summarize some of the conventions around matrix-naming:\nWorld Matrix: Sometimes referred to as the Model matrix, this is a matrix that takes the vertices of a model and moves them to world space. Camera Matrix: This matrix positions the camera in the world. You can also think of it as the World matrix for the camera. View Matrix: This matrix moves everything else in the world in front of the camera. As we’ve seen, this is the inverse of the Camera matrix. Projection Matrix: This is the matrix that converts a frustum of space into clip space. You can also think of it as the matrix returned by your matrix math library’s perspective or orthographic function. Local Matrix: The matrix is used in scene graphs, where the matrix, at any particular node on the graph, is used before multiplying with any other nodes. "},"title":"Animations"},"/notes/cs/rtgw/06/":{"data":{"":"","alpha-blending#Alpha Blending":"Alpha blending is enabled using the following line of code:\ngl.enable(gl.BLEND); For each available fragment, the alpha blending operation reads the color from the framebuffer by the appropriate fragment coordinates and creates a new color based on a linear interpolation between the previously calculated color in the fragment shader and the color from the framebuffer.\nThe Blending Function With blending enabled, the next step is to define a blending function. This function will determine how fragment colors from the object (source) are combined with the fragment colors present in the framebuffer (destination).\nWe combine source and destination colors as follows:\ncolor = S ** sW + D ** dW; Where:\nS: source color (vec4) D: destination color (vec4) sW: source scaling factor dW: destination scaling factor S.rgb: RGB components of the source color S.a: Alpha component of the source color D.rgb: RGB components of the destination color D.a: Alpha component of the destination color It’s important to note that the rendering order will determine the source and the destination fragments.\nIf a sphere is rendered first, it will then become the destination of the blending operation because the sphere fragments are stored in the framebuffer at the time that the cone is rendered. In other words, alpha blending is a non-commutative operation with respect to rendering order:\nSeparate Blending Functions It is also possible to determine how the RGB channels are going to be combined independently from the alpha channels. For that, we use the gl.blendFuncSeparate function.\nWe define two independent functions this way:\ncolor = S.rgb ** sW.rgb + D.rgb ** dW.rgb; alpha = S.a ** sW.a + D.a ** dW.a; More precisely:\nS.rgb: RGB components of the source color sW.rgb: is the source scaling factor (only RGB) S.a: Alpha component of the source color sW.a: is the source scaling factor for the source alpha value D.rgb: RGB components of the destination color sW.rgb: is the destination scaling factor (only RGB) D.a: Alpha component of the destination color sD.a: is the source scaling factor for the destination alpha value Then, we could have something such as the following:\ncolor = S.rgb ** S.a + D.rgb ** (1.0 - S.a); alpha = S.a ** 1.0 + D.a ** 0.0; This would be translated into code as follows:\ngl.blendFuncSeparate(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ZERO); The Blend Equation We could have a case where we do not want to interpolate the source and destination fragment colors with scale or add operations. For example, we may want to subtract one from the other. In this case, WebGL provides the gl.blendEquation function.\nThis function receives one parameter that determines the operation on the scaled source and destination fragment colors. For example, gl.blendEquation(gl.FUNC_ADD) is calculated as such:\ncolor = S ** sW + D ** dW; And, gl.blendEquation(gl.FUNC_SUBTRACT) corresponds to the following:\ncolor = S ** sW - D ** dW; There is a third option, gl.blendEquation(gl.FUNC_REVERSE_SUBTRACT), that corresponds to the following:\ncolor = D** dw - S ** sW; As expected, you can define the blending equation separately for the RGB channels and for the alpha channel. For that, we use the gl.blendEquationSeparate function.\nWebGL Alpha-Blending API WebGL function Description gl.enable/disable(gl.BLEND) Enable/disable blending gl.blendFunc(sW, dW) Specify pixel arithmetic gl.blendFuncSeparate(sW_rgb, dW_rgb, sW_a, dW_a) Specify pixel arithmetic for RGB and alpha components separately gl.blendEquation(mode) Specify the equation used for both the RGB blend equation and the alpha blend equation gl.blendEquationSeparate(modeRGB, modeAlpha) Set the RGB blend equation and the alpha blend equation separately. gl.blendColor(red, green, blue, alpha) Set the blend color. gl.getParameter(name) Just like with other WebGL variables, it is possible to query blending parameters using gl.getParameter. The Blend Color WebGL provides the gl.CONSTANT_COLOR and gl.ONE_MINUS_CONSTANT_COLOR scaling factors. These scaling factors can be used with gl.blendFunc and gl.blendFuncSeparate. However, we need to first establish the blend color. We do so by invoking gl.blendColor.\nAlpha Blending Modes Depending on the parameter selection for sW and dW, we can create different blending modes.\nAdditive Blending Additive blending simply adds the colors of the source and destination fragments, creating a lighter image. We obtain additive blending by writing the following:\ngl.blendFunc(gl.ONE, gl.ONE); This assigns the weights for source and destination fragments sW and dW to $1$. The color output will be as follows:\ncolor = S ** 1.0 + D ** 1.0; color = S + D; Substractive Blending Similarly, we can obtain subtractive blending by writing the following:\ngl.blendEquation(gl.FUNC_SUBTRACT); gl.blendFunc(gl.ONE, gl.ONE); This will change the blending equation to the following:\ncolor = S ** 1.0 - D ** 1.0; color = S - D; Multiplicative Blending We obtain multiplicative blending by writing the following:\ngl.blendFunc(gl.DST_COLOR, gl.ZERO); This will be reflected in the blending equation as the following:\ncolor = S ** D + D ** 0.0; color = S * D; The result will always be a darker blending\nInterpolative Blending If we set sW to S.a and dW to 1 - S.a, then we get the following:\ncolor = S ** S.a + D **(1 - S.a); This will create a linear interpolation between the source and destination color using the source alpha color, S.a, as the scaling factor. In code, this is translated as the following:\ngl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA); Interpolative blending allows us to create a transparency effect as long as the destination fragments have passed the depth test. As expected, this requires that the objects be rendered from back to front.","creating-transparent-objects#Creating Transparent Objects":"We’ve learned that in order to create transparency, we need to:\nEnable alpha blending and select the interpolative blending function Render the faces of objects back to front How do we create transparent objects when there is nothing to blend them against? In other words, if there’s only one object, how can we make it transparent? One solution is to use face-culling. Face-culling allows us to only render the back or front face of an object.\nSimilar to other options in the pipeline, culling is disabled by default. We enable it by calling the following:\ngl.enable(gl.FACE_CULLING); To render only the back faces of an object, we call gl.cullFace(gl.FRONT) before we call drawArrays or drawElements. Similarly, to render only the front face, we use gl.cullFace(gl.BACK) before the draw call.\nThe following diagram summarizes the steps needed to create a transparent object with alpha blending and face-culling:","depth-testing#Depth Testing":"Each fragment that has been processed by the fragment shader carries an associated depth value. Though fragments are two-dimensional since they’re rendered on the screen, the depth value keeps the information of how far the fragment is from the camera (screen).\nDepth values are stored in a special WebGL buffer named depth buffer or z-buffer. The $z$ comes from the fact that $x$ and $y$ values correspond to the screen coordinates of the fragment, while the $z$ value measures distance perpendicular to the screen.\nAfter the fragment has been calculated by the fragment shader, it becomes available for depth testing. This only occurs if the depth test is enabled.\ngl.enable(gl.DEPTH_TEST); The depth test takes the depth value of a fragment into consideration and compares it to the depth value for the same fragment coordinates already stored in the depth buffer. The depth test determines whether that fragment is accepted for further processing in the rendering pipeline.\nIn normal circumstances, when the depth test is enabled, only those fragments with a lower depth value than the corresponding fragments present in the depth buffer will be accepted.\nDepth testing is a commutative operation with respect to the rendering order. This means that no matter which object gets rendered first, as long as depth testing is enabled, we will always have a consistent scene.\nDepth Function In some applications, we may be interested in changing the default behavior of depth testing, which discards fragments with a higher depth value than those fragments in the depth buffer. For that purpose, WebGL provides the gl.depthFunc(function) method.\nThis method has only one parameter, the function to use:\nParameter Description gl.NEVER The depth test always fails. gl.LESS Only fragments with a depth lower than current fragments on the depth buffer will pass the test gl.LEQUAL Fragments with a depth less than or equal to corresponding current fragments in the depth buffer will pass the test. gl.EQUAL Only fragments with the same depth as current fragments on the depth buffer will pass the test gl.NOTEQUAL Only fragments that do not have the same depth value as fragments on the depth buffer will pass the test. gl.GEQUAL Fragments with greater or equal depth value will pass the test. gl.GREATER Only fragments with a greater depth value will pass the test. gl.ALWAYS The depth test always passes. The depth test is disabled by default in WebGL. When enabled, if no depth function is set, the gl.LESS function is selected by default.","use-of-color-in-lights#Use of Color in Lights":"Scalability Problem Given the desire to use more than one light in our scene, we need to define and map the number of appropriate uniforms of the lighting model of choice. If we have four properties per light (ambient, diffuse, specular, and location), we need to define four uniforms for each light. If we want to have three lights, we need to write, use, and map twelve uniforms! We need to resolve this complexity before it gets out of hand.\nHow Many Uniforms Can We Use To find out the limit for your WebGL implementation, you can query WebGL using the gl.getParameter function with these constants:\ngl.MAX_VERTEX_UNIFORM_VECTORS gl.MAX_FRAGMENT_UNIFORM_VECTORS Simplifying the Problem In order to simplify the problem, we can assume that the ambient component is the same for all of the lights. This will reduce the number of uniforms—one fewer uniform for each light.\nUsing Uniform Arrays to Handle Multiple Lights As we’ve seen, handling light properties with individual uniforms makes the code verbose and difficult to maintain. Fortunately, ESSL provides several mechanisms we can use to solve the problem of handling multiple lights. One of them is uniform arrays.\nThis technique allows us to handle multiple lights by introducing enumerable arrays of vectors in the shaders. This allows us to calculate light contributions by iterating through the light arrays in the shaders.\nuniform vec3 uPositionLight[3]; It’s important to note that ESSL does not support dynamic initialization of uniform arrays. We could try something such as this, but will not work:\nuniform int numLights; uniform vec3 uPositionLight[numLights]; However, this construct is valid:\nconst int numLights = 3; uniform vec3 uPositionLight[numLights]; To map these variables on javascript:\nconst lightPosition1 = [0, 7, 3]; const lightPosition2 = [2.5, 3, 3]; const lightPosition3 = [-2.5, 3, 3]; const location = gl.getUniformLocation(program, \"uPositionLight\"); // The values are concatenated on a single flat array gl.uniform3fv(location, [ ...lightPosition1, ...lightPosition2, ...lightPosition3, ]); Directional Point Lights In this section, we will combine directional and positional lights creating a directional point light, commonly referred to as a spot light.\nThe trick to creating these lights is to subtract the light-direction vector from the normal for each vertex. The resulting vector will create a different Lambert coefficient that will reflect into the cone generated by the light source. On the following excerpts we show a practical example of how a sportlight could be implemented. On the first place we have the vertex shader whose responsability it is to compute:\nThe rays, vRay, for each light source. This is the vector between the position of the light and the position of the vertex (after is has been transformed by the model view). The “modified” normal, vTransformedNormals. This stores the normals after the ligth direction vector has been substracted from it. We will use both of these vectors to compute the lambert term on the fragment shader.\n#version 300 es const int numLights = 3; uniform mat4 uModelViewMatrix; uniform mat4 uNormalMatrix; uniform mat4 uProjectionMatrix; uniform vec3 uLightPositions[numLights]; uniform vec3 uLightDirections[numLights]; in vec3 aPos; in vec3 aNormal; out vec3 vRay[numLights]; out vec3 vTransformedNormals[numLights]; void main(void) { vec4 vertex = uModelViewMatrix * vec4(aPos, 1.0); vec3 normal = vec3(uNormalMatrix * vec4(aNormal, 1.0)); // Iterate over each light for(int i = 0; i \u003c numLights; i++) { // Define each ray as the vector berween the light and the vertex vec4 lightPosition = uModelViewMatrix * vec4(uLightPositions[i], 1.0); vRay[i] = vertex.xyz - lightPosition.xyz; // Transform the direction of the light vec3 directionLight = vec3(uNormalMatrix * vec4(uLightDirections[i], 1.0)); // Transform the normal by substracting the direction of each light vTransformedNormals[i] = normal - directionLight; } gl_Position = uProjectionMatrix * vertex; } Here we have the fragment shader where we compute the final color. This color is made up from two main sources:\nAmbient light Diffuse light: these light is computed taking into account a number of lights given numLights. For each one we incrementally modify the final diffuse light, Id. Note that for each of these diffuse lights we apply the Lambertian Reflection Model, where we compute the final color as the product of the color of the light, the color of the material and finally the cosine of the angle between the light source (vRay) and the normal of the surface (that is the lamberTerm). In this case, instead of the normal of the surface we use our transformed normal, vTransformedNormals.\n#version 300 es precision mediump float; const int numLights = 3; uniform vec4 uLightColors[numLights]; uniform vec4 uMaterialAmbient; uniform vec4 uMaterialDiffuse; uniform vec4 uLightAmbient; uniform float uLightCutOff; in vec3 vRay[numLights]; in vec3 vTransformedNormals[numLights]; out vec4 fragColor; void main(void) { vec4 Ia = uLightAmbient * uMaterialAmbient; vec4 Id = vec4(0.0); // Iterate over each light for(int i = 0; i \u003c numLights; i++) { // Define the normalized transformed normal per each light, as we // have modified the surface normal with the light's direction vec3 N = normalize(vTransformedNormals[i]); vec3 L = normalize(vRay[i]); // Cosine of angle between light and surface float lambertTerm = dot(N, -L); // If cosine is bigger than cutoff (the angle is less than an implicit // threhsold imposed but that cutoff) then we update the // sum of the diffuse color if (lambertTerm \u003e uLightCutOff) { Id += uLightColors[i] ** uMaterialDiffuse ** lambertTerm; } } fragColor = vec4(vec3(Ia + Id), 1.0); } One other thing to note is the uLightCutOff. This variable allows us to create a spotlight, it basically defines the minimum value of the cosine of the angle between the light source and the normal. This cosine is maximized when the light is perpendicular to the surface, and minimized when the light is perpendicular. So with the uLightCutOff we are kind of saying what is the maximum angle we allow between the light and the surface.\nAttenuation Factor However we can use this threshold as the variable to define an attenuation. For example by computing the final color as follows:\nif (lambertTerm \u003e uLightCutOff) { Id += uLightColors[i] ** uMaterialDiffuse ** pow(lamberTerm, 10.0 * uLightCutOff); } So now the effect of lamberTerm is not as straight forward, and it does not increasig “linearly” but by the means of a power function:\n$$ \\begin{aligned} f(x) = \\text{lambert term}^{10 \\text{cutoff}} \\end{aligned} $$This is illustrated of the following figure:","use-of-color-in-the-scene#Use of Color in the Scene":"Transparency The first approach to render transparent objects is to use polygon stippling. This technique consists of discarding some fragments so that you can see through the object. OpenGL supports polygon stippling through the glPolygonStipple function. This function is not available in WebGL. You could try to replicate this functionality by dropping some fragments in the fragment shader using the ESSL discard command. More commonly, we can use the alpha channel information to obtain translucent objects. However, modifying the alpha values does not produce transparency automatically.\nCreating transparency corresponds to altering the fragments that we’ve already written to the framebuffer. On a scene where there is one translucent object in front of an opaque object (from our camera view) we need to be able to see the opaque object through the translucent object. Therefore, the fragments that overlap between the far and near objects need to be combined somehow to create the transparency effect.\nTo properly render transparent surfaces, we need to learn about two important WebGL concepts: depth testing and alpha blending.\nUpdated Rendering Pipeline Depth testing and alpha blending are two optional stages for fragments once they’ve been processed by the fragment shader.\nIf the depth test is not activated, all the fragments are automatically available for alpha blending. If the depth test is enabled, those fragments that fail the test will automatically be discarded by the pipeline and will no longer be available for any other operation. This means that discarded fragments will not be rendered.\nThe following diagram shows the order in which depth testing and alpha blending are performed:","using-colors-in-objects#Using Colors in Objects":"Constant Coloring To obtain a constant color, we store the desired color in a uniform that is passed to the fragment shader. This uniform is usually called the object’s diffuse material property. We can also combine object normals and light-source information to obtain a Lambert coefficient. We can use the Lambert coefficient to proportionally change the reflecting color depending on the angle on which the light hits the object.\nPer-Vertex Coloring To implement per-vertex coloring, we need to define an attribute that stores the color for the vertex in the vertex shader:\nin vec4 aVertexColor; The next step is to assign the aVertexColor attribute to a varying so that it can be passed to the fragment shader. Remember that varyings are automatically interpolated. Therefore, each fragment will have a color that is the weighted result of its contributing vertices.\nIf we want our color map to be sensitive to lighting conditions, we can multiply each vertex color by the diffuse component of the light. The result is then assigned to the varying that will transfer the result to the fragment shader.\nPer-Fragment Coloring We can also assign a random color to each pixel of the object we are rendering.","using-colors-in-weblgl#Using Colors in WeblGL":"WebGL supplies a fourth attribute to the RGB model. This attribute is called the alpha channel. The extended model then is known as the RGBA model, where A stands for alpha. The alpha channel contains a value between the range of $0.0$ to $1.0$.\nA completely opaque color will have an alpha value of $1.0$, whereas a completely transparent color will have an alpha value of $0.0$. This is the general case, but as we will see, we need to take other factors into account when we obtain translucent colors."},"title":"Colors, Depth Testing, and Alpha Blending"},"/notes/cs/rtgw/07/":{"data":{"":"","creating-and-uploading-a-texture#Creating and Uploading a Texture":"Unlike traditional native OpenGL applications, browsers load textures “upside down”. As a result, many WebGL applications set textures to be loaded with the $Y$ coordinate flipped by:\ngl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true); Creating textures follows the same pattern as using buffers:\nCreate a new texture const texture = gl.createTexture(); Bind it to make it the current texture. The first parameter indicates the type of texture we’re binding. gl.bindTexture(gl.TEXTURE_2D, texture); Pass the texture contents // From DOM const image = document.getElementById(\"texture-image\"); gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image); // From Image const texture = gl.createTexture(); const image = new Image(); image.src = \"texture-file.png\"; image.onload = () =\u003e { gl.bindTexture(gl.TEXTURE_2D, texture); gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST); gl.bindTexture(gl.TEXTURE_2D, null); }; Set the filter mode or other texture parameters. We’ll see what filters are later on, the simplest ones are the following: gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST); Unbind the texture gl.bindTexture(gl.TEXTURE_2D, null); When we no longer need the texture we can remove it and free up the associated memory as follows:\ngl.deleteTexture(texture); ","cube-maps#Cube Maps":"A cube map is a cube of textures. Six individual textures are created, each assigned to a different face of the cube. The graphics hardware can sample them as a single entity, by using a 3D texture coordinate.\nThe faces of the cube are identified by the axis they face and whether they are on the positive or negative side of that axis:\nCube mapping introduces a few new texture targets that indicate we are working with cube maps. These targets also indicate which face of the cube map we’re manipulating:\nTEXTURE_CUBE_MAP TEXTURE_CUBE_MAP_POSITIVE_X TEXTURE_CUBE_MAP_NEGATIVE_X TEXTURE_CUBE_MAP_POSITIVE_Y TEXTURE_CUBE_MAP_NEGATIVE_Y TEXTURE_CUBE_MAP_POSITIVE_Z TEXTURE_CUBE_MAP_NEGATIVE_Z Cube maps are created like a normal texture, but binding and property manipulation happen with the TEXTURE_CUBE_MAP target:\nconst cubeTexture = gl.createTexture(); gl.bindTexture(gl.TEXTURE_CUBE_MAP, cubeTexture); gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, gl.LINEAR); gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, gl.LINEAR); When uploading the image data for the texture, you need to specify the side that you are manipulating:\ngl.texImage2D( gl.TEXTURE_CUBE_MAP_POSITIVE_X, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, positiveXImage ); gl.texImage2D( gl.TEXTURE_CUBE_MAP_NEGATIVE_X, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, negativeXImage ); gl.texImage2D( gl.TEXTURE_CUBE_MAP_POSITIVE_Y, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, positiveYImage ); Exposing the cube map texture to the shader is done in the same way as a normal texture, just with the cube map target:\ngl.activeTexture(gl.TEXTURE0); gl.bindTexture(gl.TEXTURE_CUBE_MAP, cubeTexture); gl.uniform1i(program.uCubeSampler, 0); However, the uniform type within the shader is specific to cube maps:\nuniform samplerCube uCubeSampler; When sampling from the cube map, you also use a cube map-specific function:\ntexture(uCubeSampler, vCubeTextureCoords); The 3D coordinates you provide are normalized by the graphics hardware into a unit vector, which specifies a direction from the center of the “cube.” A ray is traced along that vector, and where it intersects the cube face is where the texture is sampled:","texture-filter-modes#Texture Filter Modes":"If you were to zoom in on a texture you would see that it begins to alias, where we can see that jagged edges develop around the WebGL logo.\nWhy do we see these artifacts in the first place? In the fragment shader the texture coordinates provided by the vertex shader are interpolated (as they are varying variables). In a perfect situation, the texture would display at a 1:1 ratio on screen, meaning each pixel of the texture would take up exactly one pixel on screen. In this scenario, there would be no artifacts:\nThe reality of 3D applications, however, is that textures are almost never displayed at their native resolution. We refer to these scenarios as magnification and minification.\nWhen a texture is magnified or minified, there can be some ambiguity about what color the texture sampler should return, for example:\nTexture filtering allows us to control how textures are sampled and achieve the look we want. We change the currently bound texture’s filter mode by:\ngl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST); Note that different textures can have different filters.\nNearest Textures using the NEAREST filter always return the color of the texel whose center is nearest to the sample point. With this mode, textures will look pixilated up close:\nLinear Returns the weighted average of the four pixels whose centers are nearest to the sample point. Also known as bilinear filtering.\nThe graphics hardware has to read four times as many pixels per fragment, so it is slower.\nMipmapping A problem arises when sampling minified textures. In cases where we use LINEAR filtering and the sample points are so far apart, we can completely miss some details of the texture.\nTo avoid this, graphics cards can utilize a mipmap chain. Mipmaps are scaled-down copies of a texture, with each copy being exactly half the size of the previous one.\nWith these chains, graphics hardware can choose the copy of the texture that most closely matches the size of the texture on screen.\nNEAREST_MIPMAP_NEAREST: select the mipmap that most closely matches the size of the texture on screen and samples from it using the NEAREST algorithm. LINEAR_MIPMAP_NEAREST: selects the mipmap that most closely matches the size of the texture on screen and samples from it using the LINEAR algorithm. NEAREST_MIPMAP_LINEAR: selects two mipmaps that most closely match the size of the texture on screen and samples from both of them by using the NEAREST algorithm. The color returned is a weighted average of those two samples. LINEAR_MIPMAP_LINEAR: selects two mipmaps that most closely match the size of the texture on screen and samples from both of them using the LINEAR algorithm. The color returned is a weighted average of those two samples (also known as trilinear filtering). Generating Mipmaps We have to create mipamps for every texture:\ngl.generateMipmap(gl.TEXTURE_2D); This insttruction has to be called after the texture has been populated with the image.\nTo provide the mipmaps manually we use:\ngl.texImage2D( gl.TEXTURE_2D, 1, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, mipmapImage ); By passing a number other than 0 as the second parameter we are creating the first mipmap level.\nIn order to use mipmaps with a texture in WebGL 1, mipmaps need to satisfy some dimension restrictions. Namely, the texture width and height must both be Powers of Two (POT). This does not apply for WebGL 2.","texture-wrapping#Texture Wrapping":"Texture wrapping describes the behavior of the sampler when the texture coordinates fall outside the range of $0$ and $1$. The wrapping mode can be set independently for both the S and T coordinates:\ngl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE); CLAMP_TO_EDGE This wrap mode rounds any texture coordinates greater than $1$ down to $1$; any coordinates lower than $0$ are rounded up to $0$, clamping the values to the $(0, 1)$ range. Visually, this has the effect of repeating the texture’s border pixels indefinitely once the coordinates go out of the $(0, 1)$ range.\nREPEAT This is the default wrap mode. It ignores the integer part of the texture coordinate. This creates the visual effect of the texture repeating as you move outside of the $(0, 1)$ range.\nMIRRORED_REPEAT If the coordinate’s integer portion is even, the texture coordinates will be the same as they were with REPEAT. If the integer portion of the coordinate is odd, the resulting coordinate is $1$ minus the fractional portion of the coordinate. This results in a texture that “flip-flops” as it repeats.","using-multiple-textures#Using Multiple Textures":"There are times when we may want to have multiple textures contribute to a fragment. In such cases, we can use WebGL’s ability to access multiple textures in a single draw call, commonly referred to as multi-texturing.\nWhen talking about exposing a texture to a shader as a sampler uniform, we used the following code:\ngl.activeTexture(gl.TEXTURE0); gl.bindTexture(gl.TEXTURE_2D, texture); We use it to tell the WebGL state machine which texture we’re going to use in subsequent texture functions. If we want to attach a different texture to the second texture unit, we would use gl.TEXTURE1 instead.\nIt may be more convenient to specify the texture unit programmatically or find a need to refer to a texture unit above $31$. In such situations, you can always substitute gl.TEXTURE0 + i for gl.TEXTUREi, as in the following example:\ngl.TEXTURE0 + 2 === gl.TEXTURE2; Accessing multiple textures in a shader is as simple as declaring multiple samplers:\nuniform sampler2D uSampler; uniform sampler2D uOtherSamp When setting up your draw call, tell the shader which texture is associated with which sampler by providing the texture unit to gl.uniform1i.\n// bind the first texture gl.activeTexture(gl.TEXTURE0); gl.bindTexture(gl.TEXTURE_2D, texture); gl.uniform1i(program.uSampler, 0); // bind the second texture gl.activeTexture(gl.TEXTURE1); gl.bindTexture(gl.TEXTURE_2D, otherTexture); gl.uniform1i(program.uOtherSampler, 1); ","using-texture-coordinates#Using Texture Coordinates":"Before we apply our texture to our surface, we need to figure out which part of the texture maps onto which part of the surface. We do this through another vertex attribute known as texture coordinates.\nWebGL forces all of the texture coordinates into a $0$ to $1$ range, where $(0, 0)$ represents the top left-hand side corner of the texture and $(1, 1)$ represents the bottom right-hand side corner.\nThis comes in handy because if the texture coordinates were defined in terms of pixels, then the mapping would be dependent on the resolution of the image.\nThe process of laying out textures and generating texture coordinates is called unwrapping.\nPolygon Mesh A polygon mesh is a collection of vertices, edges, and faces that defines the shape of a polyhedral object in 3D computer graphics and solid\nTexture Coordinates Texture coordinates also have a common symbolic representation. Unfortunately, it’s not consistent across all 3D software applications. OpenGL and WebGL refer to these coordinates as $s$ and $t$ for the $x$ and $y$ components, respectively. However, DirectX and many popular modeling packages refer to them as $u$ and $v$ (so they are usually referred to as “UVs”).","using-textures-in-a-shader#Using Textures in a Shader":"We’ll want to include a two-element vector attribute in our vertex shader that will map to our texture coordinates:\nin vec2 aVertexTextureCoords; We need to add a new uniform to the fragment shader that uses a type we haven’t seen before: sampler2D. The sampler2D uniform is what allows us to access the texture data in the shader:\nuniform sampler2D uSampler; The following code shows how to associate a texture with a specific sampler uniform:\ngl.activeTexture(gl.TEXTURE0); gl.bindTexture(gl.TEXTURE_2D, texture); gl.uniform1i(program.uSampler, 0); First off, we are changing the active texture with gl.activeTexture. Next, we bind the texture we wish to use, which associates it with the currently active texture, TEXTURE0. Finally, we tell the sampler uniform which texture it should be associated with. Here, we give it $0$ to indicate that the sampler should use TEXTURE0.\nTo use our texture in the fragment shader by return the value of the texture as the fragment color:\ntexture(uSampler, vTextureCoord); texture takes in the sampler uniform we wish to query and the coordinates to lookup, and returns the color of the texture image at those coordinates as vec4. If the image has no alpha channel, vec4 will still be returned with the alpha component always set to $1$."},"title":"Textures"},"/notes/cs/rtgw/08/":{"data":{"":"","assigning-one-color-per-object-in-the-scene#Assigning One Color per Object in the Scene":"We will pick an object based on its primitive color, we need to make sure that the color is constant per object and that each object has a different unique color. In situations where objects may share the same diffuse color, we can create a new ESSL uniform to store the picking color and make it unique for every object that’s rendered into the offscreen framebuffer. The following diagram illustrates the situation:","clicking-on-the-canvas#Clicking on the Canvas":"The next step is to capture and read the mouse coordinates. The following diagram shows how we use the offset calculation to obtain the clicked canvas coordinates:","looking-for-hits#Looking for Hits":"Now, we will check whether the color obtained from the offscreen framebuffer matches any of the objects in our scene. When looking for hits, we compare each object’s diffuse color with the label obtained from the offscreen framebuffer. There is, however, an additional step to consider: each color channel comes back in a $[0, 255]$ range while the object diffuse colors are in a $[0, 1]$ range.\nWe do not need to compare the alpha channel. If we had two objects with the same color but a different alpha channel, we could use the alpha channel in the comparison, but this is not the case in our example. Also, it’s important to note that the comparison is not precise, as we are dealing with decimal values in the $[0, 1]$ range. Because of that, we introduce a fudge factor by assuming that we have a hit after rescaling the colors and subtract the readout (object label) – the difference is less than one.","reading-pixels-from-the-offscreen-framebuffer#Reading Pixels from the Offscreen Framebuffer":"WebGL allows us to read back from a framebuffer using the readPixels function:\ngl.readPixels(x, y, width, height, format, type, pixels); We need to ensure that the offscreen framebuffer that we want to read from is the currently bound one. To do so, we bind it by using bindFramebuffer:\n// read one pixel const readout = new Uint8Array(1 ** (1 ** 4)); gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer); gl.readPixels(coords.x, coords.y, 1, 1, gl.RGBA, gl.UNSIGNED_BYTE, readout); gl.bindFramebuffer(gl.FRAMEBUFFER, null); Here, the size of the readout array is $1 \\cdot 1 \\cdot 4$. This means that it has one pixel of width times one pixel height times four channels, since the format is RGBA.","rendering-to-an-offscreen-framebuffer#Rendering to an Offscreen Framebuffer":"In order to perform object selection using the offscreen framebuffer, we need to ensure that both framebuffers are synchronized. The following diagram shows the behavior of the render function:","setting-up-an-offscreen-framebuffer#Setting up an Offscreen Framebuffer":"The results of the rendering on your screen are the contents of the framebuffer. Every call to gl.drawArrays, gl.drawElements, and gl.clear will change the contents of the framebuffer. Instead of rendering to the default framebuffer, we can also render to a scene that is offscreen – we call this the offscreen framebuffer. To set up a framebuffer, we need to create storage for at least two things: colors and depth information. To store colors, we will use a WebGL texture; to store depth information, we will use a renderbuffer.\nCreating a Texture to Store Colors The only difference is that we do not have an image to bind to the texture, so when we call gl.texImage2D, the last argument is null. This is because we are allocating space to store colors for the offscreen framebuffer\nconst canvas = document.getElementById(\"webgl-canvas\"); const { width, height } = canvas; const texture = gl.createTexture(); gl.bindTexture(gl.TEXTURE_2D, texture); gl.texImage2D( gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null ); It’s important to note that the width and height of the texture are set to the canvas size. This is because we want to ensure that the offscreen framebuffer resembles the dimensions of our 3D scene.\nCreating a Renderbuffer to Store Depth Information Renderbuffers are used to provide storage for the individual buffers used in a framebuffer. The depth buffer (z-buffer) is an example of a renderbuffer. It is always attached to the screen framebuffer, which is the default rendering destination in WebGL.\nThe code to create a renderbuffer looks like the following code:\nconst renderbuffer = gl.createRenderbuffer(); gl.bindRenderbuffer(gl.RENDERBUFFER, renderbuffer); gl.renderbufferStorage(gl.RENDERBUFFER, gl.DEPTH_COMPONENT16, width, height); The third line of code determines the storage size of the renderbuffer. Similar to before, we need to ensure that for every fragment (pixel) in the framebuffer, we have a color (stored in the texture) and a depth value (stored in the renderbuffer), so the size of the canvas and the size of the render buffer must be the same.\nCreating a Framebuffer for Offscreen Rendering We need to create a framebuffer and attach the texture and the renderbuffer:\nconst framebuffer = gl.createFramebuffer(); // Frame buffer gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer); // Texture gl.framebufferTexture2D( gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0 ); // Render buffer gl.framebufferRenderbuffer( gl.FRAMEBUFFER, gl.DEPTH_ATTACHMENT, gl.RENDERBUFFER, renderbuffer ); // Clean up gl.bindTexture(gl.TEXTURE_2D, null); gl.bindRenderbuffer(gl.RENDERBUFFER, null); gl.bindFramebuffer(gl.FRAMEBUFFER, null); "},"title":"Picking"},"/notes/datascience/":{"data":{"":" Data Science Master "},"title":"Data Science"},"/notes/datascience/master/":{"data":{"":"","2c-2c#2C 2C":" Aprendizaje Automático II Deep Learning Modelos Bayesianos Jerárquicos ","3c-1c#3C 1C":" Infraestructuras Computacionales para Procesamiento de Datos Masivos "},"title":"Data Science Master"},"/notes/datascience/master/2c_2c/mbj/":{"data":{"appendix#Appendix":"T2 Thanks to how little I understand this book i will use other sources in order to properly understand Bayesian Hierarchical Modeling, the contents on the following chapter explains how hierarchical Bayesian models came to be and its appeal. Then on section 2 it lays out Hierarchical Nolmal Modeling followed by an explanation on hierarchical Beta-Binomial modeling on section 3.\nBayesian Hierarchical Modeling\nIntroduction Hierarchical Normal Modeling Hierarchical Beta-Binomial Modeling ","modelos-bayesianos-jerárquicos#Modelos Bayesianos Jerárquicos":"Modelos Bayesianos Jerárquicos Introduccion a la Inferencia Bayesiana Modelos Jerarquicos Constructing a Parametrized Prior Distribution Exchangeability and Hierarchical Models Bayesian Analysis of Conjugate Hierarchical Models Normal Model with Exchangeable Parameters Example: Parallel Experiments in Eight Schools Hierarchical Modeling Applied to Meta-analysis Weakly Informative Priors Evaluación y Comparación de Modelos Measures of Predictive Accuracy Information Criteria and Cross-validation Model Comparison Based on Predictive Performance Model Comparison Using Bayes Factors Aspectos Computacionales de la Inferencia Bayesiana Gibbs Sampler Metropolis and Metropolis-Hastings Algorithms Using Gibbs and Metropolis as Buliding Blocks Inference and Assessing Convergence Effective Number of Simulation Draws "},"title":"index"},"/notes/datascience/master/3c_1c/icpdm/":{"data":{"infraestructuras-computacionales-para-procesamiento-de-datos-masivos#Infraestructuras Computacionales para Procesamiento de Datos Masivos":"Infraestructuras Computacionales para Procesamiento de Datos Masivos","módulo-1#Módulo 1":" Tema 1. Introducción a Big Data Tema 2. El Núcleo de Hadoop Tema 3. Programación MapReduce Tema 4. Inyección Extracción y Serialización/Deserialización de los datos ","módulo-2#Módulo 2":" Tema 1. Introducción a Apache Spark Tema 2. Programación en aplicaciones Spark Tema 3. Librerías/Componentes de Spark Tema 4. Configuración, monitorización y optimización de Spark ","módulo-3#Módulo 3":" Tema 1. Introducción a las arquitecturas de procesamiento de streams: Lambda y Kappa Tema 2. Componentes tecnológicos de adquisición y transmisión/distribución de eventos: Kafka Tema 3. Procesamiento de streams: Apache Spark Streaming ","módulo-4#Módulo 4":" Tema 1. Proveedores de soluciones: AWS "},"title":"index"},"/notes/datascience/master/aaii/":{"data":{"":" Tema 1. Random Forests Tema 2. Intensificación (boosting) Tema 3. Otras Combinaciones de Modelos Tema 4. Aprendizaje No Supervisado "},"title":"Aprendizaje Automático II"},"/notes/datascience/master/aaii/01_random_forests/":{"data":{"":"","bagging#Bagging":"Introduction The decision trees discussed suffer from high variance. In contrast, a procedure with low variance will yield similar results if applied repeatedly to distinct data sets.\nBootstrap aggregation, or bagging, is a procedure for reducing the variance of a statistical learning method.\nRecall that given a set of $n$ independent observations $Z_1, \\cdots, Z_n$ each with variance $\\sigma^2$, the variance of the mean $\\overline{Z}$ of the observations is given by $\\frac{\\sigma^2}{n}$.\nSo, averaging a set of observations reduces variance. Thus, to reduce the variance and increase the prediction accuracy of a statistical learning method is to take many training sets from the population, build a separate prediction model using each training set, and average the resulting predictions.\nUsing $B$ separate training sets, and average them in order to obtain a single low-variance statistical learning model, given by:\n$$ \\begin{aligned} \\hat{f}_{avg}(x) = \\frac{1}{B}\\sum_{b=1}^B \\hat{f}^b(x) \\end{aligned} $$For each bootstrap sample $Z^{**b}, b = 1, 2, \\cdots, B$, we fit our model, giving prediction $\\hat{f}^{**b}(x)$. The bagging estimate is defined by:\n$$ \\begin{aligned} \\hat{f}_{bag}(x) = \\frac{1}{B}\\sum_{b=1}^B \\hat{f}^{*b}(x) \\end{aligned} $$Bagging on Regression Trees To apply bagging to regression trees, we simply construct $B$ regression trees using $B$ bootstrapped training sets, and average the resulting predictions.\nThese trees are grown deep, and are not pruned. Hence each individual tree has high variance, but low bias. Averaging these B trees reduces the variance.\nBagging on Decision Trees How can bagging be extended to a classification problem where Y is qualitative? For a given test observation, we can record the class predicted by each of the $B$ trees, and take a majority vote.\nSuppose our tree produces a classifier $\\hat{G}(x)$ for a $K$-class response. Then the bagged estimate $\\hat{f}_{bag}(x)$ is a $K$-vector $[p_1(x), p_2(x), \\cdots, p_K(x)]$, with $p_k(x)$ equal to the proportion of trees predicting class $k$ at $x$.\nThe bagged classifier selects the class with the most votes from the $B$ trees, $\\hat{G}{bag}(x) = \\arg \\max_k \\hat{f}{bag}(x)$.\nOften we require the class-probability estimates at $x$. For many classifiers $\\hat{G}(x)$ there is already an underlying function $\\hat{f}(x)$ that estimates the class probabilities at $x$ (for trees, the class proportions in the terminal node). An alternative bagging strategy is to average these instead.\nThe number of trees $B$ is not a critical parameter with bagging; using a very large value of $B$ will not lead to overfitting. In practice we use a value of $B$ sufficiently large that the error has settled down.\nNote that bagging a good classifier can make it better, but bagging a bad classifier can make it worse.\nOut-of-Bag Error Estimation There is a very straightforward way to estimate the test error of a bagged model\nOne can show that on average, each bagged tree makes use of around two-thirds of the observations. The observations not used to fit a given bagged tree are referred to as the out-of-bag (OOB) observations.\nAn OOB prediction can be obtained for each of the $n$ observations on the OOB observation set, from which the overall OOB MSE (for a regression problem) or classification error (for a classification problem) can be computed.\nThe resulting OOB error is a valid estimate of the test error for the bagged model.\nVariable Importance Measures Although the collection of bagged trees is much more difficult to interpret than a single tree, one can obtain an overall summary of the importance of each predictor using the RSS (for bagging regression trees) or the Gini index (for bagging classification trees)\nIn the case of bagging regression trees, we can record the total amount that the RSS is decreased due to splits over a given predictor, averaged over all $B$ trees.\nFor classification trees, we can add up the total amount that the Gini index is decreased by splits over a given predictor, averaged over all $B$ trees.\nAdvantages of ensemble models Performance: it improves single models’ perfomance. Robustness: reduces predictions’ variance. So it also improves the equilibrium between bias and variance.\nHow to generate diversity Manipulating instances: selecting a different subset of instances for each model. Manipulating features: selecting a different subset of features for each model. Manipulating models’ definition: selecting different hyperparameters, optimization algorithm for ach model. Hybridation: Mix any of the previous practices.\nEnsemble algorithms Bagging Models are trained concurrently with different data sets generated using bootstrapping.\nBoosting Construye múltiples modelos (típicamente modelos del mismo tipo) secuenciales, cada uno de los cuales aprende a corregir los errores de predicción de un modelo anterior en la cadena.\nEl objetivo es desarrollar un modelo fuerte a partir de muchos modelos débiles especialmente diseñados que se combinan mediante votación simple o promediando.\nStaking Construye múltiples modelos sobre el mismo conjunto de datos, típicamente modelos de diferentes tipos (modelos de nivel 0); y un modelo supervisado o meta modelo (modelo de nivel 1) que aprende cómo combinar mejor las predicciones de los modelos primarios.\nModel of Experts Podemos dividir el espacio de características de entrada en subespacios según algún conocimiento de dominio del problema.\nLuego se puede entrenar un modelo en cada subespacio del problema, convirtiéndose de hecho en un experto en el subproblema específico.\nLuego, un modelo aprende a qué experto recurrir para predecir nuevos ejemplos en el futuro.","biasvariance-tradeoff#Bias/Variance Tradeoff":"Test error, also referred to as generalization error, is the prediction error over an independent test sample:\n$$ \\begin{aligned} Err_{\\mathcal{T}} = \\mathbb{E}[L(Y | \\hat{f}(X)) | \\mathcal{T}] \\end{aligned} $$Where $L$ is the loss function. A related quantity is the expected prediction error (or expected test error):\n$$ \\begin{aligned} Err = \\mathbb{E}[Err_{\\mathcal{T}}] \\end{aligned} $$where $Err_{\\mathcal{T}}$ is the test error.\nThe error can always be decomposed into the sum of three fundamental quantities:\nThe variance of $\\hat{f}(x_0)$ The squared bias of $\\hat{f}(x_0)$ The variance of the error terms $\\epsilon$. That is,\n$$ \\begin{aligned} \\mathbb{E}[\\left(y_0 - \\hat{f}(x_0)\\right)^2] = \\mathbb{V}[\\hat{f}(x_0)] + [Bias(\\hat{f}(x_0))]^2 + \\mathbb{V}[\\epsilon] \\end{aligned} $$This amount is derived from:\n$$ \\begin{aligned} Err(x_0) = \\mathbb{E}[(Y - \\hat{f}(x_0))^2] = \\mathbb{E}[Y^2 + \\hat{f}(x_0)^2 - 2Y\\hat{f}(x_0)] \\end{aligned} $$$$ \\begin{aligned} = \\mathbb{E}[Y^2] + \\mathbb{E}[\\hat{f}(x_0)^2] -2\\mathbb{E}[Y]\\mathbb{E}[\\hat{f}(x_0)] \\end{aligned} $$We know that $\\mathbb{V}[X] = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$, such that:\n$$ \\begin{aligned} = \\mathbb{V}[Y] + \\mathbb{E}[Y]^2 + \\mathbb{V}[\\hat{f}(x_0)] + \\mathbb{E}[\\hat{f}(x_0)]^2 -2\\mathbb{E}[Y]\\mathbb{E}[\\hat{f}(x_0)] \\end{aligned} $$$$ \\begin{aligned} = \\mathbb{E}[(Y - \\mathbb{E}[Y])^2] + \\mathbb{E}[Y]^2 + \\mathbb{E}[(\\hat{f}(x_0) - \\mathbb{E}[\\hat{f}(x_0)])^2] + \\mathbb{E}[\\hat{f}(x_0)]^2 -2\\mathbb{E}[Y]\\mathbb{E}[\\hat{f}(x_0)] \\end{aligned} $$Note that, $Y = f(x_0) + \\epsilon[/$], donde [$]\\mathbb{E}[\\epsilon] = 0$, thus it follows:\n$$ \\begin{aligned} = \\mathbb{E}[(Y - \\mathbb{E}[Y])^2] + (\\mathbb{E}[f(x_0)] + \\mathbb{E}[\\epsilon])^2 + \\mathbb{E}[(\\hat{f}(x_0) - \\mathbb{E}[\\hat{f}(x_0)])^2] + \\mathbb{E}[\\hat{f}(x_0)]^2 -2(\\mathbb{E}[f(x_0)] + \\mathbb{E}[\\epsilon])\\mathbb{E}[\\hat{f}(x_0)] \\end{aligned} $$$$ \\begin{aligned} = \\mathbb{E}[(Y - \\mathbb{E}[Y])^2] + \\mathbb{E}[f(x_0)]^2 + \\mathbb{E}[(\\hat{f}(x_0) - \\mathbb{E}[\\hat{f}(x_0)])^2] + \\mathbb{E}[\\hat{f}(x_0)]^2 -2\\mathbb{E}[f(x_0)]\\mathbb{E}[\\hat{f}(x_0)] \\end{aligned} $$We know that $(a + b)^2 = a^2 + b^2 + 2ab$ and that $\\mathbb{E}[f(x_0)] = f(x_0)$, such that:\n$$ \\begin{aligned} = \\mathbb{E}[(Y - \\mathbb{E}[Y])^2] + \\mathbb{E}[(\\hat{f}(x_0) - \\mathbb{E}[\\hat{f}(x_0)])^2] + f(x_0)^2 + \\mathbb{E}[\\hat{f}(x_0)]^2 -2f(x_0)\\mathbb{E}[\\hat{f}(x_0)] \\end{aligned} $$$$ \\begin{aligned} = \\mathbb{E}[(Y - \\mathbb{E}[Y])^2] + \\mathbb{E}[(\\hat{f}(x_0) - \\mathbb{E}[\\hat{f}(x_0)])^2] + \\left(\\mathbb{E}[\\hat{f}(x_0)] - f(x_0)\\right)^2 \\end{aligned} $$Here the notation $\\mathbb{E}[\\left(y_0 - \\hat{f}(x_0)\\right)^2]$ defines the expected test MSE, and refers expected to the average test MSE that we would obtain if we repeatedly $f$ using a large number of training sets, and tested each at $x_0$.\nThe overall expected test MSE can be computed by averaging $\\mathbb{E}[\\left(y_0 - \\hat{f}(x_0)\\right)^2]$ over all possible values of $x_0$ in the test set.\nThe previous equation tells us that in order to minimize the expected test error, we need to select a statistical learning method that simultaneously achieves low variance and low bias. Note that variance is inherently a nonnegative quantity, and squared bias is also nonnegative. Hence, we see that the expected test MSE can never lie below $\\mathbb{V}[\\epsilon]$, the irreducible error.\nThe variance of the error terms, $\\mathbb{V}[\\epsilon]$, is the variance of the target around its true mean $f(x_0)$, and cannot be avoided no matter how well we estimate $f(x_0)$, unless $\\sigma^2 = 0$.\nVariance refers to the amount by which $\\hat{f}$ would change if we estimated it using a different training data set. Ideally the estimate for $f$ should not vary too much between training sets. This is computed as the expected squared deviation of $\\hat{f}(x_0)$ around its mean.\nBias refers to the error that is introduced by approximating a real-life problem by a simpler model. This quentifies the amount by which the average of our estimate differs from the true mean.\nAs a general rule, as we use more flexible methods, the variance will increase and the bias will decrease.\nAs we increase the flexibility, the bias tends to initially decrease faster than the variance increases. Consequently, the expected test MSE declines. At some point increasing flexibility has little impact on the bias but starts to significantly increase the variance.\nIn a real-life situation in which $f$ is unobserved, it is generally not possible to explicitly compute the test MSE, bias, or variance for a statistical learning method.\nTraining error consistently decreases with model complexity, typically dropping to zero if we increase the model complexity enough. A model with zero training error is overfit to the training dat and will typically generalize poorly.\nIt is important to note that there are in fact two separate goals:\nModel selection: estimating the performance of different models in order to choose the best model. Model assessment: having chosen a final model, estimating its prediction error (generalization error) on new data. The training set is used to fit the models. The validation set is used to estimate prediction error for model selection. The test set is used for assessment of the generalization error","bootstrapping#Bootstrapping":"Bootstrapping is a resampling technique used in statistics to estimate the sampling distribution of a statistic by sampling with replacement from the original dataset. The method is particularly useful when analytical methods for deriving the sampling distribution are complex or unavailable.\nHere’s a breakdown of the bootstrapping process:\nSampling with Replacement: From the original dataset, randomly draw $n$ samples with replacement. This means that each observation has an equal chance of being selected for the sample, and an observation may be selected multiple times. Sample Statistics: Calculate the statistic of interest (e.g., mean, median, standard deviation, regression coefficient) on each bootstrapped sample. Repeat: Repeat steps $2$ and $3$ a large number of times to generate multiple bootstrap samples and their corresponding statistics. Estimate Sampling Distribution: With the collection of bootstrap statistics, you can estimate the sampling distribution of the statistic of interest. This empirical distribution approximates the true sampling distribution of the statistic, providing information about its variability and uncertainty. Inference: Use the estimated sampling distribution to make inferences about the population parameter or to construct confidence intervals. ","random-forests#Random Forests":"Definition The idea in random forests (ilustrated on the image below) is to improve the variance reduction of bagging by reducing the correlation between the trees, without increasing the variance too much. This is achieved in the tree-growing process through random selection of the input variables.\nAn average of $B$ i.i.d. random variables, each with variance $\\sigma^2$, has variance $\\frac{1}{B}\\sigma^2$.\nIf the variables are simply i.d. (identically distributed, but not necessarily independent) with positive pairwise correlation ρ, the variance of the average is:\n$$ \\begin{aligned} \\rho\\sigma^2 + \\frac{1 - \\rho}{B}\\sigma^2 \\end{aligned} $$As $B$ increases, the second term disappears, but the first remains, and hence the size of the correlation of pairs of bagged trees limits the benefits of averaging.\nWhen growing a tree on a bootstrapped dataset before each split, select $m \\leq p$ of the input variables at random as candidates for splitting.\nAfter $B$ such trees ${T(x; \\Theta_b)}_1^B$ are grown, the random forest (regression) predictor is:\n$$ \\begin{aligned} \\hat{f}_{rf}^B(x) = \\frac{1}{B}\\sum_{b=1}^B T(x; \\Theta_b) \\end{aligned} $$Where $\\Theta_b$ characterizes the bth random forest tree in terms of split variables, cutpoints at each node, and terminal-node values.\nIntuitively, reducing $m$ will reduce the correlation between any pair of trees in the ensemble.\nDetails of Random Forests For classification, the default value for $m$ is $\\lfloor \\sqrt{p} \\rfloor$ and the minimum node size is one.\nFor regression, the default value for $m$ is $\\lfloor \\frac{p}{3} \\rfloor$ and the minimum node size is five.\nIn practice the best values for these parameters will depend on the problem, and they should be treated as tuning parameters (hyperparamters).\nVariable Importance At each split in each tree, the improvement in the split-criterion is the importance measure attributed to the splitting variable, and is accumulated over all the trees in the forest separately for each variable.\nRandom forests also use the OOB samples to construct a different variable importance measure.\nWhen the bth tree is grown, the OOB samples are passed down the tree, and the prediction accuracy is recorded. Then the values for the jth variable are randomly permuted in the OOB samples, and the accuracy is again computed. The decrease in accuracy as a result of this permuting is averaged over all trees, and is used as a measure of the importance of variable $j$ in the random forest. Proximity Plots In growing a random forest, an $N \\times N$ proximity matrix is accumulated for the training data. Such that the entry $ij$ contains the number of trees for which the OOB sample $x_i$ and the OOB sample $x_j$ are on the same terminal node.\nThis proximity matrix is then represented in two dimensions using multidimensional scaling like the following example:\nThe proximity plot gives an indication of which observations are effectively close together in the eyes of the random forest classifier.\nRandom Forests and Overfitting When the number of variables $p$ is large, but the fraction of relevant variables small, random forests are likely to perform poorly with small $m$. At each split the chance can be small that the relevant variables will be selected.\nAnother claim is that random forests “cannot overfit” the data."},"title":"Tema 1. Random Forests"},"/notes/datascience/master/aaii/02_boosting/":{"data":{"":"","ada-boost#Ada Boost":"Definition AdaBoost, also known as Adaptive Boosting, is a machine learning algorithm that combines multiple weak classifiers to create a strong classifier. Let’s break down the AdaBoost algorithm using the pseudocode shown in:\nInitialization: AdaBoost starts by initializing the weights of all training examples equally $D_1(i) = \\frac{1}{N}$ for $i = 1, 2, \\cdots, N$. Iterative Process for $t = 1, \\cdots, T$: AdaBoost iterates through rounds, where each round involves training a weak classifier $h_t: \\mathcal{X} \\rightarrow {-1, +1}$ on the data $D_t$. The algorithm adjusts the weights of the training examples based on the performance of the weak classifier: $D_{t+1} = \\frac{D_t(i) \\cdot e^{-\\alpha_ty_th_t(x_t)}}{Z_t}$, where $Z_t$ is a regularization term and $\\alpha_t$ is the weight of $h_t$ on the final ensemble model based on its accuracy. Combining Classifiers: After multiple rounds, AdaBoost combines all the weak classifiers into a final strong classifier. The final classifier makes predictions based on a weighted voting system using the predictions of the individual weak classifiers: $H(x) = sign(\\sum_{t=1}^T \\alpha_t h_t(x))$ Predictions: When making predictions on new data, AdaBoost uses the combined classifier to predict the class label based on the weighted votes of the weak classifiers Characteristics The weak learning assumption means that we assume each weak classifier makes errors that are not too close to random guessing. So the the error $\\epsilon_t$ is at most $\\frac{1}{2} - \\gamma$ for some small positive constant $\\gamma$.\nIt can be proven that the training error of the c ombined classifier drops exponentially fas as a function of the number of weak classifiers combined, but it says nothing about the behaviour of its generalization error computed over the test data.\nToy Example To illustrate how AdaBoost works, let us look at the tiny toy learning problem shown in the following picture:\nRound 1 On round $1$, we assign equal weights to all the examples. So $D1_(i) = \\frac{1}{n} = \\frac{1}{10}$.\nThe hypothesis $h_1$ classifies incorrectly three points, so its error is $\\epsilon_1 = 0.3$, so it follows that the weight assigned to this first model is $\\alpha_1 = 0.42$.\nRound 2 When constructing $D_2$ we increment the weight of the three points misclassified by $h_1$. And we define a new hypothesis $h_2$ over this data, where we can see that it classifies correctly the three points misclassified by $h_1$ however it still classifies incorrectly three other points.\nThe error of this model is $\\epsilon_2 = 0.21$ and thus the weight of this model is defined as $\\alpha_2 = 0.65$.\nRound 3 We modify the weights of the data taking into account the three points previously misclassified, augmenting their weight and decresing the weight of those correctly classified.\nThis classifier misses none of the points misclassified by $h_1$ and $h_2$.\nFinal Round The combined classifier $H$ is defiend as a weigthed vote between $h_1$, $h_2$ and $h_3$ where the weights are given by $\\alpha_1$, $\\alpha_2$ and $\\alpha_3$.","boosting#Boosting":"Regression Trees Boosting regression trees, often referred to as gradient boosting machines:\nWhat is the idea behind this procedure? Given the current model, we fit a decision tree to the residuals $r_i$ from the model rather than the outcome $Y$.\nEach of these trees can be rather small, with just a few terminal nodes, determined by the parameter $d$.\nBy fitting small trees to the residuals, we slowly improve $\\hat{f}$ in areas where it does not perform well.\nThe shrinkage parameter $\\lambda$ slows the process down even further.\nBoosting has three tuning parameters:\nThe number of trees $B$: boosting can overfit if $B$ is too large. The shrinkage parameter $\\lambda$: this controls the rate at which boosting learns. The number $d$ of splits in each tree, which controls the complexity of the ensemble. ","boosting-trees#Boosting Trees":"Variable Space Partitioning Partitioning the predictor variable space into regions in boosting trees involves recursively splitting the data based on predictor variables to create distinct regions with associated constant values for making predictions.\nStarting Point: entire predictor variable space is considered as one large region, $R_1$. Decision Making: At each step, a decision tree algorithm finds the best split based on a predictor variable $x_j$ and a split point $s$ that minimizes a certain criterion. This split divides region $R_j$ into two subregions $R_{left}$ and $R_{right}$. Splitting Criteria: it can be represented as $(j, s) = arg \\min_{j, s} [\\sum_{x_i \\in R_{left}} L(y_i, f(x_i)) + \\sum_{x_i \\in R_{right}} L(y_i, f(x_i)]$ Recursive Process: This process is repeated recursively for each resulting subregion until a stopping criterion is met. Terminal Nodes: The final regions, or terminal nodes, are denoted as $R_J$ and are assigned constant values $\\gamma_j$ representing the prediction for data points falling into that region. Constant Assigment: Each terminal node is associated with a constant value, resulting in a piecewise constant function, such that each tree can be denoted as: $T(x; \\Theta) = \\sum_{j=1}^J \\gamma_j I(x \\in R_j)$ where $I(\\cdot)$ is the indication function and $\\Theta = {R_j, \\gamma_j}_1^J$ are the parameters. Prediction: When making predictions for new data points, the algorithm determines the region $R_j$ that the data point belongs to based on the predictor variables. The prediction for that data point is then based on the constant value $\\gamma_j$ assigned to the corresponding region. Optimization Problem So as we have seen the optimization problem is defined, on a simplified manner, as follows:\n$$ \\begin{aligned} \\hat{\\Theta} = \\arg \\min_{\\Theta} \\sum_{j=1}^J \\sum_{x_i \\in R_j} L(y_i, \\gamma_j) \\end{aligned} $$This is a combinatorial problem that we usually aproximate using suboptimal solutions.\nFinding $\\gamma_j$ given $R_j$: we usually define $\\hat{\\gamma}_j = \\overline{y}_j$ for regression problems. Finding $R_j$: this is the difficult part. We usually resort to a greedy, top-down recursive partitioning algorithm to find $R_j$. Boosting Trees In boosting trees, terminal-node trees refer to the individual decision trees that make up the ensemble model. Each terminal-node tree is denoted as $T(x; \\Theta_m)$ where $\\Theta_m = {R_{jm}, \\gamma_{jm}}_1^{J_m}$.\nThe boosted tree model is an additive model, where each tree is added sequentially to improve the overall prediction. The model can be expressed as\n$$ \\begin{aligned} f_M(x) = \\sum_{m=1}^M T(x; \\Theta_m) \\end{aligned} $$where $M$ represents the total number of trees in the ensemble.\nOptimization Problem The optimization problem for boosting trees involves finding the optimal regions and constants for each tree in the ensemble model.\nOptimization Objective The goal is to minimize the empirical risk:\n$$ \\begin{aligned} \\hat{\\Theta} = arg \\min_{\\Theta} \\sum_{x_i \\in R_j} L(y_i, \\gamma_j) \\end{aligned} $$Where $L(y_i, \\gamma_i)$ represents the loss incurred for pedicting the target value $y_i$ with constant $\\gamma_j$ in region $R_j$.\nFinding Optimal Consants Given the regions $R_{jm}$ finding the optimal constant in $\\gamma_j$ in each regions involves minimizing the loss function for the data points within that region:\n$$ \\begin{aligned} \\hat{\\gamma}_{jm} = arg \\min_{\\gamma_{jm}} \\sum_{x_i \\in R_{jm}} L(y_i, f_{m - 1}(x_i) + \\gamma_{jm}) \\end{aligned} $$$$ \\begin{aligned} \\hat{\\gamma}_{jm} = arg \\min_{\\gamma_{jm}} \\sum_{x \\in R_{jm}} L(y_i, f_{m - 1}(x_i) + T(x_i; \\Theta_m)) \\end{aligned} $$Finding the regions is difficult, and even more difficult than for a single tree.\nSolution for Regression Trees For regressions trees the solution for boosted trees consists on choosing the regression tree that best predicts the current residuals $y_i - f_{m-1}(x_i)$ and $\\hat{\\gamma}_{jm}$\nSolution for Classification Trees For two-class classification and exponential loss, it gives rise to the AdaBoost method. It can be showin that given $R_{jm}$ the solution is:\n$$ \\begin{aligned} \\hat{\\gamma}_{jm} = \\log \\frac{\\sum_{x_i \\in R_{jm}} w_i^{(m)} I(y_i = 1)}{\\sum_{x_i \\in R_{jm}} w_i^{(m)} I(y_i = -1)} \\end{aligned} $$Appendix Greedy Top-Down Recurisve Partitioning Algorithm A greedy, top-down recursive partitioning algorithm is a method used in decision tree construction to recursively split the predictor variable space into regions in a step-by-step manner.\nGreedy Approach: at each step, it makes the best split based on the available data without considering the impact of future splits. Top Down Process: starts at the top with the entire predictor variable space considered as one region. It then recursively divides this space into smaller regions Recursive Partitioning: At each step the predictor variable space is divided into two or more subregions based on a splitting criterion. This process continues recursively for each resulting subregion until a stopping criterion is met. ","examples#Examples":"California Housing The dataset consists of information from $20,460$ neighborhoods in California. The target variable ($Y$) is the median house value in each neighborhood.\nPredictor variables include demographic factors like median income (MedInc), housing density (House), average occupancy (AveOccup), location coordinates (longitude and latitude), and house attributes like average number of rooms (AveRooms) and bedrooms (AveBedrms). There are thus a total of eight predictors, all numeric.\nWe fit a gradient boosting model using the MART procedure, with $J = 6$ terminal nodes.\nThe test error is seen to decrease monotonically with increasing $M$, more rapidly during the early stages and then leveling off to being nearly constant as iterations increase. Thus, the choice of a particular value of $M$ is not critical, as long as it is not too small.\nThe next figure displays the relative variable importances for each of the eight predictor variables.\nNot surprisingly, median income in the neighborhood is the most relevant predictor. Longitude, latitude, and average occupancy all have roughly half the relevance of income, whereas the others are somewhat less influential\nOn the following graphs we show single-variable partial dependence plots on the most relevant nonlocation predictors.\nNote that the plots are not strictly smooth as a consequence of using tree-based models.\nThe hash marks at the base of each plot delineate the deciles of the data distribution of the corresponding variables. So for example, $90%$ of the data have a MedInc value of less than $6$.\nThe partial dependence of median house value on median income is monotonic increasing. House value is generally monotonic decreasing with increasing average occupancy, except perhaps for average occupancy rates less than one.\nMedian house value is seen to have a very weak partial dependence on house age that is inconsistent with its importance ranking. This suggests that this weak main effect may be masking stronger interaction effects with other variables.\nThe next graph shows the two-variable partial dependence of the fitted model on joint values of longitude and latitude:\nThere is a very strong dependence of median house value on the neighborhood location in California. It can be viewed as representing an extra premium one pays for location. This premium is seen to be relatively large near the Pacific coast especially in the Bay Area and Los Angeles–San Diego. In the northern, central valley, and southeastern desert regions of California, location costs considerably less.","gradient-boosting#Gradient Boosting":"Numerical Optimization via Gradient Imagine you have a machine learning model that makes predictions, but it’s not perfect. Gradient boosting is like a smart way to teach this model to make better predictions over time.\nInstead of trying to fix all the prediction errors at once, gradient boosting focuses on correcting one error at a time. It does this by looking at the direction where the error is the steepest and making adjustments to improve the prediction in that direction.\nBy repeating this process step by step, the model gradually gets better at making predictions, leading to more accurate results.\nSo if you have the following function you want to optimize:\n$$ \\begin{aligned} L(f) = \\sum_{i=1}^N L(y_i, f(x_i)) \\end{aligned} $$where $f \\in \\mathbb{R}^N$ is the prediction function and its evaluation at each instance $x_i$ are the parameteres we want to optimize:\n$$ \\begin{aligned} f = \\{f(x_1), \\cdots, f(x_i), \\cdots, f(x_n)\\} \\end{aligned} $$Therefore the optimization problem with respect to $f$ can be summarized as follows:\n$$ \\begin{aligned} \\hat{f} = \\arg \\min_f L(f) \\end{aligned} $$Solving this entire problem at once may be challenging. To make it easier, numerical optimization procedures break down this big problem into smaller pieces, represented by component vectors. Each component vector addresses a specific aspect of the problem. So:\n$$ \\begin{aligned} f_{M} = \\sum_{m = 0}^M h_m, h_m \\in \\mathbb{R}^N \\end{aligned} $$where $f_M$ represents the final model or prediction function obtained after M iterations or steps of the boosting algorithm.\nHere $f_m$ represents the model at iteration $m$, whereas $h_m$ represents the increment to the model at iteration $m$ It is the component vector added to the current model to move towards the optimized solution. Each $h_m$ is induced based on the current parameter vector $f_{m-1}$ and contributes to the overall model improvement.\nHere is a simple layout of how the algorithm optimizes:\nAt the beginning of the gradient boosting process, the initial model $f_0$ is set to an initial guess. As the algorithm progresses through iterations ($m = 1, 2, \\cdots, M$), each step involves updating the model based on the gradient information to reduce errors in predictions. Numerical optimization methods differ in their prescriptions for computing each increment vector $h_m$. Steepest Descent Steepest descent is a method used in optimization to find the minimum value of a function. This method chooses $h_m = \\rho_m g_m$ where $\\rho_m$ is a scalar and $g_m$ is the gradient of $L(f_{m-1})$, that is, the cost function evaluated at values predicted by the “previous model”.\nThe components of the gradient $g_m$ are defined as follows:\n$$ \\begin{aligned} g_{im} = \\left[\\frac{\\delta L(y_i, f(x_i))}{\\delta f(x_i)}\\right]_{f_m(x_i) = f_{m-1}(x_i)} \\end{aligned} $$The step length (kinda like the learning rate):\n$$ \\begin{aligned} \\rho_m = \\arg \\min_{\\rho} L(f_{m-1} - \\rho g_m) \\end{aligned} $$Thus, at each step, the predictor is updated as follows:\n$$ \\begin{aligned} f_m = f_{m - 1} - \\rho_m g_m \\in \\mathbb{R}^N \\end{aligned} $$This updates $f_m$ towards the direction of maximum descent at $L(f_{m-1})$, which is why this is often interpreted as a greedy algorithm.\nGradient Boosting Gradient Boosting aims to create a strong predictive model by combining multiple weak models. It starts with a simple model and gradually enhances it to minimize errors.\nAt each iteration, a new tree model is fit to the negative gradient of the loss function. The predictions from these trees guide the model towards better predictions. Using squared error to measure closeness, this leads us to:\n$$ \\begin{aligned} \\tilde{\\Theta}_m = \\arg \\min_{\\Theta} \\sum_{i=1}^N (-g_{im} - T(x_i; \\Theta))^2 \\end{aligned} $$This measures how close each prediction $T(x_i; \\Theta)$ is to the gradient $-g_{im}$.\nThe negative gradient of the loss function represents the direction in which the model’s predictions need to be adjusted to reduce errors. By fitting a new tree to this negative gradient, the model learns how to correct its predictions to move closer to the actual target values. That is at each iteration, the new tree model focuses on capturing the errors or residuals of the current ensemble model.\nWhile the exact regions where the new tree makes corrections may not match perfectly with the original model’s regions, they are close enough to serve the same purpose of improving the model’s accuracy. Here the original model is the ensemble model.\nThe following figure summarizes the gradients for commonly used loss functions:\nImplementations of Gradient Boosting Algorithm $10.3$ presents the generic gradient tree-boosting algorithm for regression. Specific algorithms are obtained by inserting different loss criteria $L(y,f(x))$.\nStart with an initial model $f_0(x)$ that minimizes the loss function $L(y, f(x))$. For each boosting round $m = 1, \\cdots, M$: Calculate the negative gradient for each data point $$ \\begin{aligned} r_{im} = -\\left[\\frac{\\delta L(y_i, f(x_i))}{\\delta f(x_i)}\\right]_{f(x_i) = f_{m-1}(x_i)} \\end{aligned} $$ Fit a regression tree to the gradients $r_{im}$, which gives us the regions $R_{jm}, j = 1, 2, \\cdots, J_m$ The step length $\\gamma$ is determined by minimizing the loss using the previous model ($f_{m-1}$): $$ \\begin{aligned} \\gamma_{jm} = \\arg \\min_{\\gamma} \\sum_{x_i \\in R_{jm}} L(y_i, f_{m-1}(x_i) + \\gamma) \\end{aligned} $$ Update the model by adding a new tree to the ensemble $f_m(x) = f_{m-1}(x) + \\gamma T(x; \\Theta_m)$, where $T(x; \\Theta)$ is the new tree model with parameters $\\Theta_m$ that corrects the errors in the previous model. The output of the ensemble model is defined as $\\hat{f}(x) = f_M(x)$, that is as the sum of the weaker models. Step Length The step length $\\gamma$ is crucial in determining how much each new tree should contribute to the ensemble model. It controls the impact of the new tree on the overall model’s predictions.\nThe line search aims to find the value of γ that minimizes the loss function:\n$$ \\begin{aligned} L(f_{m-1} - \\gamma g_m) \\end{aligned} $$This means finding the optimal step length that results in the smallest possible loss when updating the model with the new tree. By minimizing the loss function with respect to $\\gamma$, the algorithm is essentially performing a form of gradient descent.\nCharacteristics Two basic tuning parameters are the number of iterations $M$ and the sizes of each of the constituent trees $J_m, m = 1, 2, \\cdots, M$.\nThe original implementation of this algorithm was called MART for “multiple additive regression trees”.","interpretability#Interpretability":"Importance of Predictor Variables We attempt to discuss the relevance of predictor variables in a statistical modeling technique called boosting.\nDecision Trees We define the following as a measure of relevance for each predictor variable $X_{\\mathcal{l}}$:\n$$ \\begin{aligned} I_{\\mathcal{l}}^2(T) = \\sum_{t = 1}^{J - 1} \\hat{i}^2_t I(v(t) = \\mathcal{l}) \\end{aligned} $$This equation calculates the relevance of each predictor variable based on the squared improvements in error risk within the internal nodes of the tree. Let’s split each part of the equation:\nThe term $\\hat{i}^2_t$ represents the squared improvement in error risk at node $t$ when splitting on the $X_{\\mathcal{l}}$ predictor variable. The variable $v(t)$ indicates which predictor variable is used for the split at node $t$. Each improvement is weighted by the indicator function $I(v(t) = \\mathcal{l})$, which checks if the splitting variable at node $t$ is the predictor variable of interest $X_{\\mathcal{l}}$. This weighting ensures that only the improvements related to the predictor variable $X_{\\mathcal{l}}$ are considered in the calculation. We sum these improvements over the $J - 1$ internal nodes on the tree, which are not terminal nodes. Additive Models This importance measure is easily generalized to additive tree expansions:\n$$ \\begin{aligned} I_{\\mathcal{l}}^2 = \\frac{1}{M}\\sum_{m = 1}^{M} I_{\\mathcal{l}}^2(T_m) \\end{aligned} $$Due to the stabilizing effect of averaging, this measure turns out to be more reliable than the measure computed only over one tree.\nPartial Dependence Plots Partial dependence functions, by isolating the effects of selected variables, provides an interpretable analysis of their impact on the model’s predictions, overcoming the challenges of information overload in high-dimensional spaces. Let’s define the partial dependency of $f(X)$ on $X_S$,\n$$ \\begin{aligned} f_S(X_S) = \\mathbb{E}_{X_C}[f(X_S, X_C)] \\end{aligned} $$where:\n$X_S$ is the subset of variables we want to study. $X_C$ is the complement set, that is the rest of variables. $E_{X_C}$ denotes the expectation operator with respect to the variables in the complement set $X_C$. It averages the model’s output over the variables in the complement set. $f$ represents the model. $f_S(X_S)$ represents the relationship between the subset of variables $X_S$ and the model’s output. The average can be estimated as follows:\n$$ \\begin{aligned} \\overline{f}_S(X_S) = \\frac{1}{N} \\sum_{i=1}^N f(X_S, x_{i\\mathcal{C}}) \\end{aligned} $$We simply iterate over every data point on the training set, such that $x_{i\\mathcal{C}}$ refers to the values of the variables in the complement set $X_C$ for the $i$th data point.\nPreviously we measured the effects of $X_S$ after accounting for the effects of the other variables $X_C$ on $F(X)$, they were not the effect of $X_S$ on $f(X)$ ignoring the effects of $X_C$, that is given by:\n$$ \\begin{aligned} \\tilde{f}_S(X_S) = \\mathbb{E}(f(X_S, X_C)|X_S) \\end{aligned} $$Thus $\\tilde{f}_S(X_S) = \\overline{f}_S(X_S)$ only if $X_S$ and $X_C$ are independent.\nExample If we assume a purely additive effect, where the overall prediction is the sum of two components:\n$$ \\begin{aligned} f(X) = h_1(X_S) + h_2(X_C) \\end{aligned} $$This implies that the effect of $X_S$ on the prediction is independent of the other variables in $X_C$. However if the prediction is defined as:\n$$ \\begin{aligned} f(X) = h_1(X_S) \\cdot h_2(X_C) \\end{aligned} $$Then this implies that the effect of $X_S$ on the prediction is dependent on the values of the variables in $X_C$.\nRepresentation Owing to the limitations of computer graphics, and human perception, the size of the subsets $X_S$ must be small ($l \\approx 1, 2, 3$).","practice#Practice":"Boosting Just like random forest, GBM is an ensemble method.\nImagine a data set just $10$ examples and two numeric predictor variables, and we are trying to learn to distinguish between two possible classes: circle or cross.\nThe very simplest decision tree we can make has just one node; I will represent it with a straight line in the following diagrams.\nIt scored $60%$: six right, four wrong.\nWhat we do now is train another very simple tree, but first we modify the training data to give the four rows it got wrong a higher weight. How much of a higher weight? That is where the “gradient” bit of GBM comes in.\nIn the next figure the circles and crosses for the wrong items are bigger, and our next tree pays more attention to them.\nIt got a different three items wrong so it still scores $60%$.\nSo, for our third tree, we tell it those four are more important; the one it has got wrong twice in a row is the biggest of all.\nIf we stop training here, we end up with three weak models that scored $60%$, $60%$, and $80%$, respectively. However, at least one of each of those three trees got every training row correct. You can see how they can work together to cover each other’s weaknesses.\nGBM naturally focuses attention on the difficult rows in your training data, the ones that are hard to learn. That is good, but it can also be bad. If there is one outlier that each tree keeps getting wrong it is going to get boosted and boosted until it is bigger than the whole universe. This is bad when the data is a mistake instead of an outlier, as it distorts the model’s accuracy.\nThe mysterious? Well, unlike (simple) decision trees, which can be really good at explaining their thinking, it becomes a bit of a black box.\nParameters n_trees: how many trees to make. max_depth: how deep are the trees allowed to be. learn_rate: controls the speed at which the model learns learn_rate_annealing: allows you to have the learn_rate start high, then gradually get lower as trees are added. min_rows: how many examples are needed to make a leaf node. Low number might lead to overfitting. min_split_improvement: controls how much error improvement must be to perform a split. histogram_type: what type of histogram to use for finding optimal split points. nbins: For numerical columns, build a histogram of (at least) this many bins, then split at the best point. nbins_cat: For categorical columns, build a histogram of (at most) this many bins, then split at the best point. build_tree_one_node: Run on one node only. Building Energy Efficiency: Default GBM This data set deals with the heating/cooling costs of various house designs.\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator m = H2OGradientBoostingEstimator(model_id=\"GBM_defaults\", nfolds=10) m.train(x, y, train) Fifty trees were made, each of depth $5$. On cross-validation data, the MSE (mean squared error) is $2.462$, and $R^2$ is $0.962$. Under “Variable Importances” (shown next), which can be seen with h2o.varimp(m) you will see it is giving X5 way more importance than any of the others; this is typical for GBM models.\nHow about on the unseen data? m.model_performance(test) is saying MSE is $2.318$, better than on the training data.\nBuilding Energy Efficiency: Tuned GBM I decided to start, this time, with a big random grid search. The hyperparameters tuned are the following:\nmax_depth: The default is $5$, and we tried $5,10,15,20,25,30,40,50,60,75,90$. The ninth best model was max_depth=75, so high values may not be bad, as such, but they don’t appear to help. min_rows sample_rate col_sample_rate nbins What about ntrees? Instead of trying to tune it, we set it high ($1000$) and used early stopping.\nMore model results just confirmed the first impression: min_rows of $1$ (or $2$) is effective with max_depth of $5$, but really poor with higher values. min_rows of $10$ is effective with any value of max_depth, but possibly $10$ to $20$ is best. Curiously min_rows of $5$ is mediocre. A sample_rate of $0.9$ or $0.95$ looks best, while there is still no clarity for col_sample_rate or nbins.\nLet’s see how it does on the test data, we obtain a MSE of $1.640$. This is way better than the default GBM’s 2.462, and also way better than the best tuned random forest model from the previous chapter.\nMNIST: Default GBM It is a multinomial classification, trying to look at the $784$ pixels of a handwritten digit, and say which of $0$ to $9$ it is.\nm = h2o.estimators.H2OGradientBoostingEstimator(model_id=\"GBM_defaults\") m.train(x, y, train, validation_frame=valid) The confusion matrix on the training data (h2o.confusionMatrix(m)) shows an error rate of $2.08%$, while on the validation data it is a bit higher at $4.82%$. MSE is $0.028$ and $0.044$, respectively. So we have a bit of overfitting on the training data, but not too much.\nOn the test data the error this time is $4.44%$ (MSE is $0.048$); in other words, the validation and test sets are giving us similar numbers, which is good.\nMNIST: Tuned GBM As usual, the first thing I want to do is switch to using early stopping, so I can then give it lots of trees to work with, with the following parameters:\nstopping_tolerance = 0.001, stopping_rounds = 3, score_tree_interval = 10, ntrees = 400 Just using this, with all other default settings, had some interesting properties\nTraining classification score was perfect after 140 trees. Validation score was down to $2.83%$. The MSE and logloss of both the training data and validation data continued to fall, and so did the validation classification score. Relative runtime kept increasing. That is, each new tree is taking longer. It finished up with 360 trees, with a very respectable $2.17%$ error on the validation data.\nHow can we improve that further? We know there is a lot of examples and variables, so we expect that lower sample ratios will be more effective.\nIn terms of the learn_rate we know low is slower, but better… and we have a lot of data. So we use a high (quick) learn_rate for the first grid or two, then lower it later on, once we start to home in on the best parameters.\nThis is going to be a random grid search, because we are going to use a lot of parameters.\nThe first discovery was that a high max_depth was very slow and no better than a shallow one. Also min_rows=1 seemed poor. We also found that max_depth=20 was distinctly worse than max_depth=5. We also noticed that min_rows=10 seemed to be doing best, though it was less clear. Reducing the three sample rates to $1$ did seem to help, though there was not enough data to draw a confident conclusion.\nSo, another try. We’ll leave max_depth and min_rows at their defaults, and just concentrate on testing sampling rates.\nThere was not that much clarity in the parameters, but the best two had col_sample_rate of $0.8$ and sample_rate of $0.95$, whereas sample_rate=0.5 was only chosen once, but was the worst of the nine. The default model with just early stopping added, would have come second best in the grid measured on classification error, but fourth on MSE, and seventh on logloss, whereas the “tuned” model is top on all metrics, so we have more confidence in selecting it.\nAs a final step, we ran the chosen model on the test data and got an error rate of $2.33%$. This compares to $4.44%$ with the default settings."},"title":"Tema 2. Intensificación (boosting)"},"/notes/datascience/master/aaii/03_combination/":{"data":{"":"","conclusiones#Conclusiones":"While a large number of combination techniques have been proposed, the literature still lacks a comprehensive performance analysis of such techniques for a given application. The review showed that while one strategy (e.g. fusion at decision level) may outperform others for a given application, the results from such a strategy may not be the best for another application.\nHowever overall, it was shown that classifiers combinations in general improve performance significantly over individual classifiers for most problems.\nAn important research direction relies on adding an enhancement stage (post processing) to the classifiers output before applying combination rules. This would improve the performance of individual classifiers before the combination stage. Many classifiers combination techniques have performed well under certain restrictions which include independence assumption, Gaussian distribution, linear process, limited class problem (mostly 2-class problem) and low dimensional feature space. Thus, future work can reconsider relaxing some of these constraints\nAnother issue that needs to be further investigated is to explore the advantages of using different strategies for the fusion including probabilistic, learning, decision based, or evidence based techniques.\nThe discussion on voting based approaches has shown that there is a scope for improving classification accuracy. This issue also offers numerous opportunities for developing optimization techniques to determine the weights. Some of the approaches including GA, PSO, and Ant optimization techniques, among others, can be investigated.\nNeural networks as well as similar models such as fuzzy networks, deep neural networks; SVM, etc. also offer an excellent opportunity for developing adaptive techniques to combine individual classifiers outputs. For example, can individual classifiers be considered as layers of more general architectures.\nComputational complexity is an important issue that needs further research especially when the different algorithms are deployed over mobile or low power platform\nAn important issue which is still open is that of finding the optimal number of classifiers to be combined for a given application. Additionally, for a given number of features, is there a way to distribute these among the different classifiers to be combined.\nFinally, the use of hybrid approaches to integrate results from different combination techniques, offers further opportunities for solving more involved applications.","estrategias-para-la-combinación-de-clasificadores#Estrategias para la combinación de clasificadores":"Levels of Classifiers Combination Classifiers combination can be carried out at three different levels:\nEarly combination at sensor data level: combination of data collected from two or more sensors before feature selection technique is applied. Combination at feature level: it may simply involve basic concatenation of feature vectors with equal or different weights (might result in high dimensonal vectors, whose dimension has to be reduced). Late combination at the decision level: they are based on one of three approaches: abstract, rank, and score: Abstract-based: a single output label from each individual classifier is used as input to the combination scheme. Rank-based: each classifier yields several labels ranked from the most likely to the least likely. This information is then used by the combination scheme to reach the final decision. Score-based: each classifier outputs the $n$ best labels together with their confidence scores. The combination can be density-based, transformation-based or classifier-based score fusion. Hard and Soft Level Classifier Combination Another way to categorize combination algorithms is whether hard thresholding or soft scoring is used with each of the classifiers.\nHard-level combination: uses the output of the classifier after it is hard thresholded. Soft-level combination: uses estimates of the aposteriori probability of the class. The sum, product, max, min rules, etc., fall under the soft level combiners as they use the output aposteriori probability of the classifier or a score.\nSum rule: The class with the highest sum of probabilities is chosen as the final prediction. Product rule: The class with the highest product of probabilities is chosen as the final prediction. Max rule: the class with the highest posterior probability among all classifications made by individual classifiers is selected as the final prediction. Min rule: the class with the lowest posterior probability among all classifications made by individual classifiers is selected as the final prediction. Majority voting is a typical example of hard-level combiners and has found widespread use in the literature. There are three different versions of voting:\nUnanimous voting. More than half voting. Highest number of votes. Considering the output label vector of the $i$th classifier as:\n$$ \\begin{aligned} [d_{i, 1}, \\cdots, d_{i, N}]^T \\in [0, 1]^N \\end{aligned} $$where $i = 1, 2, \\cdots, M$ and $d_{i, j} = 1$ if the classifier $D_i$ labels the $i$th instance as class $\\omega_j$ and $0$ otherwise. The majority vote results in a decision for class $\\omega_k$ if:\n$$ \\begin{aligned} \\sum_{i = 1}^M d_{i, k} = \\max_{j = 1}^N \\sum_{i = 1}^M d_{i, j} \\end{aligned} $$Where $M$ is the total number of classifiers and $N$ is total number of classes. Such that class $\\omega_k$ is the most “selected” on all the classifier.\nThe accuracy of the combination scheme is given as:\n$$ \\begin{aligned} P_{maj} = \\sum_{m = \\frac{M}{2} + 1}^M \\binom{M}{m} p^m (1-p)^{M - m} \\end{aligned} $$where $p$ is the probability of correct classification.\nMajority voting provides an accurate class label when at least $\\frac{M}{2} + 1$ classifiers give correct classifications, it also requires participating classifiers to have comparable accuracies.\nWeighted Majority Voting Weighted majority voting is used when the classifiers’ accuracies are not similar, so it is reasonable to assign more weight to the most accurate classifier. Now the decision rule becomes:\n$$ \\begin{aligned} \\sum_{i = 1}^M b_i d_{i, k} = \\max_{j = 1}^N \\sum_{i = 1}^M b_i d_{i, j} \\end{aligned} $$where $b_i$ is the weight associated with classifier $D_i$. For the sake of convenience, it is a good practice to normalize the weights such that the sum is one.\nThe weight selection is very important in determining the overall accuracy of the classifier combinations. Therefore, to minimize the classification error of the combination, the weights are assigned as follows:\n$$ \\begin{aligned} b_i \\propto \\log\\left(\\frac{p_i}{1 - p_i}\\right) \\end{aligned} $$where $p_i, \\cdots, p_M$ are the individual accuracies for each independent classifier.\nDynamic Weighted Consult-and-vote In [30], Muhlbaier et al. introduced a method for combining ensembles of classifiers using a dynamic weighted consult-and-vote approach for incremental learning of new classes. The proposed technique focuses on incremental learning, specifically for incorporating new classes into the classification system. The consult-and-vote strategy involves a dynamic process where individual classifiers within the ensemble consult with each other to determine their respective voting weights for classifying test instances.\nThe voting weights assigned to each classifier are determined based on their relative performance on the training data.\nThe method proposed by Muhlbaier et al. represents an enhancement over a previous approach developed by the authors. The previous approach may have encountered the “out-voting” problem, where certain classifiers dominate the decision-making process, potentially leading to biased or inaccurate results.\nDivide and Conquer Another modification of majority voting, involving a divide and conquer strategy, is described in [31]. It aims to enhance the majority voting approach by breaking down the classification task into smaller, more manageable sub-problems. Each sub-problem is then addressed independently, with dedicated classifiers or classification algorithms focusing on solving the specific challenges within that subset of data. After solving each of the smaller sub-problems individually, the results or decisions from these segments are combined using a majority voting scheme. Majority voting involves aggregating the outputs of the classifiers or algorithms involved in solving the sub-problems and selecting the class label that receives the most votes as the final decision.\nQuality Based Combination Techniques The quality-based combination approach, as referenced in [32], focuses on assigning higher weights to more reliable classifiers based on specific quality measures. Quality measures used to assess the performance of classifiers may vary depending on the application domain and specific requirements.\nFeature Combination The challenge of increasing dimensionality resulting from the simple combination of features from different datasets is addressed through innovative approaches to decision-level combination, as discussed in [33]. Combining features from diverse datasets can lead to a significant increase in the dimensionality of the data. The study proposed an effective approach for decision-level combination by leveraging spectral reflectance and its higher-order derivatives to classify hyperspectral land images. Spectral reflectance and its derivatives provide valuable information about the characteristics of the land surface, which can aid in classification tasks. The study conducted experiments under two scenarios to address the curse of dimensionality:\nScenario 1 - LDA-Based Dimensionality Reduction: Linear Discriminant Analysis (LDA) was employed for dimensionality reduction. Scenario 2 - Multiple Classifiers Decision Fusion (MCDF): multiple classifiers were utilized for decision fusion to enhance classification performance. Critic Classifier In the study referenced as [34], the authors introduced an innovative approach that focuses specifically on addressing two-class classification problems. The key feature of this approach is the incorporation of a classifier critic associated with each individual classifier, aimed at predicting the error rate of the classifier. The role of the classifier critic is to forecast the potential error or misclassification rate of its associated classifier. The approach relies on classical standard voting techniques for combining the outputs of multiple classifiers.\nAdaptative Voting Technique In the study referenced as [35], the authors introduced an adaptive approach to voting techniques. The key innovation in this approach is the dynamic weighting of classifiers based on their estimated recognition performance.\nDifferent Model Combination In [36], the authors explored the combination of three distinct classifiers - Naive Bayes, J48 Decision Tree, and Decision Table - using various voting techniques to enhance classification accuracy. The classifiers were combined using different voting strategies, including simple voting (where each classifier has equal weight), weighted voting (assigning different weights to classifiers based on their performance), and probability-based voting (considering the confidence or probability estimates of classifiers). The study reported that the ensemble of classifiers using weighted and probability-based voting techniques outperformed simple majority voting. In addition to classifier combination and voting strategies, the study applied a supervised dimensionality reduction algorithm to further enhance performance. Dimensionality reduction techniques aim to reduce the complexity of the feature space while preserving relevant information, thereby improving classification accuracy and efficiency.\nIn [38], a voting strategy was employed for land cover classification of remotely sensed images by utilizing an ensemble of six different classifiers. Common voting techniques include simple majority voting, weighted voting, or probability-based voting, where the combined decision is based on the collective predictions of the ensemble members.\nIn the study referenced as [39], researchers proposed an approach that combines Artificial Neural Network (ANN) and K-Nearest Neighbors (KNN) based classifiers using a majority voting scheme. This method was specifically designed to enhance accuracy in scenarios where sensor data is prone to drift. The researchers employed a majority voting scheme to combine the predictions of the ANN and KNN classifiers. In this approach, each classifier in the ensemble provides a prediction, and the final decision is made based on the majority vote of the individual classifier outputs.\nThe primary goal of the study was to leverage the complementary strengths of ANN and KNN classifiers to address the challenge of sensor data drift. ANN models are known for their ability to learn complex patterns from data, while KNN is a non-parametric method based on instance-based learning that can be effective in classification tasks.\nBy combining multiple KNN classifiers using majority voting and employing median voting for the ANN classifiers, the researchers observed a substantial improvement in classification performance. The ensemble of ANN and KNN classifiers demonstrated enhanced accuracy in classifying sensor data, showcasing the effectiveness of the majority voting scheme in mitigating the impact of data drift on classification outcomes.\nDynamic Entropy Based Combination Technique In [37], the authors introduced a novel dynamic entropy-based technique for combining classifiers. The key idea behind the combination scheme is to assign weights to individual classifiers based on their confidence levels in making decisions. Classifiers that exhibit high confidence in their predictions are assigned larger weights, while those with lower confidence receive smaller weights.\nAssuming Linear Dependency Between Predictors In [40], the authors considered linear dependency of both classifiers and features. To address this, they proposed a new approach that models the dependencies between features without making any assumptions about the distribution of features (independency) or classifiers. The researchers introduced two key models as part of their framework:\nLinear Classifier Dependency Modelling (LCDM): This model focuses on capturing dependencies between the classifiers themselves, exploring how the outputs of different classifiers may be linearly related. Linear Feature Dependency Modelling (LFDM) : This model is designed to identify and model dependencies between the features used by the classifiers, allowing for a more comprehensive understanding of the relationships within the feature space. The results of the study demonstrated that the proposed approach outperformed existing methods in scenarios where linear dependencies between features and classifiers play a significant role. By explicitly modeling these dependencies, the framework was able to capture more complex relationships within the data and improve classification accuracy.\nRuntime Weighted Opinion Pool In [45], introduces a novel classifiers combination approach known as the Runtime Weighted Opinion Pool (RWOP). This approach dynamically assigns weights to the classifiers during runtime based on their local performance, leading to an adaptive and context-aware combination strategy. Unlike traditional weighted sum-based approaches, RWOP utilizes an intuitive runtime strategy to determine the weights for combining classifier outputs. The dynamic weight assignment in RWOP allows the system to adapt to changing conditions and varying input patterns, leading to more robust and accurate classification outcomes.\nUsing Hidden Markov Models In the study referenced as [46], the authors introduce a novel approach for combining classifiers specifically designed for Hidden Markov Model (HMM) based classifiers. Unlike traditional methods where the combination typically occurs at the decision level, this new approach operates at a more elementary level within the HMM framework.\nAssigning Weights to Classes In the study referenced as [12], a novel weighted majority voting approach was proposed for classifiers combination. This approach differs from traditional methods by assigning weights to different classes rather than individual base classifiers. The weights are determined by estimating the joint probability distribution of each class using the scores provided by all classifiers in the combination pool. The joint probability distribution is computed using the Naïve Bayes probabilistic model.\nCombination Rules In the context of multiple classifiers combination, the way individual classifiers handle input patterns can vary. Some classifiers may use the same representation of the input pattern, while others may employ their own unique representations. The effectiveness of combining these classifiers using different strategies has been explored in various studies, including those referenced as [41], [42], and [43].\nSimple Sum Rule: Despite being developed under restrictive assumptions, the simple sum rule was found to outperform other combination rules in certain scenarios. Majority Voting: The experimental results indicated that the majority voting approach was the most effective combination rule for the specific dataset used in the study. Assesment Fixed rule-based combination techniques in the context of multiple classifiers do not require a training stage and rely on class labels, distances, or confidences provided by individual classifiers. The efficiency of fixed rule techniques is influenced by various factors, as discussed in reference [44].\nAccording to reference [44], fixed rule techniques are most efficient under specific conditions:\nAvailability of Large Training Sets: Adequate training data is essential for reliable performance. Generation of Reliable Confidences: Individual classifiers should provide accurate and trustworthy confidence values. Training on Different Feature Spaces: Base classifiers should be trained on diverse feature representations to capture varied aspects of the data. In scenarios where the strict conditions for fixed rule techniques are not met, a trained combination rule may yield better results.\nAdaptative and Non-Adaptative Combiners Adaptative Combiners Adaptive techniques for classifiers combination are mainly based on evolution or artificial intelligence algorithms. They include neural networks combination strategies and genetic algorithms as well as fuzzy set theory. Techniques under these categories are summarized on the following figure:\nArtificial Neural Networks are usually used as a base classifier [29], however, it has also found wide use in combination of classifiers.\nAD and CM Combination In [48], the author introduces two innovative approaches for combining classifiers to enhance robustness and fault tolerance: the Attractor Dynamics (AD) algorithm and the Classifier Masking (CM) algorithm. The CM algorithm is described as a non-neural version of the AD algorithm, inspired by modeling properties of sensory integration in the central nervous system. Both approaches are designed to promote consensus among individual classifiers and improve the overall performance of the combined system by discarding corrupted classifier outputs.\nANN vs SVM Combination In [49], the authors conducted a comparative analysis of combining the outputs of an ensemble of Artificial Neural Networks (ANNs) with Support Vector Machine (SVM) classifiers for processing remotely sensed data. They employed an Multi-Layer Perceptron (MLP) module to facilitate the non-linear combination of the outputs generated by the networks. The researchers explored two distinct approaches for optimizing coefficient selection: the Bayesian method and the error correlation matrix. Through experimental evaluation, the authors found that the MLP-based combination scheme yielded the most favorable results compared to the SVM classifiers.\nCombination through ANN In [50], the authors proposed a novel approach where they utilized an Artificial Neural Network (ANN) as a model for combining classifiers. Instead of combining the outputs of different classifiers, they integrated various training sets with distinct classifiers to train a unified combination rule within a three-layer ANN architecture. In this setup, each classifier represented a unit in the hidden layer of the ANN.\nIncorporating A Priori Knowledge In [51], the authors delved into the significance of leveraging a priori knowledge within existing classifiers combination techniques, specifically exploring the application of the Behavior Knowledge Space and the Dempster-Shafer (D-S) theory. This investigation aimed to elucidate how incorporating prior knowledge can enhance the performance of classifiers combination, particularly when dealing with strongly correlated classifiers. The study also highlighted the utilization of adaptive combiners, encompassing strategies such as adaptive weighting, associative switching, Mixture of Local Experts (MLE), and Hierarchical MLE\nCombining Combination Strategies Dynamically In [57] an adaptive approach to combining classifiers was introduced. The proposed approach dynamically selects between two different combination strategies based on the belief values obtained from each strategy. Specifically, the study compared the performance of a Bayesian classifiers combination approach and product and max rule combination strategy. In the Bayesian method, the combination of classifiers is based on probabilistic principles, where the posterior probabilities of class labels are calculated using Bayes’ theorem. The product rule combines the outputs of individual classifiers by multiplying their probabilities or scores for each class. The max rule operates by selecting the class label that receives the highest score or confidence level among all the individual classifiers in the ensemble.\nModifying Majority Voting In [58] the authors introduced various modifications to the traditional majority voting rule by incorporating a Bayesian framework and a Genetic Algorithm (GA) to determine the weights assigned to different classifiers in the ensemble. The Bayesian framework allowed for the probabilistic modeling of the weights, while the GA provided an optimization technique to search for the best combination of weights that maximized the ensemble performance. The results of the study indicated that the modified majority voting rule, when combined with the Bayesian framework and GA for weight optimization, achieved significant improvements in accuracy. Specifically, the optimal accuracies obtained were $94.3%$ for the majority vote, $95.4%$ for the genetic algorithm, and 95.95% for the Bayesian approach.\nBased on Genetic Theory In the study referenced as [22], the authors introduced an innovative approach that involved the simultaneous extraction and selection of features and classifiers to improve the performance of gender and age classification using speech signals collected from a typical Korean home environment.\nThe authors employed a Genetic Algorithm to simultaneously select features and classifiers. GA is a metaheuristic optimization technique inspired by the process of natural selection and genetics, used to search for the optimal combination of features and classifiers for the classification task. The outputs of the selected classifiers were combined using the Dempster-Shafer theory, a mathematical theory for combining evidence from different sources to make decisions under uncertainty.\nIn [59] a novel approach based on Genetic Algorithm (GA) with self-configuration capabilities was developed for classifier combination. The researchers employed a pool of twelve expert classifiers that were already trained on the task of character recognition, including both printed and handwritten characters. These expert classifiers likely had different strengths and weaknesses, making them suitable candidates for ensemble learning. The GA was integrated into the system to optimize the combination of outputs from the expert classifiers. By using the evolutionary principles of genetic algorithms, the system could iteratively adjust the weights assigned to each classifier in the ensemble to maximize the overall accuracy of the system.\nFuzzy Based In the study referenced as [16], the authors introduced a novel approach known as Fuzzy Stacked Generalization (FSG) to combine the outputs of multiple classifiers. FSG operates within a hierarchical framework where multiple base-layer classifiers are utilized to make individual predictions on the input data. In FSG, the decisions made by the base-layer classifiers are aggregated to form a decision vector. This decision vector is then fed into a meta-layer classifier, which combines the outputs of the base-layer classifiers to make the final decision.\nIn [53], the authors proposed a classifiers combination technique using fuzzy templates (FT). An object is labeled with the class whose fuzzy template is closest to the objects’ decision profile. the authors obtained an improved performance over majority, min, max and product rules, and unweighted average combination techniques\nIn [54], an adaptive fuzzy integral was used to combine multiple classifiers. The parameter $\\lambda$-fuzzy, which measures performance, is adaptively adjusted depending upon the interaction among the classifiers. The essence of the parameter is to search for the maximum degree of agreement between the conflicting and complementary sources of evidence.\nIn [55], a fuzzy decision rule was employed to combine the outputs of multiple classifiers without the need for a training stage. Each classifier was independently applied to the input data, but no final decision was made based on their outputs at this stage. These classifiers are pre-existing models that have been trained on labeled data to make predictions or classifications. The results from the classifiers were aggregated using a fuzzy decision rule. This rule considered the membership degrees of the classes assigned by each classifier and selected the class with the highest membership degree (the confidence or certainty with which each classifier assigns a data point to a specific class) as the correct class. Two measures of accuracy, namely information reliability and global accuracy, were utilized in the combination rule to assess the performance of the combined classifiers.\nIn [56] the authors introduced a first-order Takagi-Sugeno-Kang (TSK) fuzzy model for combining multiple classifiers. Unlike conventional linear combination methods that assign different weights to pairs of classifiers and classes, the proposed TSK fuzzy model assigns weights to each individual classifier, class, and region of the classifier output space (decision boundary). This finer granularity in weight assignment allows for a more nuanced and adaptive combination of classifier outputs. The TSK fuzzy model is utilized to integrate the outputs of multiple classifiers. This model leverages fuzzy logic to combine the predictions of individual classifiers in a way that considers the uncertainty and variability in the classifier outputs. The study demonstrated improved accuracy compared to using individual classifiers alone. While the TSK fuzzy model showed promising results in enhancing classification accuracy, the authors did not explicitly address the potential bias and variance reduction that could arise from using a linear model for combining classifiers.\nNon-Adaptative Combiners The highest confidence approach is an example of nonadaptive combination techniques. It involves ranking the individual classifiers based on their confidence then selecting the decision of the top ranked one.\nThe Borda count technique is also an example of nonadaptive methods. It is based on the principle of single winner classifier in which the individual classifiers provide a ranked list of the classes. It is a more sophisticated alternative to majority voting [60] based on ranking level [9]. It does not require training, just like averaging, sum, and voting rules [52].\nConclusion In summary, adaptive combiners tend to do better than the non-adaptive types. This is due to the fact that adaptive combiners update the weights given to the individual classifier dynamically before making the final decision. Given the fact that the performance of the individual classifiers can vary over input patterns, such a dynamic combination provides an edge over its non-adaptive counterpart especially when the data space is wide and diverse.\nClassification Based on the Number of Classifiers The most commonly used techniques for ensemble based combinations are displayed in the following figure:\nBagging is one of the most intuitive and simple techniques used for ensemble based combination. However, unlike bagging, in boosting, the individual classifiers are trained hierarchically to discriminate more complex regions in the feature space. AdaBoost is a variation of the boosting technique. It is an adaptive boosting meta-algorithm that combines outputs of weak classifiers into a weighted sum that represents the final decision. However, the technique is sensitive to noisy data and outliers.\nIn [66], the authors used AdaBoost to enhance the performance of a hybrid Hidden Markov Model (HMM) and Neural Network (NN) speech recognition system. HMMs are commonly used for modeling sequential data like speech signals, while NNs are effective in capturing complex patterns in data. The researchers evaluated the performance of the hybrid HMM/NN system with and without the AdaBoost algorithm under noisy environments. Noise in speech signals can introduce distortions and affect the accuracy of the recognition system. By applying AdaBoost, the system was expected to adapt better to noisy conditions and enhance its robustness. The results of the study demonstrated that incorporating AdaBoost into the hybrid HMM/NN speech recognition system led to improved performance, even in the presence of noise. AdaBoost’s ability to focus on difficult instances and adjust the weights of the classifiers based on their performance contributed to the system’s ability to handle noisy environments and enhance overall recognition accuracy.\nIn [67] the researchers explored a combination approach at the feature level using Support Vector Machine (SVM) classifiers and a Global AdaBoost classifier. The study focused on combining features extracted from different datasets at the feature level. By utilizing SVM classifiers and a Global AdaBoost classifier, the researchers aimed to leverage the strengths of both classifiers in integrating information from multiple datasets to improve classification performance. One significant drawback identified in the study regarding feature-level combination is the issue of high dimensionality. Combining features from multiple datasets can result in a large number of features, which can lead to challenges such as increased computational complexity, overfitting, and reduced interpretability of the model.\nOther Combination Techniques In [68] the researchers introduced a novel classifiers combination technique based on an SVM active learning algorithm. The study proposed a method that leverages Support Vector Machine (SVM) classifiers in conjunction with an active learning algorithm. Active learning refers to a machine learning approach where the algorithm can select the most informative data points for labeling, thereby improving the learning process iteratively. The researchers developed a strategy where an initial classifier, likely an SVM model, is used to generate class aposteriori probabilities. These probabilities serve as inputs to the classifiers-combiner, which is based on the SVM active learning algorithm. The approach outperforms traditional classifiers combination rules when considering class labeling cost and classification accuracy.\nIn [70] and [71] the researchers introduced a novel approach using eigenclassifiers for combining correlated classifiers. The proposed method involves utilizing Principal Component Analysis (PCA) projection to create eigenclassifiers from a set of initially correlated classifiers. By applying PCA, the goal is to transform the correlated classifiers into uncorrelated eigen-classifiers. This transformation process aims to enhance the diversity and independence of the classifiers, enabling them to complement each other effectively during the combination stage. The results of the study indicated that the PCA-based eigenclassifiers technique provided better or comparable accuracy with a reduced number of classifiers compared to Bagging and AdaBoost. This suggests that the uncorrelation process facilitated by PCA enhanced the performance of the combined classifiers, leading to improved classification results with fewer individual classifiers.\nSimilarly, in [72] the researchers explored methods to address linear and non-linear correlations among the outputs of individual classifiers by leveraging Principal Component Analysis (PCA) and a generalized kernel-based PCA approach. Initially, the authors identified linear correlations among the outputs of individual classifiers. To mitigate these linear correlations, the researchers applied a simple PCA approach. Building on the success of addressing linear correlations, the authors extended their approach to consider non-linear dependencies among the outputs of individual classifiers. o handle these non-linear dependencies, the researchers proposed a generalized kernel-based PCA approach. The results of the experiments demonstrated that the generalized kernel-based PCA approach outperformed alternative methods in improving classification accuracy.\nIn [73] the researchers introduced a novel classifier combination technique that focused on extracting class boundaries and utilizing a set of local linear combination rules. The proposed technique involved extracting class boundaries, which are the decision boundaries that separate different classes in the dataset. The researchers employed a set of local linear combination rules to combine the outputs of individual classifiers. These rules likely involved linear combinations of classifier outputs within specific regions of the feature space, allowing for adaptive and context-aware decision-making. The experimental results demonstrated that the classifier combination technique based on class boundaries and local linear combination rules achieved better accuracy compared to other methods such as linear combination, voting, and decision templates.\nIn [13], the researchers proposed a weighted averaging approach that incorporated graph-theoretical clustering and a Support Vector Machine (SVM) classifier for classifier combination. The researchers utilized graph-theoretical clustering techniques as part of the weighted averaging approach. Graph theory provides a framework for analyzing relationships between data points, and clustering algorithms can group similar data points together based on certain criteria. By incorporating graph-theoretical clustering, the approach likely aimed to identify clusters of data points with similar characteristics for more effective combination of classifier outputs. In addition to clustering, the approach involved the use of an SVM classifier. SVMs are powerful machine learning models commonly used for classification tasks. By integrating an SVM classifier into the weighted averaging process, the researchers likely leveraged its ability to create optimal decision boundaries between classes in the feature space. The results obtained from the experiments indicated that the proposed approach, despite its simplicity and intuitive nature, performed comparably to more sophisticated methods.\nIn [74], the researchers employed three different techniques - Highest Rank (HR), Borda Count (BC), and Logistic Regression (LR) - for combining decisions in a multi-classifier system. The decisions produced by each individual classifier were ranked based on their confidence or accuracy. The HR, BC, and LR techniques were then applied to either reduce the set of possible classes or re-rank them during the combination process. The results obtained from the experiments demonstrated a substantial improvement in the performance of the multi-classifier system.\nSimilarly, in [75] a new combination technique called Mixed Group Rank (MGR) was introduced as a novel approach to balancing between preference and confidence in a multi-classifier system. This technique aimed to generalize the principles of Highest Rank (HR), Borda Count (BC), and Logistic Regression (LR) by incorporating elements of both preference-based ranking and confidence-based decision-making.\nIn [76], the authors introduced an innovative approach that involves dynamically switching between classifier combination and classifier selection based on the characteristics of different regions in the feature space. The authors further introduced a hybrid combination scheme that integrates clustering-and-selection (CS) techniques with decision template (DT) methods. This hybrid approach likely combines the benefits of clustering for identifying regions of dominance and selection of the most appropriate classifier, along with decision templates for combining classifier outputs in a structured manner. The authors discussed the tradeoff between selecting the best classifier and combining classifiers. This tradeoff likely involves considerations of the strengths and weaknesses of individual classifiers versus the potential benefits of combining multiple classifiers.\nIn [77], the authors introduced a method based on classifier selection that focused on identifying the most suitable candidate through confidence evaluation of distance-based classifiers. The method aimed to select the most precise candidate from a set of distance-based classifiers by evaluating their confidence levels. This process likely involved assessing the certainty or reliability of each classifier’s decision-making based on the distances between data points in the feature space. The authors likely defined specific rules or criteria for selecting the precise candidate based on the confidence evaluations of the distance-based classifiers. These rules may have considered factors such as the proximity of data points to decision boundaries, the consistency of classifier outputs, or the overall confidence levels of individual classifiers. The experiments conducted in the study likely utilized distance metrics such as Euclidean distance and city block distance for recognizing handwritten characters.\nIn [78], the author used information from the confusion matrix to merge multiple classifiers using a class ranking Borda type reconciliation method. The class ranking Borda type reconciliation method is a technique that combines the outputs of multiple classifiers by ranking the classes based on their performance and then using a Borda count approach to reconcile the rankings. The results obtained from this method were compared with three other classifier combination techniques: majority voting, sum rule, and median rule. The comparison was done using three types of confusion matrices: deterministic, uniform, and stochastic. The APBorda (aposteriori Borda count) and sum rule gave the overall best improvement, except in the case of a stochastic confusion matrix and disparate combination (where classifiers had a $10%$ accuracy difference from each other). This means that in most cases, the APBorda and sum rule performed better in combining the classifiers, but there were specific scenarios where they did not perform as well.\nIn [79] a combination technique based on the F-measure was proposed for recognizing human emotions using an SVM (Support Vector Machine) classifier. In this technique, the F-measure was used to form a decision matrix to determine the final emotion.\nIn [80], the authors proposed an approach for detecting vacant parking spaces by combining two different systems. The first system was based on analyzing image data, while the second system relied on sensor data. The experiments conducted by the authors demonstrated that combining the outputs of these two different systems resulted in a reduced error in detecting vacant parking spaces.\nIn summary, several classifiers combination techniques have been proposed in the literature with each technique having its own strengths and weaknesses. Recent techniques mostly involve hybridization or modification of previous techniques to achieve better accuracy or to remove an associated constraint on which a particular technique was built on. Some of these constraints include the issue of correlated classifiers, Gaussian distribution, and IID. There is still a need to develop classifiers combination strategies which are not constrained to specific distributions.","introduccion#Introduccion":"Bibliography Classifiers Combination Techniques: A Comprehensive Review [10] S. Chitroub, “Classifier combination and score level fusion: concepts and practical aspects,” Int. J. Image Data Fusion, vol. 1, no. 2, pp. 113–135, Jun. 2010. [11] H. He and Y. Cao, “SSC: a classifier combination method based on signal strength.,” IEEE Trans. neural networks Learn. Syst., vol. 23, no. 7, pp. 1100–17, Jul. 2012. [12] C. De Stefano, F. Fontanella, and A. S. di Freca, “A Novel Naive Bayes Voting Strategy for Combining Classifiers.,” in ICFHR, 2012, pp. 467–472. [13] J. Hou, Z.-S. Feng, and B.-P. Zhang, “A graph-theoretic approach to classifier combination,” in Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on, 2012, pp. 1017–1020. [14] Y.-D. Lan and L. Gao, “A New Model of Combining Multiple Classifiers Based on Neural Network,” 2013 Fourth Int. Conf. Emerg. Intell. Data Web Technol., no. 2, pp. 154–159, Sep. 2013. [15] H. Kuang, X. Zhang, Y.-J. Li, L. L. H. Chan, and H. Yan, “Nighttime Vehicle Detection Based on Bio-Inspired Image Enhancement and Weighted Score-Level Feature Fusion,” IEEE Trans. Intell. Transp. Syst., vol. 18, no. 4, pp. 927–936, Apr. 2017. [16] C. Senaras, M. Ozay, and F. T. Yarman Vural, “Building detection with decision fusion,” 2013. ","marco-general-para-la-combinacion-de-clasificadores#Marco general para la combinacion de clasificadores":"The task is seen as a problem of finding a combination function which accepts $N$-dimensional score vectors from each of the $M$ classifiers, then producing a single final classification score representing the selected class.\nGiven the $N$ possible classes ${\\omega_1, \\omega_2, \\cdots, \\omega_N}$ and a pattern $Z$ (that is a data sample), let $x_k$ be the measurement vector (the numerical attributes of $Z$) used by the $k$th classifier (different classifiers may use different attributes to discriminate). The probability density function of the measurement vector is represented by:\n$$ \\begin{aligned} p(x_k|\\omega_n) \\end{aligned} $$while the prior probability of the occurrence of the class is denoted by $p(\\omega_n)$. The Bayesian framework aims to determine the class label for the pattern $Z$ by considering the information provided by all $M$ classifiers. The final decision is based on the aposteriori probability, which is the probability of the pattern belonging to a specific class $j$ given the measurement vectors from all classifiers $x_1, x_2, \\cdots, x_M$.\n$$ \\begin{aligned} p(\\theta = \\omega_j|x_1, x_2, \\cdots, x_M) = \\max_{k} p(\\theta = \\omega_k | x_1, x_2, \\cdots, x_M) \\end{aligned} $$So the pattern $Z$ is assigned to class $\\omega_j$ which produces the maximum a posterior probability. Where the aposteriori distribution is computed as follows:\n$$ \\begin{aligned} p(\\theta = \\omega_j|x_1, x_2, \\cdots, x_M) = \\frac{p(x_1, x_2, \\cdots, x_M|\\theta = \\omega_j)p(\\theta=\\omega_j)}{p(x_1, x_2, \\cdots, x_M)} \\end{aligned} $$Provided that each classifier provides independently a decision support obtained from $x_k$, where $p(x_1, x_2, \\cdots, x_M)$ is the joint pdf of the observations independently of class label.\nThe important issue is that the individual classifiers should not make identical erroneous decisions on the same observation instances, they should provide complementary information.","references#References":"[12] C. De Stefano, F. Fontanella, and A. S. di Freca, “A Novel Naive Bayes Voting Strategy for Combining Classifiers.,” in ICFHR, 2012, pp. 467–472.\n[16] C. Senaras, M. Ozay, and F. T. Yarman Vural, “Building detection with decision fusion,” 2013.\n[22] Y. Zhan, H. Leung, K.-C. Kwak, and H. Yoon, “Automated speaker recognition for home service robots using genetic algorithm and Dempster–Shafer fusion technique,” Instrum. Meas. IEEE Trans., vol. 58, no. 9, pp. 3058–3068, 2009.\n[29] L. I. Kuncheva, Combining pattern classifiers: methods and algorithms. John Wiley \u0026 Sons, 2004.\n[32] N. Poh and J. Kittler, “A unified framework for biometric expert fusion incorporating quality measures,” Pattern Anal. Mach. Intell. IEEE Trans., vol. 34, no. 1, pp. 3–18, 2012.\n[33] H. R. Kalluri, S. Prasad, and L. M. Bruce, “Decision-level fusion of spectral reflectance and derivative information for robust hyperspectral land cover classification,” Geosci. Remote Sensing, IEEE Trans., vol. 48, no. 11, pp. 4047–4058, 2010.\n[34] D. J. Miller and L. Yan, “Ensemble classification by critic-driven combining,” in Acoustics, Speech, and Signal Processing, 1999. Proceedings., 1999 IEEE International Conference on, 1999, vol. 2, pp. 1029–1032\n[35] F. Mattern, T. Rohlfing, and J. Denzler, “Adaptive performancebased classifier combination for generic object recognition,” in Proc. of International Fall Workshop Vision, Modeling and Visualization (VMV), 2005, pp. 139–146\n[36] G. Jain, A. Ginwala, and Y. A. Aslandogan, “An approach to text classification using dimensionality reduction and combination of classifiers,” in Information Reuse and Integration, 2004. IRI 2004. Proceedings of the 2004 IEEE International Conference on, 2004, pp. 564–569.\n[37] M. Magimai-Doss, D. Hakkani-Tur, O. Cetin, E. Shriberg, J. Fung, and N. Mirghafori, “Entropy based classifier combination for sentence segmentation,” in Acoustics, Speech and Signal Processing, 2007. ICASSP 2007. IEEE International Conference on, 2007, vol. 4, p. IV–189\n[39] S. Adhikari and S. Saha, “Multiple classifier combination technique for sensor drift compensation using ANN \u0026 KNN,” in Advance Computing Conference (IACC), 2014 IEEE International, 2014, pp. 1184–1189.\n[40] A. J. Ma, P. C. Yuen, and J.-H. Lai, “Linear dependency modeling for classifier fusion and feature combination,” Pattern Anal. Mach. Intell. IEEE Trans., vol. 35, no. 5, pp. 1135–1148, 2013.\n[43] Z. Wu, C.-H. Li, and V. Cheng, “Large margin maximum entropy machines for classifier combination,” in Wavelet Analysis and Pattern Recognition, 2008. ICWAPR’08. International Conference on, 2008, vol. 1, pp. 378–383\n[44] R. P. W. Duin, “The combining classifier: to train or not to train?,” in Pattern Recognition, 2002. Proceedings. 16th International Conference on, 2002, vol. 2, pp. 765–770.\n[45] W. Wang, A. Brakensiek, and G. Rigoll, “Combination of multiple classifiers for handwritten word recognition,” in Frontiers in Handwriting Recognition, 2002. Proceedings. Eighth International Workshop on, 2002, pp. 117–122.\n[48] A. V Bogdanov, “Neuroinspired architecture for robust classifier fusion of multisensor imagery,” Geosci. Remote Sensing, IEEE Trans., vol. 46, no. 5, pp. 1467–1487, 2008.\n[49] G. Pasquariello, N. Ancona, P. Blonda, C. Tarantino, G. Satalino, and A. D’Addabbo, “Neural network ensemble and support vector machine classifiers for the analysis of remotely sensed data: a comparison,” in Geoscience and Remote Sensing Symposium, 2002. IGARSS’02. 2002 IEEE International, 2002, vol. 1, pp. 509–511.\n[50] Y.-D. Lan and L. Gao, “A New Model of Combining Multiple Classifiers Based on Neural Network,” in Emerging Intelligent Data and Web Technologies (EIDWT), 2013 Fourth International Conference on, 2013, pp. 154–159.\n[51] V. Di Lecce, G. Dimauro, A. Guerriero, S. Impedovo, G. Pirlo, and A. Salzo, “Knowledge-based methods for classifier combination: an experimental investigation,” in Image Analysis and Processing, 1999. Proceedings. International Conference on, 1999, pp. 562–565.\n[52] A. K. Jain, R. P. W. Duin, and J. Mao, “Statistical pattern recognition: A review,” Pattern Anal. Mach. Intell. IEEE Trans., vol. 22, no. 1, pp. 4–37, 2000.\n[53] L. I. Kuncheva, J. C. Bezdek, and M. A. Sutton, “On combining multiple classifiers by fuzzy templates,” in Fuzzy Information Processing Society-NAFIPS, 1998 Conference of the North American, 1998, pp. 193–197\n[54] T. D. Pham, “Combination of multiple classifiers using adaptive fuzzy integral,” in Artificial Intelligence Systems, 2002.(ICAIS 2002). 2002 IEEE International Conference on, 2002, pp. 50–55.\n[55] M. Fauvel, J. Chanussot, and J. A. Benediktsson, “Decision fusion for the classification of urban remote sensing images,” Geosci. Remote Sensing, IEEE Trans., vol. 44, no. 10, pp. 2828–2838, 2006.\n[56] M. Cococcioni, B. Lazzerini, and F. Marcelloni, “A TSK fuzzy model for combining outputs of multiple classifiers,” in Fuzzy Information, 2004. Processing NAFIPS’04. IEEE Annual Meeting of the, 2004, vol. 2, pp. 871–876.\n[57] Y. Yaslan and Z. Cataltepe, “Co-training with adaptive bayesian classifier combination,” in Computer and Information Sciences, 2008. ISCIS’08. 23rd International Symposium on, 2008, pp. 1–4.\n[58] L. Lam and C. Y. Suen, “Optimal combinations of pattern classifiers,” Pattern Recognit. Lett., vol. 16, no. 9, pp. 945–954, 1995.\n[59] K. Sirlantzis and M. C. Fairhurst, “Optimisation of multiple classifier systems using genetic algorithms,” in Image Processing, 2001. Proceedings. 2001 International Conference on, 2001, vol. 1, pp. 1094–1097\n[66] H. Schwenk, “Using boosting to improve a hybrid HMM/neural network speech recognizer,” in Acoustics, Speech, and Signal Processing, 1999. Proceedings., 1999 IEEE International Conference on, 1999, vol. 2, pp. 1009–1012.\n[67] J. Hu and Y. Chen, “Offline Signature Verification Using Real Adaboost Classifier Combination of Pseudo-dynamic Features,” in Document Analysis and Recognition (ICDAR), 2013 12th International Conference on, 2013, pp. 1345–1349\n[68] X. Yi, Z. Kou, and C. Zhang, “Classifier combination based on active learning,” in Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on, 2004, vol. 1, pp. 184–187.\n[69] J. Kremer, K. Steenstrup Pedersen, and C. Igel, “Active learning with support vector machines,” Wiley Interdiscip. Rev. Data Min. Knowl. Discov., vol. 4, no. 4, pp. 313–326, Jul. 2014.\n[70] A. Ulaş, O. T. Yıldız, and E. Alpaydın, “Eigenclassifiers for combining correlated classifiers,” Inf. Sci. (Ny)., vol. 187, pp. 109– 120, 2012.\n[71] E. Ulaş, A., Semerci, M., Yıldız, O. T., \u0026 Alpaydın, “Incremental construction of classifier and discriminant ensembles,” Inf. Sci. (Ny)., vol. 179, no. 9, pp. 1298–1318, 2009\n[72] U. Ekmekci and Z. Cataltepe, “Classifier combination with kernelized eigenclassifiers,” in Information Fusion (FUSION), 2013 16th International Conference on, 2013, pp. 743–749.\n[73] M. Liu, K. Li, and R. Zhao, “A boundary based classifier combination method,” in Control and Decision Conference, 2009. CCDC’09. Chinese, 2009, pp. 3777–3782\n[74] T. K. Ho, J. J. Hull, and S. N. Srihari, “Decision combination in multiple classifier systems,” Pattern Anal. Mach. Intell. IEEE Trans., vol. 16, no. 1, pp. 66–75, 1994.\n[75] O. Melnik, Y. Vardi, and C.-H. Zhang, “Mixed group ranks: Preference and confidence in classifier combination,” Pattern Anal. Mach. Intell. IEEE Trans., vol. 26, no. 8, pp. 973–981, 2004.\n[76] L. I. Kuncheva, “Switching between selection and fusion in combining classifiers: An experiment,” Syst. Man, Cybern. Part B Cybern. IEEE Trans., vol. 32, no. 2, pp. 146–156, 2002.\n[77] C.-L. Liu and M. Nakagawa, “Precise candidate selection for large character set recognition by confidence evaluation,” Pattern Anal. Mach. Intell. IEEE Trans., vol. 22, no. 6, pp. 636–641, 2000.\n[78] J. R. Parker, “Combining multiple non-homogeneous classifiers: an empirical approach,” in Cognitive Informatics, IEEE International Conference on, 2002, p. 288.\n[79] A. Agrawal and N. K. Mishra, “Fusion Based Emotion Recognition System,” in 2016 International Conference on Computational Science and Computational Intelligence (CSCI), 2016, pp. 727–732\n[80] Junzhao, L., Mohandes, M., Deriche, M., “A Multi-Classifier Image Based Vacant Parking Detection System”, IEEE International Conference on Electronics, Circuits, and Systems ICESC, pp. 933-936, Abu Dhabi, UAE, DEC 8-11, 2013"},"title":"Tema 3. Otras Combinaciones de Modelos"},"/notes/datascience/master/aaii/04_unsupervised_ml/":{"data":{"":"","cluster-analysis#Cluster Analysis":"Proximity Matrices Sometimes the data is represented directly in terms of the proximity (alikeness or affinity) between pairs of objects. This type of data can be represented by an $N \\times N$ matrix $D$, where $N$ is the number of objects, and each element $d_{ij}$ records the proximity between the $j$th and $j$th objects. This matrix is then provided as input to the clustering algorithm.\nMost algorithms assume symmetric dissimilarity matrices, so if the original matrix $D$ is not symmetric it must be replaced by $\\frac{(D + D^T)}{2}$.\nDissimilarities Based on Attributes Since most of the popular clustering algorithms take a dissimilarity matrix as their input, we must first construct pairwise dissimilarities between the observations. By far the most common choice is squared distance:\n$$ \\begin{aligned} d_j(x_{ij}, x_{i'j}) = (x_{ij} - x_{i'j})^2 \\end{aligned} $$where $j$ denotes the attribute and $i, i’$ denotes the instance.\nWe first discuss alternatives in terms of the attribute type:\nQuantitative variables Measurements of this type of variable or attribute are represented by continuous real-valued numbers. One way to do this is by looking at the absolute difference between them:\n$$ \\begin{aligned} d(x_i, x_{i'}) = l(|x_i - x_{i'}|) \\end{aligned} $$Alternatively, clustering can be based on the correlation\n$$ \\begin{aligned} \\rho (x_i, x_{i'}) = \\frac{\\sum_{j} (x_{ij} - \\overline{x}_i)(x_{ij} - \\overline{x}_i)}{\\sqrt{\\sum_{j} (x_{ij} - \\overline{x}_i)^2 \\sum_j(x_{ij} - \\overline{x}_i)^2}} \\end{aligned} $$Ordinal Variables Error measures for ordinal variables are generally defined by replacing their $M$ original values with:\n$$ \\begin{aligned} \\frac{i - \\frac{1}{2}}{M}, i = 1, \\cdots, M \\end{aligned} $$in the prescribed order of their original values. They are then treated as quantitative variables on this scale.\nCategorical variables If the variable assumes $M$ distinct values, these can be arranged in a symmetric $M \\times M$ matrix with elements:\n$$ \\begin{aligned} m_{ij} = \\begin{cases} 0 \u0026 x_{i} = x_{j} \\\\ 1 \u0026 x_{i} \\neq x_{j} \\\\ \\end{cases} \\end{aligned} $$Object Dissimilarity Next we define a procedure for combining the $p$-individual attribute dissimilarities $d_j(x_{ij},x_{i’j}), j = 1,2, \\cdots, p$ into a single overall measure of dissimilarity $D(x_i, x_i’)$.\nThis is nearly always done by means of a weighted average:\n$$ \\begin{aligned} D(x_i, x_{i'}) = \\sum_{j=1}^p w_j d_j(x_{ij}, x_{i'j}) \\end{aligned} $$where:\n$$ \\begin{aligned} \\sum_{j=1}^p w_j = 1 \\end{aligned} $$Here $w_j$ is a weight assigned to the $j$th attribute regulating the relative influence of that variable in determining the overall dissimilarity between objects.\nIf the goal is to discover natural groupings in the data, some attributes may exhibit more of a grouping tendency than others. Variables that are more relevant in separating the groups should be assigned a higher influence in defining object dissimilarity. Giving all attributes equal influence in this case will tend to obscure the groups to the point where a clustering algorithm cannot uncover them.\nSpecifying an appropriate dissimilarity measure is far more important in obtaining success with clustering than choice of clustering algorithm.\nClustering Algorithms Clustering algorithms fall into three distinct types:\nCombinatorial algorithms: work directly on the observed data with no direct reference to an underlying probability model. Mixture modeling: supposes that the data is an i.i.d sample from some population described by a probability density function. Mode seeking: take a nonparametric perspective, attempting to directly estimate distinct modes of the probability density function Combinatorial Algorithms Each observation is uniquely labeled by an integer $i \\in {1, \\cdots, N}$. One seeks the particular encoder $C^*(i)$ that assigns the $i$th observation to the $k$th cluster that satisfies the required goal based on the dissimilarities $d(x_i, x_{i’})$. The “parameters” of the procedure are the individual cluster assignments for each of the $N$ observations. These are adjusted so as to minimize a “loss” function.\nSince the goal is to assign close points to the same cluster, a natural loss function would be:\n$$ \\begin{aligned} W(C) = \\frac{1}{2} \\sum_{k=1}^K \\sum_{C(i) = k}\\sum_{C(i') = k} d(x_i, d_{i'}) \\end{aligned} $$This measure tells us how close together the things in the same group are. It is sometimes referred to as the “within cluster” point scatter. The total point scatter is given by:\n$$ \\begin{aligned} T = \\frac{1}{2} \\sum_{i=1}^N\\sum_{i'=1}^N d_{ii'} = \\frac{1}{2}\\sum_{k=1}^K\\sum_{C(i) = k} \\left(\\sum_{C(i') = k} d_{ii'} + \\sum_{C(i') \\neq k} d_{ii'}\\right) \\end{aligned} $$This basically divides, for each $i$th instance on cluster $k$, so $C(i) = k$, the distances into two categories, distances to instances on the same cluster $\\sum_{C(i’) = k} d_{ii’}$, and distances to instances on a different cluster $\\sum_{C(i’) \\neq k} d_{ii’}$. That is:\n$$ \\begin{aligned} T = W(C) + B(C) \\end{aligned} $$where $B(C)$ is the between-cluster point scatter:\n$$ \\begin{aligned} B(C) = \\frac{1}{2} \\sum_{k=1}^K \\sum_{C(i) = k} \\sum_{C(i')\\neq k} d_{ii'} \\end{aligned} $$So, minimizing $W(C)$ is equivalent to maximizing $B(C)$ given $W(C) = T - B(C)$.\nCluster analysis by combinatorial optimization is straightforward in principle. One simply minimizes $W$ or equivalently maximizes $B$ over all possible assignments of the $N$ data points to $K$ clusters. Unfortunately, such optimization by complete enumeration is feasible only for very small data sets.\nFor this reason, practical clustering algorithms are able to examine only a very small fraction of all possible encoders $k = C(i)$. The goal is to identify a small subset that is likely to contain the optimal one, or at least a good suboptimal partition. Such feasible strategies are based on iterative greedy descent. An initial partition is specified. At each iterative step, the cluster assignments are changed in such a way that the value of the criterion is improved from its previous value. Clustering algorithms of this type differ in their prescriptions for modifying the cluster assignments at each iteration. When the prescription is unable to provide an improvement, the algorithm terminates with the current assignments as its solution. However, these algorithms converge to local optima which may be highly suboptimal when compared to the global optimum.\nK-Means The K-means algorithm is one of the most popular iterative descent clustering methods, which uses the squared Euclidean distance. So the within point-scatter can be written as:\n$$ \\begin{aligned} W(C) = \\frac{1}{2} \\sum_{k=1}^K\\sum_{C(i) = k}\\sum_{C(i')=k} ||x_i - x_{i'}||^2 \\end{aligned} $$$$ \\begin{aligned} = \\sum_{k=1}^K N_k \\sum_{C(i) = k} ||x_i - \\overline{x}_k||^2 \\end{aligned} $$where $\\overline{x}k$ is the mean vector associated with the $k$th cluster and $N_k = \\sum{i=1}^N I(C(i) = k)$ is the number of instances on the $k$th cluster. Therefore the goal is to group the $N$ observations into $K$ clusters in a way that minimizes the average difference between each observation and the mean of its cluster.\n$$ \\begin{aligned} C^* \\min_{C} \\sum_{k=1}^K N_k \\sum_{C(i) = k} ||x_i - \\overline{x}_k||^2 \\end{aligned} $$can be obtained by noting that for any set of observations $S$:\n$$ \\begin{aligned} \\overline{x}_S = \\arg \\min_{m} \\sum_{i \\in S} ||x_i - m||^2 \\end{aligned} $$That is we defined the centroid for $S$ as the point $m$ that minimizes the sum of distances for each instance on $S$. Hence we can obtain $C^*$ by solving the enlarged optimization problem:\n$$ \\begin{aligned} \\min_{\\{C, m_k\\}^K_1} \\sum_{k=1}^K N_k \\sum_{C(i) = k} ||x_i - m_k||^2 \\end{aligned} $$Where for each cluster $k$, we search for the encoder $C$ and the optimal centroid $m_k$. Thus the optmimization process can be performed in two steps as seen in Algorithm 14.1. On (1) we obtain the optimal centroids $m_i, i = 1, \\cdots, K$, and on (2) we try to find the best encoder $C$ given the set of centroids ${m_1, \\cdots, m_K}$.\nGaussian Mixtures as Soft K-means Clustering The K-means clustering procedure is closely related to the EM algorithm for estimating a certain Gaussian mixture model.\nThe E-step of the EM algorithm assigns “responsibilities” for each data point based in its relative density under each mixture component (cluster). While the M-step recomputes the component density parameters based on the current responsibilities. Where the relative density is a monotone function of the euclidean distance between the data point and the mixture center. Hence in this setup EM is a “soft” version of K-means clustering, making probabilistic (rather than deterministic) assignments of points to cluster centers.\nAs $\\sigma^2$ tends to $1$, these probabilities become $0$ and $1$, and the two methods coincide:\nVector Quantization Vector quantization (VQ) is a technique used in data compression, particularly in the compression of digital signals or images. It involves representing a large set of data points (vectors) by a smaller set of representative values, called codewords or centroids. These centroids are selected from the original data set and are used to approximate the original data. By replacing groups of similar data points with these representative values, vector quantization can significantly reduce the amount of data needed to represent the information while minimizing the loss of quality.\nIn this example of vector quantization, given an image of $1024\\times 1024$ pixels we start by dividing the image into small blocks of $2\\times 2$. Each block, which contains four pixels, is treated like a tiny picture of its own. Each of the $512 \\times 512$ blocks of four numbers is regarded as vector in $\\mathbb{R}^4$. Then, using K-means clustering, we group these blocks together based on their similarity.\nThe clustering process is called the encoding step, and the collection of centroids is called the codebook. Why do we expect VQ to work at all? The reason is that for typical everyday images like photographs, many of the blocks look the same. What we have described is known as lossy compression, since our images are degraded versions of the original.\nK-Medoids The K-Means algorithm can be generalized for use with arbitrarily defined dissimilarities $D(x_i, x_{i’})$. The process of finding the centers of the clusters stays similar, but the way we measure similarity can change. This makes the algorithm versatile and applicable to various types of data. This gives way to the K-medoids algorithm:\nPractical Issues In order to apply K-means or K-medoids one must select the number of clusters $K^*$ and an initialization.\nThe latter can be defined by specifying an initial set of centers ${m_1,\\cdots,m_K}$ or ${i_1, \\cdots,i_K}$ or an initial encoder $C(i)$. A choice for the number of clusters $K$ depends on the goal. For data segmentation $K$ is usually defined as part of the problem.\nData-based methods for estimating $K^*$ typically examine the withincluster dissimilarity $W_K$ as a function of the number of clusters $K$. The corresponding values generally decrease with increasing $K$. Thus cross-validation techniques, so useful for model selection in supervised learning, cannot be utilized in this context.\nAs we increase the number of clusters, the solution quality will improve because more natural groups will be captured separately. So, if we keep adding more clusters beyond the true number ($K \u003e K^*$), some estimated clusters will start to split the real groups. However, splitting a group that’s already close together won’t improve the solution as much as properly separating two distinct groups.\nTo the extent this scenario is realized, there will be a sharp decrease in successive differences in criterion value, $W_K − W_{K+1}$, at $K = K^$. That is, ${W_K − W_{K+1} |K \u003c K^} \\geq {W_K − W_{K+1} |K \\geq K^}$. An estimate $\\hat{K}$ for $K^*$ is then obtained by identifying a “kink” in the plot of $W_K$ as a function of $K$.\nThe recently proposed Gap statistic compares the shape of a curve based on our data to a curve we’d get if the data were spread out evenly. We’re looking for a point where there’s a big gap between these two curves. This point tells us the best number of clusters for our data. If $G(K)$ is the Gap curve at $K$ clusters, the formal rule for estimating $K^*$ is:\n$$ \\begin{aligned} K^* = \\text{argmin}_{K} \\{K | G(K) \\geq G(K + 1 - s'_{K + 1}) \\} \\end{aligned} $$where $s_K$ is the standard deviation. The following figure shows and example on how to choose the optimal number of clusters:\nHierarchical Clustering As the name suggests, they produce hierarchical representations in which the clusters at each level of the hierarchy are created by merging clusters at the next lower level. At the lowest level, each cluster contains a single observation. At the highest level there is only one cluster containing all of the data.\nStrategies for hierarchical clustering divide into two basic paradigms: agglomerative (bottom-up) and divisive (top-down). Each level of the hierarchy represents a particular grouping of the data into disjoint clusters of observations. The entire hierarchy represents an ordered sequence of such groupings. It is up to the user to decide which level (if any) actually represents a “natural” clustering\nA dendrogram provides a highly interpretable complete description of the hierarchical clustering in a graphical format. Cutting the dendrogram horizontally at a particular height partitions the data into disjoint clusters represented by the vertical lines that intersect it. The height at which we cut represents the level of similarity required to form a cluster. Generally, groups that merge at higher levels in the dendrogram are considered more significant clusters. However, it’s essential to be cautious when interpreting dendrograms because different clustering methods or slight changes in the data can lead to different dendrogram structures.\nAlso, dendrogram interpretations are only valid if the data truly exhibits the hierarchical structure imposed by the clustering algorithm. This can be assesed using the cophenetic correlation coefficient, it measures the correlation between the cophenetic dissimilarities $C_{ii’}$ and the distances between observations in the original data $d_{ii’}$. The cophenetic dissimilarity $C_{ii’}$ between two observations $(i, i’)$ is the intergroup dissimilarity at which observations $i$ and $i’$ are first joined together in the same cluster.\nAgglomerative Clustering Agglomerative clustering starts with each observation as its own cluster. Then, at each step, it merges the two closest clusters together until there’s only one big cluster left. To measure dissimilarity between two clusters, let’s call them $G$ and $H$. We look at all the pairs of observations, one from $G$ and one from $H$, and find the dissimilarity between them.\nSingle linkage (SL) or nearest neighbour agglomerative clustering chooses the closest pair of observations between the two clusters as the measure of dissimilarity between the clusters:\n$$ \\begin{aligned} d_{SL}(G, H) = \\min_{i \\in G, i' \\in H} d_{ii'} \\end{aligned} $$Complete linkage (CL) or furthest-neighbor technique agglomerative clustering measures the dissimilarity between two clusters as the distance the pair of observations that are the farthest apart.\n$$ \\begin{aligned} d_{CL}(G, H) = \\max_{i \\in G, i' \\in H} d_{ii'} \\end{aligned} $$Group average (GA) clustering uses the average dissimilarity between the groups:\n$$ \\begin{aligned} d_{GA}(G, H) = \\frac{1}{N_G N_H} \\sum_{i \\in G} \\sum_{i \\in H} d_{ii'} \\end{aligned} $$where $N_G$ and $N_H$ are the respective number of observations in each group.\nIf the data shows clear clusters that are close together and distinct from each other, all three methods—single linkage, complete linkage, and average linkage—will give similar results. However, if the data doesn’t exhibit this pattern, the results of the three methods will differ. Single linkage tends to join clusters even if just one pair of observations is close together, which can lead to long chains of connections between clusters. This phenomenon is known as chaining.\nComplete linkage will tend to produce compact clusters with small diameters because it considers two groups close only if all the observations in their combined set are similar. Sometimes it may violate the rule that observations within a cluster should be closer to each other than to observations in other clusters.\nGroup average clustering strikes a balance between single and complete linkage. It tries to make clusters compact while keeping them relatively far apart. However, its outcome can be affected by how the dissimilarities between observations are measured. Changing the measurement scale can change the clustering result. In contrast, single and complete linkage methods are not affected by such changes in scale.\nDivisive Clustering Divisive clustering starts with the entire dataset as one cluster and then splits it into smaller clusters step by step. This method isn’t as widely studied as agglomerative clustering, but it has been explored, especially in engineering contexts like compression.\nOne potential advantage of divisive clustering is when you want to divide the data into only a few clusters. Divisive methods can be used recursively with techniques like K-means or K-medoids to split clusters into smaller ones. However the way you begin the splitting process at each step can influence the final outcome.\nA method has been developed to overcome this limitations. The divisive algorithm, proposed by Macnaughton Smith et al. (1965), is defined as:\nPuts all observations in one big cluster called $G$. It picks the observation that’s farthest on average from all the others and makes it the first member of a new cluster called $H$. At each successive step that observation in $G$ whose average distance from those in $H$, minus that for the remaining observations in $G$ is largest, is transferred to $H$. This continues until there are no more observations in $G$ that are closer to those in $H$. This splitting procedure is repeated for each new cluster formed at the previous level, creating a hierarchical structure. Kaufman and Rousseeuw (1990) suggest choosing the cluster with the largest diameter for splitting at each level, but another option is to pick the one with the largest average dissimilarity among its members.","evaluation-metrics#Evaluation Metrics":"Formal Limitations of Clustering Jon Kleinberg proposes three axioms that highlight the characteristics that a grouping problem should exhibit and can be considered “good”.\nScale Invariance: indicates that a clustering algorithm should not modify its results when all distances between points are scaled by the factor determined by a constant $\\alpha$. Richness: the clustering function must be flexible enough to produce any arbitrary partition/clustering of the input data set. Consistency: the clustering results do not change if the distances within clusters decrease and/or the distances between clusters increase. Given the above three axioms, Kleinberg proves the following theorem: For every $n \\geq 2$, there is no clustering function $f$ that satisfies scale invariance, richness, and consistency. Since the three axioms cannot hold simultaneously, clustering algorithms can be designed to violate one of the axioms while sarisfying the other two.\n$k$-cluster stopping condition: Stop merging clusters when we have $k$ clusters (violates the richness axiom). Distance $r$ stopping condition: Stop merging clusters when the nearest pair of clusters are farther than $r $ (violates scale invariance). Scale-$\\epsilon$ stopping condition: Stop merging clusters when the nearest pair of clusters are farther than a fraction $\\epsilon$ the maximum pairwise distance $\\Delta$. (consistency is violated). Methods for Clustering Evaluation When analyzing clustering results, several aspects must be taken into account for the validation of the algorithm results:\nDetermining the clustering tendency in the data (i.e. whether non-random structure really exists). Determining the correct number of clusters. Assessing the quality of the clustering results without external information. Comparing the results obtained with external information. Comparing two sets of clusters to determine which one is better. The first three issues are addressed by internal or unsupervised validation, because there is no use of external information. The fourth issue is resolved by external or supervised validation. Finally, the last issue can be addressed by both supervised and unsupervised validation techniques.\nNull Hypothesis Testing One of the desirable characteristics of a clustering process is to show whether data exhibits some tendency to form actual clusters. In this case, the null hypothesis $H_0$ is the randomness of data and, when the null hypothesis is rejected, we assume that the data is significantly unlikely to be random.\nOne of the difficulties of null hypothesis testing in this context is determining the statistical distribution under which the randomness hypothesis can be rejected. Jain and Dubes propose three alternatives:\nRandom plot hypothesis $H_0$: all proximity matrices of order $n \\times n$ are equally likely. Random label hypothesis $H_0$: all permutations of labels of $n$ objects are equally likely. Randon position hypothesis $H_0$: all sets of $n$ locations is some region of a $d$-dimensional space are equally likely. Internal Validation Internal validation methods (or internal indices) make it possible to establish the quality of the clustering structure without having access to external information. In general, two types of internal validation metrics can be combined:\nCohesion measures: evaluates how closely the elements of the same cluster are to each other. Separation measures: quantify the level of separation between clusters. Internal indices are usually employed in conjunction with two clustering algorithm families: hierarchical clustering algorithms and partitional algorithms. For partitional algorithms, metrics based on the proximity matrix, as well as metrics of cohesion and separation, such as the silhouette coefficient, are often used. For hierarchical algorithms, the cophenetic coefficient is the most common.\nPartitional Methods In general, the internal validation value of a set of $K$ clusters can be decomposed as the sum of the validation values for each cluster:\n$$ \\begin{aligned} \\text{general validity} = \\sum_{i=1}^K w_i \\text{validity}(C_i) \\end{aligned} $$This measure of validity can be cohesion, separation, or some combination of both. Quite often, the weights that appear in the previous expression correspond to cluster size. The individual measures of cohesion and separation are defined as follows:\n$$ \\begin{aligned} \\text{cohesion}(C_i) = \\sum_{x \\in C_i, y \\in C_i} \\text{proximity}(x, y) \\end{aligned} $$$$ \\begin{aligned} \\text{separation}(C_i, C_j) = \\sum_{x \\in C_i, y \\in C_j} \\text{proximity}(x, y) \\end{aligned} $$It should be noted that the cohesion metric defined above is equivalent to the cluster SSE [Sum of Squared Errors]:\n$$ \\begin{aligned} SSE(C_i) = \\sum_{x \\in C_i} d(c_i, x)^2 = \\frac{1}{2m_i} \\sum_{x \\in C_i} \\sum_{y \\in C_i} d(x, y)^2 \\end{aligned} $$Likewise, we can maximize the distance between clusters using a separation metric. This approach leads to the between group sum of squares, or SSB:\n$$ \\begin{aligned} SSB = \\sum_{i = 1}^K m_i d(c_i, c)^2 = \\frac{1}{2K} \\sum_{i=1}^K \\sum_{j = 1}^K \\frac{m}{K} d(c_i, c_j)^2 \\end{aligned} $$where $c_i$ is the mean of the $i$th cluster and $c$ is the overall mean.\nInstead of dealing with separate metrics for cohesion and separation, there are several metrics that try to quantify the level of separation and cohesion in a single measure:\nThe Calisnki-Harabasz coefficient: it is a measure based on the internal dispersion of clusters and the dispersion between clusters. We would choose the number of clusters that maximizes the CH. $$ \\begin{aligned} CH = \\frac{\\frac{SSB_M}{M - 1}}{\\frac{SSE_M}{M}} \\end{aligned} $$ The Dunn index is the ratio of the smallest distance between data from different clusters and the largest distance between clusters. Again, this ratio should be maximized: $$ \\begin{aligned} D = \\min_{1 \u003c i \u003c k} \\left\\{\\min_{1 \u003c j \u003c k, i\\neq j} \\left\\{\\frac{\\delta (C_i, C_j)}{\\max_{1 \u003c l \u003c k} \\{\\Delta (C_l)\\}}\\right\\}\\right\\} \\end{aligned} $$ The Xie-Beni score was designed for fuzzy clustering, but it can applied to hard clustering. It is a ratio whose numerator estimates the level of compaction of the data within the same cluster and whose denominator estimates the level of separation of the data from different clusters: $$ \\begin{aligned} XB = \\frac{\\sum_{i=1}^N \\sum_{k=1}^M u^2_{ik} ||x_i - C_k||^2}{N_{t \\neq s} \\min (||C_t - C_s||^2)} \\end{aligned} $$ The Ball-Hall index is a dispersion measure based on the quadratic distances of the cluster points with respect to their centroid $$ \\begin{aligned} BH = \\frac{SSE_M}{M} \\end{aligned} $$ The Hartigan index is based on the logarithmic relationship between the sum of squares within the cluster and the sum of squares between clusters: $$ \\begin{aligned} H = \\log \\left(\\frac{SSB_M}{SSE_M}\\right) \\end{aligned} $$ The Xu coefficient takes into account the dimensionality $D$ of the data, the number $N$ of data examples, and the sum of squared errors $SSE_M$ form $M$ clusters: $$ \\begin{aligned} X_u = D \\log_2 \\left(\\sqrt{\\frac{SSE_M}{DN^2}}\\right) + \\log M \\end{aligned} $$ The silhouette coefficient is the most common way to combine the metrics of cohesion and separation in a single measure. Its computation is divided into four steps: Compute the average intracluster distance for each example $i$: $a(i) = \\frac{1}{|C_a|} \\sum_{j \\in C_a, i \\neq j} d(i, j)$ Compute the minimum intercluster distance for each example $i$: $b(i) = \\min_{C_b \\neq C_a} \\frac{1}{|C_b|} \\sum_{j \\in C_b} d(i, j)$ Compute the silhouette coefficient for each example $i$: $s(i) = \\frac{b(i) - a(i)}{max(a(i), b(i))}$ Compute the silhouette puntuation as the average of the silhouette coefficients: $S = \\frac{1}{n} \\sum_{i = 1}^n s(i)$ The silhouette is defined in the interval $[-1, 1]$. Positive values indicate a high separation between clusters, negative values are an indication that the clusters are mixed with each other. When the silhouette coefficient is zero, it is an an indication that the data are uniformly distributed throughout the Euclidean space.\nUnfortunately, one of the main drawbacks of the silhouette coefficient is its high computational complexity.\nCohesion and separation metrics are not the only validation method available for partitional clustering techniques. In fact, cohesion and separation metrics do not perform well when it comes to analyzing results obtained by algorithms based on density analysis.\nOne way to validate clustering is by comparing the actual proximity matrix with an ideal version based on the provided clustering by the algorithm. If we reorder rows and columns so that all examples of the same cluster appear together, the ideal proximity matrix has a block diagonal structure. High correlation between the actual and ideal proximity matrices indicates that examples in the same cluster are close to each other, although it may not be a good measure for density-based clustering.\nImagine you have a table where each row and column represents a data point, and the cells contain numbers indicating how similar or close those data points are to each other. Now, if you group similar data points together into clusters, you can rearrange the rows and columns of the table so that all the data points within each cluster are together. When you do this, the table will have a diagonal pattern where each cluster forms a block of closely related data points. This diagonal pattern is what we mean by a “block diagonal structure” in the context of a proximity matrix.\nUnfortunately, the mere construction of the whole proximity matrix is computationally expensive.\nHierarchical Methods Cophenetic Correlation Coefficient The cophenetic distance between two examples is the proximity at which an agglomerative hierarchical clustering algorithm puts the examples in the same cluster for the first time. The cophenetic correlation coefficient (CPCC) is defined as he correlation between the entries of the cophenetic matrix $P_c$ containing cophenetic distances, and the proximity matrix $P$, containing similarities. The cophenetic correlation coefficient is then defined as:\n$$ \\begin{aligned} \\text{CPCC} = \\frac{\\sum_{i \u003c j} (d_{ij} - \\overline{d})(d_{ij}^** - \\overline{d}^**)}{\\sqrt{\\sum_{i \u003c j} (d_{ij} - \\overline{d})^2 \\sum_{i \u003c j}(d_{ij}^** - \\overline{d}^**)}} \\end{aligned} $$where $d_{ij}$ is the distance between the example pair $(i, j)$, $d_{ij}^$ is their cophenetic distance, $\\overline{d}$ is the average of the distances in the proximity matrix and $d_{ij}^$ is the average of the cophenetic distances in the cophenetic matrix.\n$$ \\begin{aligned} \\overline{d} = \\frac{\\sum_{i \u003c j} d_{ij}}{2(n^2 - n)} \\end{aligned} $$$$ \\begin{aligned} \\overline{d}^** = \\sqrt{\\frac{\\sum_{i \u003c j} (d_{ij} - d_{ij}^**)^2}{\\sum_{i \u003c j} (d_{ij}^*)^2}} \\end{aligned} $$The cophenetic correlation coefficient is a value in the interval $[−1, 1]$. High CPCC values indicate a high level of similarity between the two matrices, an indication that the clustering algorithm has been able to identify the underlying structure of its input data.\nHubert Statistic First, concordance are discordance are defined for pairs of examples. A pair $(i, j)$ is concordant when $((v_{p_i} \u003c v_{c_i}) \\\u0026 (v_{p_j} \u003c v_{c_j}))$ or $((v_{p_i} \u003e v_{c_i}) \\\u0026 (v_{p_j} \u003e v_{c_j}))$. And it is said to be discordant when $((v_{p_i} \u003c v_{c_i}) \\\u0026 (v_{p_j} \u003e v_{c_j}))$ or $((v_{p_i} \u003e v_{c_i}) \\\u0026 (v_{p_j} \u003c v_{c_j}))$. Therefore, a pair is neither concordant nor discordant if $v_{p_i} = v_{c_i}$ or $v_{p_j} = v_{c_j}$.\nLet $S_+$ and $S_-$ be the number of concordant and discordant pairs, respectively. Then, the Hubert coefficient is defined as:\n$$ \\begin{aligned} \\gamma = \\frac{S_+ - S_-}{S_+ + S_-} \\end{aligned} $$The Hubert statistic is between $-1$ and $1$. It has been mainly used to compare the results of two hierarchical clustering algorithms. A higher Hubert $\\gamma$ value corresponds to a better clustering of data.\nExternal Validation External validation proceeds by incorporating additional information in the clustering validation process, i.e. external class labels for the training examples. We want to compare the result of a clustering algorithm $C = {C_1, C_2, \\cdots, C_m}$ to a potentially different partition of data $P = {P_1, P_2, \\cdots, P_s}$ which might represent the expert knowledge of the analyst (his experience or intuition), prior knowledge of the data in the form of class labels, the results obtained by another clustering algorithm, or simply a grouping considered to be “correct”.\nIn order to carry out this analysis, a contingency matrix must be built to evaluate the clusters detected by the algorithm that encompasses the following data:\n$TP$: The number of data pairs found in the same cluster, both in $C$ and in $P$. $FP$: The number of data pairs found in the same cluster in $C$ but in different clusters in $P$. $FN$: The number of data pairs found in different clusters in $C$ but in the same cluster in $P$. $TN$: The number of data pairs found in different clusters, both in $C$ and in $P$. Matching Sets Several measures can be defined to measure the similarity between the clusters in $C$, obtained by the clustering algorithm, and the clusters if $P$, corresponding to our prior (external) knowledge:\nPrecision: $Pr = \\frac{TP}{TP + FP}$ Recall: $R = \\frac{TP}{TP + FN}$ F-measure: $F_{\\alpha} = \\frac{1 + \\alpha}{\\frac{1}{Pr} + \\frac{\\alpha}{R}}$ Quite often, precision and recall are evenly combined with an unweighted harmonic mean ($\\alpha = 1$):\n$$ \\begin{aligned} F = \\frac{2 \\cdot Pr \\cdot R}{Pr + R} \\end{aligned} $$ Purity: evaluates whether each cluster contains only examples from the same class: $$ \\begin{aligned} U = \\sum_{i} p_i (\\max_j \\frac{p_{ij}}{p_i}) \\end{aligned} $$where $p_i = \\frac{n_i}{n}$, $p_j = \\frac{n_j}{n}$ and $p_{ij} = \\frac{n_{ij}}{n}$. Where $n_{ij}$ are the number of examples belonging to the class $i$ found in the cluster $j$ and $n_i$ is the number of examples in the cluster $i$.\nPeer-to-peer Correlation A second family of measures for external validation are based on the correlation between pairs, i.e. they seek to measure the similarity between two partitions under equal conditions, such as the result of a grouping process for the same set, but by means of two different methods $C$ and $P$.\nThe Jaccard Coefficient: $J = \\frac{TP}{TP + FP + FN}$ The Rand Coefficient: $Rand = \\frac{TP + TN}{M}$ The Folkes and Mallows coefficient: $FM = \\sqrt{\\frac{TP}{TP + FP} \\cdot \\frac{TP}{TP + FN}}$ The Hubert statistical coefficient: $\\Gamma = \\frac{1}{M} \\sum_{i=1}^{n - 1} \\sum_{j = i + 1}^{n} X_{ij} Y_{ij}$ Where $n_{ij}$ are the number of examples belonging to the class $i$ found in the cluster $j$ and $n_i$ is the number of examples in the cluster $i$.\nMeasures Based on Information Theory This family includes basic measures such as entropy and mutual information, as well as their respective normalized variants.\nEntropy: $H = - \\sum_{i} p_i \\left(\\sum_{j} \\frac{p_{ij}}{p_i} \\log \\frac{p_{ij}}{p_i}\\right)$ Mutual Information: $MI = \\sum_{i} \\sum_{j} p_{ij} \\log \\frac{p_{ij}}{p_i p_j}$ Where $p_{ij} = \\frac{n_{ij}}{n}$ and $p_i = \\frac{n_i}{n}$.\nHyperparameter Tuning Even though external validation metrics can help us evaluate whether the obtained clusters closely match the underlying categories in the training data, which the clustering algorithm tries to identify without externally-provided class labels, those metrics cannot address other issues such as the right number of clusters for our current data set.\nHyperparameter tuning tries to determine, for the different possible values of the parameters in $P_{alg}$ , which set of parameter values is the most suitable for our particular clustering problem. We could proceed in the following way:\nWhen the algorithm does not include the number of clusters $n_c$ among its parameters, we run the algorithm with different values for its parameters so that we can determine their largest range for which $n_c$ remains constant. Later, we choose as parameter values the values in the middle of this range. When the algorithm parameters Palg include the desired number of clusters $n_c$, we run the algorithm for a range of values for $n_c$. For each value of $n_c$, we run the algorithm multiple times using different sets of values (i.e. starting from different initial conditions) and choose the value that optimizes our desired validation metric. When we just want to determine the “right” number of clusters, $n_c$, plotting the validation results for different values of $n_c$ can sometimes show a relevant change in the validation metric, commonly referred to as a “knee” or “elbow”.\nHyperparameter tuning can then be seen as a combinatorial optimization problem using different strategies:\nGrid Search: is based on a systematic exploration of the hyperparameter space. Random Search: chooses parameter configurations at random. Smart Search techniques try to optimize the problem of searching for hyperparameter values. Different strategies can be implemented, such as Bayesian optimization using Gaussian processes and evolutionary optimization using genetic algorithms or evolution strategies. ","introduction#Introduction":"In this chapter we address unsupervised learning. In this case one has a set of $N$ observations $(x_1,x_2, \\cdots ,x_N)$ of a random vector $X$ having joint density $\\text{Pr}(X)$. The goal is to directly infer the properties of this probability density without the help of a supervisor or teacher providing correct answers or degree-of-error for each observation.\nPrincipal components, multidimensional scaling, self-organizing maps, and principal curves try to find simpler patterns in complex data. They look for lower-dimensional structures in the data that capture where most of the data points lie. By doing this, they help us understand how variables are related to each other and if they can be thought of as being controlled by a smaller group of underlying factors.\nCluster analysis looks for groups or clusters in the data that are like little “bumps” or “peaks” where the data is most concentrated, that is convex regios of the $X$-space that contain modes of $\\text{Pr}(X)$. It helps us see if the data can be divided into different types or categories. Mixture modeling aims for the same thing. Association rules try to find simple rules or patterns that describe where the data is most concentrated, especially when dealing with data that has many features and is either present or absent (binary-valued).\nIn unsupervised learning, where we don’t have clear outcomes to compare against. We often have to rely on guesswork and intuition to decide if the results make sense or not. This uncertainty has led to many different methods being proposed, but ultimately, it’s hard to know for sure which one is the best since there’s no straightforward way to check their effectiveness."},"title":"Tema 4. Aprendizaje No Supervisado"},"/notes/datascience/master/dl/":{"data":{"":" T1. Fundamentos de las Redes Neuronales Profundas T2. Tipologías de las redes neuronales profundas T3. Herramientas y estrategias de programación e implemetación de redes neuronales T4. Redes Neuronales Convolucionales en Visión Artificial T5. Redes Neuronales Recurrentes T6. Servicios y proveedores de Deep Learning en la nube "},"title":"Deep Learning"},"/notes/datascience/master/dl/01_foundation/":{"data":{"":"","deep-networks#Deep networks":"","introducing-popular-open-source-libraries#Introducing popular open source libraries":"The basic unit for data storage is the tensor. A tensor is a generalization of a matrix to higher dimensions.\nNeural networks are represented as a computational graph of operations. The nodes of the graph represent the operations (weighted sum, activation function, and so on). The edges represent the flow of data.\nSome common libraries:\nTensorflow Keras: is a high-level neural net Python library that runs on top of TensorFlow, CNTK or Theano. Pytorch: is a deep learning library based on Torch. ","the-reasons-for-deep-learnings-popularity#The reasons for deep learning\u0026rsquo;s popularity":"Deep networks We could define deep learning as a class of machine learning techniques, where information is processed in hierarchical layers to understand representations and features from data in increasing levels of complexity.\nIn practice, all deep learning algorithms are neural networks.\nWith that in mind, let’s look at the main classes of neural networks. The following list is not exhaustive, but it represents the vast majority of algorithms in use today:\nMulti-layer perceptrons (MLPs) Convolutional neural networks (CNNs) Recurrent networks Autoencoders Training deep networks We can use different algorithms to train a neural network. But in practice, we almost always use Stochastic Gradient Descent (SGD) and backpropagation.\nIn the following section, we’ll introduce momentum, the weight update rule is defined as follows:\n$$ \\begin{aligned} w \\rightarrow w - \\lambda \\nabla (J(w)) \\end{aligned} $$where $\\lambda$ is the learning rate. First we calculate the weight update value\n$$ \\begin{aligned} \\Delta w \\rightarrow \\mu\\Delta w - \\lambda (\\nabla J(w)) \\end{aligned} $$We see that the first component, $\\mu\\Delta w$, is the momentum. The $\\Delta w$ represents the previous value of the weight update and $\\mu$ is the coefficient, which wil determine how much the new value depends on the previous ones.\nThen we update the weight:\n$$ \\begin{aligned} w \\rightarrow w + \\Delta w \\end{aligned} $$You may encounter other gradient descent optimizations, such as:\nNesterov momentum ADADELTA RMSProps Adam The reasons for deep learning’s popularity The first reason is, today, we have a lot more data than in the past.\nThe second reason is the increased computing power. This is most visible in the drastically increased processing capacity of Graphical Processing Units (GPUs). Neural networks are organized in such a way as to take advantage of the GPU’s parallel architecture.","training-deep-networks#Training deep networks":""},"title":"T1. Fundamentos de las Redes Neuronales Profundas"},"/notes/datascience/master/dl/02_typologies/":{"data":{"":"","autoencoders#Autoencoders":"Autoencoders An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning).\nAn autoencoder learns two functions:\nAn encoding function that transforms the input data A decoding function that recreates the input data from the encoded representation. The autoencoder learns dense representations (encoding) for a set of data.\nWe can force the network to learn useful features adding different types of constraints, for example:\nDefining the dense representation such that is has a lower dimensionality than the input data. Adding noise to the input data (Denoising Autoencoders). The number of neurons in the output layer must be equal to the number of inputs.\nThe outputs are often called the reconstructions because The cost function contains a reconstruction loss that penalizes the model when the reconstructions are different from the inputs.\nUndercomplete autoencoder: the internal representation has a lower dimensionality than the input data. Overcomplete autoencoder: the internal representation has a higher dimensionality than the input data. Stacked Autoencoders Stacked autoencoders are said to be autoencoders that have multiple hidden layers.\nTying weights An autoencoder with tied weights has decoder weights that are the transpose of the encoder weights\nThis reduces the number of parameters of the model, thus speeds up training and limits the risk of overfitting.\nConvolutional Autoencoders Used with image data.\nThe encoder is a regular CNN composed of convolutional layers and pooling layers. It reduces the spatial dimensionality of the inputs (i.e., height and width) while increasing the depth (i.e., the number of feature maps). The decoder must do the reverse (upscale the image and reduce its depth back to the original dimensions). Recurrent Autoencoders Used with sequential data.\nThe encoder is typically a sequence-to-vector RNN, which compresses the input sequence down to a single vector. The decoder is a vector-to-sequence RNN that does the reverse Denoising Autoencoders We want to add noise to the input data, and then train the network to be able to recover the original noise-free inputs.\nThe noise can be pure Gaussian noise added to the inputs, or it can be randomly switched-off inputs, just like in dropout.\nSparse Autoencoders A sparse autoencoder is an autoencoder whose training criterion involves a sparsity penalty.\nIn most cases, we would construct our loss function by penalizing activations of hidden layers so that only a few nodes are encouraged to activate when a single sample is fed into the network.\nVariational Autoencoders They are probabilistic autoencoders as well as generative models.\nInstead of directly producing a coding for a given input, the encoder produces a mean coding $\\mu$ and a standard deviation $\\sigma$. The actual coding is then sampled randomly from a Gaussian distribution with mean $\\mu$ and standard deviation $\\sigma$. After that the decoder decodes the sampled coding normally. Generative Adversarial Networks GANs are composed of two neural networks:\nA generator that tries to generate data that looks similar to the training data A discriminator that tries to tell real data from fake data. Takes either a fake image from the generator or a real image from the training set as input, and must guess whether the input image is fake or real. Each training iteration is divided into two phases:\nWe train the discriminator. A batch of data where half are real real images and the other half are fake images produced by the generator. The labels are set to $0$ for fake images and $1$ for real images, and the discriminator is trained on this labeled batch for one step. Backpropagation only optimizes the weights of the discriminator. We train the generator: we only add fake images to the data, and all the labels are set to $1$ (real). We want the generator to produce images that the discriminator will believe to be real. Backpropagation only affects the weights of the generator. The generator and the discriminator compete against each other during training.\nThe Difficulties of Traning GANs It has been demonstrated that a GAN can only reach a single Nash equilibrium (we assume the training process to be finished): that’s when the generator produces perfectly realistic images, and the discriminator is forced to guess ($50%$ real, $50%$ fake). Nothing guarantees that the equilibrium will ever be reached.\nThe biggest difficulty is called mode collapse: this is when the generator’s outputs gradually become less diverse. Such that the generator gets very good at generating data of a concrete kind, good enough to fool the discriminator, however it progressively start representing data of another kind and then forgets about the previous class of data.\nMoreover, because the generator and the discriminator are constantly pushing against each other, their parameters may end up oscillating and becoming unstable. And since many factors affect these complex dynamics, GANs are very sensitive to the hyperparameters.\nThere are some techniques that aim to avoid this behaviour like: experience replay and mini-batch discrimination.\nExperience replay: stores images on a buffer and the discriminator uses the images on this buffer as input for fake images. Old images are then progressively replaces by newer images. Mini-batch discrimination: it measures how similar are images on the batch, the discriminator uses this statistic to decide whether to reject the whole batch or not. Deep Convolutional GANs These are GANs based on deeper convolutional nets for larger images.\nProgressive Growing of GANs It begins by generating images at low resolution, such as $4 \\times 4$ pixels. The model is first trained on low-resolution images. Once training stabilizes at this resolution, additional layers are added to the generator and discriminator to allow for the generation of higher-resolution images. After adding new layers, there is usually a transition phase where the model is trained on a mixture of images at the old and new resolutions. This gradual transition allows the model to adapt to the increased resolution without destabilizing the training process. Once the training stabilizes at the new resolution, the transition phase ends, and the model continues to train exclusively on images at the higher resolution. Increasing the resolution progressively allows the model to learn to capture both global and local features of the images more effectively.\nStyle GANs What sets StyleGANs apart is the introduction of “style” into the generation process. In traditional GANs, the generator takes random noise as input and directly generates images. In StyleGANs, the generator learns to separate the “content” of the image (e.g., facial features) from the “style” (e.g., lighting, color, texture). This allows for more fine-grained control over the generated images.\nThe StyleGAN generator and discriminator models are trained using the progressive growing GAN training method.\nStyleGANs consist of two main components: a mapping network and a synthesis network.\nThe mapping network takes as input a latent vector (random noise) and maps it to an intermediate latent space, which controls the style of the generated image. The synthesis network then takes the intermediate latent representation and generates the final image. ","boltzmann-based-networks#Boltzmann Based Networks":"Boltzmann Machines They are fully connected artificial neural networks, but they are based on stochastic neurons. The working of Boltzmann Machine is mainly inspired by the Boltzmann Distribution which says that the current state of the system depends on the energy of the system and the temperature at which it is currently operating. These neurons output $1$ with some probability, given by the following equation:\n$$ \\begin{aligned} p(s_i^{\\text{next step}} = 1) \\sigma\\left(\\frac{\\sum_{j=1}^N w_{i,j}s_j + b_i}{T}\\right) \\end{aligned} $$Where:\n$s_j$ is the $j$th neuron’s state ($0$ or $1$). $w_{i,j}$ is the connection weight between the $i$th and $j$th neurons. Note that $w_{i,i}$ = 0. $b_i$ is the ith neuron’s bias term. $N$ is the number of neurons in the network. $T$ is a number called the network’s temperature; the higher the temperature, the more random the output. $\\sigma$ is the logistic function. Hence to implement these as Neural Networks, we use the Energy Models. The energy term was equivalent to the deviation from the actual answer. The higher the energy, the more the deviation. It has been thus important to train the model until it reaches a low-energy point.\nThe nodes in Boltzmann Machines are simply categorized as visible and hidden nodes. The visible nodes take in the input. The same nodes which take in the input will return back the reconstructed input as the output.\nThe energy function of the Boltzmann machine is defined as follows:\n$$ \\begin{aligned} E(v, h) = - \\sum_{i} v_ib_i - \\sum_k h_kb_k - \\sum_{i, j}v_iv_jw_{i,j} \\sum_{i,k}v_ih_kw_{i, k} - \\sum_{k,l}h_kh_kw_{k,l} \\end{aligned} $$Where $v$ are the visible units, $h$ as the hidden units $b$ is the bias and $w_{i, j}$ are the weights between units $i$ and $j$.\nThe probability of a joint configuration over both the visible unit and the hidden unit is as follows:\n$$ \\begin{aligned} p(v,h) = \\frac{e^{-E(v,h)}}{\\sum\\_{m, n} e^{-E(m, n)}} \\end{aligned} $$And, for example, the probability distribution of visible units is obtained by marginalizing out hidden units:\n$$ \\begin{aligned} p(v) = \\frac{\\sum_h e^{-E(v,h)}}{\\sum\\_{m, n} e^{-E(m, n)}} \\end{aligned} $$This can now be utilized to sample visible units.\nTraining a Boltzmann machine means finding the parameters that will make the network approximate the training set’s probability distribution. So we have to obtain the parameters tha maximize the likelihood of the observed data. The traning algorithm runs as described:\nObtain the log likelihood function of visible units, by marginalizing the hidden units: $$ \\begin{aligned} l(v|w) = \\log p(v|w) = \\log \\sum_h e^{-E_{v, h}} - \\log \\sum_{m, n} e^{-E_{m, n}} \\end{aligned} $$ Take the derivative of the log likelihood function as a function of $w$: $$ \\begin{aligned} \\frac{\\delta l(v|w)}{\\delta w} = \\frac{\\delta \\log \\sum_h e^{-E_{v, h}}}{\\delta \\sum_h e^{-E_{v, h}}} \\cdot \\frac{\\delta \\sum_h e^{-E_{v, h}}}{\\delta w} - \\frac{\\delta \\log \\sum_h e^{-E_{v, h}}}{\\delta \\sum_{m,n} e^{-E_{m, n}}} \\cdot \\frac{\\delta \\sum_{m,n} e^{-E_{m, n}}}{\\delta w} \\end{aligned} $$$$ \\begin{aligned} = \\frac{1}{\\sum_h e^{-E_{v, h}}} \\cdot \\sum_h \\frac{\\delta e^{-E_{v,h}}}{\\delta w} - \\frac{1}{\\sum_{m,n} e^{-E_{m, n}}} \\cdot \\sum_{m,n} \\frac{\\delta e^{-E_{m,m}}}{\\delta w} \\end{aligned} $$$$ \\begin{aligned} = \\frac{1}{\\sum_h e^{-E_{v, h}}} \\cdot \\sum_h -e^{-E_{v,h}} \\frac{\\delta E_{v,h}}{\\delta w} - \\frac{1}{\\sum_{m,n} e^{-E_{m, n}}} \\cdot \\sum_{m,n} -e^{E_{m,m}} \\frac{\\delta E_{m,m}}{\\delta w} \\end{aligned} $$$$ \\begin{aligned} = -\\sum_h \\frac{e^{-E_{v,h}}}{\\sum_h e^{-E_{v, h}}} \\frac{\\delta E_{v,h}}{\\delta w} + \\sum_{m,n} \\frac{e^{E_{m,m}}}{\\sum_{m,n} e^{-E_{m, n}}} \\frac{\\delta E_{m,m}}{\\delta w} \\end{aligned} $$We know that:\n$$ \\begin{aligned} p(h|v) = \\frac{p(v, h)}{p(v)} = \\frac{\\frac{e^{-E_{v, h}}}{\\sum_{m,n} e^{-E_{m, n}}}}{\\frac{\\sum_h e^{-E_{v, h}}}{\\sum_{m,n} e^{-E_{m, n}}}} \\end{aligned} $$By removing both $\\sum_{m,n} e^{-E_{m, n}}$, we obtain:\n$$ \\begin{aligned} = \\frac{e^{-E_{v, h}}}{\\sum_h e^{-E_{v, h}}} \\end{aligned} $$Such that:\n$$ \\begin{aligned} = -\\sum_h p(h|v) \\frac{\\delta E_{v,h}}{\\delta w} + \\sum_{m,n} p(m,n) \\frac{\\delta E_{m,m}}{\\delta w} \\end{aligned} $$And by de definition of the expected value $\\mathbb{E}(x) = \\sum_x x p(x)$:\n$$ \\begin{aligned} = - \\mathbb{E}_{p(h|v)}[\\frac{\\delta E_{v,h}}{\\delta w}] + \\mathbb{E}_{p(m,n)}[\\frac{\\delta E_{m,m}}{\\delta w}] \\end{aligned} $$Computing these expectations is in general an intractable problem. he general approach for solving this problem is to use Markov chain Monte Carlo (MCMC) to approximate these quantities:\n$$ \\begin{aligned} \\frac{\\delta l(v|w)}{\\delta w} = -{\\langle s_i, s_j\\rangle}_{p(h_{data}|v_{data})} + {\\langle s_i, s_j\\rangle}_{p(h_{model}|v_{model})} \\end{aligned} $$Here $\\langle\\cdot, \\cdot\\rangle$ denotes the expectation.\nRestricted Boltzmann Machines An RBM is a Boltzmann machine that only has connections between visible and hidden units.\nThe energy function of the RBM is defined as follows:\n$$ \\begin{aligned} E(v, h) = - \\sum_i v_ib_i - \\sum_k h_kb_k - \\sum_{i,k} v_i h_k w_{i,k} \\end{aligned} $$Contrastive Divergence This is a very efficient training algorithm for Boltzmann machines. Here is how it works:\nFor each training instance $x$, the algorithm starts by feeding it to the network by setting the state of the visible units to $x_1, \\cdots, x_n$. Compute the state of the hidden units by applying the output formula for a hidden neuron (see ), which gives us the vector $h$, where $h_i$ is the output of the ith neuron. Next you compute the state of the visible units, by applying the same stochastic equation, which gives you vector $x’$. Once again you compute the state of the hidden units, which gives you a vector $h’$. Now you can update each connection weight by applying:\n$$ \\begin{aligned} w_{i, j} = w_{i, j} + \\eta (xh^T - x'h'^T) \\end{aligned} $$The great benefit of this algorithm is that it does not require waiting for the network to reach thermal equilibrium.\nDeep Belief Nets A Deep Belief Net is an RBM where several layers of RBMs can be stacked. Such that the hidden units of the first-level RBM serve as the visible units for the second-layer RBM.\nYou can train DBNs one layer at a time using Contrastive Divergence, starting with the lower layers.\nTheir lower layers learn low-level features in the input data, while higher layers learn high-level features. Thus it learns information in a hierarchical way.\nJust like RBMs, DBNs are fundamentally unsupervised, but you can also train them in a semi-supervised manner by adding some visible units to represent the labels.\nThe following describes the training process:\nRBM 1 is trained without supervision. RBM 2 is trained with RBM 1’s hidden units as inputs without supervision RBM 3 is trained using RBM 2’s hidden units as inputs, as well as extra visible units used to represent the target labels One advantage of this semisupervised approach is that you don’t need much labeled training data.\nDBNs can also work in reverse. If you activate one of the label units, the signal will propagate up to the hidden units of RBM 3, then down to RBM 2, and then RBM 1, and a new instance will be output by the visible units of RBM 1.\nThis generative capability of DBNs is quite powerful. For example, it has been used to automatically generate captions for images, and vice versa: first a DBN is trained (without supervision) to learn features in images, and another DBN is trained (again without supervision) to learn features in sets of captions (e.g., “car” often comes with “automobile”). Then an RBM is stacked on top of both DBNs and trained with a set of images along with their captions; it learns to associate high-level features in images with high-level features in captions. Next, if you feed the image DBN an image of a car, the signal will propagate through the network, up to the top-level RBM, and back down to the bottom of the caption DBN, producing a caption. Due to the stochastic nature of RBMs and DBNs, the caption will keep changing randomly\nA DBN, however, suffers from the following problems:\nInference in DBNs is a problem because of the “explaining away” effect A DBN can only use greedy retraining and no joint optimization over all layers Deep Boltzmann Machines The distinction between DBM and DBN from the previous section is that DBM information flows on bidirectional connections in the bottom layers.\nYou can also train a DBM using contrastive divergence.","convolutional-nets#Convolutional Nets":"Deep convolutional neural network A deep convolutional neural network (DCNN) consists of many neural network layers.\nTwo different types of layers, convolutional and pooling, are typically alternated\nLocal receptive fields If we want to preserve spatial information, we represent each image with a matrix of pixels.\nConvolution operation: To encode the local structure is to connect a submatrix of adjacent input neurons (pixels) into one single hidden neuron belonging to the next layer. That single hidden neuron represents one local receptive field.\nWe can encode more information by having overlapping submatrices.\nA feature map is the result of applying the convolution on the input data, on the previous example the matrix on the right would be one feature map.\nThe kernel size is the size of each the submatrices, in the previous example $3 \\times 3$.\nThe stride is the number of elements between each submatrix. With a stide of $1$ we obtain the following result:\nThis convolutional layer is usually followed by a non-linear activation function (e.g. ReLU).\nShared weights and bias To detect the same feature independently from its location on the input we define the same weights for all the neurons on a layer. This way we force the neural net to search for relevant features everywhere on the input data, instead of searching for features on specific places on the input image.\nPooling Layer It consists on using the spatial contiguity of the output from a single feature map and aggregate the values into a single output. On the following image max pooling is being performed.\nOther common pooling operation is average pooling.\nAn example of DCNN — LeNet It is a family of ConvNets trained for recognizing MNIST handwritten characters with robustness to simple geometric transformations and to distortion.\nIt is defined as follows:\nOn the low-layers we alternate convolution operations with max-pooling operations. (using carefully chosen local receptive fields and and shared weights). On higher levels are fully connected layers based on a traditional MLP with hidden layers and softmax as the output layer. Understanding the power of deep learning Deep networks always outperform the simple network and the gap is bigger when the number of examples provided for training is progressively reduced.","recurrent-neural-nets#Recurrent Neural Nets":"SimpleRNN cells RNN cells incorporate this dependence by having a hidden state, or memory. The value of the hidden state is a function of the value of the hidden state at the previous time step and the value of the input at the current time step.\n$$ \\begin{aligned} h_t = \\phi(h_{t-1}, x_t) \\end{aligned} $$where $h_t$ and $h_{t-1}$ are the values of the hidden states at the time steps $t$ and $t-1$ and $x_t$ is the values of the input at time $t$. Note that the equation is recursive\nAt time $t$ the cell has an input $x_t$ and an output $y_t$. Part of the output $y_t$ (the hidden state $h_t$) is fed back into the cell for use at a later time step $t+1$. On the previous image we show the behaviour of a single cell unrolled.\nNotice that the weight matrices $U$, $V$, and $W$ are shared across the steps. We can also describe the computations within an RNN in terms of equations:\n$$ \\begin{aligned} h_t = tanh(Wh_{t-1} + Ux_t) \\end{aligned} $$$$ \\begin{aligned} y_t = sofmax(Vh_t) \\end{aligned} $$RNN topologies RNNs can be arranged in many ways to solve specific problems.\nIn the basic topology, all input sequences are of the same length and an output is produced at each time step.\nAnother example of a many to many RNN could be a machine translation network shown on the many-to-many topology. These take in a sequence and produces another sequence. For example, the input could be a sequence in English and the output could be the translation in Spanish.\nOther variants are the one-to-many network, an example of which could be an image captioning network, where the input is an image and the output a sequence of words.\nSimilarly, an example of a many-to-one network could be a network that does sentiment analysis of sentences, where the input is a sequence of words and the output is a positive or negative sentiment.\nVanishing and exploding gradients Training the RNN involves backpropagation, where the gradient at each output depends not only on the current time step, but also on the previous ones, this process is called backpropagation through time (BPTT).\nDuring backpropagation (shown by dotted lines), the gradients of the loss with respect to the parameters $U$, $V$, and $W$ are computed at each time step and the parameters are updated with the sum of the gradients.\nThe following equation shows the gradient of the loss with respect to $W$:\n$$ \\begin{aligned} \\frac{\\delta L}{\\delta W} = \\sum_t \\frac{\\delta L_t}{\\delta W} \\end{aligned} $$Let us now look at what happens to the gradient of the loss at the last time step ($t=3$)\n$$ \\begin{aligned} \\frac{\\delta L_3}{\\delta W} = \\frac{\\delta L_3}{\\delta y_3} \\frac{\\delta y_3}{\\delta h_2} \\frac{\\delta h_2}{\\delta_W} \\end{aligned} $$The previous equation is simply deriving by applying the chain rule, where:\nThe loss function $L_3$ is defined as a function of $y_3$, Then $y_3 = softmax(Vh_2)$ And finally $h_2 = tanh(Wh_1 + Ux_1)$ The gradient of the hidden state $h_2$ with respect to $W$ can be further decomposed as the sum of the gradient of each hidden state with respect to the previous one.\n$$ \\begin{aligned} \\frac{\\delta L_3}{\\delta W} = \\sum_{t=0}^2 \\frac{\\delta L_3}{\\delta y_3} \\frac{\\delta y_3}{\\delta h_2} \\frac{\\delta h_2}{\\delta h_t}\\frac{\\delta h_t}{\\delta_W} \\end{aligned} $$Finally, each gradient of the hidden state with respect to the previous one can be further decomposed as the product of gradients of the current hidden state against the previous one.\n$$ \\begin{aligned} \\frac{\\delta L_3}{\\delta W} = \\sum_{t=0}^2 \\frac{\\delta L_3}{\\delta y_3} \\frac{\\delta y_3}{\\delta h_2} \\left(\\prod_{j=t+1}^2 \\frac{\\delta h_j}{\\delta h_{j-1}}\\right)\\frac{\\delta h_t}{\\delta_W} \\end{aligned} $$For example for $t = 3$:\n$$ \\begin{aligned} \\frac{\\delta L_4}{\\delta W} = \\frac{\\delta L_4}{\\delta y_4} \\frac{\\delta y_4}{\\delta h_3} \\left(\\prod_{j=4}^2 \\frac{\\delta h_j}{\\delta h_{j-1}}\\right)\\frac{\\delta h_4}{\\delta_W} \\end{aligned} $$$$ \\begin{aligned} \\frac{\\delta L_4}{\\delta W} = \\frac{\\delta L_4}{\\delta y_4} \\frac{\\delta y_4}{\\delta h_3} \\left(\\frac{\\delta h_4}{\\delta h_3}\\frac{\\delta h_3}{\\delta h_2}\\frac{\\delta h_2}{\\delta h_1}\\right)\\frac{\\delta h_4}{\\delta_W} \\end{aligned} $$On general:\n$$ \\begin{aligned} \\frac{\\delta L_i}{\\delta W} = \\sum_{t=0}^i \\frac{\\delta L_i}{\\delta y_i} \\frac{\\delta y_i}{\\delta h_{i-1}} \\left(\\prod_{j=t+1}^i \\frac{\\delta h_j}{\\delta h_{j-1}}\\right)\\frac{\\delta h_i}{\\delta_W} \\end{aligned} $$Consider the case where the individual gradients of a hidden state with respect to the previous one is less than one. As we backpropagate across multiple time steps, the product of gradients get smaller and smaller, leading to the problem of vanishing gradients.\nSimilarly, if the gradients are larger than one, the products get larger and larger, leading to the problem of exploding gradients.\nThe effect of vanishing gradients is that the gradients from steps that are far away do not contribute anything to the learning process, so the RNN ends up not learning long range dependencies.\nWhile there are a few approaches to minimize the problem of vanishing gradients, such as:\nProper initialization of the $W$ matrix Using a ReLU instead of tanh layers Pre-training the layers using unsupervised methods The most popular solution is to use the LSTM or GRU architectures.\nLong short term memory — LSTM The LSTM is a variant of RNN that is capable of learning long term dependencies.\nThe line across the top of the diagram is the cell state c, and represents the internal memory of the unit.\nThe line across the bottom is the hidden state.\nAlso, $i$, $f$, and $o$ are the input, forget, and output gates.\nThe forget gate defines how much of the previous state $h_{t-1}$ you want to allow to pass through.\nThe input gate defines how much of the newly computed state for the current input $x_t$ you want to let through.\nThe output gate defines how much of the internal state you want to expose to the next layer.\nThe internal hidden state $g$ is computed based on the current input $x_t$ and the previous hidden state $h_{t-1}$.\nSuch that:\n$$ \\begin{aligned} i = \\sigma(W_ih_{t-1} + U_ix_t) \\end{aligned} $$$$ \\begin{aligned} f = \\sigma(W_fh_{t-1} + U_fx_t) \\end{aligned} $$$$ \\begin{aligned} o = \\sigma(W_oh_{t-1} + U_ox_t) \\end{aligned} $$$$ \\begin{aligned} g = \\tanh(W_gh_{t-1} + U_gx_t) \\end{aligned} $$$$ \\begin{aligned} c_t = (c_{t-1} \\otimes f) \\oplus (g \\otimes i) \\end{aligned} $$$$ \\begin{aligned} h_t = tanh(c_t) \\otimes o \\end{aligned} $$One thing to realize is that an LSTM is a drop-in replacement for a SimpleRNN on the recurrent neural network.\nGated recurrent unit — GRU This type of cell has two gates, an update gate $z$, and a reset gate $r$.\nThe update gate defines how much previous memory to keep around.\nThe reset gate defines how to combine the new input with the previous memory.\nThe following equations define the gating mechanism in a GRU:\n$$ \\begin{aligned} z = \\sigma(W_zh_{t-1} + U_z x_t) \\end{aligned} $$$$ \\begin{aligned} r = \\sigma(W_rh_{t-1} + U_r x_t) \\end{aligned} $$$$ \\begin{aligned} c_t = tanh(W_c(h_{t-1} \\otimes r) + U_cx_t) \\end{aligned} $$$$ \\begin{aligned} h_t = (z \\otimes c) \\oplus ((1 - z) \\otimes h_{t-1}) \\end{aligned} $$GRU and LSTM have comparable performance, while GRUs are faster to train and need less data to generalize in situations where there is enough data, an LSTM’s greater expressive power may lead to better results."},"title":"T2. Tipologías de las redes neuronales profundas"},"/notes/datascience/master/dl/03_tools/":{"data":{"":"","computación-acelerada#Computación Acelerada":"Diferencias CPU/GPU Una CPU tiene un número limitado de cores, mientras que una GPU tiene un número muy elevado de cores. Una GPU tiene procesadores menos potentes (menos operaciones por ciclo), sin embargo tiene muchas más unidades lógicas-aritméticas (ALU), por lo que tiene más capacidad de cálculo a coste de tener menos capacidad de manejo de almacenamiento. Proveedores Nvidia: se basa en la arquitecture Compute Unified Device Architecture (CUDA). AMD: se basa en una arquitectura más abierta, Heterogeneous System Architecture (HSA), que es multiplataforma. Su arquitectura se puede utilizar con distintos proveedores, p.ej. Nvidia. Flujo de Procesamiento en CUDA Plataformas TPU Diseñado por Google especialmente diseñado para operaciones matriciales y tensores. Su uso fundamental es en el entrenamiento de redes neuronales y la inferencia.\nPor qué utilizar TPUs? Según Google:\nSon 30x más rápidos que GPUs y CPUs. Presentan una gran eficiencia energética. Las NN desarrolladas con Tensorflow requieren muy pocas líneas de código. Requieren menos tiempo -\u003e menos dinero. Cuándo deberíamos utilizar una TPU? Versiones Hay dos versiones:\nV2: HBM de 8 GB/TPU core. 1MXU (128x128) por core. TPU pod, hasta 512 cores (4TB de memoria) V3: HBM de 16 GB/TPU core. 2 MXU (128x128) por core. TPU pod, hasta 2048 cores (32 TB de memoria) Flujo de Ejecución de TPUs ","frameworks-para-deep-learning#Frameworks para Deep Learning":"Tensorflow Arquitectura Tensorflow Presenta un núcleo de bajo nivel (C++/CUDA). Además se define un API Python sencillo para definir el gráfico computacional, así como APIs de alto nivel (TF-Learn, Keras, etc)\nTensorflow vs Numpy Numpy no dispone de funciones/métodos para la creación de funciones de tensores y no computa automáticamente sus derivadas. NumPy no tiene soporte para GPU. Modelo Computacional de Tensorflow Tensorflow construye grafos donde cada nodo es un tensor y cada arista es una operación entre los tensores. De tal manera que, como vemos en la figura inferior, se pueden repartir las computaciones entre distintas GPUs.\nLazy Evaluation Este grafo sólo encompasa la definición de las operaciones, de tal manera que no requiere de su ejecución. Si no que la ejecución sólo se produce durante el entrenamiento.\nTensorflow Hub Se trata de un repositorio de modelo pre-entrenados.\nOperaciones A continuación mostramos una serie de operaciones soportadas por Tensorflow:\nTheano Se trata de otro framework, pionero en el uso de grafos computacionales. Es una herramienta generalista, tal que podemos implementar cualquier tipo de algoirtmo sobre el framework. Además se puede especificar como backend a utilizar en Keras, en lugar de Tensorflow.\nSin embargo, finalizó su desarrollo a partir de la versión 1.0.\nLibrerías que usan Theano\nKeras blocks lasagne sklearn-theano PyMC 3 theano-rnn Morb Además presenta las siguientes características:\nPermite la evaluación lazy del grafo (precursor de esta ténica). Da soporte para GPU’s. Permite la diferenciación simbólica. Keras Keras puede ser utilizado con tensorflow o también como una librería adicional. Además presenta las siguientes ventajas:\nSencilla para comenzar, y sencilla para avanzar Se ejecuta sobre Theano y TensorFlow Disponibilidad de herramientas de visualización (Tensorboard) Escrita de forma modular: fácil de expandir Suficientemente potente para escribir modelos serios Pero también presenta las siguiente desventajas:\nMenos flexible Menos tipos: no hay modelos RBM, por ejemplo. Menos proyectos disponibles online que Caffe Soporte Multi-GPU no del 100% La idea general para la creación de modelos/algoritmos sigue el siguiente esquema:\nPreparar los tensores de entrada y salida Crear la primera capa (layer) para manejar el tensor de entrada Crear la última capa (layer) para manejar el tensor de salida (targets) Construir virtualmente cualquier modelo entre estas dos capas (hidden layers) Las definiciones de los modelos pueden ser guardados y recuperados en formato json y en formato yaml. Los parámetros también pueden ser guardados y recuperados en formato h5.\nTipos de Modelos Keras soporta dos tipos de modelos:\nModelo Secuencial API funcional: Se usa para definir modelos complejos: modelos multi-output, grafos acíclicos dirigidos (graph) o modelos con capa compartidas Grafo (deprecado) Caffe Construido sobre C++, CUDA. Presenta una gran cantidad de modelos pre-entrenados La definición de modelos de hace de forma declarativa:\nCuáles son sus aplicaciones?\nObject Detection Pixelwise Prediction Torch Su backend está basado en C y en CUDA. Su frontend está escrito sobre Lua. PyTorch Torch en python.\nFast.AI Es muy similar a Keras, Fast.AI permite generar herramientas y modelos pre-entranados de manera muy sencilla.\nAplicaciones de DL Visión Speech Recognition NLP ","proveedores-1#Proveedores":"Deep Cognition Se trata de una plataforma que incorpora un IDE visual que permite definir una red neuronal. Se puede utilizar:\nEn la nube En local En una máquina virtual En una máquina de azure H2O.AI Su arquitecture se detalla en la siguiente imagen:\nEn la parte superior vemos los lenguajes que soporta:\nSeguidamente tenemos un bloque de tradcutores (Rapids en C++ y Scala en Java):\nA continuación tenemos los algoritmos definidos así como la herramienta de predcción para H2O:\nEn la siguiente imagen tenemos la parte de la gestión de la computación que se lleva a cabo encima de clusters Spark/Hadoop o sobre la distribución standalone de H2O:\nAuto ML Permite evaluar modelos dado un conjunto de datos en base a una serie de métricas:\nDriverless AI Permite desarrollar el pipeline completo de H2O de forma visual, tal que permite automatizar tareas.\nBig ML Se trata de una empresa española. Define algoritmos de clasificación, regresión, análisis de clusters, detección de anomalías, descubrimiento de asociación y modelado. Destaca sobretodo en el preprocesamiento de datos, visualización y en la evaluación de modelo.\nNo soporta ni CNN (no soporta capas de convolución ni de pooling) ni RNN.\nLos parámetros soportados son los siguientes:"},"title":"T3. Herramientas y estrategias de programación e implemetación de redes neuronales"},"/notes/datascience/master/dl/04_cnn/":{"data":{"":"","aplicaciones#Aplicaciones":" Aprendizaje de similaridad. Subtitulado de imágenes. Generación de imágenes. Seguimiento en secuencias de imágenes. Todo lo comentado aplicado a vídeo y a imagen 3D. Robots: odometría y localización y creación de mapas (SLAM) usando cámaras. ","clasificación-de-imágenes#Clasificación de Imágenes":"Una CNN para clasificación de imágenes está conformada por dos bloques:\nConjunto de capas que llevan a cabo la extracción de caracterísitcas Clasificador que toma como entrada las características extraídas por la red neuronal Este tipo de redes necesita una gran cantidad de datos. En caso de no poseer un volumen elevado de datos se puede hacer uso de técnicas como el aumento de muestras y el uso de redes pre-entrenadas.\nAumento de Muestras Consiste en crear nuevas muestras a partir de muestras existentes utilizando transformaciones aleatorias:\nRotaciones y translaciones. Recorte o zoom. Voltear horizontalmente (si no hay suposiciones de simetría horizontal). Añadir pequeñas cantidades de ruido. En Keras esto se puede llevar a cabo utilizando ImageDataGenerator.\nRedes Pre-entrenadas Si la red ha sido entrenada sobre un conjunto de datos lo suficientemente grande y general entonces, entonces podemos utilizarlo sobre clases no utilizadas en el entrenamiento original. Existen dos técnicas:\nExtracción de de características: utiliza la red pre-entrenada para extraer características de los nuevos datos. Con las nuevas características se entrena un clasificador desde cero. Ajuste fino: utiliza unas cuantas capas de la red pre-entrenada y las entrena conjuntamente con el nuevo clasificador. Extracción de Características Se puede hacer de dos maneras:\nAplicar la base convolutiva sobre el conjunto de datos y utlizarla para entrenar el clasificador. No permite el aumento de datos Extender la base convolutiva con un nuevo clasificador y entrenar todo el conjunto. Es mucho más lenta per permite el aumento de datos Ajuste Fino Se lleva a cabo como sigue:\nSe añade la nueva red sobre la CNN pre-entrenada Se bloquea la red pre-entrenada, de manera que sus pesos no cambian Se entrena la nueva red Se desbloquean algunas capas superior (que extraer las características de más alto nivel), tal que sus pesos sí se pueden entrenar Entrenar estas capas y la nueva red ","detección-de-objetos#Detección de Objetos":"Un sistema de detección de objetos debe producir el nombre de la clase asignada a la imagen, una caja de abarque (bounding box) y generalmente la probabilidad de que el objeto pertenezca a la clase.\nSe presentan los siguientes retos a la hora de llevar a cabo la detección: oclusiones, cambios de puntos de vista y tamaños, objetos no rígidos y desenfoque por movimiento\nMétodos Antes del desarrollo de las redes neuronales se empleaban las Cascadas de Haar, que extraer características por convolución con kernels suma de píxeles en negro menos en blanco que seguidamente se pasan a un clasificador entrenado.\nPor otra parte, tenemos la detección basada en CNN que consiste en modificar nuestras redes CNN para no sólo clasificar, si no también obtener la caja de abarque y la forma del objeto. Dentro de estes distinguimos dos tipos:\nDetectores de dos etapas, como por ejemeplo Region CNN. Son letos y no permiten su aplicación en tiempo real. Detectore de una etapa, como por ejemplo Single Shot Multibox Detector. Sí que permiten su aplicación en tiempo real. RegionCNN Se generan una serie de propuestas de caja de abarque a distintas escalas. Se procesan las cajas utilizando una CNN pre-entrenada Se clasifican utilizando un clasificador como SVM Se procesan las cajas utilizando regresión lineal para ajustar las coordenadas ","segmentación-semántica#Segmentación Semántica":"En la segmentación clásica el objetivo consiste en agrupar píxeles contiguos de una categoría similar.\nLa segmentación semántica se distingue de la segmentación clásica en que intenta particionar la imagen en partes con significado y clasificarlas.\nMétodos Se utiliza una especie de GAN, ya que tienen una red codificadora pre-entrenada seguida de una red decodificadora:\nLa red codificadora aprende características distintivas a baja resolución La red decodificadora proyecta semánticamente las características en el espacio de píxeles (alta resolución) "},"title":"T4. Redes Neuronales Convolucionales en Visión Artificial"},"/notes/datascience/master/dl/05_rnn/":{"data":{"":"","ejemplos-de-deep-learning-para-natural-language-processing#Ejemplos de Deep Learning para Natural Language Processing":"Clasificación de Textos Para la clasificación de texto se define la siguiente estructura:\nCapa de embedding: que transforma la secuencia de palabras en una tabla de vectores capturando la semántica de las mismas. Componente de representación profunda: se utiliza RNN o CNN para obtener una representación comprimida de la entrada. Parte totalmente conectada: transforma la representación comprimida en clases o puntuaciones para cada clase. Ver el capítulo Text Classification Using LSTM de Hands-On Natural Language Processing with Python.\nGeneración de Textos Se utilizan RNNs para crear modelos generativos, tal que la generación se puede llevar a cabo en base a caracteres o a palabras. Estas son capaces de aprender dependencias a largo plazo.\nVer el capítulo Text Generation and Summarization Using GRUs de Hands-On Natural Language Processing with Python.\nResumen de Textos Distinguimos entre dos tipos:\nExtractivos: se extraen frases o palabras clave. Son simples y robustos y no permiten la paráfrasis. Abstractivos: la salida contiene texto no contenido en el original manteniendo el significado. Ver el cap. Text Generation and Summarization Using GRUs de Hands-On Natural Language Processing with Python.\nTraducción Distinguimos distintos sistemas que efectúan la traducción automática:\nSistemas expertos: se definen reglas lingüísticas y sintácticas. Traducción estadística: se aprenden reglas estadísticamente a partir de un gran conjunto de datos bilingüe. Tal que define un modelo de traducción que mapea textos de un lenguaje a otro. Solo funciona bien traduciendo textos similares a los de entrenamiento y necesita gran cantidad de datos Traducción con redes neuronales: utilizan un sólo modelo que trabaja sobre segmentos de texto, no sólo sobre palabras o frases. Ver el cap. Machine Translation Using the Attention-Based Model de Hands-On Natural Language Processing with Python.\nBúsqueda y Eliminación de Duplicados Se puede conseguir utilizando una CNN basada en caracteres, que proporciona la flexibilidad para entrenar modelos con caracteres desconocidos y ofrece mayor capacidad de generalición que los embeddings a nivel de palabra.\nVer el capítulo Searching and DeDuplicating Using CNNs de Hands-On Natural Language Processing with Python.","introducción-a-las-aplicaciones-del-deep-learning-para-el-nlp#Introducción a las aplicaciones del Deep Learning para el NLP":"Comparación entre enfoques clásico y de Deep Learning Enfoque Clásico El enfoque clásico se compone de los siguientes pasos:\nDetección de idioma Pre-procesado Tokenizado Etiquetado gramatical (POS) Eliminación de stop-words etc. Modelado Extracción de características (entidades (NER), categorías (POS) …) Aplicación de algoritmos de ML etc. Salida Análisis de sentimientos Clasificación de textos Traducción etc Enfoque Deep Learning Mientas que el enfoque basado en Deep Learning se compone de los siguientes pasos:\nPre-procesado Tokenizado Etiquetado gramatical (POS) Eliminación de stop-words etc. Representaciones distribuidas (word embeddings): transformación de palabras/secuencias en vectores que es la entrada que aceptan las redes neuronales. Para ello se distinguen métodos como: word2vec, Glove, etc. Procesamiento en capas ocultas: no permite generar representación comprimida de la entradas. Capa de salida Análisis de sentimientos Clasificación de textos Traducción etc Arquitecturas Para llevar a cabo Natural Languague Processing (NLP) con Deep Learning podemos utilizar las siguientes arquitecturas:\nRedes recurrentes (RNN) LSTM (Long Short Term Memory) GRU (Gated Recurrent Units) Redes convolucionales (CNN) Autoencoders ","otras-aplicaciones#Otras Aplicaciones":" Preguntas-respuestas y chatbots Reconocimiento de voz Texto a voz "},"title":"T5. Redes Neuronales Recurrentes"},"/notes/datascience/master/dl/06_cloud_services/":{"data":{"":"","awm-machine-learning#AWM Machine Learning":"La estructura se divide en tres bloques, de menor a mayor abstracción:\nInfraestructura Plataformas Servicios How to use Amazon SageMaker","capacidades#Capacidades":" SaaS (Software as a Service): Se utiliza/alquila un servicio concreto, p.ej. One Drive. PaaS (Platform as a Service): Permite tener entornos preconfigurados para poder ejecutar ciertos conjuntos de aplicaciones. IaaS (Infraestructure as a Service): Se da acceso a la infraestructura, tal que te permite utilizarla para ejecutar los servicios que tu convengas. ","características#Características":" IT Services Catalog Global network access Instant elasticity Chargeback Common IT-resouces pool ","google-cloud-platform#Google Cloud Platform":"A continuación mostramos el ciclo completo de desarrollo de soluciones ML, y las herramientas de GCP asociadas y disponibles para cada una de ellas:\nEn la fase de desarrollo se definen varias herramientas:\nData labeling service: se encarga del etiquetamiento correcto de los datos de forma semiautomática. Deep Learning VM Image: proporciona imágenes virtuales sobre las cuales llevar a cabo el procesamiento. API Platform Notebook ","modelos-de-despliegue#Modelos de Despliegue":"Como modelos de despliegue tenemos:\nPrivate Cloud: se cierra el acceso para que sólo la propia infraestructura tenga acceso. Community Cloud: conjunto de nubes públicas que comparten recursos. Hybrid Cloud: tiene parte pública y tiene parte a la que se restringe el acceso. Public Cloud: permite el acceso desde la nube pública de internet. "},"title":"T6. Servicios y Proveedores de Deep Learning en la Nube"},"/notes/math/":{"data":{"":" A Graphical Approach to Algebra and Trigonometry Calculus Ealy Transcendentals "},"title":"Math"},"/notes/math/agaa/":{"data":{"":" Linear Functions, Equations and Inequalities Analysis of Graphs of Functions Polynomial Functions Rational, Power and Root Functions Inverse, Exponential and Logarithmic Functions Systems and Matrices Analytic Geometry and Nonlinear Systems Trigonometric Functions and Applications Trigonometric Identities and Equations Applications of Trigonometry and Vectors Further Topics in Algebra Appendix "},"title":"A Graphical Approach to Algebra and Trigonometry"},"/notes/math/agaa/01_linear_functions/":{"data":{"":"","applications-of-linear-functions#Applications of Linear Functions":"Problem-Solving Strategies These steps may be helpful in solving application problems.\nRead the problem and make sure you understand it. Assign a variable to what you are being asked to find. Write an equation that relates the quantities described in the problem. Solve the equation and determine the solution to the posed question Look back and check your solution. Direct Variation A common application involving linear functions deals with quantities that vary directly (or are in direct proportion).\nA number $y$ varies directly with $x$ if there exists a nonzero number $k$ such that:\n$$ \\begin{aligned} y = kx \\end{aligned} $$The number k is called the constant of variation.","equations-of-lines-and-linear-models#Equations of Lines and Linear Models":"Point Slope Form FIGURE 51 shows a line passing through the fixed point $(x_1, y_1)$ with slope $m$. Let $(x, y)$ be any other point on the line.\nBy the slope formula:\n$$ \\begin{aligned} m = \\frac{y - y_1}{x - x_1} \\end{aligned} $$$$ \\begin{aligned} y - y_1 = m(x - x_1) \\end{aligned} $$This result is called the point–slope form of the equation of a line.\nStandard Form of the Equation of a Line A linear equation written in the form:\n$$ \\begin{aligned} Ax + By = C \\end{aligned} $$where $A$, $B$, and $C$ are real numbers ($A$ and $B$ not both $0$), is said to be in standard form.\nParallel and Perpendicular Lines Two distinct nonvertical lines are parallel if and only if they have the same slope.\nTwo lines, neither of which is vertical, are perpendicular if and only if their slopes have product $-1$.\nLinear Models and Regression When data points are plotted in the $xy$-plane, the resulting graph is sometimes called a scatter diagram. Scatter diagrams are often helpful for analyzing trends in data\nGraphing calculators are capable of finding the line of “best fit,” for the data called the least-squares regression line, by using a technique taught in statistics courses known as least-squares regression.\nOne common measure of the strength of the linear relationship in a data set is called the correlation coefficient, denoted $r$, where $-1 \\leq r \\leq 1$.","introduction-to-relations-and-functions#Introduction to Relations and Functions":"Set-Builder Notation and Interval Notation The following chart summarizes set-builder notation, interval notation, and graphs of intervals of real numbers. It is assumed that $a \u003c b$.\nRelations, Domain, and Range A relation is a set of ordered pairs. If we denote the ordered pairs of a relation by $(x, y)$, then the set of all $x$-values is called the domain of the relation and the set of all $y$-values is called the range of the relation.\nA relation can be represented by any of the following:\nA graph, as illustrated in FIGURE 17 and FIGURE 18 A table of $xy$-values, as shown in FIGURE 18(a) An equation, such as $y = 2x$ in FIGURE 18(b) A mapping or diagram, as illustrated in FIGURE 19 Functions A function is a relation in which each element in the domain corresponds to exactly one element in the range. In a function, each $x$-value must correspond to exactly one $y$-value\nVertical Line Test If every vertical line intersects a graph in no more than one point, then the graph is the graph of a function.\nFunction Notation To say that $y$ is a function of $x$ means that for each value of $x$ from the domain of the function, there is exactly one value of $y$. To emphasize that $y$ is a function of $x$, or that $y$ depends on $x$, it is common to write\n$$ \\begin{aligned} y = f(x) \\end{aligned} $$with $f(x)$ read “f of x.” This notation is called function notation.","linear-equations-and-inequalities#Linear Equations and Inequalities":"Solving Linear Equations in One Variable A linear equation in the variable $x$ is an equation that can be written in the form:\n$$ \\begin{aligned} ax + b = 0, a \\neq 0 \\end{aligned} $$We use two distinct approaches to solving equations.\nThe analytic approach, in which we use paper and pencil to transform complicated equations into simpler ones. The graphical approach, in which we often support our analytic solutions by using graphs or tables. The words root, solution, and zero all refer to the same basic concept.\nIdentities and Contradictions A contradiction is an equation that has no solution.\nAn identity is an equation that is true for all values in the domain of its variables.\nAnalytic Approach One way to solve a given equation analytically is to rewrite it as a series of simpler equivalent equations, each of which has the same solution set as the given one. Equivalent equations are obtained by using the properties of equality.\nGraphical Approaches to Solving Linear Equations In general, if $f$ and $g$ are linear functions, then their graphs are lines that intersect at a single point, no point, or infinitely many points, as illustrated in FIGURE 67.\nIntersection-of-Graphs Method of Graphical Solution To solve the equation $f(x) = g(x)$ graphically, graph\n$$ \\begin{aligned} y_1 = f(x) \\end{aligned} $$and\n$$ \\begin{aligned} y_2 = g(x) \\end{aligned} $$The $x$-coordinate of any point of intersection of the two graphs is a solution of the equation.\nx-Intercept Method of Graphical Solution To solve the equation $f(x) = g(x)$ graphically, graph\n$$ \\begin{aligned} y = f(x) - g(x) = F(x) \\end{aligned} $$The $x$-coordinate of any $x$-intercept of the graph of $y = F(x)$ (or zero of the function $F$) is a solution of the equation.\nSolving Linear Inequalities in One Variable An inequality says that one expression is greater than, greater than or equal to, less than, or less than or equal to another.\nTwo inequalities with the same solution set are equivalent inequalities. Inequalities are solved using the properties of inequality:\nFor real numbers $a$, $b$, and $c$:\n$a \u003c b$ and $a + c \u003c b + c$ are equivalent If $c \u003e 0$, then $a \u003c b$ and $ac \u003c bc$ are equivalent If $c \u003c 0$, then $a \u003c b$ and $ac \u003e bc$ are equivalent Similar properties exist for $\u003e, \\leq$ and $\\geq$.\nA linear inequality in the variable $x$ is an inequality that can be written in one of the following forms, where $a \\neq 0$.\n$$ \\begin{aligned} ax + b \u003e 0 \\end{aligned} $$$$ \\begin{aligned} ax + b \u003c 0 \\end{aligned} $$$$ \\begin{aligned} ax + b \\geq 0 \\end{aligned} $$$$ \\begin{aligned} ax + b \\leq 0 \\end{aligned} $$The solution set of a linear inequality is typically an interval of the real number line and can be expressed in interval notation.\nGraphical Approaches to Solving Linear Inequalities Intersection-of-Graphs Method of Solution of a Linear Inequality Suppose that $f$ and $g$ are linear functions. The solution set of $f(x) \u003e g(x)$ is the set of all real numbers $x$ such that the graph of $f$ is above the graph of $g$.\nx-Intercept Method of Solution of a Linear Inequality To solve $ƒ(x) \u003e g(x)$, we can rewrite the inequality as $ƒ(x) - g(x) \u003e 0$ or $F(x) \u003e 0$. Such that the solution set of $F(x) \u003e 0$ is the set of all real numbers $x$ such that the graph of $F$ is above the $x$-axis.","linear-functions#Linear Functions":"Linear Function A function $f$ defined by $f(x) = ax + b$, where $a$ and $b$ are real numbers, is called a linear function.\nGraphing linear equations by hand involves plotting points whose coordinates are solutions of the equation and then connecting them with a straight line.\nFrom geometry, we know that two distinct points determine a line. Therefore, if we know the coordinates of two points, we can graph the line.\nUnless otherwise specified, the domain of a linear function is the set of all real numbers. The range of a nonconstant linear function is also the set of all real numbers.\nIntercepts To find the $x$-intercept of the graph of $y = ax + b$, let $y = 0$ and solve for $x$ (assuming that $a \\neq 0$). To find the $y$-intercept, let $x = 0$ and solve for $y$.\nLet $ƒ$ be a function. Then any number $c$ for which $f(c) = 0$ is called a zero of the function $ƒ$. The point $(c, 0)$ is an $x$-intercept of the graph of $f$.\nConstant Function A function $f(x) = b$, where $b$ is a real number, is called a constant function. Its graph is a horizontal line with $y$-intercept $(0, b)$. For $b \\neq 0$, it has no $x$-intercept. (Every constant function is also linear.)\nSlope of a Line The slope $m$ of the line passing through the points $(x_1, y_1)$ and $(x_2, y_2)$ is:\n$$ \\begin{aligned} m = \\frac{\\Delta y}{\\Delta x} = \\frac{y_2 - y_1}{x_2 - x_1} \\end{aligned} $$where $\\Delta x = x_2 - x_1 \\neq 0$\nGeometric Orientation Based on Slope For a line with slope $m$,\nIf $m \u003e 0$ (i.e., slope is positive), the line rises from left to right. If $m \u003c 0$ (i.e., slope is negative), the line falls from left to right. If $m = 0$ (i.e., slope is $0$), the line is horizontal. Vertical Line A vertical line with $x$-intercept $(k, 0)$ has an equation of the form $x = k$. Its slope is undefined.\nSlope–Intercept Form of the Equation of a Line In general, if $f(x) = ax + b$, then the slope of the graph of $f(x)$ is $a$ and the $y$-coordinate of the $y$-intercept is b. To verify this fact, notice that $f(0) = a(0) + b = b$.\nBecause the slope of the graph of $f(x) = ax + b$ is $a$, it is often convenient to use $m$ rather than $a$ in the general form of the equation. Therefore, we can write either\n$$ \\begin{aligned} f(x) = mx + b \\end{aligned} $$or\n$$ \\begin{aligned} y = mx + b \\end{aligned} $$This equation for $f(x)$ is generally called the slope–intercept form of the equation of a line.","real-numbers-and-the-rectangular-system#Real Numbers and the Rectangular System":"Sets of Real Numbers Several important sets of numbers are used in mathematics. Some of these sets are listed in the following table\nSet Description Natural Numbers ${1, 2, 3, \\cdots}$ Whole Numbers ${0, 1, 2, 3, \\cdots}$ Integers ${\\cdots, -1, 0, 1, 2, 3, \\cdots}$ Rational Numbers ${\\frac{p}{q} \\shortmid p \\text{ and } q \\text{ are integers, } q \\neq 0}$ Irrational Numbers ${x \\shortmid x \\text { is not rational}}$ Real Numbers ${x \\shortmid x \\text { is a decimal number}}$ The Rectangular Coordinate System If we place two number lines at right angles, intersecting at their origins, we obtain a two-dimensional rectangular coordinate system. This rectangular coordinate system is also called the Cartesian coordinate system.\nPythagorean Theorem In a right triangle, the sum of the squares of the lengths of the legs is equal to the square of the length of the hypotenuse.\n$$ \\begin{aligned} a^2 + b^2 = c^2 \\end{aligned} $$Distance Formula Suppose that $P(x_1, y_1)$ and $R(x_2, y_2)$ are two points in a coordinate plane. Then the distance between $P$ and $R$, written $d(P, R)$, is given by the distance formula.\n$$ \\begin{aligned} d(P, R) = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} \\end{aligned} $$Midpoint Formula The midpoint $M$ of the line segment with endpoints $(x_1, y_1)$ and $(x_2, y_2)$ has the following coordinates.\n$$ \\begin{aligned} M = \\left(\\frac{x_1 + x_2}{2}, \\frac{y_1 + y_2}{2}\\right) \\end{aligned} $$"},"title":"Linear Functions, Equations and Inequalities"},"/notes/math/agaa/02_graph_analysis/":{"data":{"":"","absolute-value-functions#Absolute Value Functions":"The Graph of $y = ∣f(x)∣$ The domain of $y = |f(x)|$ is the same as the domain of $f$, while the range of $y = |f(x)|$ will be a subset of $[0, \\infty)$.\nProperties of Absolute Value For all real numbers $a$ and $b$:\n$|ab| = |a| |b|$ $|\\frac{a}{b}| = \\frac{|a|}{|b|}$ $|a| = |-a|$ $|a| + |b| \\geq |a + b|$ Equations and Inequalities Involving Absolute Value Let $k$ be a positive number.\nTo solve $|ax + b| = k$, solve: $$ \\begin{aligned} a x + b = k, \\text{ or } ax + b = -k \\end{aligned} $$ To solve $|ax + b| \u003e k$, solve: $$ \\begin{aligned} a x + b \u003e k, \\text{ or } ax + b \u003c -k \\end{aligned} $$ To solve $|ax + b| \u003c k$, solve: $$ \\begin{aligned} a x + b \u003c k, \\text{ or } ax + b \u003e -k \\end{aligned} $$Inequalities involving $\\leq$ or $\\geq$ are solved similarly.\nIf two quantities have the same absolute value, they must either be equal to each other or be negatives of each other. This fact allows us to solve absolute value equations (and related inequalities) of the form $|ax + b| = |cx + d|$ by solving:\n$$ \\begin{aligned} ax + b = cx + d, \\text{ or } ax + b = -(cx + d) \\end{aligned} $$","graphs-of-basic-functions-and-relations-symmetry#Graphs of Basic Functions and Relations: Symmetry":"Increasing, Decreasing, and Constant Functions Suppose that a function $f$ is defined over an open interval $I$.\n$f$ increases on $I$ if, whenever $x_1 \u003c x_2$, $f(x_1) \u003c ƒ(x_2)$ $f$ decreases on $I$ if, whenever $x_1 \u003c x_2$, $f(x_1) \u003e ƒ(x_2)$ $f$ is constant on $I$ if for every $x_1$, $x_2$, $f(x_1) = ƒ(x_2)$ Symmetry with Respect to the $y$-Axis If a function $f$ is defined so that:\n$$ \\begin{aligned} f(-x) = f(x) \\end{aligned} $$for all $x$ in its domain, then the graph of $f$ is symmetric with respect to the $y$-axis.\nSymmetry with Respect to the Origin If a function $f$ is defined so that:\n$$ \\begin{aligned} f(-x) = -f(x) \\end{aligned} $$for all $x$ in its domain, then the graph of $f$ is symmetric with respect to the origin.\nSymmetry with Respect to the $x$-Axis If replacing $y$ with $-y$ in an equation results in the same equation, then the graph is symmetric with respect to the $x$-axis.\nEven and Odd Functions A function $f$ is called an even function if $f(-x) = f(x)$ for all $x$ in the domain of $f$. (Its graph is symmetric with respect to the y-axis.)\nA function $f$ is called an odd function if $f(-x) = -f(x)$ for all $x$ in the domain of $f$. (Its graph is symmetric with respect to the origin.)\nThe Absolute Value Function On a number line, the absolute value of a real number x, denoted $|x|$, represents its undirected distance from the origin, $0$. The absolute value function, $f(x) = |x|$, pairs every real number with its absolute value and is defined as follows:\n$$ \\begin{aligned} f(x) = |x| = \\begin{cases} x \u0026 \\text{ if } x \\geq 0 \\\\ -x \u0026 \\text{ if } x \u003c 0 \\\\ \\end{cases} \\end{aligned} $$","operations-and-composition#Operations and Composition":"Operations on Functions Given two functions $ƒ$ and $g$, for all values of $x$ for which both $f(x)$ and $g(x)$ are defined:\n$$ \\begin{aligned} (f + g)(x) = f(x) + g(x) \\end{aligned} $$$$ \\begin{aligned} (f - g)(x) = f(x) - g(x) \\end{aligned} $$$$ \\begin{aligned} (fg)(x) = f(x)g(x) \\end{aligned} $$$$ \\begin{aligned} \\left(\\frac{f}{g}\\right)(x) = \\frac{f(x)}{g(x)}, g(x) \\neq 0 \\end{aligned} $$The domains of $f + g$, $f - g$, and $fg$ include all real numbers in the intersection of the domains of $f$ and $g$, while the domain of $\\frac{f}{g}$ includes those real numbers in the intersection of the domains of $f$ and $g$ for which $g(x) \\neq 0$.\nThe Difference Quotient Suppose that the point $P$ lies on the graph of $y = f(x)$ as in FIGURE 68, and suppose that $h$ is a positive number. If we let $(x, f(x))$ denote the coordinates of $P$ and $(x + h, f(x + h))$ denote the coordinates of $Q$, then the line joining $P$ and $Q$ has slope:\n$$ \\begin{aligned} m = \\frac{f(x + h) - f(x)}{(x + h) - x} = \\frac{f(x + h) - f(x)}{h} \\end{aligned} $$This expression, called the difference quotient. FIGURE 68 shows the graph of the line PQ (called a secant line. This slope is equal to the average rate of change of $f$ from $x$ to $x + h$.\nComposition of Functions The diagram in FIGURE 69 shows a function $ƒ$ that assigns, to each $x$ in its domain, a value $ƒ(x)$. Then another function $g$ assigns, to each $f(x)$ in the domain of $g$, a value $g(f(x))$. This two-step process takes an element $x$ and outputs an element $g(f(x))$.\nThe function with $y$-values $g(f(x))$ is called the composition of function $g$ and $f$, written $g \\circ f$ and read “$g$ of $f$”.","piecewise-defined-functions#Piecewise-Defined Functions":"Graphing Piecewise-Defined Functions The absolute value function is a simple example of a function defined by different rules (formulas) over different subsets of its domain. Such a function is called a piecewise-defined function. See FIGURE 55.","vertical-and-horizontal-shifts-of-graphs#Vertical and Horizontal Shifts of Graphs":"Vertical Shifts If $c \u003e 0$, then the graph of $y = f(x) + c$ is obtained by shifting the graph of $y = f(x)$ upward a distance of $c$ units. The graph of $y = f(x) - c$ is obtained by shifting the graph of $y = f(x)$ downward a distance of $c$ units.\nHorizontal Shifts If $c \u003e 0$, then the graph of $y = f(x - c)$ is obtained by shifting the graph of $y = f(x)$ to the right a distance of $c$ units. The graph of $y = f(x + c)$ is obtained by shifting the graph of $y = f(x)$ to the left a distance of $c$ units.","vertical-and-horizontal-shifts-of-graphsstretching-shrinking-and-reflecting-graphs#Vertical and Horizontal Shifts of GraphsStretching, Shrinking and Reflecting Graphs":"Vertical Stretching If $c \u003e 1$, then the graph of $y = cf(x)$ is a vertical stretching of the graph of $y = f(x)$ by applying a factor of $c$.\nIn FIGURE 25, we graphically interpret the preceding statement. Notice that the graphs have the same $x$-intercepts\nVertical Shrinking If $0 \u003c c \u003c 1$, then the graph of $y = cf(x)$ is a vertical shrinking of the graph of $y = f(x)$ by applying a factor of $c$.\nFIGURE 27 shows a vertical shrink graphically. Vertical stretching or shrinking does not change the $x$-intercepts of the graph but it can change the $y$-intercept.\nHorizontal Stretching and Shrinking If $0 \u003c c \u003c 1$, then the graph of $y = f(cx)$ is a horizontal stretching of the graph of $y = f(x)$.\nIf $c \u003e 1$, then the graph of $y = f(cx)$ is a horizontal shrinking of the graph of $y = f(x)$.\nNotice in FIGURE 32 that horizontal stretching or shrinking can change the $x$-intercepts, but not the $y$-intercept.\nReflecting across an Axis For a function $y = f(x)$, the following are true.\nThe graph of $y = −f(x)$ is a reflection of the graph of $f$ across the $x$-axis. The graph of $y = f(−x)$ is a reflection of the graph of $f$ across the $y$-axis. Combining Transformations of Graphs We can create infinitely many functions from a basic function by stretching or shrinking, shifting upward, downward, left, or right, and reflecting across an axis. To determine the order in which the transformations are made, follow the conventional order of operations as they would be applied to a particular $x$-value."},"title":"Analysis of Graphs of Functions"},"/notes/math/agaa/03_polynomial_functions/":{"data":{"":"","complex-numbers#Complex Numbers":"The Imaginary Unit i The imaginary unit is defined as:\n$$ \\begin{aligned} i = \\sqrt{-1} \\end{aligned} $$and therefore\n$$ \\begin{aligned} i^2 = -1 \\end{aligned} $$Complex Numbers Numbers of the form $a + bi$, where $a$ and $b$ are real numbers, are called complex numbers. In the complex number $a + bi$, $a$ is the real part and $b$ is the imaginary part.\nTwo complex numbers $a + bi$ and $c + di$ are equal provided that their real parts are equal and their imaginary parts are equal.\nFor a complex number $a + bi$, if $b = 0$, then $a + bi =$ a, which is a real number.\nIf $a = 0$ and $b \\neq 0$, the complex number is a pure imaginary number.\nSimplifying Powers of i By definition, $i^1 = i$ and $i^2 = -1$. Now, observe the following pattern.\n$$ \\begin{aligned} i^1 = i \\end{aligned} $$$$ \\begin{aligned} i^2 = -1 \\end{aligned} $$$$ \\begin{aligned} i^3 = i^2 i^1 = -i \\end{aligned} $$$$ \\begin{aligned} i^4 = i^2 i^2 = 1 \\end{aligned} $$Such that:\n$$ \\begin{aligned} (i^4)^n = 1 \\end{aligned} $$We can then simplify powers of $i$ by considering the other factor. For example,\n$$ \\begin{aligned} i^53 = i^52 i^1 = (i^4)^13 i^1 = i \\end{aligned} $$Complex Conjugates The conjugate of the complex number $a + bi$ is $a - bi$. Their product is the sum of the squares of their real and imaginary parts.\nTo find the quotient of two complex numbers in standard form, we multiply numerator and denominator by the conjugate of the denominator.","high-degree-polynomial-functions-and-graphs#High-Degree Polynomial Functions and Graphs":"Polynomial Function A polynomial function of degree $n$ in the variable $x$ is a function of the form:\n$$ \\begin{aligned} P(x) = a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1 x + a_0 \\end{aligned} $$where each $a_1$ is a real number, $a_n \\neq 0$ and $n$ is a whole number.\nThe behavior of the graph of a polynomial function is due largely to the value of the coefficient $a_n$ and the parity of the exponent $n$ on the term of greatest degree. For this reason, we will refer to $a_n$ as the leading coefficient and to $a_n x_n$ as the dominating term.\nThe term $a_0$ is the constant term of the polynomial function, and since $P(0) = a_0$, it is the $y$-value of the $y$-intercept of the graph.\nCubic Functions A polynomial function of the form:\n$$ \\begin{aligned} P(x) = ax^3 + bx^2 + cx + d, a \\neq 0 \\end{aligned} $$is a cubic function.\nQuartic Functions A polynomial function of the form:\n$$ \\begin{aligned} P(x) = ax^4 + bx^3 + cx^2 + dx + e, a \\neq 0 \\end{aligned} $$is a quartic function.\nExtrema The graphs for polynomial may have turning points where the function changes from increasing to decreasing or vice versa.\nLet $c$ be in the domain of $P$, then the following hold:\n$P(c)$ is an absolute maximum if $P(c) \\geq P(x)$ for all $x$ in the domain of $P$ $P(c)$ is an absolute minimum if $P(c) \\leq P(x)$ for all $x$ in the domain of $P$ $P(c)$ is an local maximum if $P(c) \\geq P(x)$ when $x$ is near $c$ $P(c)$ is an local minimum if $P(c) \\leq P(x)$ when $x$ is near $c$ Number of Turning Points The number of turning points of the graph of a polynomial function of degree $n \\geq 1$ is at most $n - 1$.\nEnd Behaviour Suppose that $ax^n$ is the dominating term of a polynomial function $P$ of odd degree.\nIf $a \u003e 0$, then as $x \\rightarrow \\infty$, $P(x) \\rightarrow \\infty$, and as $x \\rightarrow -\\infty$, $P(x) \\rightarrow -\\infty$. Therefore, the end behavior of the graph is of the type shown in FIGURE 52(a). If $a \u003c 0$, then as $x \\rightarrow \\infty$, $P(x) \\rightarrow -\\infty$, and as $x \\rightarrow -\\infty$, $P(x) \\rightarrow \\infty$. Therefore, the end behavior of the graph is of the type shown in FIGURE 52(b). Suppose that $ax^n$ is the dominating term of a polynomial function $P$ of even degree.\nIf $a \u003e 0$, then as $|x| \\rightarrow \\infty$, $P(x) \\rightarrow \\infty$. Therefore, the end behavior of the graph is of the type shown in FIGURE 53(a). If $a \u003c 0$, then as $|x| \\rightarrow \\infty$, $P(x) \\rightarrow -\\infty$. Therefore, the end behavior of the graph is of the type shown in FIGURE 53(b). x-Intercepts (Real Zeros) The graph of a polynomial function of degree $n$ will have at most $n$ $x$-intercepts (real zeros).\nComprehensive Graphs The most important features of the graph of a polynomial function are its intercepts, extrema, and end behavior. For this reason, a comprehensive graph of a polynomial function will exhibit the following features.\nAll $x$-intercepts (if any) The $y$-intercept All extreme points (if any) Enough of the graph to reveal the correct end behavior ","polynomial-equations-and-inequalities-further-applications-and-models#Polynomial Equations and Inequalities; Further Applications and Models":"Complex nth Roots If $n$ is a positive integer and $k$ is a nonzero complex number, then a solution of $x^n = k$ is called an $n$th root of $k$.\nComplex nth Roots Theorem If $n$ is a positive integer and $k$ is a nonzero complex number, then the equation $x^n = k$ has exactly $n$ complex roots.","quadratic-equations-and-inequalities#Quadratic Equations and Inequalities":"Quadratic Equation in One Variable An equation that can be written in the form:\n$$ \\begin{aligned} ax^2 + bx + c = 0 \\end{aligned} $$where $a$ and $b$ are real numbers, with $a \\neq 0$ is a quadratic equation in standard form.\nFIGURE 25 shows possible numbers of $x$-intercepts of the graph of a quadratic function that opens upward\nSimilarly, FIGURE 26 shows possible numbers of x-intercepts of the graph of a quadratic function that opens downward.\nThus, a quadratic equation can have zero, one, or two real solutions.\nSquare Root Property The solution set of $x^2 = k$ is one of the following\n${\\pm \\sqrt{k}}$ if $k \u003e 0$ ${0}$ if $k = 0$ ${\\pm i\\sqrt{|k|}}$ if $k \u003c 0$ Quadratic Formula and the Discriminant There is a formula that can be used to solve any quadratic equation. To find it, we complete the square on the standard form of $ax^2 + bx + c = 0$.\n$$ \\begin{aligned} ax^2 + bx + c = 0 \\end{aligned} $$$$ \\begin{aligned} x^2 + \\frac{b}{a}x + \\frac{c}{a} = 0 \\end{aligned} $$$$ \\begin{aligned} x^2 + \\frac{b}{a}x = -\\frac{c}{a} \\end{aligned} $$$$ \\begin{aligned} x^2 + \\frac{b}{a}x + \\left(\\frac{b}{2a}\\right)^2= -\\frac{c}{a} + \\left(\\frac{b}{2a}\\right)^2 \\end{aligned} $$$$ \\begin{aligned} (x + \\frac{b}{2a})^2 = -\\frac{c}{a} + \\frac{b^2}{4a^2} \\end{aligned} $$$$ \\begin{aligned} x + \\frac{b}{2a} = \\sqrt{-\\frac{c}{a} + \\frac{b^2}{4a^2}} \\end{aligned} $$$$ \\begin{aligned} x + \\frac{b}{2a} = \\pm \\sqrt{\\frac{b^2 - 4ac}{4a^2}} \\end{aligned} $$$$ \\begin{aligned} x + \\frac{b}{2a} = \\pm \\frac{\\sqrt{b^2 - 4ac}}{2a} \\end{aligned} $$$$ \\begin{aligned} x = - \\frac{b}{2a} \\pm \\frac{\\sqrt{b^2 - 4ac}}{2a} \\end{aligned} $$$$ \\begin{aligned} x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\end{aligned} $$The expression $b^2 − 4ac$ under the radical in the quadratic formula is called the discriminant.\nIf $b^2 - 4ac \u003e 0$ then there are two real solutions. If $b^2 - 4ac = 0$ then there is one real solutions. If $b^2 - 4ac \u003c 0$ then there are two non-real complex solutions. Solving Quadratic Inequalities A quadratic inequality is an inequality that can be written in the form:\n$$ \\begin{aligned} ax^2 + bx + c \u003c 0 \\end{aligned} $$where $a$, $b$ and $c$ are real numbers with $a \\neq 0$.\nWe can solve a quadratic inequality graphically, using the ideas shown in the following table.\nTo solve a quadratic inequality analytically, follow these steps.\nSolve the corresponding quadratic equation. Identify the intervals determined by the solutions of the equation Use a test value from each interval to determine which intervals form the solution set. ","quadratic-functions-and-graphs#Quadratic Functions and Graphs":"Quadratic Function The function:\n$$ \\begin{aligned} P(x) = ax^2 + bx + c \\end{aligned} $$where $a$, $b$, and $c$ are real numbers, with $a \\neq 0$, is called a quadratic function.\nQuadratic functions, as well as linear functions, are examples of polynomial functions.\nCompleting the Square To transform the quadratic function $P(x) = ax^2 + bx + c$ into the form $P(x) = a(x - h)^2 + k$, follow these steps.\nDivide each side of the equation by $a$ so the coefficient of $x^2$ is $1$. $$ \\begin{aligned} \\frac{P(x)}{a} = x^2 + \\frac{b}{a}x + \\frac{c}{a} \\end{aligned} $$ Add $-\\frac{c}{a}$ to each side $$ \\begin{aligned} \\frac{P(x)}{a} - \\frac{c}{a} = x^2 + \\frac{b}{a}x \\end{aligned} $$ Completing the squares: Add to each side the square of hald the coefficient of $x$: $\\left(\\frac{b}{2a}\\right)^2$ $$ \\begin{aligned} \\frac{P(x)}{a} - \\frac{c}{a} + \\left(\\frac{b}{2a}\\right)^2 = x^2 + \\frac{b}{a}x + \\left(\\frac{b}{2a}\\right)^2 \\end{aligned} $$ Factor the right side as the square of a binomial and combine terms on the left. $$ \\begin{aligned} \\frac{P(x)}{a} - \\frac{c}{a} + \\left(\\frac{b}{2a}\\right)^2 = (x + \\frac{b}{a})^2 \\end{aligned} $$ Isolate the term involving $P(x)$ on the left. $$ \\begin{aligned} \\frac{P(x)}{a} = (x + \\frac{b}{a})^2 + \\frac{c}{a} - \\left(\\frac{b}{2a}\\right)^2 \\end{aligned} $$$$ \\begin{aligned} = (x + \\frac{b}{a})^2 + \\frac{c}{a} - \\frac{b^2}{4a^2} \\end{aligned} $$ Multiply each side by $a$. $$ \\begin{aligned} P(x) = a(x + \\frac{b}{a})^2 + c - \\frac{b^2}{4a} \\end{aligned} $$$$ \\begin{aligned} = a(x + \\frac{b}{a})^2 + \\frac{4ac - b^2}{4a} \\end{aligned} $$Graphs of Quadratic Functions Recall from Intercepts that the $y$-intercept of the graph of an equation is the point that has $x$-coordinate 0. For a parabola given in the form $P(x) = ax^2 + bx + c$, the $y$-value of the $y$-intercept is $P(0) = c$.\nConsider the graph of $P(x) = a(x - h)^2 + k (a \\neq 0)$, then:\nThe graph is a parabola with vertex $(h, k)$ and vertical line $x = h$ as its axis of symmetry. The graph opens upward if $a \u003e 0$ and downward if $a \u003c 0$. The graph is wider than the graph of $y = x^2$ if $0 \u003c |a| \u003c 1$ and narrower if $|a| \u003e 1$. Vertex Formula We can determine the coordinates of the vertex of the graph of a quadratic function by completing the square, as shown earlier. Given the standard form of the quadratic function $P(x) = ax^2 + bx + c, where a \\neq 0$, then:\n$$ \\begin{aligned} P(x) = a\\left(x - \\left(-\\frac{b}{a}\\right)\\right)^2 + + \\frac{4ac - b^2}{4a} \\end{aligned} $$This equation shows that the vertex $(h, k)$ can be expressed in terms of $a, b$ and $c$, such that:\n$$ \\begin{aligned} h = \\left(-\\frac{b}{a}\\right) \\end{aligned} $$and\n$$ \\begin{aligned} k = \\frac{4ac - b^2}{4a} \\end{aligned} $$Extreme Values The vertex of the graph of\n$$ \\begin{aligned} P(x) = ax^2 + bx + c \\end{aligned} $$is the lowest point on the graph of the function if $a \u003e 0$ and the highest point if $a \u003c 0$. Such points are called extreme points (also extrema; singular, extremum).\nIf $a \u003e 0$ then the vertex $(h, k)$ is called the minimum point of the graph. The minimum value of the function is $P(h) = k$. If $a \u003c 0$ then the vertex $(h, k)$ is called the maximum point of the graph. The maximum value of the function is $P(h) = k$. FIGURE 14 illustrates these ideas.","topics-in-the-theory-of-polynomial-functions-i#Topics in the Theory of Polynomial Functions (I)":"Intermediate Value Theorem If $P(x)$ defines a polynomial function with only real coefficients, and if, for real numbers $a$ and $b$, the values $P(a)$ and $P(b)$ are opposite in sign, then there exists at least one real zero between $a$ and $b$.\nDivision of Polynomials by x − k and Synthetic Division We can use long division to determine whether one whole number is a factor of another.\nIf the degree $n$ polynomial $P(x)$ (where $n \\geq 1$) is divided by $x - k$, then the quotient polynomial, $Q(x)$, has degree $n - 1$.\nThe remainder $R$ is a constant (and may be $0$). The complete quotient for $\\frac{P(x)}{x - k}$ may be written as:\n$$ \\begin{aligned} \\frac{P(x)}{x - k} = Q(x) + \\frac{R}{x - k} \\end{aligned} $$Long division of a polynomial by a binomial of the form $x - k$ can be condensed\nOn the right, exactly the same division is shown without the variables. All the numbers in color on the right are repetitions of the numbers directly above them, so they can be omitted, as shown below on the left. Since the coefficient of $x$ in the divisor is always $1$, it can be omitted, too\nThe numbers in color on the left are again repetitions of the numbers directly above them. They may be omitted, as shown on the right. Now the problem can be condensed. If the 3 in the dividend is brought down to the beginning of the bottom row, the top row can be omitted, since it duplicates the bottom row\nTo simplify the arithmetic, we replace subtraction in the second row by addition and compensate by changing the $-3$ at the upper left to its additive inverse, $3$.\nRemainder Theorem If a polynomial $P(x)$ is divided by $x - k$, the remainder is equal to $P(k)$. By the division algorithm for polynomials:\n$$ \\begin{aligned} P(x) = Q(x)(x-k) + R \\end{aligned} $$$$ \\begin{aligned} P(k) = Q(k)(k-k) + R = R \\end{aligned} $$Factor Theorem A polynomial $P(x)$ has a factor $x - k$ if and only if $P(k) = 0$. By the remainder theorem:\n$$ \\begin{aligned} P(k) = R \\end{aligned} $$where $R$ is the remainder, which is necessarily $0$.\nDivision of Any Two Polynomials Let $P(x)$ and $D(x)$ be two polynomials, with the degree of $D(x)$ greater than zero and less than the degree of $P(x)$. Then there exist unique polynomials $Q(x)$ and $R(x)$ such that:\n$$ \\begin{aligned} \\frac{P(x)}{D(x)} = Q(x) + \\frac{R(x)}{D(x)} \\end{aligned} $$","topics-in-the-theory-of-polynomial-functions-ii#Topics in the Theory of Polynomial Functions (II)":"Conjugate Zeros Theorem If $P(x)$ is a polynomial function having only real coefficients, and if $a + bi$ is a zero of $P(x)$, then the conjugate $a - bi$ is also a zero of $P(x)$.\nFundamental Theorem of Algebra Every function defined by a polynomial of degree $1$ or more has at least one complex zero.\nNumber of Zeros Theorem A function defined by a polynomial of degree $n$ has at most $n$ distinct (unique) complex zeros.\nMultiplicity The number of times a zero appears is referred to as the multiplicity of the zero.\nA zero $k$ of a polynomial function has as multiplicity the exponent of the factor $x - k$.\nIf the zero has multiplicity one, the graph crosses the $x$-axis at the corresponding $x$-intercept as seen in FIGURE 74(a) on the next page. If the zero has even multiplicity, the graph is tangent to the $x$-axis at the corresponding $x$-intercept (see FIGURE 74(b)). If the zero has odd multiplicity greater than one, the graph crosses the $x$-axis and is tangent to the $x$-axis at the corresponding $x$-intercept. (See FIGURE 74(c)). Rational Zeros Theorem Let $P(x) = a_nx^n + a_{n-1}x^{n - 1} + \\cdots + a_1x + a_0$, where $a_n \\neq 0$ and $a_0 \\neq 0$, be a polynomial function with integer coefficients. If $\\frac{p}{q}$ is a rational number written in lowest terms, and if $\\frac{p}{q}$ is a zero of $P(x)$, then $p$ is a factor of the constant term $a_0$, and $q$ is a factor of the leading coefficient $a_n$.\nProof $P(\\frac{p}{q}) = 0$ since $\\frac{p}{q}$ is a zero of $P(x)$:\nWe substitute $x$ by $\\frac{p}{q}$\n$$ \\begin{aligned} a_n \\left(\\frac{p}{q}\\right)^n + a_{n-1} \\left(\\frac{p}{q}\\right)^{n - 1} + \\cdots + a_{1} \\left(\\frac{p}{q}\\right) + a_0 = 0 \\end{aligned} $$$$ \\begin{aligned} a_n \\left(\\frac{p^n}{q^n}\\right) + a_{n-1} \\left(\\frac{p^{n-1}}{q^{n-1}}\\right) + \\cdots + a_{1} \\left(\\frac{p}{q}\\right) + a_0 = 0 \\end{aligned} $$We multiply by $q^n$ and we add $-a_0q^n$\n$$ \\begin{aligned} a_n p^n + a_{n-1} p^{n-1}q + \\cdots + a_{1} p q^{n-1} = -a_0 + q^{n} \\end{aligned} $$We factor out $p$\n$$ \\begin{aligned} p(a_n p^{n-1} + a_{n-1} p^{n-2}q + \\cdots + a_{1} q^{n-1}) = -a_0 + q^{n} \\end{aligned} $$Thus, $-a_0q^n$ equals the product of the two factors, $p$ and $(a_np^{n-1} + \\cdots + a_1q^{n-1})$. For this reason, $p$ must be a factor of $-a_0q^n$.\nSince it was assumed that $\\frac{p}{q}$ is written in lowest terms, $p$ and $q$ have no common factor other than $1$, so $p$ is not a factor of $q^n$. Thus, $p$ must be a factor of $a_0$.\nDescartes’ Rule of Signs Let $P(x)$ be a polynomial function with real coefficients and a nonzero constant term, with terms in descending powers of $x$.\nThe number of positive real zeros either equals the number of variations in sign occurring in the coefficients of $P(x)$ or is less than the number of variations by a positive even integer. The number of negative real zeros either equals the number of variations in sign occurring in the coefficients of $P(-x)$ or is less than the number of variations by a positive even integer. Boundedness Theorem Let $P(x)$ be a polynomial function of degree $n \\geq 1$ with real coefficients and with a positive leading coefficient. Suppose $P(x)$ is divided synthetically by $x - c$.\nIf $c \u003e 0$ and all numbers in the bottom row of the synthetic division are nonnegative, then $P(x)$ has no zero greater than $c$. If $c \u003c 0$ and the numbers in the bottom row of the synthetic division alternate in sign (with $0$ considered positive or negative, as needed), then $P(x)$ has no zero less than $c$. "},"title":"Polynomial Functions"},"/notes/math/agaa/04_special_functions/":{"data":{"":"","equations-inequalities-and-applications-involving-root-functions#Equations, Inequalities, and Applications Involving Root Functions":"Equations and Inequalities Power Property If $P$ and $Q$ are algebraic expressions, then every solution of the equation $P = Q$ is among the solutions of the equation $P^n = Q^n$, for any positive integer $n$.\nWhen the power property is used to solve equations, the new equation may have more solutions than the original equation. We call these proposed solutions of the original equation. After applying the power property on equations that contain radicals or rational exponents, it is essential to check all proposed solutions in the original equation.\nTo solve equations involving roots, follow these steps.\nIsolate a term involving a root on one side of the equation Raise each side of the equation to a positive integer power that will eliminate the radical or rational exponent. Solve the resulting equation. (If a root is still present after Step 2, repeat Steps 1 and 2.) Check each proposed solution in the original equation ","functions-defined-by-powers-and-roots#Functions Defined by Powers and Roots":"Power and Root Functions A function $f$ of the form:\n$$ \\begin{aligned} f(x) = x^b \\end{aligned} $$where $b$ is a constant, is a power function.\nIf $b = \\frac{1}{m}$, for some integer $n \\geq 2$, then $f$ is a root function\nFrequently, the domain of a power function $f$ is restricted to nonnegative numbers. Suppose the rational number $\\frac{p}{q}$ is written in lowest terms. Then the domain of $f(x) = x^{\\frac{p}{q}}$ is all real numbers whenever $q$ is odd and all nonnegative real numbers whenever $q$ is even. If $b$ is a positive irrational number, the domain of $f(x) = x^b$ is all nonnegative real number.\nGraphs of $f(x) = \\sqrt[n]{ax + b}$ When $n$ is even, the graph of the root function $f(x) = \\sqrt[n]{x}$ resembles the graph of the square root function.\nWhen $n$ is odd, the graph of the root function $f(x) = \\sqrt[n]{x}$ resembles the graph of the cube root function.\nTo determine the domain of a root function of the form:\n$$ \\begin{aligned} f(x) = \\sqrt[n]{ax + b} \\end{aligned} $$we must note the parity of $n$:\nIf $n$ is even in $\\sqrt[n]{ax + b}$, then $ax + b$ must be greater than or equal to $0$. If $n$ is odd in $\\sqrt[n]{ax + b}$, then $ax + b$ can be any real number. ","rational-equations-inequalities-models-and-applications#Rational Equations, Inequalities, Models and Applications":"Solving Rational Equations and Inequalities A rational equation (or rational inequality) is an equation (or inequality) with at least one term having a variable expression in a denominator or at least one term having a variable expression raised to a negative integer power.\nSolving Rational Equations Determine all values for which the rational equation has undefined expressions. To clear fractions, multiply each side of the equation by the least common denominator of all rational expressions in the equation. Solve the resulting equation. Reject any values found in Step 1. Solving Rational Inequalities Rewrite the inequality, if necessary, so that $0$ is on one side and there is a single rational expression on the other side. Determine the values that will cause either the numerator or the denominator of the rational expression to equal $0$. These values determine the intervals on the number line to consider. Use a test value from each interval to determine which intervals form the solution set. Inverse Variation When two quantities vary inversely, an increase in one quantity results in a decrease in the other.\nLet $x$ and $y$ denote two quantities and $n$ be a positive number. Then $y$ is inversely proportional to the nth power of $x$, or $y$ varies inversely with the nth power of $x$, if there exists a nonzero number $k$ such that:\n$$ \\begin{aligned} y = \\frac{k}{x^n} \\end{aligned} $$If $y = \\frac{k}{x}$, then $y$ is inversely proportional to $x$, or $y$ varies inversely with $x$.\nJoint Variation Let $m$ and $n$ be real numbers. Then $z$ varies jointly with the $n$th power of $x$ and the $m$th power of $y$ if a nonzero real number $k$ exists such that\n$$ \\begin{aligned} z = kx^ny^m \\end{aligned} $$","rational-functions-and-graphs-i#Rational Functions and Graphs (I)":"Rational Function A function $f$ of the form:\n$$ \\begin{aligned} f(x) = \\frac{p(x)}{q(x)} \\end{aligned} $$where $p(x)$ and $q(x)$ are polynomials, with $q(x) \\neq 0$, is called a rational function.\nThe Reciprocal Function The simplest rational function with a variable denominator is the reciprocal function, defined as:\n$$ \\begin{aligned} f(x) = \\frac{1}{x} \\end{aligned} $$","rational-functions-and-graphs-ii#Rational Functions and Graphs (II)":"Vertical and Horizontal Asymptotes Let $p(x)$ and $q(x)$ be polynomials. For the rational function $f(x) = \\frac{p(x)}{q(x)}$, written in lowest terms, and for real numbers $a$ and $b$,\nIf $|f(x)| \\rightarrow \\infty$ as $x \\rightarrow a$, then the line $x = a$ is a vertical asymptote If $|f(x)| \\rightarrow b$ as $x \\rightarrow \\infty$, then the line $y = b$ is a horizontal asymptote To find asymptotes of a rational function defined by a rational expression in lowest terms, use the following procedures:\nVertical asymptotes are found by determining the values of $x$ that make the denominator, but not the numerator, equal to $0$. Other asymptotes: If the numerator has lesser degree than the denominator, then there is a horizontal asymptote $y = 0$ . If the numerator and denominator have the same degree and the function is of the form: $$ \\begin{aligned} f(x) = \\frac{a_nx^n + \\cdots + a_0}{b_nx^n + \\cdots + b_0}, \\text{ where } b_n \\neq 0 \\end{aligned} $$then dividing by $x_n$ in the numberator and denominator produces de horizontal asymptote $y = \\frac{a_n}{b_n}$.\nIf the numerator is of degree exactly one greater than the denominator, then there may be an oblique (or slant) asymptote. To find it, divide the numerator by the denominator and disregard any remainder. Set the (linear) polynomial portion of the quotient equal to $y$ to find the equation of the asymptote. Graphic a Rational Function Let $f(x) = \\frac{p(x)}{q(x)}$ be a function with the rational expression in lowest terms. To sketch its graph, follow these steps.\nFind the domain and all vertical asymptotes. Find any horizontal or oblique asymptote. Find the $y$-intercept, if possible, by evaluating $f(0)$ Find the $x$-intercepts, if any, by solving $f(x) = 0$. Determine whether the graph will intersect its nonvertical asymptote $y = b$ by solving $f(x) = b$, where $b$ is the $y$-value of the horizontal asymptote, or by solving $f(x) = mx + b$, where $y = mx + b$ is the equation of the oblique asymptote. Plot selected points as necessary. Behavior of Graphs of Rational Functions Near Vertical Asymptotes Suppose that $f(x)$ is a rational expression in lowest terms. If $n$ is the largest positive integer such that $(x - a)^n$ is a factor of the denominator of $f(x)$, the graph will behave in the manner illustrated near $a$.\nBehavior of Graphs of Rational Functions Near x-Intercepts Suppose that $f(x)$ is a rational expression in lowest terms. If $n$ is the largest positive integer such that $(x - c)^n$ is a factor of the numerator of $f(x)$, the graph will behave in the manner illustrated near $c$.\nGraphs with Points of Discontinuity A rational function that has a common variable factor in the numerator and denominator is not in lowest terms. Its graph usually has a hole, or point of discontinuity."},"title":"Rational, Power and Root Functions"},"/notes/math/agaa/05_exp_functions/":{"data":{"":"","exponential-and-logarithmic-equations-and-inequalities#Exponential and Logarithmic Equations and Inequalities":"Properties of Logarithmic and Exponential Functions For $b \u003e 0$ and $b \\neq 1$:\n$b^x = b^y$ if and only if $x = y$. If $x \u003e 0$ and $y \u003e 0$, then $log_b x = log_b y$ if and only if $x = y$ Exponential Equations and Inequalities (Type 2) Unlike a Type 1 exponential equation (or inequality) a Type 2 exponential equation (or inequality) is one in which the exponential expressions cannot easily be written as powers of the same base. For example:\n$$ \\begin{aligned} 7^x = 12 \\end{aligned} $$ Solving Exponential and Logarithmic Equations An exponential or logarithmic equation can be solved by changing the equation into one of the following forms, where $a$ and $b$ are real numbers, $a \u003e 0$, and $a \\neq 1$.\n$a^{f(x)} = b$: Solve by taking a logarithm of each side. $\\log_a f(x) = \\log_a g(x)$: The equation is satisfied when $f(x) = g(x)$ $\\log_a f(x) = b$: Solve by changing to exponential form $f(x) = a^b$ ","exponential-functions#Exponential Functions":"Real-Number Exponents For any real number $a \u003e 0$, $a \\neq 1$, the following statements are true:\n$a^{x}$ is a unique real number for each real number $x$. $a^b = a^c$ if and only if $b = c$. If $a \u003e 1$ and $m \u003c n$, then $a^m \u003e a^n$. Graphs of Exponential Functions If $a \u003e 0$ and $a \\neq 1$, then:\n$$ \\begin{aligned} f(x) = a^x \\end{aligned} $$is the exponential function with base $a$.\nThe behavior of the graph of an exponential function depends, in general, on the magnitude of $a$. As a becomes larger ($a \u003e 1$), the graph becomes steeper moving to the right of the $y$-axis. (See FIGURE 16(a)).\nIf the base $a$ is between $0$ and $1$, as a gets closer to $0$, the graph becomes steeper moving to the left of the $y$-axis. (See FIGURE 16(b)).\nExponential Equations (Type 1) On the equation $25^x = 125$ the variable appears in the exponent, we refer to such an equation as a Type 1 exponential equation (this is not any type of standard naming, it is just used on this manual).","further-applications-and-modeling-with-exponential-and-logarithmic-functions#Further Applications and Modeling with Exponential and Logarithmic Functions":"Physical Science Applications A function of the form:\n$$ \\begin{aligned} A(t) = A_0 e^{kt} \\end{aligned} $$where $A_0$ represent the initial quantity present, $t$ represents the time elapsed, $k \u003e 0$ represents the growth constant is called an exponential growth function.\nA function of the form:\n$$ \\begin{aligned} A(t) = A_0 e^{-kt} \\end{aligned} $$is an exponential decay function.\nIf a quantity decays exponentially, the amount of time that it takes to reach onehalf its original amount is called the half-life.","inverse-functions#Inverse Functions":"One-to-One Functions A function $f$ is a one-to-one function if, for elements $a$ and $b$ from the domain of $f$:\n$$ \\begin{aligned} a \\neq b \\end{aligned} $$implies\n$$ \\begin{aligned} f(a) \\neq f(b) \\end{aligned} $$And by the contrapositive:\n$$ \\begin{aligned} f(a) = f(b) \\end{aligned} $$implies\n$$ \\begin{aligned} a = b \\end{aligned} $$A function that is either always increasing or always decreasing on its domain must be one-to-one.\nHorizontal Line Test A function is one-to-one if every horizontal line intersects the graph of the function at most once.\nInverse Function Let $f$ be a one-to-one function. Then $g$ is the inverse function of $f$ and $f$ is the inverse function of $g$ if:\n$$ \\begin{aligned} (f \\circ g)(x) = x \\text{ for every } x \\text{ in the domain of } g \\end{aligned} $$and\n$$ \\begin{aligned} (g \\circ x)(x) = x \\text{ for every } x \\text{ in the domain of } f \\end{aligned} $$A special notation is often used for inverse functions. If $g$ is the inverse function of $ƒ$, then $g$ can be written as $f^{-1}$ (read “f-inverse”).\nBy the definition of an inverse function, the domain of $f$ equals the range of $f^{-1}$, and the range of $f$ equals the domain of $f^{-1}$.\nFinding the Equation of the Inverse of y = ƒ(x) For a one-to-one function $f$ defined by an equation $y = f(x)$, find the defining equation of the inverse as follows. (You may need to replace $f(x)$ with $y$ first. Any restrictions on $x$ and $y$ should be considered.)\nInterchange $x$ and $y$. Solve for $y$. Replace $y$ with $f^{-1}$. Geometric Relationship between the graphs of $f$ and $f^{-1}$ If a function $f$ is one-to-one, then the graph of its inverse $f^{-1}$ is a reflection of the graph of $f$ across the line $y = x$.\nImportant Facts about Inverses If $f$ is one-to-one, then $f^{-1}$ exists The domain of $f$ is equal to the range of $f^{-1}$, and the range of $f$ is equal to the domain of $f^{-1}$. If the point $(a, b)$ lies on the graph of $f$, then $(b, a)$ lies on the graph of $f^{-1}$. The graphs of $f$ and $f^{-1}$ are reflections of each other across the line $y = x$. ","logarithms-and-their-properties#Logarithms and Their Properties":"Logarithm For all positive numbers $a$, where $a \\neq 1$,\n$$ \\begin{aligned} a^y = x \\end{aligned} $$is equivalent to\n$$ \\begin{aligned} y = \\log_a x \\end{aligned} $$The expression $\\log_a x$ represents the exponent to which the base $a$ must be raised in order to obtain $x$.\nThe number $a$ is called the base of the logarithm, and $x$ is called the argument of the expression.\nThe argument of a logarithm must be a positive number.\nCommon Logarithm Base $10$ logarithms are called common logarithms. The common logarithm of $x$ is written $log x$, where the base is understood to be $10$.\nNatural Logarithm Logarithms with base $e$ are called natural logarithms. The natural logarithm of a positive number $x$ is written $\\ln x$.\nProperties of Logarithms For $a \u003e 0$, $a \\neq q$, and any real number $k$, the following hold.\n$log_a 1 = 0$ $log_a a^k = k$ $a^{\\log_a k} = k ,k \u003e 0$ Product rule $\\log_a xy = \\log_a x + \\log_a y$ Quotient rule $\\log_a \\frac{x}{y} = \\log_a x - \\log_a y$ Power rule $\\log_a x^r = r\\log_a x$ Proofs Property $1$ is true because $a^0 = 1$ for any nonzero value of $a$.\nProperty $2$ is verified by writing the equation in exponential form. By the definition of the logarithm, if $\\log_a a^k = k$, then $a^k = a^k$, which is true.\nProperty $3$ is justified by the fact that $\\log_a k$ is the value we have to raise $a$ to obtain $k$. If we raise $a$ by $\\log_a k$, then by the definition of the logarithm we obtain $k$.\nThe proof of Property $4$, the product rule, is as follows:\nLet $m = \\log_a x$ and $n = \\log_a y$, then\n$a^m = x$ and $a^n = y$ by the definiton of a logarithm. If we multiply them:\n$$ \\begin{aligned} a^m a^n = xy \\end{aligned} $$$$ \\begin{aligned} a^{m + n} = xy \\end{aligned} $$By the definition of the logarithm:\n$$ \\begin{aligned} \\log_a xy = m + n \\end{aligned} $$Substituting $m = \\log_a x$ and $n = \\log_a y$\n$$ \\begin{aligned} \\log_a xy = \\log_a x + \\log_a y \\end{aligned} $$Properties $5$ and $6$, the quotient and power rules, are proved in a similar way\nChange-of-Base Rule For any positive real numbers $x$, $a$, and $b$, where $a \\neq 1$ and $b \\neq 1$\n$$ \\begin{aligned} \\log_a x = \\frac{\\log_b x}{\\log_b a} \\end{aligned} $$Let\n$$ \\begin{aligned} y = \\log_a x \\end{aligned} $$By the definition of the logarithm:\n$$ \\begin{aligned} a^y = x \\end{aligned} $$We apply the logarithm on both sides:\n$$ \\begin{aligned} \\log_b a^y = \\log_b x \\end{aligned} $$By the power rule:\n$$ \\begin{aligned} y \\log_b a = \\log_b x \\end{aligned} $$$$ \\begin{aligned} y = \\frac{\\log_b x}{\\log_b a} \\end{aligned} $$Substituting $y = \\log_a x$\n$$ \\begin{aligned} \\log_a x = \\frac{\\log_b x}{\\log_b a} \\end{aligned} $$","logarithms-functions#Logarithms Functions":"Logarithmic Function If $a \u003e 0$, $a \\neq 1$, and $x \u003e 0$, then\n$$ \\begin{aligned} f(x) = \\log_a x \\end{aligned} $$is the logarithmic function with base $a$.\nThe exponential function $f(x) = a^x$, $a \u003e 1$, is increasing on its domain. If $0\u003c a \u003c1$, the function is decreasing on its domain. Thus, for all allowable bases $a$, function $f$ is one-to-one and has an inverse. We can find the rule for $f^{-1}$ analytically:\n$$ \\begin{aligned} f(x) = a^x \\end{aligned} $$$$ \\begin{aligned} y = a^x \\end{aligned} $$$$ \\begin{aligned} x = a^y \\end{aligned} $$By the definition of the logarithm:\n$$ \\begin{aligned} y = \\log_a x \\end{aligned} $$$$ \\begin{aligned} f^{-1}(x) = \\log_a x \\end{aligned} $$To confirm this, use properties of logarithms to show that $(f \\circ f^{-1})(x) = x$ and $(f^{-1} \\circ f)(x) = x$.\n$$ \\begin{aligned} (f \\circ f^{-1})(x) = f(f^{-1}(x)) = a^{\\log_a x} = x \\end{aligned} $$$$ \\begin{aligned} (f^{-1} \\circ f)(x) = f^{-1}(f(x)) = \\log_a a^x = x \\end{aligned} $$Thus, the functions $f(x) = a^x$ and $g(x) = log_a x$ are inverse functions.\nGraphs of Logarithmic Functions "},"title":"Inverse, Exponential and Logarithmic Functions"},"/notes/math/agaa/06_systems/":{"data":{"":"","determinants-and-cramers-rule#Determinants and Cramer\u0026rsquo;s Rule":"Systems of Equations Linear Systems Any equation of the form:\n$$ \\begin{aligned} a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n = b \\end{aligned} $$for real numbers $a_1, a_2, \\cdots, a_n$ (not all zero) and $b$ is a linear equation or a first-degree equation in $n$ unknowns.\nA set of equations is called a system of equations. The solutions of a system of equations must satisfy every equation in the system. If all the equations in a system are linear, the system is a system of linear equations, or a linear system.\nThere are three possible outcomes for the graph of a system of two linear equations in two variables:\nThe graphs intersect at exactly one point, which gives the (single) ordered-pair solution of the system. The system is consistent and the equations are independent. (FIGURE 1a) The graphs are parallel lines, so there is no solution and the solution set is $\\emptyset$. The system is inconsistent and the equations are independent. See FIGURE 1(b). The graphs are the same line, and there are infinitely many solutions. The system is consistent and the equations are dependent. See FIGURE 1(c). Substitution Method In a system of two equations with two variables, the substitution method involves using one equation to find an expression for one variable in terms of the other, and then substituting this expression into the other equation of the system.\nSubstitution Method Another way to solve a system of two equations, the elimination method, uses multiplication and addition to eliminate a variable from one equation. Systems that have the same solution set are called equivalent systems. The three transformations allowed are the following:\nInterchange any two equations of the system. Multiply or divide any equation of the system by a nonzero real number. Replace any equation of the system by the sum of that equation and a multiple of another equation in the system. Nonlinear Systems A nonlinear system of equations is a system in which at least one of the equations is not a linear equation.\nSolutions of Linear Systems in Three Variables We can extend the ideas of systems of equations in two variables to linear equations of the form:\n$$ \\begin{aligned} Ax + By + Cz = D \\end{aligned} $$Considering the possible intersections of the planes representing three equations in three unknowns shows that the solution set of such a system may be either a single ordered triple $(x, y, z)$, an infinite set of ordered triples (dependent equations), or the empty set (an inconsistent system).\nThe following steps can be used to solve a linear system with three variables.\nEliminate a variable from any two of the equations. Eliminate the same variable from a different pair of equations. Eliminate a second variable using the resulting two equations in two variables to get an equation with just one variable. Find the values of the remaining variables by substitution. Solution of Linear Systems by Row Transformations Matrix Row Transformations For any augmented matrix of a system of linear equations, the following row transformations will result in the matrix of an equivalent system.\nAny two rows may be interchanged. The elements of any row may be multiplied by a nonzero real number. Any row may be changed by adding to its elements a multiple of the corresponding elements of another row. Row Echelon Method The echelon (triangular) form of an augmented matrix has 1s down the diagonal from upper left to lower right and 0s below each 1.\nOnce a system of linear equations is in echelon form, back-substitution can be used to find the solution set. The row echelon method uses matrices to solve a system of linear equations.\nStart by obtaining a 1 as the first entry in the first column and then transform all entries below it to a 0. Continue through the columns obtaining a 1 as the second entry in the second column (zeros below), the third entry in the third column (zeros below), and so on. Repeat this process to row echelon form. The following matrix is an augmented matrix in row echelon form:\n$$ \\begin{aligned} \\begin{bmatrix} 1 \u0026 2 \u0026 3 \u0026 4\\\\ 0 \u0026 5 \u0026 6 \u0026 7\\\\ 0 \u0026 0 \u0026 0 \u0026 9\\\\ \\end{bmatrix} \\end{aligned} $$Reduced Row Echelon Method The reduced row echelon form has 1s along the main diagonal and 0s both below and above. For example\n$$ \\begin{aligned} \\begin{bmatrix} 1 \u0026 1 \u0026 1 \u0026 6\\\\ 2 \u0026 -1 \u0026 1 \u0026 5\\\\ 3 \u0026 1 \u0026 -1 \u0026 9\\\\ \\end{bmatrix} \\end{aligned} $$By using row transformations, this augmented matrix can be transformed to\n$$ \\begin{aligned} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 3\\\\ 0 \u0026 1 \u0026 0 \u0026 2\\\\ 0 \u0026 0 \u0026 1 \u0026 1\\\\ \\end{bmatrix} \\end{aligned} $$Which represents $x = 3, y = 2, z = 1$. There is no need for back-substitution with reduced row echelon form.\nSpecial Cases Whenever a row of the augmented matrix is of the form\n$$ \\begin{aligned} \\begin{bmatrix} 0 \u0026 0 \u0026 \\cdots \u0026 a\\\\ \\end{bmatrix} \\end{aligned} $$where $a \\neq 0$ the system is inconsistent and there will be no solution.\nA row of the matrix of a linear system in the form:\n$$ \\begin{aligned} \\begin{bmatrix} 0 \u0026 0 \u0026 \\cdots \u0026 0\\\\ \\end{bmatrix} \\end{aligned} $$indicates that the equations of the system are dependent.\nMatrix Properties and Operations Matrix addition The sum of two $m \\times n$ matrices $A$ and $B$ is the $m \\times n$ matrix $A + B$ in which each element is the sum of the corresponding elements of $A$ and $B$.\nOnly matrices with the same dimension can be added.\nMultiplication of a Matrix by a Scalar The product of a scalar $k$ and a matrix $A$ is the matrix $kA$, each of whose elements is $k$ times the corresponding element of $A$.\nMatrix Multiplication The product $AB$ of an $m \\times n$ matrix $A$ and an $n \\times k$ matrix $B$ is an $m \\times k$ matrix and is found as follows.\nTo find the $i$th row, $j$th column element of $AB$, multiply each element in the $i$th row of $A$ by the corresponding element in the $j$th column of $B$. The sum of these products gives the element of row $i$, column $j$ of $AB$.\n$$ \\begin{aligned} c_{ij} = \\sum_{k=1}^{n} a_{ik}b_{kj} \\end{aligned} $$The product AB can be found only if the number of columns of A is the same as the number of rows of B. The final product will have as many rows as A and as many columns as B.\nDeterminants and Cramer’s Rule Determinants of $2 \\times 2$ matrices The determinant of a $2 \\times 2$ matrix $A$ is a real number defined as $det(A) = a_{11} a_{22}− a_{21} a_{12}$.\nDeterminants of $3 \\times 3$ matrices The determinant of a $3 \\times 3$ matrix $A$ is a real number defined as $det(A) = (a_{11}a_{22}a_{33} + a_{12} a_{23} a_{31} + a_{13} a_{21}a_{32}) − (a_{31}a_{22}a_{13} + a_{32} a_{23} a_{11} + a_{33} a_{21}a_{12})$.\nCofactor Let $M_{ij}$ be the minor for element $a_{ij}$ in an $n \\times n$ matrix. The cofactor of $a_{ij}$, written $A_{ij}$, is defined as follows.\n$$ \\begin{aligned} A_{ij} = (-1)^{i + j} \\cdot M_{ij} \\end{aligned} $$Cramer’s Rule for $2 \\times 2$ Systems The solution of the system:\n$$ \\begin{aligned} a_1x + b_1y = c_1 \\end{aligned} $$$$ \\begin{aligned} a_2x + b_2y = c_2 \\end{aligned} $$is given by:\n$$ \\begin{aligned} x = \\frac{D_x}{D}, y = \\frac{D_y}{D} \\end{aligned} $$where:\n$$ \\begin{aligned} D_x = det( \\begin{bmatrix} c_1 \u0026 b_1 \\\\ c_2 \u0026 b_2 \\\\ \\end{bmatrix}) \\end{aligned} $$$$ \\begin{aligned} D_y = det( \\begin{bmatrix} a_1 \u0026 c_1 \\\\ a_2 \u0026 c_2 \\\\ \\end{bmatrix}) \\end{aligned} $$$$ \\begin{aligned} D = det( \\begin{bmatrix} a_1 \u0026 b_1 \\\\ a_2 \u0026 b_2 \\\\ \\end{bmatrix}) \\neq 0 \\end{aligned} $$","matrix-properties-and-operations#Matrix Properties and Operations":"","partial-fractions#Partial Fractions":"Decomposition of Rational Expressions Partial Fraction Decomposition of $\\frac{f(x)}{g(x)}$ If $\\frac{f(x)}{g(x)}$ is not a proper fraction (a fraction whose numerator is lesser degree than it denominator) divide $f(x)$ by $g(x)$. For example $$ \\begin{aligned} \\frac{x^4 - 3x^3 + x^2 + 5x}{x^2 + 3} = x^2 - 3x - 2 + \\frac{14x + 6}{x^2 + 3} \\end{aligned} $$Then appy the following steps to the remainder.\nFactor the denominator $g(x)$ into factors of the form $(ax + b)^m$ or $(cx^2 + dx + e)^n$. For each distinct linear factor $(ax + b)$, the decomposition must include the term \\frac{A}{ax + b}. For each repeated linear factor $(ax + b)^m$, the decomposition must include the terms: $$ \\begin{aligned} \\frac{A_1}{(ax + b)} + \\frac{A_2}{(ax + b)^2} + \\cdots + \\frac{A_m}{(ax + b)^m} \\end{aligned} $$ For each distinct quadratic factor $(cx^2 + dx + e)$, the decomposition must include the term $\\frac{Bx + C}{cx2 + dx + e}$ For each repeated quadratic factor $(cx^2 + dx + e)^n$, the decomposition must include the terms: $$ \\begin{aligned} \\frac{B_1x + C_1}{(cx^2 + dx + e)} + \\frac{B_2x + C_2}{(cx^2 + dx + e)^2} + \\cdots + \\frac{B_nx + C_n}{(cx^2 + dx + e)^n} \\end{aligned} $$ Use algebraic techniques to solve for the constants in the numerators of the decomposition. Techniques for Decomposition into Partial Fractions For Linear Factors Multiply each side of the resulting rational equation by the common denominator. Substitute the zero of each factor into the resulting equation. For repeated linear factors, substitute as many other numbers as is necessary to find all the constants in the numerators. The number of substitutions required will equal the number of constants $A, B, \\cdots$. For example:\n$$ \\begin{aligned} \\frac{f(x)}{(x-1)(x-2)} = \\frac{A}{(x-1)} + \\frac{B}{(x - 2)} = \\frac{A(x-2) + B(x-1)}{(x-2)(x-1)} \\end{aligned} $$Multiply both sides by $(x-1)(x-2)$:\n$$ \\begin{aligned} f(x) = A(x-2) + B(x-1) \\end{aligned} $$Solve for $x = 2$:\n$$ \\begin{aligned} f(2) = A(0) + B(1) \\end{aligned} $$And then solve for $x = 1$:\n$$ \\begin{aligned} f(1) = A(-1) + B(0) \\end{aligned} $$For Quadratic Factors Multiply each side of the resulting rational equation by the common denominator. Collect terms on the right side of the equation. Equate the coefficients of like terms to get a system of equations. Solve the system to find the constants in the numerators. For example:\n$$ \\begin{aligned} \\frac{x^2 + 3x - 1}{(x + 1)(x^2 + 2)} = \\frac{A}{(x + 1)} + \\frac{Bx + C}{(x^2 + 2)} \\end{aligned} $$Multiply each side by $(x + 1)(x^2 + 2)$:\n$$ \\begin{aligned} x^2 + 3x - 1 = A(x^2 + 2) + (Bx + C)(x + 1) \\end{aligned} $$Collect the terms on each side of the equation:\n$$ \\begin{aligned} x^2 + 3x - 1 = Ax^2 + A2 + Bx^2 + Bx + Cx + C = x^2 (A + B) + x (B + C) + 2A + C \\end{aligned} $$Equate the coefficients of like terms to get a system of equations:\n$$ \\begin{aligned} (A + B) = 1 \\end{aligned} $$$$ \\begin{aligned} (B + C) = 3 \\end{aligned} $$$$ \\begin{aligned} 2A + C = -1 \\end{aligned} $$Solving this system for $A$, $B$, and $C$ would give the partial fraction decomposition.","solution-of-linear-systems-by-matrix-inverses#Solution of Linear Systems by Matrix Inverses":"Multiplicative Inverses of Square Matrices In a similar way, if $A$ is an $n \\times n$ matrix, then its multiplicative inverse, written $A^{-1}$, must satisfy both:\n$$ \\begin{aligned} AA^{-1} = A^{-1}A = I_n \\end{aligned} $$This result means that only a square matrix can have a multiplicative inverse.\nThe inverse matrix of an $n \\times n$ matrix $A$ (if it exists) can be found analytically by first forming the augmented matrix $[A|I_n]$ such that $Ax = I_n$, thus $x = A^{-1}$.\nThis means you are solving $n$ systems of linear equations of the form $Ax_i = I_{n_i}$.\nThis system is solved by performing matrix row operations, until the left side of the augmented matrix becomes the identity matrix.\nThe resulting augmented matrix can be written as $[I_n|A^{-1}]$, where the right side of the matrix is $A^{-1}$.\nIf $A^{-1}$ exists, then it is unique. If $A^{-1}$ does not exist, then $A$ is a singular matrix.\nUsing Determinants to Find Inverses If\n$$ \\begin{aligned} A = \\begin{bmatrix} a \u0026 b \\\\ c \u0026 d \\end{bmatrix} \\end{aligned} $$and $det(A) \\neq 0$ then\n$$ \\begin{aligned} A^{-1} = \\frac{1}{det(A)}\\begin{bmatrix} d \u0026 -b \\\\ -c \u0026 a \\end{bmatrix} \\end{aligned} $$If $det(A) = 0$, then $A^{−1}$ does not exist and $A$ is a singular matrix.\nSolving Linear Systems Using Inverse Matrices To solve the matrix equation $AX = B$, first see if $A^{-1}$ exists. Assuming that it does, use the facts that $A^{-1}A = I$ and $IX = X$.\n$$ \\begin{aligned} AX = B \\end{aligned} $$$$ \\begin{aligned} A^{-1}(AX) = A^{-1}B \\end{aligned} $$$$ \\begin{aligned} (A^{-1}A)X = A^{-1}B \\end{aligned} $$$$ \\begin{aligned} IX = A^{-1}B \\end{aligned} $$$$ \\begin{aligned} X = A^{-1}B \\end{aligned} $$","solution-of-linear-systems-by-row-transformations#Solution of Linear Systems by Row Transformations":"","solutions-of-linear-systems-in-three-variables#Solutions of Linear Systems in Three Variables":"","systems-of-equations#Systems of Equations":"","systems-of-inequalities-and-linear-programming#Systems of Inequalities and Linear Programming":"Solving Linear Inequalities A linear inequality in two variables is an inequality of the form\n$$ \\begin{aligned} Ax + By \\leq C, \\end{aligned} $$where $A$, $B$, and $C$ are real numbers with $A$ and $B$ not both equal to $0$. (The symbol $\\leq$ be replaced with $\\geq$, $\u003e$ or $\u003c$).\nGraphing a Linear Inequality Graph $x + 4y 7 \u003e 4$.\nThe boundary here is the line $x + 4y = 4$. Since the points on this line do not satisfy $x + 4y = 4$, make the line dashed. To decide which half plane represents the solution, solve for $y$. Such that $y \u003e -\\frac{1}{4}x + 1$ Since $y$ is greater than $-\\frac{1}{4}x + 1$, the graph of the solution set is the half plane above the boundary Two Methods for Graphing an Inequality For a function $f$, the graph of $y \u003c f(x)$ consists of all the points that are below the graph of y = ƒ(x). The graph of $y \u003e f(x)$ consists of all the points that are above the graph of $y = f(x)$.\nIf the inequality is not or cannot be solved for $y$, choose a test point not on the boundary. If the test point satisfies the inequality, the graph includes all points on the same side of the boundary as the test point. Otherwise, the graph includes all points on the other side of the boundary.\nSoliving Systems of Inequalitites The solution set of a system of inequalities is the intersection of the solution sets of its members\nGraph the solution set of the system.\n$$ \\begin{aligned} x \u003e 6 - 2y \\end{aligned} $$$$ \\begin{aligned} x^2 \u003c 2y \\end{aligned} $$The next figures show the graphs for both inequalities as well as the solution set, that is the intersection of the regions that represent the solution set for each inequality.\nLinear Programming We use linear programming to find an optimum value. A linear programming problem typically needs the definition of the following concepts:\nThe restrictions of the problem, usually a system of inequalitites, that conform the constraints. An objetive function, which is the function we aim to optimize. The region of feasible solutions that is the set of values for $x$ and $y$ that satisfy all constraints. Fundamental Theorem of Linear Programming If the optimal value for a linear programming problem exists, it occurs at a vertex of the region of feasible solutions.\nSolving a Linear Programming Problem Write the objective function and all necessary constraints. Graph the region of feasible solutions. Identify all vertices (corner points). Evaluate the objective function at each vertex. The solution is given by the vertex producing the optimal value of the objective function. "},"title":"Systems and Matrices"},"/notes/math/agaa/07_analytic_geometry/":{"data":{"":"","circles-and-parabolas#Circles and Parabolas":"Conic Sections Parabolas, circles, ellipses, and hyperbolas form a group of curves known as the conic sections, because they are the result of intersecting a cone with a plane.\nCircle A circle is a set of points in a plane that are equidistant from a fixed point. The distance is called the radius of the circle, and the fixed point is called the center.\nSuppose a circle has center $(h, k)$ and radius $r \u003e 0$. Then the distance between the center $(h, k)$ and any point $(x, y)$ on the circle must equal $r$. Thus, an equation of the circle is as follows:\n$$ \\begin{aligned} \\sqrt{(x - h)^2 + (y - k)^2} = r \\end{aligned} $$$$ \\begin{aligned} (x - h)^2 + (y - k)^2 = r^2 \\end{aligned} $$Therefore the center–radius form of the equation of a circle with center $(h, k)$ and radius $r$ is:\n$$ \\begin{aligned} (x - h)^2 + (y - k)^2 = r^2 \\end{aligned} $$Notice that a circle is the graph of a relation that is not a function.\nA circle with center $(0, 0)$ and radius $r$ has equation:\n$$ \\begin{aligned} x^2 + y^2 = r^2 \\end{aligned} $$General Form of the Equation of a Circle For real numbers $c$, $d$, and $e$, the equation:\n$$ \\begin{aligned} x^2 + y^2 + cx + dy + e = 0 \\end{aligned} $$can have a graph that is a circle, that is a point, or that is empty (contains no points.)\nStarting with an equation in this general form, we can work in reverse by completing the square to get an equation of the form:\n$$ \\begin{aligned} (x - h)^2 + (y - k)^2 = m \\text{ for some } m \\end{aligned} $$There are three possibilities for the graph, based on the value of $m$:\nIf $m \u003e 0$, then $r^2 = m$, and the equation represents a circle with radius $\\sqrt{m}$. If $m = 0$, the equation represents the single point $(h, k)$. If $m \u003c 0$, no points satisfy the equation and the graph is empty. Parabola A parabola is a set of points in a plane equidistant from a fixed point and a fixed line. The fixed point is called the focus, and the fixed line the directrix, of the parabola.\nWe can find an equation of a parabola from the preceding definition. Let the directrix be the line $y = -c$ and the focus be the point $F$ with coordinates $(0, c)$. Given a point $P$ on the parabola, with coordinates $(x, y)$, using the distance formula gives the following result:\n$$ \\begin{aligned} d(P, F) = d(P, D) \\end{aligned} $$$$ \\begin{aligned} \\sqrt{(x - 0)^2 + (y - c)^2} = \\sqrt{(x - x)^2 + [y - (-c)]^2} \\end{aligned} $$$$ \\begin{aligned} x^2 + (y - c)^2 = [y +c]^2 \\end{aligned} $$$$ \\begin{aligned} x^2 + (y - c)^2 = (y + c)^2 \\end{aligned} $$$$ \\begin{aligned} x^2 + y^2 + c^2 - 2cy = y^2 + c^2 + 2cy \\end{aligned} $$$$ \\begin{aligned} x^2 = 4cy \\end{aligned} $$ The focal chord through the focus and perpendicular to the axis of symmetry of a parabola is called the latus rectum, and has length $|4c|$.\nTo see this, note in the previous image that the endpoints of the chord are $(-x, c)$ and $(x, c)$. Let $y = c$ in the equation of the parabola and solve for $x$.\n$$ \\begin{aligned} x^2 = 4cy \\end{aligned} $$$$ \\begin{aligned} x^2 = 4c^2 \\end{aligned} $$$$ \\begin{aligned} x = |2c| \\end{aligned} $$The length of half the focal chord is |2c| (from x = 0 to x = 2c or x = -2c) , so its full length is |4c|.\nParabola with a Horizontal Axis and Vertex $(0, 0)$ The parabola with focus $(c, 0)$ and directrix $x = -c$ has equation:\n$$ \\begin{aligned} y^2 = 4cx \\end{aligned} $$The parabola has vertex $(0, 0)$, horizontal axis $y = 0$, and opens to the right if $c \u003e 0$ or to the left if $c \u003c 0$.\nNotice that the graph of a parabola with a horizontal axis is not a function.\nEquation Forms for Translated Parabolas A parabola with vertex $(h, k)$ has an equation of the form:\nVertical axis:\n$$ \\begin{aligned} (x - h)^2 = 4c(y - k) \\end{aligned} $$Horizontal axis:\n$$ \\begin{aligned} (y - k)^2 = 4c(x - h) \\end{aligned} $$where the focus is a distance $|c|$ from the vertex:","ellipses-and-hyperbolas#Ellipses and Hyperbolas":"Ellipse An ellipse is the set of all points in a plane, the sum of whose distances from two fixed points is constant. Each fixed point is called a focus (plural, foci) of the ellipse.\nAn ellipse has two axes of symmetry: the major axis (the longer one) and the minor axis (the shorter one). The foci are always located on the major axis. The midpoint of the major axis is the center of the ellipse, and the endpoints of the major axis are the vertices of the ellipse.\nA chord through a focus and perpendicular to the major axis is called a latus rectum. The graph of an ellipse is not the graph of a function.\nGiven an ellipse with center at the origin, foci $F(c, 0)$ and $F′(-c, 0)$, and vertices $V(a, 0)$ and $V′(-a, 0)$. From the previous image we know that the distance from $V$ to $F$ is $a - c$ and the distance from $V$ to $F′$ is $a + c$. The sum of these distances is $2a$. Since $V$ is on the ellipse, all othe points must satisfy this distance, such that for any point $P(x, y)$ on the ellipse:\n$$ \\begin{aligned} d(P, F) + d(P, F') = 2a \\end{aligned} $$$$ \\begin{aligned} \\sqrt{(x - c)^2 + y^2} + \\sqrt{(x + c)^2 + y^2} = 2a \\end{aligned} $$$$ \\begin{aligned} \\sqrt{(x - c)^2 + y^2} = 2a - \\sqrt{(x + c)^2 + y^2} \\end{aligned} $$We now square each side:\n$$ \\begin{aligned} (x - c)^2 + y^2 = 4a^2 - 4a\\sqrt{(x + c)^2 + y^2} + (x + c)^2 + y^2 \\end{aligned} $$$$ \\begin{aligned} x^2 + c^2 - 2xc + y^2 = 4a^2 - 4a\\sqrt{(x + c)^2 + y^2} + x^2 + c^2 + 2xc + y^2 \\end{aligned} $$$$ \\begin{aligned}\n4xc = 4a^2 - 4a\\sqrt{(x + c)^2 + y^2} \\end{aligned} $$ $$ \\begin{aligned}\nxc = a^2 - a\\sqrt{(x + c)^2 + y^2} \\end{aligned} $$ $$ \\begin{aligned} xc + a^2 = a\\sqrt{(x + c)^2 + y^2} \\end{aligned} $$We square both sides again:\n$$ \\begin{aligned} (xc + a^2)^2 = a^2\\left((x + c)^2 + y^2\\right) \\end{aligned} $$$$ \\begin{aligned} x^2c^2 + a^4 + 2xca^2 = a^2\\left(x^2 + c^2 + 2xc + y^2\\right) \\end{aligned} $$$$ \\begin{aligned} x^2c^2 + a^4 + 2xca^2 = a^2x^2 + a^2c^2 + 2xca^2 + a^2y^2 \\end{aligned} $$$$ \\begin{aligned} x^2c^2 + a^4 = a^2x^2 + a^2c^2 + a^2y^2 \\end{aligned} $$$$ \\begin{aligned} x^2c^2 - a^2x^2 - a^2y^2 = - a^4 + a^2c^2 \\end{aligned} $$$$ \\begin{aligned} x^2(c^2 - a^2)- a^2y^2 = a^2 (-a^2 + c^2) \\end{aligned} $$We multiply both sides by $-1$:\n$$ \\begin{aligned} x^2(a^2 - c^2) + a^2y^2 = a^2 (a^2 - c^2) \\end{aligned} $$We divide both sides by $a^2(a^2 - c^2)$:\n$$ \\begin{aligned} \\frac{x^2}{a^2} + \\frac{y^2}{(a^2 - c^2)} = 1 \\end{aligned} $$Which gives us the standard form equation for the ellipse with center on the origin, vertices $(\\pm a, 0)$ and foci $(\\pm c, 0)$.\nSince $B(0, b)$ is on the ellipse, then:\n$$ \\begin{aligned} d(B, F) + d(B + F') = 2a \\end{aligned} $$$$ \\begin{aligned} \\sqrt{(-c)^2 + b^2} + \\sqrt{c^2 + b^2} = 2a \\end{aligned} $$$$ \\begin{aligned} 2\\sqrt{c^2 + b^2} = 2a \\end{aligned} $$We square both sides\n$$ \\begin{aligned} 4(c^2 + b^2) = 4a^2 \\end{aligned} $$$$ \\begin{aligned} c^2 + b^2 = a^2 \\end{aligned} $$$$ \\begin{aligned} b^2 = a^2 - c^2 \\end{aligned} $$Therefore, by sustuting on the ellipse formula we obtain:\n$$ \\begin{aligned} \\frac{x^2}{a^2} + \\frac{y^2}{b^2} = 1 \\end{aligned} $$Standard Forms of Equations for Ellipses The ellipse with center at the origin and equation:\n$$ \\begin{aligned} \\frac{x^2}{a^2} + \\frac{y^2}{b^2} = 1, (a \u003e b \u003e 0) \\end{aligned} $$ has vertices $(\\pm a, 0)$, endpoints of the minor axis $(0, \\pm b)$ and foci $(\\pm c, 0)$ where $c^2 = a^2 - b^2$\nThe ellipse with center at the origin and equation\n$$ \\begin{aligned} \\frac{x^2}{b^2} + \\frac{y^2}{a^2} = 1, (a \u003e b \u003e 0) \\end{aligned} $$ has vertices $(0, \\pm a)$, endpoints of the minor axis $(\\pm b, 0)$ and foci $(0, \\pm c)$ where $c^2 = a^2 - b^2$\nTranslations of Ellipses An ellipse with center at $(h, k)$ where $b^2 = a^2 - c^2$ with $a \u003e b \u003e 0$ and $c \u003e 0$ satisfies one of the following equations:\nMajor axis: horizontal, foci $(h \\pm c, k)$ and vertices $(h \\pm a, k)$: $$ \\begin{aligned} \\frac{(x - h)^2}{a^2} + \\frac{(y - k)^2}{b^2} = 1 \\end{aligned} $$ Major axis: vertical, foci $(h, k \\pm c)$ and vertices $(h, k \\pm a)$: $$ \\begin{aligned} \\frac{(x - h)^2}{b^2} + \\frac{(y - k)^2}{a^2} = 1 \\end{aligned} $$Hyperbola A hyperbola is the set of all points in a plane such that the absolute value of the difference of the distances from two fixed points is constant. The two fixed points are called the foci of the hyperbola.\nSuppose a hyperbola has center at the origin and foci at $F’(- c, 0)$ and $F(c, 0)$. The midpoint of the segment $F′F$ is the center of the hyperbola, and the points $V’(- a, 0)$ and $V(a, 0)$ are the vertices of the hyperbola. The line segment V’V is the transverse axis of the hyperbola.\nA chord through a focus and perpendicular to an extension of the transverse axis is a latus rectum.\nStandard Forms of Equations for Hyperbolas The hyperbola with center at the origin and equation\n$$ \\begin{aligned} \\frac{x^2}{a^2} - \\frac{y^2}{b^2} = 1 \\end{aligned} $$ has vertices $(\\pm a, 0)$, asymptotes $y = \\pm \\frac{b}{a}x$ and foci $(\\pm c, 0)$ where $c^2 = a^2 + b^2$.\nThe hyperbola with center at the origin and equation\n$$ \\begin{aligned} \\frac{y^2}{a^2} - \\frac{x^2}{b^2} = 1 \\end{aligned} $$ has vertices $(0, \\pm a)$, asymptotes $y = \\pm \\frac{a}{b}x$ and foci $(0, \\pm c)$ where $c^2 = a^2 + b^2$.\nTo explain the concept of asymptotes, we can start with the first equation for a hyperbola, where the foci are on the x-axis, and solve for $y$:\n$$ \\begin{aligned} \\frac{x^2}{a^2} - \\frac{y^2}{b^2} = 1 \\end{aligned} $$$$ \\begin{aligned} \\frac{y^2}{b^2} = \\frac{x^2}{a^2} - 1 \\end{aligned} $$$$ \\begin{aligned} \\frac{y^2}{b^2} = \\frac{x^2 - a^2}{a^2} \\end{aligned} $$$$ \\begin{aligned} \\frac{y}{b} = \\pm \\frac{1}{a} \\sqrt{x^2 - a^2} \\end{aligned} $$$$ \\begin{aligned} y = \\pm \\frac{b}{a} \\sqrt{x^2 - a^2} \\end{aligned} $$$$ \\begin{aligned} y = \\pm \\frac{b}{a} \\frac{x}{x} \\sqrt{x^2 - a^2} \\end{aligned} $$$$ \\begin{aligned} y = \\pm \\frac{b}{a} x \\sqrt{\\frac{x^2 - a^2}{x^2}} \\end{aligned} $$$$ \\begin{aligned} y = \\pm \\frac{b}{a} x \\sqrt{\\frac{x^2}{x^2} - \\frac{a^2}{x^2}} \\end{aligned} $$$$ \\begin{aligned} y = \\pm \\frac{b}{a} x \\sqrt{1 - \\frac{a^2}{x^2}} \\end{aligned} $$So when $x \\rightarrow \\infty$ we know that $\\frac{a^2}{x^2} \\rightarrow 0$ and thus:\n$$ \\begin{aligned} y = \\pm \\frac{b}{a} x \\sqrt{1} \\end{aligned} $$$$ \\begin{aligned} y = \\pm \\frac{b}{a} x \\end{aligned} $$Which defines the asymptotes of the hyperbola. The lines are the extended diagonals of the rectangle whose vertices are $(a, b)$, $(- a, b)$, $(a, - b)$, and $(- a, - b)$. This rectangle is called the fundamental rectangle of the hyperbola.\nIf the foci are on the y-axis the hyperbola is defined as follows:\n$$ \\begin{aligned} y = \\pm \\frac{a}{b} x \\end{aligned} $$Translations of Hyperbolas A hyperbola with center $(h, k)$, where $c^2 = a^2 + b^2$ is defined in one of two ways:\nTraverse axis is horizontal, vertices are $(h \\pm a, k)$, foci are $(h \\pm c, k)$ and asymptotes are $y = \\pm \\frac{b}{a}(x - h) + k$ $$ \\begin{aligned} \\frac{(x - h)^2}{a^2} - \\frac{(y - k)^2}{b^2} = 1 \\end{aligned} $$ Traverse axis is verticsl, vertices are $(k, h \\pm a)$, foci are $(k, h \\pm c)$ and asymptotes are $y = \\pm \\frac{a}{b}(x - h) + k$ $$ \\begin{aligned} \\frac{(y - k)^2}{a^2} - \\frac{(x - h)^2}{b^2} = 1 \\end{aligned} $$","parametric-equations#Parametric Equations":"Graphing a Parabola Defined Parametrically Graph the plane curve $x = t^2, y = 2t + 3$ for $t \\in [-3, 3]$.\nMake a table of corresponding values of $t$, $x$, and $y$ over the domain of $t$.\n$t$ $x$ $y$ $-3$ $9$ $-3$ $-2$ $4$ $-1$ $-1$ $1$ $1$ $0$ $0$ $3$ $1$ $1$ $5$ $2$ $4$ $7$ $3$ $9$ $9$ Then plot the points.\nTo find an equivalent rectangular equation, we eliminate the parameter $t$.\n$$ \\begin{aligned} y = 2t + 3 \\end{aligned} $$$$ \\begin{aligned} y - 3 = 2t \\end{aligned} $$$$ \\begin{aligned} \\frac{y - 3}{2} = t \\end{aligned} $$Now we substitute the result in the first equation $x = t^2$:\n$$ \\begin{aligned} x = t^2 = \\left(\\frac{y - 3}{2}\\right)^2 = \\frac{(y - 3)^2}{4} = \\frac{1}{4}(y-3)^2 \\end{aligned} $$This is indeed an equation of a horizontal parabola that opens to the right.\nBecause $t$ is in $[3, -3]$, $x$ is in $[3, 0]$, and $y$ is in $[-3, 9]$. The rectangular equation must be given with its restricted domain as:\n$$ \\begin{aligned} x = \\frac{1}{4}(y-3)^2, \\text{ for } x \\in [0, 9] \\end{aligned} $$","the-conic-sections-and-nonlinear-systems#The Conic Sections and Nonlinear Systems":"Characteristics The conic sections in this chapter have equations that can be written in the form:\n$$ \\begin{aligned} Ax^2 + Dx + Cy^2 + Ey + F = 0 \\end{aligned} $$where either $A$ or $C$ must be nonzero.\nThe special characteristics of each conic section are summarizeed in the following table.\nThe chart summarizes our work with conic sections:\nEccentricity A conic is the set of all points $P(x, y)$ in a plane such that the ratio of the distance from $P$ to a fixed point and the distance from $P$ to a fixed line is constant.\nThe constant ratio is called the ecccentricity of the conic, written $e$.\nParabola If the conic is a parabola, then by definition, the distances $d(P, F)$ and $d(P, D)$ are equal, thus every parabola has eccentricity $1$.\nEllipse For an ellipse, eccentricity is a measure of its “roundness”. The constant ratio in the definition is $e = \\frac{c}{a}$, where $c$ is the distance from the center of the figure to a focus and $a$ is the distance from the center to a vertex.\nBy the definition of an ellipse, $a^2 \u003e b^2$ and $c = \\sqrt{a^2 - b^2}$. Thus, for the ellipse:\n$$ \\begin{aligned} 0 \u003c c \u003c a \\end{aligned} $$Divide by $a$:\n$$ \\begin{aligned} 0 \u003c \\frac{c}{a} \u003c 1 \\end{aligned} $$Where $e = \\frac{c}{a}$:\n$$ \\begin{aligned} 0 \u003c e \u003c 1 \\end{aligned} $$ Circle In the circle the foci coincide with the center such that $a = b$ and $c = \\sqrt{a^2 - b^2} = 0$ and therefore $e = \\frac{c}{a} = 0$.\nHyperbola The hyperbola also has eccentricity $e = \\frac{c}{a}$. By definition $c = \\sqrt{a^2 + b^2} \u003e a$, so:\n$$ \\begin{aligned} 0 \u003c a \u003c c \\end{aligned} $$Divide by $a$:\n$$ \\begin{aligned} 0 \u003c 1 \u003c \\frac{a}{c} \\end{aligned} $$$$ \\begin{aligned} 0 \u003c 1 \u003c e \\end{aligned} $$Therefore $e \u003e 1$. Such that narrow hyperbolas have $e$ near $1$ and wide hyperbolas have a large value of $e$.\nNonlinear Systems A nonlinear system of equations can have any number of solutions."},"title":"Analytic Geometry and Nonlinear Systems"},"/notes/math/agaa/08_trigonometry/":{"data":{"":"","angles-and-their-measures#Angles and Their Measures":"Basic Terminology Two distinct points $A$ and $B$ determine a line called line $AB$. The portion of the line between $A$ and $B$, including points $A$ and $B$, is segment $AB$. The portion of line $AB$ that starts at $A$ and continues through $B$ and on past $B$ is called ray $AB$. Point $A$ is the endpoint of the ray.\nIn trigonometry, an angle consists of two rays in a plane with a common endpoint, or two line segments with a common endpoint. These two rays (or segments) are called the sides of the angle and the common endpoint is called the vertex of the angle.\nAssociated with an angle is its measure, generated by a rotation about the vertex. This measure is determined by rotating a ray starting at one side of the angle, called the initial side, to the position of the other side, called the terminal side.\nA counterclockwise rotation generates an angle with positive measure, while a clockwise rotation generates an angle with negative measure.\nDegree Measure The most common unit used to measure the size of angles is the degree. We assign $360$ degrees to a complete rotation of a ray.\nAn angle measuring between $0$° and $90$° is an acute angle. An angle measuring exactly $90$° is a right angle. An angle measuring more than $90$° but less than $180$° is an obtuse angle, and an angle of exactly $180$° is a straight angle.\nIf the sum of the measures of two positive angles is $90°$, the angles are called complementary and the angles are complements. Two positive angles with measures whose sum is $180°$ are supplementary and the angles are supplements.\nOne minute, written $1’$, is $\\frac{1}{60}$ of a degree and one second, $1’’$, is $\\frac{1}{60}$ of a minute.However angles are commonly measured in decimal degrees.\nStandard Position and Coterminal Angles An angle is in standard position if its vertex is at the origin and its initial side is along the positive x-axis. The angles in (a) and (b) are in standard position.\nAn angle in standard position is said to lie in the quadrant in which its terminal side lies, such as angles with measures $90°$, $180°$, $270°$, and so on, are called quadrantal angles. If the terminal side lies along an axis, then the angle does not lie in any quadrant. For example, an acute angle is in quadrant I (a) and an obtuse angle is in quadrant II (b).\nThe angles whose measures differ by a multiple of $360º$ are called coterminal angles.\nRadian Measure An angle with vertex at the center of a circle that intercepts an arc on the circle equal in length to the radius of the circle has measure $1$ radian.\nAn angle $\\theta$ whose vertex is at the center of a circle is called central angle.\nIn general, if $\\theta$ is a central angle in a circle of radius $r$, and $\\theta$ intercepts an arc of lengt $s$, the radian measure of $\\theta$ is $\\frac{s}{r}$.\nDegree to Radian Conversion We know that the circumference of a circle is given by $C = 2\\pi r$, where $r$ is the radius. This shows that the radius can be laid $2\\pi$ times around the circle.\nTherefore, an angle of $360°$, which corresponds to a complete circle, intercepts an arc equal in length to $2\\pi$ times the radius of the circle. Thus, an angle of $360º$ has measure $2\\pi$.\n$$ \\begin{aligned} 360º = 2\\pi \\text{ radians} \\end{aligned} $$ To convert a degree measure to radians multiply the degree measure by $\\frac{2\\pi}{360} = \\frac{\\pi}{180}$ To convert a radian measure to degrees multiply the radian measure by $\\frac{360}{2\\pi} = \\frac{180}{\\pi}$ Arc Lengths and Areas of Sectors In the following figure angle $QOP$ has measure $1$ radian and intercepts an arc of length $r$. While angle $ROT$ has measure $\\theta$ radians and intercepts an arc of length $s$.\nSince the lengths of the arcs are proportional to the measures of their central angles:\n$$ \\begin{aligned} \\frac{s}{r} = \\frac{\\theta}{1} \\end{aligned} $$$$ \\begin{aligned} s = r\\theta \\end{aligned} $$A sector of a circle is the portion of the interior of a circle intercepted by a central angle.\nThe interior of a circle can be thought of as a sector intercepted by a central angle of measure $2\\pi$ radians.\nIf a central angle for a sector has measure $\\theta$ radians, then the sector makes up the fraction $\\frac{\\theta}{2\\pi}$ of a complete circle. The area inside a circle with radius $r$ is $\\mathcal{A} = \\pi r^2$, Therefore, the area of the sector is given by the product of the fraction $\\frac{\\theta}{2\\pi}$ and the total area:\n$$ \\begin{aligned} \\mathcal{A} = \\frac{\\theta}{2\\pi}(\\pi r^2) = \\frac{1}{1}r^2 \\theta, \\theta \\text{ in radians} \\end{aligned} $$Linear and Angular Speed Suppose that point $P$ moves at a constant speed along a circle of radius $r$ and center $O$.\nThe measure of how fast the position of $P$ is changing is called linear speed. If $v$ represents linear speed, then:\n$$ \\begin{aligned} v = \\frac{s}{t} \\end{aligned} $$where $s$ is the length of the arc traced by point $P$ in time $t$. (This formula is just a restatement of $d = rt$ with $s$ as distance, $v$ as rate (speed), and $t$ as time.)\nAs point $P$ moves along the circle, ray $OP$ rotates around the origin, so the speed at which the measure ofthe angle changes is called angular speed, $\\omega$ and is given by:\n$$ \\begin{aligned} \\omega = \\frac{\\theta}{t}, \\theta \\text{ in radians} \\end{aligned} $$where $\\theta$ is the measure of angle $POB$.\nTo relate linear and angular speeds we use the result $s = r\\theta$, therefor:\n$$ \\begin{aligned} v = \\frac{s}{t} = \\frac{r\\theta}{t} = r \\frac{\\theta}{t} = r \\omega \\end{aligned} $$Appendix Latitude gives the measure of a central angle with vertex at Earth’s center whose initial side goes through the equator and whose terminal side goes through the given location (basically like north-south orientation).","applications-of-right-triangles#Applications of Right Triangles":"Solving Triangles To solve a triangle means to find the measures of all the angles and sides of the triangle.\nAngles of Elevation or Depression The angle of elevation from point $X$ to point $Y$ (above $X$) is the acute angle formed by ray $XY$ and a horizontal ray with endpoint at $X$ (see FIGURE 61).\nThe angle of depression from point $X$ to point $Y$ (below $X$) is the acute angle formed by ray $XY$ and a horizontal ray with endpoint $X$ (see FIGURE 62).\nBearing When a single angle is given, such as $164°$, it is understood that the bearing is measured in a clockwise direction from due north (see FIGURE 64).\nThe second method for expressing bearing starts with a north–south line and uses an acute angle to show the direction, either east or west, from this line (see FIGURE 66).","graphs-of-the-other-circular-functions#Graphs of the Other Circular Functions":"Graphs of the Secant and Cosecant Functions The secant function is undefined for odd multiples of $\\frac{\\pi}{2}$ and has vertical asymptotes for such values. Furthermore, since $\\sec (-x) = \\sec x$, the secant function is even and its graph is symmetric with respect to the y-axis.\nFIGURE 100 shows how the graphs of $y = \\cos x$ and $y = \\sec x$ are related\nThe vertical asymptotes of the cosecant function are at $x$-values that are integer multiples of $\\pi$. Because $\\csc (-x) = -\\csc x$, the cosecant function is odd and its graph is symmetric with respect to the origin.\nFIGURE 102 shows how the graphs of $y = \\sin x$ and $y = \\csc x$ are related.\nGuidelines for Sketching Graphs of the Secant and Cosecant Functions\nTo graph $y = a \\sec bx$ or $y = a \\csc bx$, with $b \u003e 0$, follow these steps:\nGraph the reciprocal function as a guide. For $y = a \\sec bx$, graph $y = a \\cos bx$ For $y = a \\csc bx$, graph $y = a \\sin bx$ Sketch the vertical asymptotes with equations $x = k$, where $(k, 0)$ is an $x$-intercept of the graph of the guide function. Sketch the graph of the desired function by drawing the typical U-shaped branches between the adjacent asymptotes. The branches will be above the graph of the guide function when the guide function values are positive and below the graph of the guide function when the guide function values are negative. Graphs of the Tangent and Cotangent Functions The tangent function is undefined for odd multiples of $\\frac{\\pi}{2}$ and has vertical asymptotes for such values. Furthermore, since $\\tan (-x) = -\\tan x$, the tangent function is odd and its graph is symmetric with respect to the origin.\nThe tangent function has period $\\pi$. Because $\\tan x = \\frac{\\sin x}{\\cos x}$, tangent values are $0$ when sine values are $0$ ($x = 0$), and undefined when cosine values are $0$ ($x = \\frac{\\pi}{2}$ or $x = -\\frac{\\pi}{2}$). As x-values go from $-\\frac{\\pi}{2}$ to $\\frac{\\pi}{2}$, tangent values go from $- \\infty$ to $\\infty$.\nThe graph of $y = \\tan x$ is shown in FIGURE 110.\nThe cotangent function’s vertical asymptotes are at x-values that are integer multiples of $\\pi$. Because $\\cot (-x) = -\\cot x$, the cotangent function is odd and its graph is symmetric with respect to the origin. Its graph is plotted on Figure 112.\nThe cotangent function also has period $\\pi$. Cotangent values are $0$ when cosine values are $0$ ($x = \\frac{\\pi}{2}$), and undefined when sine values are $0$ ($x = 0$ or $x = \\pi$). As $x$-values go from $0$ to $\\pi$, cotangent values go from $\\infty$ to $-\\infty$ and decrease throughout the interval.\nGuidelines for Sketching Graphs of the Tangent and Cotangent Functions\nTo graph $y = a \\tan bx$ or $y = a \\cot bx$, with $b \u003e 0$, follow these steps:\nThe period is $\\frac{\\pi}{b}$. To locate two adjacent vertical asymptotes, solve the following equations for $x$. For $y = a \\tan bx$: $bx = - \\frac{\\pi}{2}$ and $bx = \\frac{\\pi}{2}$ For $y = a \\cot bx$: $bx = 0$ and $bx = \\pi$ Sketch the two vertical asymptotes. Divide the interval formed by the vertical asymptotes into four. Evaluate the function for the first-quarter point, midpoint, and thirdquarter point. Join the points with a smooth curve. ","graphs-of-the-sine-and-cosine-functions#Graphs of the Sine and Cosine Functions":"Periodic Function A periodic function is a function $f$, such that:\n$$ \\begin{aligned} f(x) = f(x + np) \\end{aligned} $$for every real number $x$ in the domain of $f$, every integer $n$ and some positive real number $p$. The least possible value of $p$ is the period of the function.\nGraph of the Sine Function See FIGURE 85, and trace along the circle to verify the results shown in the table.\nThis graph is called a sine wave or sinusoid.\nAmplitude The graph of $y = a \\sin x$ or $y = a \\cos x$, with $a \\neq 0$, will have the same shape as the graph of $y = \\sin x$ or $y = \\cos x$, respectively, except with range $[-|a|, |a|]$. The amplitude is $|a|$.\nNo matter what the value of the amplitude, the periods of $y = a \\sin x$ and $y = a \\cos x$ are still $2\\pi$.\nPeriod In general, the graph of a function of the form $y = \\sin bx$ or $y = \\cos bx$, for $b \u003e 0$, will have a period different from $2\\pi$ when $b \\neq 1$.\nWe know that $bx$ ranges from $0$ to $2\\pi$, therefore:\n$$ \\begin{aligned} 0 \\leq bx \\leq 2\\pi \\end{aligned} $$$$ \\begin{aligned} 0 \\leq x \\leq \\frac{2\\pi}{b} \\end{aligned} $$Therefore the period is $\\frac{2\\pi}{b}$. By dividing the interval $[0, \\frac{2\\pi}{b}]$ into four equal parts, we obtain the values for which $\\sin bx$ or $\\cos bx$ is $-1$, $0$, or $1$.\nGuidelines for Sketching Graphs of the Sine and Cosine Functions To graph $y = a \\sin bx$ or $y = a \\cos bx$, with $b \u003e 0$, follow these steps.\nFind the period, $\\frac{2\\pi}{b}$. Divide the interval into four equal parts. Evaluate the function for each of the five x-values. The points will be maximum points, minimum points, and x-intercepts. Plot the points found in Step 3, and join them with a sinusoidal curve having amplitude $|a|$. Translations and Transformations In general, the graph of a function of the form:\n$$ \\begin{aligned} y = f(x - d) \\end{aligned} $$is translated horizontally compared with the graph of $y = f(x)$. The translation is $d$ units to the right if $d \u003e 0$ and $|d|$ units to the left if $d \u003c 0$.\nIn general, the graph of a function of the form:\n$$ \\begin{aligned} y = c + f(x) \\end{aligned} $$is translated vertically compared with the graph of $y = f(x)$. The translation is $c$ units up if $c \u003e 0$ and $|c|$ units down if $c \u003c 0$.\nFurther Guidelines for Sketching Graphs of the Sine and Cosine Functions A function of the form $y = c + a \\sin [b(x − d)]$ or $y = c + a \\cos [b(x − d)]$ , $b \u003e 0$ can be graphed according to the following guidelines:\nMethod 1: Find an interval whose length is one period $\\frac{2\\pi}{b}$ by solving the three-part inequality $0 \\leq b(x - d) \\leq 2\\pi$. Divide the interval into four equal parts. Evaluate the function for each of the five x-values. The points will be maximum points, minimum points, and points that intersect the line $y = c$. Plot the points in Step 3, and join them with a sinusoidal curve having amplitude $|a|$. Method 2: Graph $y = a \\sin bx$ or $y = a \\cos bx$. The amplitude of the function is $|a|$, and the period is $\\frac{2\\pi}{b}$. Use translations to graph the desired function. ","harmonic-motion#Harmonic Motion":"Simple Harmonic Motion Consider FIGURE 119, suppose the point $P(x, y)$ moves around the circle counterclockwise at a uniform angular speed $\\omega$. Assume that at time $t = 0$, $P$ is at $(a, 0)$. The angle swept out by ray OP at time $t$ is given by:\n$$ \\begin{aligned} \\theta = \\omega t \\end{aligned} $$The coordinates of point $P$ at time $t$ are:\n$$ \\begin{aligned} x = a \\cos \\theta = a \\cos \\omega t \\end{aligned} $$and\n$$ \\begin{aligned} y = a \\sin \\theta = a \\sin \\omega t \\end{aligned} $$ The number of oscillations, or cycles per unit of time, called the frequency, is the reciprocal o the period.\nThe position of a point oscillating about an equilibrium position at time $t$ is modeled by either:\n$$ \\begin{aligned} s(t) = a \\cos \\omega t \\end{aligned} $$or\n$$ \\begin{aligned} s(t) = a \\sin \\omega t \\end{aligned} $$where $a$ and $\\omega$ are constants with $\\omega \u003e 0$. The amplitude of the motion is $|a|$, the period is $\\frac{2 \\pi}{\\omega}$ and the frequency is $\\frac{\\omega}{2 \\pi}$.\nDampled Oscillatory Motion Up until now we disregarded the effect of friction, which causes the amplitude of the motion to diminish gradually. We say that the motion has been damped by the force of friction. Most oscillatory motions are damped, and the decrease in amplitude follows the pattern of exponential decay.\nAn example of damped oscillatory motion is given by the function:\n$$ \\begin{aligned} s(t) = e^{-t} \\sin t \\end{aligned} $$","right-triangles-and-evaluating-trigonometric-functions#Right Triangles and Evaluating Trigonometric Functions":"Right-Triangle Definitions of the Trigonometric Functions FIGURE 41 shows an acute angle $A$ in standard position. The side of length $y$ in FIGURE 41 is called the side opposite angle $A$, and the side of length $x$ is called the side adjacent to angle $A$.\nSuch that:\n$$ \\begin{aligned} \\sin A = \\frac{y}{r} = \\frac{\\text{side opposite}}{\\text{hypotenuse}} \\end{aligned} $$$$ \\begin{aligned} \\cos A = \\frac{x}{r} = \\frac{\\text{side adjacent}}{\\text{hypotenuse}} \\end{aligned} $$$$ \\begin{aligned} \\tan A = \\frac{y}{x} = \\frac{\\text{side opposite}}{\\text{side adjacent}} \\end{aligned} $$$$ \\begin{aligned} \\csc A = \\frac{r}{y} = \\frac{\\text{hypotenuse}}{\\text{side opposite}} \\end{aligned} $$$$ \\begin{aligned} \\sec A = \\frac{r}{x} = \\frac{\\text{hypotenuse}}{\\text{side adjacent}} \\end{aligned} $$$$ \\begin{aligned} \\cot A = \\frac{x}{y} = \\frac{\\text{side adjacent}}{\\text{side opposite}} \\end{aligned} $$Trigonometric Function Values of Special Angles Certain special angles, such as $30º, 45º$ and $60º$ occur so often that they deserve special study. See Figure 43(a), for convenience the length of the sides is $2$.\nBisecting one angle of this equilateral triangle leads to two right triangles, each of which has angles of $30°, 60°$, and $90°$, as shown in FIGURE 43(b).\nLet $x$ represent the length of the longer leg:\n$$ \\begin{aligned} 2^2 = 1^2 + x^2 \\end{aligned} $$$$ \\begin{aligned} 4 = 1 + x^2 \\end{aligned} $$$$ \\begin{aligned} 3 = x^2 \\end{aligned} $$$$ \\begin{aligned} \\sqrt{3} = x \\end{aligned} $$Therefore the hypotenuse is $2$, the side opposite is $1$ and the side adjacent is $\\sqrt{3}$. From the definition of the trigonometric functions:\n$$ \\begin{aligned} \\sin 30º = \\frac{\\text{side opposite}}{\\text{hypotenuse}} = \\frac{1}{2} \\end{aligned} $$$$ \\begin{aligned} \\cos 30º = \\frac{\\text{side adjacent}}{\\text{hypotenuse}} = \\frac{\\sqrt{3}}{2} \\end{aligned} $$$$ \\begin{aligned} \\tan 30º = \\frac{\\text{side opposite}}{\\text{side adjacent}} = \\frac{\\sqrt{3}}{3} \\end{aligned} $$$$ \\begin{aligned} \\csc 30º = \\frac{\\text{hypotenuse}}{\\text{side opposite}} = \\frac{2}{1} = 2 \\end{aligned} $$$$ \\begin{aligned} \\sec 30º = \\frac{\\text{hypotenuse}}{\\text{side adjacent}} = \\frac{2\\sqrt{3}}{3} \\end{aligned} $$$$ \\begin{aligned} \\cot 30º = \\frac{\\text{side adjacent}}{\\text{side opposite}} = \\frac{\\sqrt{3}}{1} = \\sqrt{3} \\end{aligned} $$For $60º$ refer to Figure 44, such that hypotenuse is $2$, side opposite is $\\sqrt{3}$ and side adjacent is $1$.\nTherefore from the definition of the trigonometric functions:\n$$ \\begin{aligned} \\sin 60º = \\frac{\\text{side opposite}}{\\text{hypotenuse}} = \\frac{\\sqrt{3}}{2} \\end{aligned} $$$$ \\begin{aligned} \\cos 60º = \\frac{\\text{side adjacent}}{\\text{hypotenuse}} = \\frac{1}{2} \\end{aligned} $$$$ \\begin{aligned} \\tan 60º = \\frac{\\text{side opposite}}{\\text{side adjacent}} = \\frac{\\sqrt{3}}{1} = \\sqrt{3} \\end{aligned} $$$$ \\begin{aligned} \\csc 60º = \\frac{\\text{hypotenuse}}{\\text{side opposite}} = \\frac{2\\sqrt{3}}{3} \\end{aligned} $$$$ \\begin{aligned} \\sec 60º = \\frac{\\text{hypotenuse}}{\\text{side adjacent}} = \\frac{2}{1} = 2 \\end{aligned} $$$$ \\begin{aligned} \\cot 60º = \\frac{\\text{side adjacent}}{\\text{side opposite}} = \\frac{\\sqrt{3}}{3} \\end{aligned} $$For $45º$ we start with a $45º-45º$ right triangle as shown in Figure 45. This triangle has two equal sides whose length is $1$ unit.\nTherefore, by the Pythagoread theorem:\n$$ \\begin{aligned} 1^2 + 1^2 = r^2 \\end{aligned} $$$$ \\begin{aligned} r = \\sqrt{2} \\end{aligned} $$That is the hypotenuse is $\\sqrt{2}$, the side opposite is $1$ and the side adjacent is $1$, so from the definition of the trigonometric functions:\n$$ \\begin{aligned} \\sin 45º = \\frac{\\text{side opposite}}{\\text{hypotenuse}} = \\frac{1}{\\sqrt{2}} = \\frac{\\sqrt{2}}{2} \\end{aligned} $$$$ \\begin{aligned} \\cos 45º = \\frac{\\text{side adjacent}}{\\text{hypotenuse}} = \\frac{1}{\\sqrt{2}} = \\frac{\\sqrt{2}}{2} \\end{aligned} $$$$ \\begin{aligned} \\tan 45º = \\frac{\\text{side opposite}}{\\text{side adjacent}} = \\frac{1}{1} = 1 \\end{aligned} $$$$ \\begin{aligned} \\csc 45º = \\frac{\\text{hypotenuse}}{\\text{side opposite}} = \\frac{\\sqrt{2}}{1} = \\sqrt{2} \\end{aligned} $$$$ \\begin{aligned} \\sec 45º = \\frac{\\text{hypotenuse}}{\\text{side adjacent}} = \\frac{\\sqrt{2}}{1} = \\sqrt{2} \\end{aligned} $$$$ \\begin{aligned} \\cot 45º = \\frac{\\text{side adjacent}}{\\text{side opposite}} = \\frac{1}{1} = 1 \\end{aligned} $$Cofunction Identities In a right triangle $ABC$ with right angle $C$, the acute angles $A$ and $B$ are complementary. See FIGURE 46.\nThe length of the side opposite angle $A$ is $a$, and the length of the side opposite angle $B$ is $b$. The length of the hypotenuse is $c$. In this triangle, $\\sin A = \\frac{a}{c}$ and $\\cos B$ is also equal to $\\frac{a}{c}$.\nSimilar reasoning yields the following.\n$$ \\begin{aligned} \\tan A = \\frac{a}{b} = \\cot B \\end{aligned} $$$$ \\begin{aligned} \\sec A = \\frac{c}{b} = \\csc B \\end{aligned} $$If these identities follow we say $\\sin$ and $\\cos$ are cofunctions, as well as $\\tan$ and $\\cot$ and $\\sec$ and $\\csc$.\nSince angles $A$ and $B$ are complementary $A + B = 90º$, that is $B = 90º - A$, therefore:\n$$ \\begin{aligned} \\sin A = \\cos B = \\cos (90º - A) \\end{aligned} $$This is a cofunction identity, the rest are as follows: given an acute angle $A$ in degrees:\n$$ \\begin{aligned} \\cos A = \\sin B = \\sin (90º - A) \\end{aligned} $$$$ \\begin{aligned} \\tan A = \\cot B = \\cot (90º - A) \\end{aligned} $$$$ \\begin{aligned} \\csc A = \\sec B = \\sec (90º - A) \\end{aligned} $$$$ \\begin{aligned} \\sec A = \\csc B = \\csc (90º - A) \\end{aligned} $$$$ \\begin{aligned} \\cot A = \\tan B = \\tan (90º - A) \\end{aligned} $$Given an acute angle $A$ is radians:\n$$ \\begin{aligned} \\sin A = \\cos B = \\cos \\left(\\frac{\\pi}{2} - A\\right) \\end{aligned} $$$$ \\begin{aligned} \\cos A = \\sin B = \\sin \\left(\\frac{\\pi}{2} - A\\right) \\end{aligned} $$$$ \\begin{aligned} \\tan A = \\cot B = \\cot \\left(\\frac{\\pi}{2} - A\\right) \\end{aligned} $$$$ \\begin{aligned} \\csc A = \\sec B = \\sec \\left(\\frac{\\pi}{2} - A\\right) \\end{aligned} $$$$ \\begin{aligned} \\sec A = \\csc B = \\csc \\left(\\frac{\\pi}{2} - A\\right) \\end{aligned} $$$$ \\begin{aligned} \\cot A = \\tan B = \\tan \\left(\\frac{\\pi}{2} - A\\right) \\end{aligned} $$Reference Angles A reference angle for an angle $\\theta$, written $\\theta’$, is the positive acute angle made by the terminal side of angle $\\theta$ and the x-axis.\nIf an angle $\\theta$ is negative or has measure greater than $360°$, its reference angle is found by first finding its coterminal angle that is between $0°$ and $360°$.\nFinding Trigonometric Function Values for a Nonquadrantal Angle $\\theta$ If $\\theta \u003e 360°$, or if $\\theta \u003c 0°$, then find a coterminal angle. Find the reference angle $\\theta’$. Find the trigonometric function values for reference angle $\\theta’$. Determine the correct signs for the values, given by the quadrant of $\\theta$. ","the-circular-functions#The Circular Functions":"Circular Functions For any real number $s$ represented by a directed arc on the unit circle $x^2 + y^2 = 1$, the following definitions hold.\n$$ \\begin{aligned} \\sin s = \\frac{y}{r} = y \\end{aligned} $$$$ \\begin{aligned} \\cos s = \\frac{x}{r} = x \\end{aligned} $$$$ \\begin{aligned} \\tan s = \\frac{y}{x}, x \\neq 0 \\end{aligned} $$$$ \\begin{aligned} \\csc s = \\frac{r}{y} = \\frac{1}{y}, y \\neq 0 \\end{aligned} $$$$ \\begin{aligned} \\sec s = \\frac{r}{x} = \\frac{1}{x}, x \\neq 0 \\end{aligned} $$$$ \\begin{aligned} \\cot s = \\frac{x}{y}, y \\neq 0 \\end{aligned} $$So circular function values of real numbers are obtained in the same manner as trigonometric function values of angles measured in radians.\nWe can use the following figure to easily obtain exact solutions to some angles:\nThe diagram shown in FIGURE 82 illustrates a correspondence that relates the right triangle ratio definitions of the trigonometric functions and the unit circle interpretation.\nThe arc $SR$ is the first-quadrant portion of the unit circle, and the standard-position angle $POQ$ is designated $\\theta$. By definition, the coordinates of $P$ are $(cos \\theta, sin \\theta)$. The six trigonometric functions of $\\theta$ can be interpreted as lengths of line segments.\nFor $\\cos \\theta$ and $\\sin \\theta$, use right triangle $POQ$ and right-triangle ratios:\n$$ \\begin{aligned} \\cos \\theta = \\frac{\\text{adyacent}}{\\text{hypotenuse}} = \\frac{OQ}{OP} = \\frac{OQ}{1} = OQ \\end{aligned} $$$$ \\begin{aligned} \\sin \\theta = \\frac{\\text{opposite}}{\\text{hypotenuse}} = \\frac{PQ}{OP} = \\frac{PQ}{1} = PQ \\end{aligned} $$For $\\tan \\theta$ and $\\sec \\theta$, use right triangle $VOR$ and right-triangle ratios:\n$$ \\begin{aligned} \\tan \\theta = \\frac{\\text{opposite}}{\\text{adyacent}} = \\frac{VR}{OR} = \\frac{VR}{1} = VR \\end{aligned} $$$$ \\begin{aligned} \\sec \\theta = \\frac{\\text{hypotenuse}}{\\text{adyacent}} = \\frac{OV}{OR} = \\frac{OV}{1} = OV \\end{aligned} $$For $\\csc \\theta$ and $\\cot \\theta$, first note that $US$ and $OR$ are parallel. Thus angle $SUO$ is equal to $\\theta$:\n$$ \\begin{aligned} \\csc \\theta = \\frac{\\text{hypotenuse}}{\\text{opposite}} = \\frac{OU}{OS} = \\frac{OU}{1} = OU \\end{aligned} $$$$ \\begin{aligned} \\cot \\theta = \\frac{\\text{adjacent}}{\\text{opposite}} = \\frac{US}{OS} = \\frac{US}{1} = US \\end{aligned} $$FIGURE 83 illustrates the results found above.","trigonometric-functions-and-fundamental-identities#Trigonometric Functions and Fundamental Identities":"Trigonometric Functions Let $(x, y)$ be a point other than the origin on the terminal side of an angle $\\theta$ instandard position. The distance from the point to the origin is $r = \\sqrt{x^2 + y^2}$. The six trigonometric functions of $\\theta$ are as follows:\n$$ \\begin{aligned} \\sin \\theta = \\frac{y}{r} \\end{aligned} $$$$ \\begin{aligned} \\cos \\theta = \\frac{x}{r} \\end{aligned} $$$$ \\begin{aligned} \\tan \\theta = \\frac{y}{x}, x \\neq 0 \\end{aligned} $$$$ \\begin{aligned} \\csc \\theta = \\frac{r}{y} \\end{aligned} $$$$ \\begin{aligned} \\sec \\theta = \\frac{r}{x} \\end{aligned} $$$$ \\begin{aligned} \\cot \\theta = \\frac{x}{y}, y \\neq 0 \\end{aligned} $$ $\\sin \\theta = \\frac{y}{r}$ is the same no matter which point is used to find it. Refer to FIGURE 28, which shows an angle $\\theta$ and two distinct points on its terminal side. Point $P$ has coordinates $(x, y)$, and point $P’$ with coordinates $(x’, y’)$. Let $r$ be the length of the hypotenuse of triangle $OPQ$, and let $r’$ be the length of the hypotenuse of triangle $OP’Q’$. Since corresponding sides of similar triangles are in proportion:\n$$ \\begin{aligned} \\frac{y}{r} = \\frac{y'}{r'} = \\sin \\theta \\end{aligned} $$We can also find the trigonometric function values of an angle if we know the equation of the line coinciding with the terminal ray:\n$$ \\begin{aligned} Ax + By = 0 \\end{aligned} $$By choosing any point on the ray, we can find the trigonometric function values of the angle.\nIn general, it is true that $m = \\tan \\theta$.\nFunction Values of Quadrantal Angles Conditions for Undefined Function Values\nIf the terminal side of the quadrantal angle lies along the y-axis ($x$ equals zero), then the tangent and secant functions are undefined. If the terminal side of the quadrantal angle lies along the x-axis ($y$ equals zero), then the cotangent and cosecant functions are undefined. Reciprocal Identities The definitions of the trigonometric functions were written to illustrate that certain function pairs are reciprocals of each other. Since:\n$$ \\begin{aligned} \\sin \\theta = \\frac{y}{r} \\end{aligned} $$and\n$$ \\begin{aligned} \\csc \\theta = \\frac{r}{y} \\end{aligned} $$Then:\n$$ \\begin{aligned} \\sin \\theta = \\frac{1}{\\csc \\theta} \\end{aligned} $$Therefore, the reciprocal identities are listed below:\n$$ \\begin{aligned} \\sin \\theta = \\frac{1}{\\csc \\theta} \\end{aligned} $$$$ \\begin{aligned} \\cos \\theta = \\frac{1}{\\sec \\theta} \\end{aligned} $$$$ \\begin{aligned} \\tan \\theta = \\frac{1}{\\cot \\theta} \\end{aligned} $$$$ \\begin{aligned} \\csc \\theta = \\frac{1}{\\sin \\theta} \\end{aligned} $$$$ \\begin{aligned} \\sec \\theta = \\frac{1}{\\cos \\theta} \\end{aligned} $$$$ \\begin{aligned} \\cot \\theta = \\frac{1}{\\tan \\theta} \\end{aligned} $$Signs and Ranges of Function Values A point $(x, y)$ in quadrant II has $x \u003c 0$ and $y \u003e 0$. This makes the values of sine and cosecant positive for quadrant II angles, while the other four functions take on negative values. Similar results can be obtained for the other quadrants, as summarized here.\nIn Figure 37 we can see that as the measure of the angle increases, $y$ increases, but never exceeds $r$, so $y \\leq r$. In a similar way, angles in quadrant IV suggest that $-r \\leq y$. Therefore:\n$$ \\begin{aligned} -r \\leq y \\leq r \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\frac{y}{r} \\leq 1 \\end{aligned} $$$$ \\begin{aligned} -1 \\leq \\sin \\theta \\leq 1 \\end{aligned} $$Similar reasoning leads to the following:\n$$ \\begin{aligned} -1 \\leq \\cos \\theta \\leq 1 \\end{aligned} $$The tangent of an angle is defined as $\\frac{y}{x}$. It is possible that $x \u003c y$, $x = y$, or $x \u003e y$. For this reason, $\\frac{y}{x}$ can take any value, so $\\tan \\theta$ can be any real number, as can $\\cot \\theta$.\nThe functions $\\sec \\theta$ and $\\csc \\theta$ are reciprocals of the functions $\\cos \\theta$ and $\\sin \\theta$, respectively, making the following true:\n$$ \\begin{aligned} \\sec \\theta \\leq -1 \\text{ or } \\sec \\theta \\geq 1 \\end{aligned} $$and\n$$ \\begin{aligned} \\csc \\theta \\leq -1 \\text{ or } \\csc \\theta \\geq 1 \\end{aligned} $$Pythagorean Identities Given $x^2 + y^2 = r^2$, then:\n$$ \\begin{aligned} \\frac{x^2}{r^2} + \\frac{y^2}{r^2} = \\frac{r^2}{r^2} \\end{aligned} $$$$ \\begin{aligned} \\left(\\frac{x}{r}\\right)^2 + \\left(\\frac{y}{r}\\right)^2 = 1 \\end{aligned} $$$$ \\begin{aligned} \\left(\\cos \\theta\\right)^2 + \\left(\\sin \\theta\\right)^2 = 1 \\end{aligned} $$Similarly:\n$$ \\begin{aligned} \\frac{x^2}{x^2} + \\frac{y^2}{x^2} = \\frac{r^2}{x^2} \\end{aligned} $$$$ \\begin{aligned} 1 + \\left(\\frac{y}{x}\\right)^2 = \\left(\\frac{r}{x}\\right)^2 \\end{aligned} $$$$ \\begin{aligned} 1 + \\left(\\tan \\theta\\right)^2 = \\left(\\sec \\theta\\right)^2 \\end{aligned} $$Similarly:\n$$ \\begin{aligned} \\frac{x^2}{y^2} + \\frac{y^2}{y^2} = \\frac{r^2}{y^2} \\end{aligned} $$$$ \\begin{aligned} \\left(\\frac{x}{y}\\right)^2 + 1 = \\left(\\frac{r}{y}\\right)^2 \\end{aligned} $$$$ \\begin{aligned} \\left(\\cot \\theta\\right)^2 + 1 = \\left(\\csc \\theta \\right)^2 \\end{aligned} $$Quotient Identities Consider the quotient of $\\sin \\theta$ and $\\cos \\theta$:\n$$ \\begin{aligned} \\frac{\\sin \\theta}{\\cos \\theta} = \\frac{\\frac{y}{r}}{\\frac{x}{r}} = \\frac{y}{x} = \\tan \\theta \\end{aligned} $$where $\\cos \\theta \\neq 0$. Similarly:\n$$ \\begin{aligned} \\frac{\\cos \\theta}{\\sin \\theta} = \\frac{\\frac{x}{r}}{\\frac{y}{r}} = \\frac{x}{y} = \\cot \\theta \\end{aligned} $$"},"title":"Trigonometric Functions and Applications"},"/notes/math/agaa/09_trig_identities/":{"data":{"":"","further-identities#Further Identities":"Double-Number Identities The double-number identities, or double-angle identities, result from the sum identities when $A = B$ so that $A + B = A + A = 2A$.\n$$ \\begin{aligned} \\cos 2A = \\cos(A + A) = \\cos A \\cos A - \\sin A \\sin A \\end{aligned} $$$$ \\begin{aligned} = \\cos^2 A - \\sin^2 A \\end{aligned} $$Two other common forms of this identity are obtained by substitution:\n$$ \\begin{aligned} \\cos 2A = \\cos^2 A - \\sin^2 A = (1 - \\sin^2 A) - \\sin^2 A \\end{aligned} $$$$ \\begin{aligned} 1 - 2\\sin^2 A \\end{aligned} $$and\n$$ \\begin{aligned} \\cos 2A = \\cos^2 A - \\sin^2 A = \\cos^2 A - (1 - \\cos^2 A) \\end{aligned} $$$$ \\begin{aligned} = 2\\cos^2 A - 1 \\end{aligned} $$We find $\\sin 2A$ with the identity for $\\sin (A + B)$\n$$ \\begin{aligned} \\sin 2A = \\sin (A + A) = \\sin A \\cos A + \\sin A \\cos A \\end{aligned} $$$$ \\begin{aligned} = 2\\sin A \\cos A \\end{aligned} $$Similarly, we use the identity for $\\tan (A + B)$ to find $\\tan 2A$.\n$$ \\begin{aligned} \\tan 2A = \\tan (A + A) = \\frac{\\tan A + \\tan A}{1- \\tan A \\tan A} \\end{aligned} $$$$ \\begin{aligned} = \\frac{2 \\tan A}{1 - \\tan^2 A} \\end{aligned} $$Product-to-Sum Identities Adding the identities for $\\cos (A + B)$ and $\\cos (A - B)$ gives the following:\n$$ \\begin{aligned} \\cos (A + B) + \\cos (A - B) = \\cos A \\cos B - \\sin A \\sin B + \\cos A \\cos B + \\sin A \\sin B \\end{aligned} $$$$ \\begin{aligned} = 2\\cos A \\cos B \\end{aligned} $$Thus:\n$$ \\begin{aligned} 2 \\cos A \\cos B = \\left[\\cos(A + B) + \\cos(A - B)\\right] \\end{aligned} $$$$ \\begin{aligned} \\cos A \\cos B = \\frac{1}{2} \\left[\\cos(A + B) + \\cos(A - B)\\right] \\end{aligned} $$Substracting $\\cos(A - B)$ from $\\cos (A + B)$ gives the following:\n$$ \\begin{aligned} \\cos (A + B) - \\cos (A - B) = \\cos A \\cos B - \\sin A \\sin B - \\cos A \\cos B - \\sin A \\sin B \\end{aligned} $$$$ \\begin{aligned} = -2 \\sin A \\sin B \\end{aligned} $$Thus:\n$$ \\begin{aligned}\n2 \\sin A \\sin B = \\left[\\cos(A + B) - \\cos(A - B)\\right] \\end{aligned} $$ $$ \\begin{aligned} 2 \\sin A \\sin B = -\\frac{1}{2} \\left[\\cos(A + B) - \\cos(A - B)\\right] \\end{aligned} $$$$ \\begin{aligned} \\sin A \\sin B = \\frac{1}{2} \\left[\\cos(A - B) - \\cos(A + B)\\right] \\end{aligned} $$Adding the identities for $\\sin (A + B)$ and $\\sin (A - B)$ gives the following:\n$$ \\begin{aligned} \\sin(A + B) + \\sin (A - B) = \\sin A \\cos B + \\sin B \\cos A + \\sin A \\cos B - \\sin B \\cos A \\end{aligned} $$$$ \\begin{aligned} = 2 \\sin A \\cos B \\end{aligned} $$Thus:\n$$ \\begin{aligned} 2 \\sin A \\cos B = \\sin (A + B) + \\sin (A - B) \\end{aligned} $$$$ \\begin{aligned} \\sin A \\cos B = \\frac{1}{2} \\left[\\sin (A + B) + \\sin (A - B)\\right] \\end{aligned} $$Substracting $\\sin (A - B)$ from $\\sin (A + B)$ gives the following:\n$$ \\begin{aligned} \\sin(A + B) - \\sin (A - B) = \\sin A \\cos B + \\sin B \\cos A - \\sin A \\cos B + \\sin B \\cos A \\end{aligned} $$$$ \\begin{aligned} = 2 \\sin B \\cos A \\end{aligned} $$Thus:\n$$ \\begin{aligned} 2 \\sin B \\cos A = \\sin (A + B) - \\sin (A - B) \\end{aligned} $$$$ \\begin{aligned} \\sin B \\cos A = \\frac{1}{2} \\left[\\sin (A + B) - \\sin (A - B)\\right] \\end{aligned} $$Sum-to-Product Identities From the previous identities we can derive another group of identities. For the sum of sines we have:\n$$ \\begin{aligned} \\sin A + \\sin B = \\sin (\\frac{2A}{2} + \\frac{B - B}{2}) + \\sin (\\frac{2B}{2} + \\frac{A - A}{2}) \\end{aligned} $$$$ \\begin{aligned} = \\sin (\\frac{(A + B) + (A - B)}{2}) + \\sin (\\frac{(A + B) - (A - B)}{2}) \\end{aligned} $$If $x = \\frac{A + B}{2}$ and $y = \\frac{A - B}{2}$, then\n$$ \\begin{aligned} = \\sin (x + y) + \\sin (x - y) \\end{aligned} $$By the product to sum identity we have:\n$$ \\begin{aligned} = 2 (\\sin x \\cos y) = 2 \\sin(\\frac{A + B}{2}) \\cos(\\frac{A - B}{2}) \\end{aligned} $$For the difference of sines we have:\n$$ \\begin{aligned} \\sin A - \\sin B = \\sin (\\frac{2A}{2} + \\frac{B - B}{2}) - \\sin (\\frac{2B}{2} + \\frac{A - A}{2}) \\end{aligned} $$$$ \\begin{aligned} = \\sin (\\frac{(A + B) + (A - B)}{2}) - \\sin (\\frac{(A + B) - (A - B)}{2}) \\end{aligned} $$If $x = \\frac{A + B}{2}$ and $y = \\frac{A - B}{2}$, then\n$$ \\begin{aligned} = \\sin (x + y) - \\sin (x - y) \\end{aligned} $$By the product to sum identity we have:\n$$ \\begin{aligned} = 2 (\\cos x \\sin y) = 2 \\cos(\\frac{A + B}{2}) \\sin(\\frac{A - B}{2}) \\end{aligned} $$For the sum of cosines we have:\n$$ \\begin{aligned} \\cos A + \\cos B = \\cos (\\frac{2A}{2} + \\frac{B - B}{2}) + \\cos (\\frac{2B}{2} + \\frac{A - A}{2}) \\end{aligned} $$$$ \\begin{aligned} = \\cos (\\frac{(A + B) + (A - B)}{2}) + \\cos (\\frac{(A + B) - (A - B)}{2}) \\end{aligned} $$If $x = \\frac{A + B}{2}$ and $y = \\frac{A - B}{2}$, then\n$$ \\begin{aligned} = 2 \\cos (x + y) + \\cos (x - y) \\end{aligned} $$By the product to sum identity we have:\n$$ \\begin{aligned} = 2 (\\cos x \\cos y) = 2 \\cos(\\frac{A + B}{2}) \\cos(\\frac{A - B}{2}) \\end{aligned} $$For the difference of cosines we have:\n$$ \\begin{aligned} \\cos A - \\cos B = \\cos (\\frac{2A}{2} + \\frac{B - B}{2}) - \\cos (\\frac{2B}{2} + \\frac{A - A}{2}) \\end{aligned} $$$$ \\begin{aligned} = \\cos (\\frac{(A + B) + (A - B)}{2}) - \\cos (\\frac{(A + B) - (A - B)}{2}) \\end{aligned} $$If $x = \\frac{A + B}{2}$ and $y = \\frac{A - B}{2}$, then\n$$ \\begin{aligned} = \\cos (x + y) - \\cos (x - y) \\end{aligned} $$By the product to sum identity we have:\n$$ \\begin{aligned} = -2 (\\sin x \\sin y) = -2 \\sin(\\frac{A + B}{2}) \\sin(\\frac{A - B}{2}) \\end{aligned} $$Half-Number Identities We derive identities for $\\sin \\frac{A}{2}$, $\\cos \\frac{A}{2}$ and $\\tan \\frac{A}{2}$. These are known as half-number identities, or half-angle identities.\nWe derive the identity for $\\cos \\frac{A}{2}$ as follows:\n$$ \\begin{aligned} \\cos 2x = 2 \\cos^2 x - 1 \\end{aligned} $$$$ \\begin{aligned} \\cos 2x + 1 = 2 \\cos^2 x \\end{aligned} $$$$ \\begin{aligned} \\cos x = \\pm \\sqrt{\\frac{1 + \\cos 2x}{2}} \\end{aligned} $$Now we replace $x$ with $\\frac{A}{2}$, such that:\n$$ \\begin{aligned} \\cos \\frac{A}{2} = \\pm \\sqrt{\\frac{1 + \\cos A}{2}} \\end{aligned} $$We derive the identity for $\\sin \\frac{A}{2}$ as follows:\n$$ \\begin{aligned} \\cos 2x = 1 - 2 \\sin^2 x \\end{aligned} $$$$ \\begin{aligned} \\frac{1 - \\cos 2x}{2} = \\sin^2 x \\end{aligned} $$$$ \\begin{aligned} \\sin x = \\pm \\sqrt{\\frac{1 - \\cos 2x}{2}} \\end{aligned} $$Now we replace $x$ with $\\frac{A}{2}$ to obtain:\n$$ \\begin{aligned} \\sin \\frac{A}{2} = \\pm \\sqrt{\\frac{1 - \\cos A}{2}} \\end{aligned} $$An identity for $\\tan \\frac{A}{2}$ comes from the half-number identities for sine and cosine.\n$$ \\begin{aligned} \\tan {\\frac{A}{2}} = \\frac{\\sin \\frac{A}{2}}{\\cos \\frac{A}{2}} \\end{aligned} $$$$ \\begin{aligned} = \\frac{\\pm \\sqrt{\\frac{1 - \\cos A}{2}}}{\\pm \\sqrt{\\frac{1 + \\cos A}{2}}} \\end{aligned} $$$$ \\begin{aligned} = \\pm \\sqrt{\\frac{\\frac{1 - \\cos A}{2}}{\\frac{1 + \\cos A}{2}}} = \\pm \\sqrt{\\frac{1 - \\cos A}{1 + \\cos A}} \\end{aligned} $$We derive an alternative identity for $\\tan \\frac{A}{2}$ by using double-number identities.\n$$ \\begin{aligned} \\tan \\frac{A}{2} = \\frac{\\sin \\frac{A}{2}}{\\cos \\frac{A}{2}} \\end{aligned} $$We multiply by $2 \\cos \\frac{A}{2}$ on both the numerator and the denominator:\n$$ \\begin{aligned} = \\frac{2 \\sin \\frac{A}{2} \\cos \\frac{A}{2}}{2 \\cos^2 \\frac{A}{2}} \\end{aligned} $$We apply the double-number identity $\\sin 2A = 2 \\sin A \\cos A$ and $\\cos 2A = 2 \\cos^2 A - 1$:\n$$ \\begin{aligned} = \\frac{\\sin \\left[2 \\frac{A}{2}\\right]}{1 + \\cos\\left[2 \\frac{A}{2}\\right]} \\end{aligned} $$$$ \\begin{aligned} = \\frac{\\sin A}{1 + \\cos A} \\end{aligned} $$If we multiply this identity by $\\frac{1 - \\cos A}{1 - \\cos A}$ we obtain:\n$$ \\begin{aligned} = \\frac{(\\sin A)(1 - \\cos A)}{(1 + \\cos A) (1 - \\cos A)} \\end{aligned} $$$$ \\begin{aligned} = \\frac{(\\sin A)(1 - \\cos A)}{1 - \\cos^2 A} \\end{aligned} $$Given $\\cos^2 x + \\sin^2 x = 1$:\n$$ \\begin{aligned} = \\frac{(\\sin A)(1 - \\cos A)}{\\sin^2 A} \\end{aligned} $$$$ \\begin{aligned} = \\frac{1 - \\cos A}{\\sin A} \\end{aligned} $$","sum-and-difference-identities#Sum and Difference Identities":"Cosine Sum and Difference Identities Let $S$ and $Q$ be the points where the terminal sides of angles $A$ and $B$, respectively, intersect the circle. Locate point $R$ on the unit circle so that angle $POR$ equals the difference $A - B$. See FIGURE 5.\nWe know:\n$Q$ has coordinates $(\\cos B, \\sin B)$ $S$ has coordinates $(\\cos A, \\sin A)$ $R$ has coordinates $(\\cos (A - B), \\sin (A - B))$ Angle $SOQ$ also equals $A - B$. Since the central angles $SOQ$ and $POR$ are equal, chords $PR$ and $SQ$ are equal. By the distance formula:\n$$ \\begin{aligned} \\sqrt{[\\cos (A - B) - 1]^2 + [\\sin(A - B) - 0]^2} = \\sqrt{(\\cos A - \\cos B)^2 + (\\sin A - \\sin B)^2} \\end{aligned} $$$$ \\begin{aligned} [\\cos (A - B) - 1]^2 + [\\sin(A - B) - 0]^2 = (\\cos A - \\cos B)^2 + (\\sin A - \\sin B)^2 \\end{aligned} $$$$ \\begin{aligned} \\cos^2 (A - B)+ 1 - 2\\cos(A - B) + \\sin^2(A - B) = \\cos^2 A + \\cos^2 B - 2\\cos A \\cos B + \\sin^2 A + \\sin^2 B - 2\\sin A \\sin B \\end{aligned} $$Because $\\sin^2 x + \\cos^2 x = 1$\n$$ \\begin{aligned} 1 + 1 - 2\\cos(A - B) = 1 + 1 - 2\\cos A \\cos B - 2\\sin A \\sin B \\end{aligned} $$$$ \\begin{aligned} -2\\cos(A - B) = - 2\\cos A \\cos B - 2\\sin A \\sin B \\end{aligned} $$$$ \\begin{aligned} \\cos(A - B) = \\cos A \\cos B + \\sin A \\sin B \\end{aligned} $$For $\\cos (A + B)$, rewrite $A + B$ as $A - (- B)$, and use the identity for $\\cos (A - B)$:\n$$ \\begin{aligned} \\cos(A + B) = \\cos(A - (-B)) = \\cos A \\cos (-B) + \\sin A \\sin (-B) \\end{aligned} $$Given $\\cos (-x) = \\cos x$ and $\\sin -x = - \\sin x$, then:\n$$ \\begin{aligned} = \\cos A \\cos B - \\sin A \\sin B \\end{aligned} $$Sine and Tangent Sum and Difference Identities Use the cofunction identity $\\sin \\theta = \\cos (\\frac{\\pi}{2} - \\theta)$ and replace $\\theta$ with $A + B$:\n$$ \\begin{aligned} \\sin (A + B) = \\cos \\left[\\frac{\\pi}{2} - (A + B)\\right] \\end{aligned} $$$$ \\begin{aligned} = \\cos \\left[(\\frac{\\pi}{2} - A) - B)\\right] \\end{aligned} $$$$ \\begin{aligned} = \\cos \\left(\\frac{\\pi}{2} - A\\right)\\cos B + \\sin \\left(\\frac{\\pi}{2} - A\\right) \\sin B \\end{aligned} $$We apply the cofunction identity again for $\\cos \\left(\\frac{\\pi}{2} - A\\right)$ and $\\sin \\left(\\frac{\\pi}{2} - A\\right)$:\n$$ \\begin{aligned} = \\sin A\\cos B + \\cos A \\sin B \\end{aligned} $$Now we write $\\sin (A - B)$ as $\\sin[A + (-B)]$ and use the identity for $\\sin (A + B)$:\n$$ \\begin{aligned} \\sin (A - B) = \\sin (A + (-B)) = \\sin A\\cos (-B) + \\cos A \\sin (-B) \\end{aligned} $$Given $\\cos (-x) = \\cos x$ and $\\sin -x = - \\sin x$, then:\n$$ \\begin{aligned} = \\sin A\\cos B - \\cos A \\sin B \\end{aligned} $$To derive the identity for $\\tan (A + B)$, proceed as follows\n$$ \\begin{aligned} \\tan (A + B) = \\frac{\\sin (A + B)}{\\cos (A + B)} \\end{aligned} $$$$ \\begin{aligned} = \\frac{\\sin A \\cos B + \\cos A \\sin B}{\\cos A \\cos B - \\sin A \\sin B} \\end{aligned} $$We multiply the numerator and denominator by $\\frac{1}{\\cos A \\cos B}$:\n$$ \\begin{aligned} = \\frac{\\frac{\\sin A \\cos B + \\cos A \\sin B}{\\cos A \\cos B}}{\\frac{\\cos A \\cos B - \\sin A \\sin B}{\\cos A \\cos B}} \\end{aligned} $$$$ \\begin{aligned} = \\frac{\\frac{\\sin A \\cos B}{\\cos A \\cos B} + \\frac{\\cos A \\sin B}{\\cos A \\cos B}}{\\frac{\\cos A \\cos B}{\\cos A \\cos B} - \\frac{\\sin A \\sin B}{\\cos A \\cos B}} \\end{aligned} $$$$ \\begin{aligned} = \\frac{\\frac{\\sin A}{\\cos A} + \\frac{\\sin B}{\\cos B}}{1 - \\frac{\\sin A \\sin B}{\\cos A \\cos B}} \\end{aligned} $$$$ \\begin{aligned} = \\frac{\\tan A + \\tan B}{1 - \\tan A \\tan B} \\end{aligned} $$Replacing $B$ with $-B$ and the fact that $\\tan (-B) = -\\tan B$ gives the identity for the tangent of the difference of two numbers:\n$$ \\begin{aligned} \\tan (A + B) = \\tan (A + (-B))= \\frac{\\tan A + \\tan (-B)}{1 - \\tan A \\tan (-B)} \\end{aligned} $$$$ \\begin{aligned} = \\frac{\\tan A - \\tan B}{1 + \\tan A \\tan B} \\end{aligned} $$","the-inverse-circular-functions#The Inverse Circular Functions":"Inverse Sine Function Applying the horizontal line test, we see that $y = \\sin x$ does not define a one-to-one function. If we restrict the domain to the interval $[-\\frac{\\pi}{2}, \\frac{\\pi}{2}]$ the function is one-to-one and has an inverse function. See FIGURE 16:\n$y = \\sin^{-1} x$ or $y = \\arcsin x$ means that $x = \\sin y$, for $-\\frac{\\pi}{2} \\leq y \\leq \\frac{\\pi}{2}$\nInverse Cosine Function The function $y = \\cos^{-1} x$ (or $y = \\arccos x$) is defined by restricting the domain of the function to the interval $[0, \\pi]$, as in FIGURE 19. The graph of $y = \\cos^{-1} x$ is shown in FIGURE 20.\n$y = \\cos^{-1} x$ or $y = \\arccos x$ means that $x = \\cos y$, for $0 \\leq y \\leq \\pi$.\nInverse Tangent Function Restricting the domain of the function $y = \\tan x$ to the open interval $(-\\frac{\\pi}{2}, \\frac{\\pi}{2})$ yields a one-to-one function. FIGURE 23 shows the graph of the restricted tangent function. FIGURE 24 gives the graph of $y = \\tan^{-1} x$.\n$y = \\tan^{-1} x$ or $y = \\arctan x$ means $x = \\tan y$, for $-\\frac{\\pi}{2} \u003c y \u003c \\frac{\\pi}{2}$\nOther Inverse Trigonometric Functions $y = \\cot^{-1} x$ or $y = arc\\cot x$ means that $x = \\cot y$, for $0 \u003c y \u003c \\pi$.\n$y = \\sec^{-1} x$ or $y = arc\\sec x$ means that $x = \\sec y$, for $0 \\leq y \\leq \\pi, y \\neq \\frac{\\pi}{2}$.\n$y = \\csc^{-1} x$ or $y = arc\\csc x$ means that $x = \\csc y$, for $-\\frac{\\pi}{2} \\leq y \\leq \\frac{\\pi}{2}, y \\neq 0$\nFinding $\\cot^{-1} x$, $\\sec^{-1} x$, and $\\csc^{-1} x$ can be achieved by expressing these functions in terms of $\\tan^{-1} x$, $\\cos{-1} x$ and $\\sin^{-1} x$.\nIf $y = \\sec^{-1} x$, then $\\sec y = x$, so it follows:\n$$ \\begin{aligned} \\sec y = \\frac{1}{\\cos y} = x \\end{aligned} $$$$ \\begin{aligned} \\cos y = \\frac{1}{x} \\end{aligned} $$Therefore:\n$$ \\begin{aligned} y = \\cos^{-1}\\left(\\frac{1}{x}\\right) \\end{aligned} $$For the cosecant function:\n$$ \\begin{aligned} \\csc y = \\frac{1}{\\sin y} = x \\end{aligned} $$$$ \\begin{aligned} \\sin y = \\frac{1}{x} \\end{aligned} $$Therefore:\n$$ \\begin{aligned} y = \\sin^{-1}\\left(\\frac{1}{x}\\right) \\end{aligned} $$Finally the inverse cotangent function can be evaluated as $90º - \\tan^{-1}x$.","trigonometric-identities#Trigonometric Identities":"Fundamental Identities Reciprocal Identities $$ \\begin{aligned} \\cot(\\theta) = \\frac{1}{\\tan \\theta} \\end{aligned} $$$$ \\begin{aligned} \\sec(\\theta) = \\frac{1}{\\cos \\theta} \\end{aligned} $$$$ \\begin{aligned} \\csc(\\theta) = \\frac{1}{\\sin \\theta} \\end{aligned} $$Quotient Identities $$ \\begin{aligned} \\tan(\\theta) = \\frac{\\sin \\theta}{\\cos \\theta} \\end{aligned} $$$$ \\begin{aligned} \\cot(\\theta) = \\frac{\\cos \\theta}{\\sin \\theta} \\end{aligned} $$Pythagorean Identities $$ \\begin{aligned} \\sin^2 \\theta + \\cos^2 \\theta = 1 \\end{aligned} $$$$ \\begin{aligned} 1 + \\tan^2 \\theta = \\sec^2 \\theta \\end{aligned} $$$$ \\begin{aligned} 1 + \\cot^2 \\theta = \\csc^2 \\theta \\end{aligned} $$Negative-Number Identities $$ \\begin{aligned} \\sin (-\\theta) = - \\sin \\theta \\end{aligned} $$$$ \\begin{aligned} \\cos (-\\theta) = \\cos \\theta \\end{aligned} $$$$ \\begin{aligned} \\tan (-\\theta) = -\\tan \\theta \\end{aligned} $$$$ \\begin{aligned} \\csc (-\\theta) = -\\csc \\theta \\end{aligned} $$$$ \\begin{aligned} \\sec (-\\theta) = \\sec \\theta \\end{aligned} $$$$ \\begin{aligned} \\cot (-\\theta) = -\\cot \\theta \\end{aligned} $$Hits for Verifying Identities Learn the fundamental identities. Try to rewrite the more complicated side of the equation. It is sometimes helpful to express all trigonometric functions in the equation in terms of sine and cosine. Usually, any factoring, division involving complex fractions, or indicated algebraic operations should be performed. As you select substitutions, keep in mind the side you are not changing, because it represents your goal. If a fractional expression contains $1 + \\sin x$, multiplying both numerator and denominator by $1 - \\sin x$ would give $1 - \\sin^2 x$, which could be replaced with $\\cos^2 x$. Note that verifying identities is not the same as solving equations. One strategy is to work with only one side and rewrite it to match the other side."},"title":"Trigonometric Identities and Equations"},"/notes/math/agaa/10_trig_applications/":{"data":{"":"","more-parametric-equations#More Parametric Equations":"Parametric Equations with Trigonometric Functions If we use trigonometric functions in parametric equations, many interesting curves can be drawn as shown in the following figure:\nThe Cycloid The path traced by a fixed point on the circumference of a circle rolling along a line is called a cycloid. A cycloid is defined by:\n$$ \\begin{aligned} x = at - a \\sin t \\end{aligned} $$$$ \\begin{aligned} y = a - a \\cos t \\end{aligned} $$For $t$ in $(-\\infty, \\infty)$.\nIt has an interesting physical property. If a flexible cord goes through points $P$ and $Q$, due to the force of gravity, a bead slides without friction along this path from $P$ to $Q$. The path that requires least time takes the shape of an inverted cycloid.\nApplications of Parametric Equations Parametric equations are used to simulate motion. If a ball is thrown with an initial velocidy of $v_0$ at an angle $\\theta$ with the horizontal, it position $(x, y)$ can be modeled by the parametric equations:\n$$ \\begin{aligned} x = (v_0 \\cos \\theta)t \\end{aligned} $$$$ \\begin{aligned} y = (v_0 \\sin \\theta)t - 16t^2 + h \\end{aligned} $$where $t$ is in seconds and $h$ is the ball’s initial height above the ground.","polar-equations-and-graphs#Polar Equations and Graphs":"Polar Coordinate System The polar coordinate system is based on a point, called the pole, and a ray, called the polar axis. The polar axis is usually drawn in the direction of the positive x-axis. See FIGURE 56.\nIn FIGURE 57, the pole has been placed at the origin of a rectangular coordinate system. The point $P$ has rectangular coordinates $(x, y)$, directed angle $\\theta$ and directed distance $r$. The ordered pair $(r, \\theta)$ gives us the polar coordinates.\nFigure 58 shows the rectangular axes over a polar coordinate grid.\nRelationships between Rectangular and Polar Coordinates If a point has rectangular coordinates $(x, y)$ and polar coordinates $(r, \\theta)$ then:\n$$ \\begin{aligned} x = r \\cos \\theta \\end{aligned} $$$$ \\begin{aligned} y = r \\sin \\theta \\end{aligned} $$$$ \\begin{aligned} r^2 = x^2 + y^2 \\end{aligned} $$$$ \\begin{aligned} \\tan \\theta = \\frac{y}{x}, x \\neq 0 \\end{aligned} $$Note that a point in the plane can only have one pair of rectangular coordinates, however this same point can have infinitely many pairs of polar coordinates. For example $(2, 30º) = (2, 390º) = (2, -330º) = (-2, 210º) = \\cdots$ (see Figure 62).\nGraph of Polar Equations Equations in $x$ and $y$ are called rectangluar (or Cartesian) equations, so equations in $r$ and $\\theta$ are called polar equations.\n$$ \\begin{aligned} r = 3 \\sin \\theta \\end{aligned} $$The rectangular forms of lines and circles can also be defined in terms of polar coordinates, usually obtained by solving for $r$. For a line:\n$$ \\begin{aligned} ax + by = c \\end{aligned} $$$$ \\begin{aligned} a(r \\cos \\theta) + b(r \\sin \\theta) = c \\end{aligned} $$$$ \\begin{aligned} r(a \\cos \\theta + b \\sin \\theta) = c \\end{aligned} $$$$ \\begin{aligned} r = \\frac{c}{a \\cos \\theta + b \\sin \\theta} \\end{aligned} $$For a circle:\n$$ \\begin{aligned} x^2 + y^2 = a^2 \\end{aligned} $$$$ \\begin{aligned} r^2 = a^2 \\end{aligned} $$$$ \\begin{aligned} r = \\pm \\sqrt{a^2} = \\pm a \\end{aligned} $$Classifying Polar Equations The table summarizes common polar graphs and forms of their equations.\nCircles $$ \\begin{aligned} r = a \\cos \\theta \\end{aligned} $$ $$ \\begin{aligned} r = a \\sin \\theta \\end{aligned} $$Lemniscates $$ \\begin{aligned} r^2 = a^2 \\sin 2 \\theta \\end{aligned} $$ $$ \\begin{aligned} r^2 = a^2 \\cos 2 \\theta \\end{aligned} $$Limaçons $$ \\begin{aligned} r = a \\pm b \\sin \\theta \\end{aligned} $$ $$ \\begin{aligned} r = a \\pm b \\cos \\theta \\end{aligned} $$Rose Curves ","power-and-roots-of-complex-numbers#Power and Roots of Complex Numbers":"Powers of Complex Numbers (De Moivre’s Theorem) Consider the following:\n$$ \\begin{aligned} r(\\cos \\theta + i \\sin \\theta)^2 = [r(cos \\theta + i \\sin \\theta)][r(cos \\theta + i \\sin \\theta)] \\end{aligned} $$By the complex number product theorem:\n$$ \\begin{aligned} = r^2 [cos (\\theta + \\theta) + i \\sin (\\theta + \\theta)] \\end{aligned} $$$$ \\begin{aligned} = r^2 (\\cos 2\\theta + i \\sin 2 \\theta) \\end{aligned} $$So by De Moivre’s Theorem:\nIf $r(\\cos \\theta + i \\sin \\theta)$ is a complex number and $n$ is any positive integer, then the following holds:\n$$ \\begin{aligned} [r(\\cos \\theta + i \\sin \\theta)]^n = r^n (\\cos n\\theta + i \\sin n\\theta) \\end{aligned} $$In compact form:\n$$ \\begin{aligned} [r\\text{ cis} \\theta]^n = r^n \\text{ cis } n\\theta \\end{aligned} $$Roots of Complex Numbers For a positive integer $n$, the complex number $a + bi$ an $n$th root of the complex number $x + yi$ if the following holds:\n$$ \\begin{aligned} (a + bi)^n = x + yi \\end{aligned} $$Finding the Roots of Complex Numbers To find the three complex cube roots of $8(\\cos 135º + i \\sin 135º)$ we look for a comple number, $r(\\cos \\alpha + i \\sin \\alpha)$ that satisfies:\n$$ \\begin{aligned} [r (\\cos \\alpha + i \\sin \\alpha)]^3 = 8(\\cos 135º + i \\sin 135º) \\end{aligned} $$Using De Moivre’s theorem the expression becomes:\n$r^3(\\cos 3\\alpha + i \\sin 3\\alpha) = 8(\\cos 135º + i \\sin 135º)$\nThe first condition implies:\n$$ \\begin{aligned} r^3 = 8 \\leftrightarrow r = 2 \\end{aligned} $$The second condition implies:\n$$ \\begin{aligned} \\cos 3\\alpha = \\cos 135º \\end{aligned} $$$$ \\begin{aligned} \\sin 3\\alpha = \\sin 135º \\end{aligned} $$Such that $3\\alpha$ must represent an angle that is coterminal with $135º$, therefore:\n$$ \\begin{aligned} 3 \\alpha = 135º + 360º k, k \\in \\mathbb{Z} \\end{aligned} $$$$ \\begin{aligned} \\alpha = \\frac{135º + 360º k}{3}, k \\in \\mathbb{Z} \\end{aligned} $$If we let $k$ take on integer values $0$, $1$ and $2$:\n$$ \\begin{aligned} \\text{If } k = 0 \\text{, then } \\alpha = 45º \\end{aligned} $$$$ \\begin{aligned} \\text{If } k = 1 \\text{, then } \\alpha = 165º \\end{aligned} $$$$ \\begin{aligned} \\text{If } k = 2 \\text{, then } \\alpha = 285º \\end{aligned} $$For $k \u003e 2$ we obtain angles bigger than $365º$ that are coterminal with the identified solution. For example, for $k = 4$ we obtain $\\alpha = 405º$ that is coterminal with $45º$.\nThis previous example represents the $n$th Root Theorem that says:\nIf $n$ is a positive integer, $r$ is a positive real number and $\\theta$ is in degrees, then the nonzero complex number $r (\\cos \\theta + i \\sin \\theta)$ has exactly $n$ distinct $n$th roots, given by:\n$$ \\begin{aligned} \\sqrt[n]{r} (\\cos \\alpha + i \\sin \\alpha) \\end{aligned} $$$$ \\begin{aligned} \\sqrt[n]{r} \\text{ cis } \\alpha \\end{aligned} $$where:\n$$ \\begin{aligned} \\alpha = \\frac{\\theta + 360º \\cdot k}{n}, k = 0, 1, \\cdots, n - 1 \\end{aligned} $$If $\\theta$ is in radians then:\n$$ \\begin{aligned} \\alpha = \\frac{\\theta + 2 \\pi \\cdot k}{n}, k = 0, 1, \\cdots, n - 1 \\end{aligned} $$","the-law-of-cosines-and-area-formulas#The Law of Cosines and Area Formulas":"Triangle Side Length Restriction In any triangle, the sum of the lengths of any two sides must be greater than the length of the remaining side.\nDerivation of the Law of Cosines Let $ABC$ be any oblique triangle. Let $B$ be a vertex at the origin and the side $BC$ be along the positive x-axis (Figure 10).\nLet $(x, y)$ be the coordinates of vertex $A$, then:\n$$ \\begin{aligned} \\sin B = \\frac{y}{c} \\end{aligned} $$and\n$$ \\begin{aligned} \\cos B = \\frac{x}{c} \\end{aligned} $$Such that:\n$$ \\begin{aligned} y = c \\sin B \\end{aligned} $$and\n$$ \\begin{aligned} x = c \\cos B \\end{aligned} $$So the coordiantes for $A$ become $(c \\cos B, c \\sin B)$. Point $C$ has coordinates $(a, 0)$ and $AC$ has length $b$. So if we apply the distance formula we obtain:\n$$ \\begin{aligned} b = \\sqrt{(c \\cos B - a)^2 + (c \\sin B - 0)^2} \\end{aligned} $$$$ \\begin{aligned} b^2 = (c \\cos B - a)^2 + (c \\sin B - 0)^2 \\end{aligned} $$$$ \\begin{aligned} b^2 = c^2 \\cos^2 B + a^2 - 2ac\\cos B + c^2 \\sin^2 B \\end{aligned} $$$$ \\begin{aligned} b^2 = c^2 (\\cos^2 B + \\sin^2 B) + a^2 - 2ac\\cos B \\end{aligned} $$$$ \\begin{aligned} b^2 = c^2 (1) + a^2 - 2ac\\cos B \\end{aligned} $$$$ \\begin{aligned} b^2 = c^2 + a^2 - 2ac\\cos B \\end{aligned} $$If we place $A$ or $C$ at the origin we obtain:\n$$ \\begin{aligned} a^2 = b^2 + c^2 - 2bc\\cos B \\end{aligned} $$$$ \\begin{aligned} c^2 = a^2 + b^2 - 2ab\\cos B \\end{aligned} $$How To Resolve Oblique Triangles Four cases can occur in solving an oblique triangle:\nCase 1: One side and two angles are known Use the angle sum formula ($A + B + C = 180º$)to find the remaining angle Use the law of sines to find the remaining sides Case 2: Two sides and one angle (not in-between) are known (ambiguous case, there may be no triangle, one triangle or two triangles) Use the law of sines to find an angle Use the angle sum formula to find the remaining angle Use the law of sines to find the remaining side If two triangles exist, repeat Step 2 and 3 Case 3: Two sides and the included angle are known Use the law of cosines to find the third side Use the law of sines to find the smaller of the two remaining angle Use the angle sum formula to find the remaining angle Case 4: Three sides are known Use the law of cosines to find the largest angle Use the law of sines to find either of the two remaining angles Use the angle sum formula to find the remaining angle Area Formulas Heron’s Area Formula Given a triangle with sides of length $a$, $b$ and $c$, its semiperimeter is:\n$$ \\begin{aligned} s = \\frac{1}{2}(a + b + c) \\end{aligned} $$And the area of the triangle is:\n$$ \\begin{aligned} \\mathcal{A} = \\sqrt{s(s-a)(s - b)(s - c)} \\end{aligned} $$Other Area Formula If we know the measures of two sides and the angle between them, we can find the area of the triangle. We know:\n$$ \\begin{aligned} \\mathcal{A} = \\frac{1}{2} bh \\end{aligned} $$ where $b$ is the base and $h$ is the height, that can be computed as follows:\n$$ \\begin{aligned} \\sin A = \\frac{h}{c} \\leftrightarrow h = c \\sin A \\end{aligned} $$Therefore:\n$$ \\begin{aligned} \\mathcal{A} = \\frac{1}{2}bh = \\frac{1}{2}bc \\sin A \\end{aligned} $$Since the labels for the vertices in triangle ABC could be rearranged, other area formulas can be written:\n$$ \\begin{aligned} \\mathcal{A} = \\frac{1}{2}ab \\sin C \\end{aligned} $$$$ \\begin{aligned} \\mathcal{A} = \\frac{1}{2}ac \\sin B \\end{aligned} $$","the-law-of-sines#The Law of Sines":"Derivation of the Law of Sines Given an acute triangle (Figure 1(a)) or an obtuse triangle (Figure 1(b)). We construct the perpendicular from $B$ to side $AC$. Let $h$ be the length of the perpendicular.\nThen:\n$$ \\begin{aligned} \\sin A = \\frac{h}{c} \\leftrightarrow h = c \\sin A \\end{aligned} $$$$ \\begin{aligned} \\sin C = \\frac{h}{a} \\leftrightarrow h = a \\sin C \\end{aligned} $$Since $h = c \\sin A = a \\sin C$, then:\n$$ \\begin{aligned} a \\sin C = c \\sin A \\end{aligned} $$$$ \\begin{aligned} \\frac{a}{\\sin A} = \\frac{c}{\\sin C} \\end{aligned} $$By constructing perpendicular lines from the other vertices, it can be shown that:\n$$ \\begin{aligned} \\frac{a}{\\sin A} = \\frac{b}{\\sin B} \\end{aligned} $$$$ \\begin{aligned} \\frac{b}{\\sin B} = \\frac{c}{\\sin C} \\end{aligned} $$Therefore:\n$$ \\begin{aligned} \\frac{a}{\\sin A} = \\frac{b}{\\sin B} = \\frac{c}{\\sin C} \\end{aligned} $$Ambiguous Case If we are given the length of two sides and the angle opposite to one of them then zero, one or two such triangles could exist. This is what we call the ambiguous case.\nTo solve this type of triangle we make use of the following facts:\nFor any angle $\\theta$ of a triangle, $0 \u003c \\sin \\theta \\leq 1$. Given an angle $\\theta$ on the triangle where $\\sin \\theta = 1$, then $\\theta = 90º$ and the triangle is a right triangle. For any angle $\\theta$ it follows $\\sin \\theta = \\sin (180º - \\theta)$ The smallest angle is opposite the shortest side, the largest angle is opposite the longest side and the midle-valued angle is opposite the intermediate side. We know that if $A$ is acute then there are four possible outcomes, whilst if $A$ is obtuse there are two possible outcomes.\nWhen $A$ is acute we define the following cases, after applying the law of sines:\nIf $\\sin B \u003e 1$ and $a \u003c h\u003c b$ then there are $0$ possible triangles, as the range of $\\sin$ is $[-1, 1]$. If $\\sin B = 1$ and $a = b$ and $h \u003c b$ then there is $1$ possible triangle. If $0 \u003c \\sin B \u003c 1$ and $a \\leq b$ there is $1$ possible triangle. If $0 \u003c \\sin B_1 \u003c 1$, $h \u003c a \u003c b$, there is $1$ possible triangle. Note that $\\sin B_1 = \\sin (180º - B_1)$, so if if, $A + B_2 \u003c 180º$ (which means there is a $C$ such that $A + B_2 + C = 180º$) then there is another possible triangle. When $A$ is obtuse we define the following cases, after applying the law of sines:\nIf $\\sin B \\geq 1$ and $a \\leq b$, then there are zero possible triangles as the range of $\\sin$is $[-1, 1]$. If $0 \u003c \\sin B \u003c 1$ and $a \u003e b$ then there is one possible triangle. ","trigonometric-polar-form-of-complex-numbers#Trigonometric (Polar) Form of Complex Numbers":"The Complex Plane and Vector Representation To graph a complex number we modify the rectangular coordinate system by calling the horizontal axis the real axis and the vertical axis the imaginary axis, such that we obtain the complex plane (Figure 46).\nEach complex number $a + bi$ determines a unique position vector $\\textbf{OP}$ with initial point $(0, 0)$ and terminal point $(a, b)$.\nTrigonometric (Polar) Form The next figure shows the complex number $x + yi$ that corresponds to a vector $\\textbf{OP}$ with direction angle $\\theta$ and magnitude $r$, such that:\n$$ \\begin{aligned} x = r \\cos \\theta \\end{aligned} $$$$ \\begin{aligned} y = r \\sin \\theta \\end{aligned} $$$$ \\begin{aligned} r = \\sqrt{x^2 + y^2} \\end{aligned} $$$$ \\begin{aligned} \\tan \\theta = \\frac{y}{x}, x \\neq 0 \\end{aligned} $$If we substitute $x = r \\cos \\theta$ and $y = r \\sin \\theta$ into $x + yi$ it gives:\n$$ \\begin{aligned} x + yi = r \\cos \\theta + r \\sin \\theta i \\end{aligned} $$$$ \\begin{aligned} = r (\\cos \\theta + i \\sin \\theta) \\end{aligned} $$This is called the trigonometric form (or polar form) of the complex number $x + yi$.\nThe expression $\\cos \\theta + i \\sin \\theta$ is sometimes abbreviated $\\text{cis} \\theta$, therefore $r(\\cos \\theta + i \\sin \\theta) = r \\text{cis} \\theta$\nThe number $r$ is the modulus or absolute value of $x + yi$ and $\\theta$ is the argument of $x + yi$.\nConverting from Rectangular to Trigonometric Form Sketch a graph of the number $x + yi$ in the complex plane. Find $r$ by using the equation $r = \\sqrt{x^2 + y^2}$. Find $\\theta$ by using th equation $\\tan \\theta = \\frac{y}{x}, x \\neq 0$ choosing the quadrant indicated in (1). A fractal is a geometric figure with an endless self-similarity property. A fractal image repeats itself infinitely with ever decreasing dimensions.\nProduc Theorem Given two complex number $x + yi$ and $a + bi$ such that their trigonometric form is given by:\n$$ \\begin{aligned} x + yi = r(\\cos \\theta + i \\sin \\theta) \\end{aligned} $$and\n$$ \\begin{aligned} a + bi = n(\\cos \\phi + i \\sin \\phi) \\end{aligned} $$If we multiply their trigonometric forms we obtain:\n$$ \\begin{aligned} [r(\\cos \\theta + i \\sin \\theta)][n(\\cos \\phi + i \\sin \\phi)] \\end{aligned} $$$$ \\begin{aligned} = r \\cdot n (\\cos \\theta + i \\sin \\theta)(\\cos \\phi + i \\sin \\phi) \\end{aligned} $$$$ \\begin{aligned} = r \\cdot n (\\cos \\theta \\cdot \\cos \\phi + i \\sin \\theta \\cdot \\cos \\phi + \\cos \\theta \\cdot i \\sin \\phi + i^2 \\sin \\theta \\cdot \\sin \\phi) \\end{aligned} $$We know that $i^2 = -1$, and we factor out $i$.\n$$ \\begin{aligned} = r \\cdot n (\\cos \\theta \\cdot \\cos \\phi + (-1) \\sin \\theta \\cdot \\sin \\phi + i (\\sin \\theta \\cdot \\cos \\phi + \\cos \\theta \\cdot \\sin \\phi)) \\end{aligned} $$$$ \\begin{aligned} = r \\cdot n (\\cos \\theta \\cdot \\cos \\phi - \\sin \\theta \\cdot \\sin \\phi + i (\\sin \\theta \\cdot \\cos \\phi + \\cos \\theta \\cdot \\sin \\phi)) \\end{aligned} $$Given $\\cos \\theta \\cdot \\cos \\phi - \\sin \\theta \\cdot \\sin \\phi = \\cos (\\theta + \\phi)$ and $\\sin \\theta \\cdot \\cos \\phi + \\cos \\theta \\cdot \\sin \\phi = \\sin (\\theta + \\phi)$\n$$ \\begin{aligned} = r \\cdot n (\\cos (\\theta + \\phi) + i \\sin (\\theta + \\phi)) \\end{aligned} $$In compact form this is written:\n$$ \\begin{aligned} = r \\cdot n \\text{cis} (\\theta + \\phi) \\end{aligned} $$Quotient Theorem Given two complex number $x + yi$ and $a + bi$ such that their trigonometric form is given by:\n$$ \\begin{aligned} x + yi = r(\\cos \\theta + i \\sin \\theta) \\end{aligned} $$and\n$$ \\begin{aligned} a + bi = n(\\cos \\phi + i \\sin \\phi) \\end{aligned} $$If we divide them we obtain:\n$$ \\begin{aligned} \\frac{x + yi}{a + bi} = \\frac{(x + yi)(a - bi)}{(a + bi)(a - bi)} \\end{aligned} $$$$ \\begin{aligned} = \\frac{ax + ayi - bxi -ybi^2}{a^2 - b^2i^2} = \\frac{ax + ayi - bxi + yb}{a^2 + b^2} \\end{aligned} $$$$ \\begin{aligned} = \\frac{a(x + yi) + b(y - xi)}{a^2 + b^2} \\end{aligned} $$If we substitute their trigonometric forms, knowing that $a = n \\cdot \\cos \\phi$, $b = n \\cdot \\sin \\phi$, $x = r \\cdot \\cos \\theta$ and $y = r \\cdot \\sin \\theta$, then\n$$ \\begin{aligned} = \\frac{(n \\cdot \\cos \\phi)(r \\cdot \\cos \\theta + i \\cdot r \\cdot \\sin \\theta) + (n \\cdot \\sin \\phi)(r \\cdot \\sin \\theta - i \\cdot r \\cdot \\cos \\theta)}{(n \\cdot \\cos \\phi)^2 + (n \\cdot \\sin \\phi)^2} \\end{aligned} $$We extract $n$ and $r$ as common factors and we expand the denominator:\n$$ \\begin{aligned} = \\frac{n \\cdot r [\\cos \\phi \\cdot (\\cos \\theta + i \\cdot \\sin \\theta) + \\sin \\phi \\cdot (\\sin \\theta - i \\cdot \\cos \\theta)]}{n^2 (\\cos^2 \\phi + \\sin^2 \\phi)} \\end{aligned} $$We know that $\\cos^2 x + \\sin^2 x = 1$. We multiply the elements on the numerator:\n$$ \\begin{aligned} = \\frac{n \\cdot r (\\cos \\phi \\cdot \\cos \\theta + i \\cdot \\cos \\phi \\cdot \\sin \\theta + \\sin \\phi \\cdot \\sin \\theta - i \\sin \\phi \\cdot \\cos \\theta)}{n^2} \\end{aligned} $$We rearrange the elements on the numerator and extract $i$ as a common factor:\n$$ \\begin{aligned} = \\frac{n \\cdot r [\\cos \\theta \\cdot \\cos \\phi + \\sin \\theta \\cdot \\sin \\phi + i \\cdot (\\sin \\theta \\cdot \\cos \\phi - \\sin \\phi \\cdot \\cos \\theta)]}{n^2} \\end{aligned} $$Given that $\\cos \\theta \\cdot \\cos \\theta + \\sin \\theta \\cdot \\sin \\phi = \\cos (\\theta - \\phi)$ and $\\sin \\theta \\cdot \\cos \\phi - \\sin \\phi \\cdot \\cos \\theta = \\sin (\\theta - \\phi)$:\n$$ \\begin{aligned} = \\frac{n \\cdot r (\\cos (\\theta - \\phi) + i \\cdot \\sin (\\theta - \\phi))}{n^2} \\end{aligned} $$$$ \\begin{aligned} = \\frac{r}{n} (\\cos (\\theta - \\phi) + i \\cdot \\sin (\\theta - \\phi)) \\end{aligned} $$In compact form this is written:\n$$ \\begin{aligned} = \\frac{r}{n} \\text{cis} (\\theta - \\phi) \\end{aligned} $$","vectors-and-their-applications#Vectors and Their Applications":"Basic Terminology Vector quantitites are defined by their magnitude and their direction. They are represented by a directed line segment, called a vector, whose length represents the magnitude.\nWhen two letters (i.e. OP) name a vector, the first indicates the initial point, while the second one indicates the terminal point. The magnitude of a vector $\\textbf{OP}$ is written $|\\textbf{OP}|$\nTwo vectors are equal if and only if they both have the same direction and the same magnitude.\nThe sum of two vectors is also a vector. There are two ways to geometrically find the sum of two vectors $\\textbf{A}$ and $\\textbf{B}$.\nPlace the initial point of vector $\\textbf{B}$ at the terminal point of vector $\\textbf{A}$ (Figure 22). The vector with the same initial point as $\\textbf{A}$ and the same terminal point as $\\textbf{B}$ is the sum $\\textbf{A} + \\textbf{B}$ Use the parallelogram rule. Place vectors $\\textbf{A}$ and $\\textbf{B}$ so that their initial points coincide (Figure 23). Then complete the parallelogram. The diagonal of the parallelogram with the same initial point as $\\textbf{A}$ and $\\textbf{B}$ is the sum $\\textbf{A} + \\textbf{B}$. Vector addition is commutative.\nFor every vector $\\textbf{v}$ there is a vector $-\\textbf{v}$ that has the same magnitude as $\\textbf{v}$ but opposite direction, and is called the opposite of $\\textbf{v}$ (Figure 24). The sum of $\\textbf{v}$ and $-\\textbf{v}$ hsa magnitude $0$ and is called the zero vector.\nTo substract vector $\\textbf{B}$ from vector $\\textbf{A}$ find the vector sum $\\textbf{A} + (-\\textbf{B})$ (Figure 25).\nThe product of a scalar $k$ and a vector $\\textbf{u}$ is called scalar multiplication. The vector $k\\textbf{u}$ has magnitude $k|\\textbf{u}|$. The vector $k\\textbf{u}$ has the same direction as $\\textbf{u}$ if $k \u003e 0$ and opposite direction if $k \u003c 0$ (Figure 26).\nInterpretation of Vectors A vector with its initial point at the origin in a rectrangular coordinate system is called a position vector. The position vector $\\textbf{u}$ with its endpoint at the point $(a, b)$ is written $\\langle a, b \\rangle$. Every vector in the real plane corresponds to an ordered pair of real numbers. Geometrically a vector is a directed line segment and algebraically it is an ordered pair, where $a$ is the horizontal component and $b$ is the vertical component of vector $\\textbf{u}$.\nFigure 27 shows the vector $\\textbf{u} = \\langle a, b \\rangle$. The positive angle between the x-axis and the position vector is called the direction angle of the vector.\nThe maginutde of vector $\\textbf{u} = \\langle a, b \\rangle$ is given by:\n$$ \\begin{aligned} |\\textbf{u}| = \\sqrt{a^2 + b^2} \\end{aligned} $$The direction angle $\\theta$ satisfies $\\tan \\theta = \\frac{b}{a}$ where $a \\neq 0$.\nA vector $\\textbf{u}$ with magnitude $|\\textbf{u}|$ and direction angle $\\theta$ has as horizontal component:\n$$ \\begin{aligned} a = |\\textbf{u}| \\cos \\theta \\end{aligned} $$and as vertical component:\n$$ \\begin{aligned} b = |\\textbf{u}| \\sin \\theta \\end{aligned} $$Therefore $\\textbf{u} = \\langle a, b \\rangle = \\langle |\\textbf{u}| \\cos \\theta, |\\textbf{u}| \\sin \\theta \\rangle$\nProperties of Parallelograms A parallelogram is quadrilateral whose opposite sides are parallel The opposite sides and opposite angles of a parallelogram are equal, and adjacent angles of a parallelogram are supplementary. The diagonals of a parallelogram bisect each other, but do not necessarily bisec the angles of the parallelogram. Vector Operations Let $a, b, c, d$ and $k$ be real numbers:\n$$ \\begin{aligned} \\langle a, b \\rangle + \\langle c, d \\rangle = \\langle a + c, b + d \\rangle \\end{aligned} $$$$ \\begin{aligned} k\\langle a, b \\rangle = \\langle ka, kb \\rangle \\end{aligned} $$$$ \\begin{aligned} \\langle a, b \\rangle - \\langle c, d \\rangle= \\langle a, b \\rangle + -\\langle c, d \\rangle = \\langle a - c, b - d \\rangle \\end{aligned} $$A unit vector is a vector that has magnitude $1$. Two important unit vectors are:\n$$ \\begin{aligned} \\textbf{i} = \\langle 1, 0 \\rangle \\end{aligned} $$$$ \\begin{aligned} \\textbf{j} = \\langle 0, 1 \\rangle \\end{aligned} $$ Vector Notation Using $i$ and $j$ If $\\textbf{v} = \\langle a, b \\rangle$ then $\\textbf{v} = a \\textbf{i} + b \\textbf{j}$\nDot Product and the Angle between Vectors The dot product (or inner product) of two vectors $\\textbf{u} = \\langle a, b \\rangle$ and $\\textbf{v} = \\langle c, d \\rangle$ id denoted as $\\textbf{u} \\cdot \\textbf{v}$ and given by the following:\n$$ \\begin{aligned} \\textbf{u} \\cdot \\textbf{v} = ac + bd \\end{aligned} $$Properties of the Dot Product For all vectors $\\textbf{u}$, $\\textbf{v}$ and $\\textbf{w}$ and real numbers $k$ the following hold:\n$\\textbf{u} \\cdot \\textbf{v} = \\textbf{v} \\cdot \\textbf{u}$ $\\textbf{u} \\cdot (\\textbf{v} + \\textbf{w}) = \\textbf{u} \\cdot \\textbf{v} + \\textbf{u} \\cdot \\textbf{w}$ $(\\textbf{u} + \\textbf{v}) \\cdot \\textbf{w} = \\textbf{u} \\cdot \\textbf{w} + \\textbf{v} \\cdot \\textbf{w}$ $(k \\textbf{u}) \\cdot \\textbf{v} = k(\\textbf{u} \\cdot \\textbf{v}) = \\textbf{u} \\cdot (k \\textbf{v})$ $0 \\cdot \\textbf{u} = 0$ $\\textbf{u} \\cdot \\textbf{u} = |\\textbf{u}|^2$ The dot product of two vectors can be positive, $0$ or negative based on the angle between them.\nIf $\\textbf{a} \\cdot \\textbf{b} = 0$ for two nonzero vectors $\\textbf{a}$ and $\\textbf{b}$, then $\\cos \\theta = 0$ and $\\theta = 90º$. Thus $\\textbf{a}$ and $\\textbf{b}$ are perpendiular or orthogonal vectors (Figure 40).\nGeometric Interpretation of the Dot Product If $\\theta$ is the angle between the two nonzero vectors $\\textbf{u}$ and $\\textbf{v}$, where $0º \\leq \\theta \\leq 180º$ then the following holds:\n$$ \\begin{aligned} \\textbf{u} \\cdot \\textbf{v} = |\\textbf{u}||\\textbf{v}| \\cos \\theta \\end{aligned} $$or equivalently\n$$ \\begin{aligned} \\cos \\theta = \\frac{\\textbf{u}\\textbf{v}}{|\\textbf{u}||\\textbf{v}|} \\end{aligned} $$ For angles $\\theta$ between $0º$ and $180º$, the following table shows the relationship between $\\cos \\theta$, the dot product and $\\theta$.\n| $\\cos \\theta$ | Dot Product | Angle $\\theta$ between Vectors | | Positive | Positive | Acute | | $0$ | $0$ | Right | | Negative | Negative | Obtuse |"},"title":"Applications of Trigonometry and Vectors"},"/notes/math/agaa/11_further_topics/":{"data":{"":"","arithmetic-sequences-and-series#Arithmetic Sequences and Series":"Arithmetic Sequences A sequence in which each term after the first is obtained by adding a fixed number, the common difference $d$, to a previous term is an arithmetic sequence (or arithmetic progression). The common difference is obtained as:\n$$ \\begin{aligned} d = a_{n + 1} - a_n \\end{aligned} $$In an arithmetic sequence with first term $a_1$ and common difference $d$, the $n$th term is:\n$$ \\begin{aligned} a_n = a_1 + (n - 1)d \\end{aligned} $$To obtain the graph for that sequence:\n$$ \\begin{aligned} a_n = a_1 + (n - 1)d \\end{aligned} $$$$ \\begin{aligned} = a_1 + dn - d \\end{aligned} $$$$ \\begin{aligned} = dn + (a_1 - d) \\end{aligned} $$$$ \\begin{aligned} = dn + c \\end{aligned} $$where $c = a_1 - d$. Such that the points on the graph of an arithmetic sequence $f$ are defined by $f(n) = dn + c$. The following image shows such a graph:\nArithmetic Series The sum of the terms of an arithmetic sequence is an arithmetic series. To obtain the general formula for the arithmetic series we first write the sum of the first $n$ terms as:\n$$ \\begin{aligned} S_n = a_1 + (a_1 + d) + (a_1 + 2d) + \\cdots + (a_1 + (n - 1)d) \\end{aligned} $$Now we write the same sum in reverse order, beginnin with $a_n$ and substracting $d$:\n$$ \\begin{aligned} S_n = a_n + (a_n - d) + (a_n - 2d) + \\cdots + (a_n - (n - 1)d) \\end{aligned} $$Now we add both expressions:\n$$ \\begin{aligned} 2 S_n = (a_1 + a_n) + (a_1 + a_n) + \\cdots + (a_1 + a_n) \\end{aligned} $$$$ \\begin{aligned} 2 S_n = n(a_1 + a_n) \\end{aligned} $$$$ \\begin{aligned} S_n = \\frac{n}{2}(a_1 + a_n) \\end{aligned} $$$$ \\begin{aligned} S_n = \\frac{n}{2}(a_1 + a_1 + (n-1)d) \\end{aligned} $$$$ \\begin{aligned} S_n = \\frac{n}{2}(2a_1 + (n-1)d) \\end{aligned} $$","counting-theory#Counting Theory":"Fundamental Principle of Counting Two events are independent events if neither influences the outcome of the other.\nIf $n$ independent events take place, with:\n$$ \\begin{aligned} \\begin{matrix} m_1 \\text{ ways for event } 1 \\text{ to occur}, \\\\ m_2 \\text{ ways for event } 2 \\text{ to occur}, \\\\ \\cdot \\\\ \\cdot \\\\ \\cdot \\\\ m_n \\text{ ways for event } n \\text{ to occur}, \\\\ \\end{matrix} \\end{aligned} $$then there are:\n$$ \\begin{aligned} m_1 \\times m_2 \\times \\cdots \\times m_n \\end{aligned} $$different ways for all $n$ events to occur.\nn-Factorial For any positive integer $n$:\n$$ \\begin{aligned} n! = n(n-1)(n-2)\\cdots (3)(2)(1) \\end{aligned} $$By definition $0! = 1$.\nPermutations A permutation of $n$ elements taken $r$ at a time if one of the possible orderings of $r$ elements from a set of $n$ elements. The number of permutations of $r$ elements on a set of $n$ elements its denoted by $P(n, r)$ and is calculated as follows:\n$$ \\begin{aligned} P(n, r) = n(n - 1)(n - 2)(n - r + 1) \\end{aligned} $$$$ \\begin{aligned} = \\frac{n(n - 1)(n - 2)(n - r + 1)(n - r)(n - r - 1) \\cdots (2)(1)}{(n - r)(n - r - 1)\\cdots (2)(1)} \\end{aligned} $$$$ \\begin{aligned} = \\frac{n!}{(n - r)!} \\end{aligned} $$Altenative notations for $P(n, r)$ are $P^n_r$ and ${n}P{r}$.\nCombinations A subset of items selected without regard to order is called a combination.\nTo evaluate $C(n, r)$, we start with the number of permutations, given by $P(n, r)$. To get rid of the repeat orderings we divide by $r!$ (the number of ways to oder the subset of $r$ elements). Such that the number of combinations of $n$ elements taken $r$ at a time is obtained as:\n$$ \\begin{aligned} C(n, r) = \\frac{P(n, r)}{r!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{n!}{(n - r)!r!} \\end{aligned} $$Altenative notations for $C(n, r)$ are $C^n_r$ and ${n}C{r}$.","geometric-sequences-and-series#Geometric Sequences and Series":"Geometric Sequences A geometric sequence (or geometric progression) is a sequence in which each term after the first is obtained by multiplying the preceding term by a constant non-zero real number, called the common ratio $r$. That is:\n$$ \\begin{aligned} r = \\frac{a_{n+1}}{a_n} \\end{aligned} $$In a geometric sequence with first term $a_1$ and common ratio $r$, where neither of them are zero, then the $n$th term is:\n$$ \\begin{aligned} a_n = a_1 r^{n-1} \\end{aligned} $$Geometric Series A geometric series is the sum of the terms of a geometric sequence. To find a formula of the sum $S_n$ first we write the sum as follows:\n$$ \\begin{aligned} S_n = a_1 + a_2 + \\cdots + a_n \\end{aligned} $$$$ \\begin{aligned} = a_1 + a_1 r + \\cdots + a_1 r^{n-1} \\end{aligned} $$We multiply each side of the equation by $r$\n$$ \\begin{aligned} rS_n = a_1r + a_1 r^2 + \\cdots + a_1 r^{n} \\end{aligned} $$And now we substract these two equations:\n$$ \\begin{aligned} S_n - rS_n = a_1 + (a_1r - a_1r) + (a_1 r^2 - a_1 r^2) + \\cdots + (a_1 r^{n-1} - a_1 r^{n-1}) - a_1 r^{n} \\end{aligned} $$$$ \\begin{aligned} S_n - rS_n = a_1 - a_1 r^{n} \\end{aligned} $$$$ \\begin{aligned} S_n (1 - r) = a_1 - a_1 r^{n} \\end{aligned} $$$$ \\begin{aligned} S_n = \\frac{a_1 - a_1 r^{n}}{1 - r}, r \\neq 1 \\end{aligned} $$Infinite Geometric Series If a geometric sequence has first term $a_1$ and common ratio $r$, then:\n$$ \\begin{aligned} S_n = \\frac{a_1 - a_1 r^{n}}{1 - r}, r \\neq 1 \\end{aligned} $$$$ \\begin{aligned} S_n = \\frac{a_1(1 - r^{n})}{1 - r}, r \\neq 1 \\end{aligned} $$If $|r| \u003c 1$, then $\\lim_{n \\rightarrow \\infty}r^n = 0$ and\n$$ \\begin{aligned} \\lim_{n \\rightarrow \\infty} S_n = \\frac{a_1(1 - 0)}{1 - r} = \\frac{a_1}{1 - r} \\end{aligned} $$The quotient $\\frac{a_1}{1 - r}$ is called the sum of the term of an infinite geometric sequence. The limit $\\lim_{n \\rightarrow \\infty} S_n$ can be expressed as $S_{\\infty}$ or $\\sum_{i=1}^{\\infty} a_i$.","mathematical-induction#Mathematical Induction":"Principle of Mathematical Induction Let $S_n$ be a statement concerning the positive integer $n$. Suppose that both of the following hold:\n$S_1$ is true. For any positive integer $k$, $k \\leq n$ if $S_k$ is true, then $S_{k+1}$ is also true. Then $S_n$ is true for every positive integer $n$.\nMethod of Proof by Mathematical Induction Prove that the statement is true for $n = 1$. Show that for any positive integer $k$, if $S_k$ is true then $S_{k+1}$ is also true. Generalized Principle of Mathematical Induction Let $S_n$ be a statement concerning the positive integer $n$. Let $j$ be a fixed positive integer. Suppose that both of the following hold.\n$S_j$ is true. For any positive integer $k$, $k \\geq j$, $S_k$ implies $S_{k+1}$ Then $S_n$ is true for all positive integers $n$, where $n \\geq j$.\nProof of the Binomial Theorem The binomial theorem can be proved by mathematical induction. That is, for any positive integer $n$ and any numbers $x$ and $y$,\n$$ \\begin{aligned} (x + y)^n = x^n + \\binom{n}{1} x^{n-1}y + \\binom{n}{2} x^{n-2}y^2 + \\cdots + \\binom{n}{r} x^{n - r}y^r + \\cdots + \\binom{n}{n-1}xy^{n-1} + y^n \\end{aligned} $$Proof Let $S_n$ be the previous statement. Begin by verifying $S_n$ for $n = 1$.\n$$ \\begin{aligned} (x + y)^{n=1} = x + y = \\binom{1}{0}x^1y^0 + \\binom{1}{1} x^0y^1 \\end{aligned} $$Now we assume $S_k$, such that:\n$$ \\begin{aligned} (x + y)^k = x^k + \\frac{k!}{1!(k - 1)!} x^{k-1}y + \\frac{k!}{2!(k - 2)!} x^{k-2}y^2 + \\cdots + \\frac{k!}{r!(k - r)!} x^{k - r}y^r + \\cdots + \\frac{k!}{(k - 1)!1!}xy^{k-1} + y^k \\end{aligned} $$We multiply the left side by $(x + y)$:\n$$ \\begin{aligned} (x + y)(x + y)^k = x(x + y)^k + y(x + y)^k \\end{aligned} $$And we apply $S_k$\n$$ \\begin{aligned} x(x + y)^k + y(x + y)^k = x\\left[x^k + \\frac{k!}{1!(k - 1)!} x^{k-1}y + \\frac{k!}{2!(k - 2)!} x^{k-2}y^2 + \\cdots + \\frac{k!}{r!(k - r)!} x^{k - r}y^r + \\cdots + \\frac{k!}{(k - 1)!1!}xy^{k-1} + y^k\\right] + y \\left[x^k + \\frac{k!}{1!(k - 1)!} x^{k-1}y + \\frac{k!}{2!(k - 2)!} x^{k-2}y^2 + \\cdots + \\frac{k!}{r!(k - r)!} x^{k - r}y^r + \\cdots + \\frac{k!}{(k - 1)!1!}xy^{k-1} + y^k\\right] \\end{aligned} $$$$ \\begin{aligned} = \\left[x^{k + 1} + \\frac{k!}{1!(k - 1)!} x^{k}y + \\frac{k!}{2!(k - 2)!} x^{k-1}y^2 + \\cdots + \\frac{k!}{r!(k - r)!} x^{k - r + 1}y^r + \\cdots + \\frac{k!}{(k - 1)!1!}x^2y^{k-1} + xy^k\\right] + \\left[yx^k + \\frac{k!}{1!(k - 1)!} x^{k-1}y^2 + \\frac{k!}{2!(k - 2)!} x^{k-2}y^3 + \\cdots + \\frac{k!}{r!(k - r)!} x^{k - r}y^{r + 1} + \\cdots + \\frac{k!}{(k - 1)!1!}xy^{k} + y^{k+1}\\right] \\end{aligned} $$Now we group the elements with the same terms:\n$$ \\begin{aligned} = x^{k+1} + \\left[\\frac{k!}{1!(k - 1)!} x^{k}y + \\frac{k!}{0!k!} yx^k \\right] + \\left[\\frac{k!}{2!(k - 2)!} x^{k-1}y^2 + \\frac{k!}{1!(k - 1)!} x^{k-1}y^2 \\right] + \\cdots + \\left[\\frac{k!}{r!(k - r)!} x^{(k - r) + 1}y^r + \\frac{k!}{(r - 1)!(k - (r - 1))!}x^{(k - r) + 1}y^{r} \\right] + \\cdots + y^{k + 1} \\end{aligned} $$We first show that:\n$$ \\begin{aligned} \\frac{k!}{r!(k - r)!} + \\frac{k!}{(r + 1)!(k - (r + 1))!} = \\binom{k + 1}{r + 1} \\end{aligned} $$By the definition of the factorial of a number:\n$$ \\begin{aligned} = \\frac{k (k - 1) (k - 2) \\cdots (k - r) \\cdots 1}{(r + 1)!(k - r - 1)!} + \\frac{k (k - 1) (k - 2) \\cdots (k - r + 1) \\cdots 1}{r!(k - r)!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{k (k - 1) (k - 2) \\cdots (k - r)}{(r + 1)!} + \\frac{k (k - 1) (k - 2) \\cdots (k - r - 1)}{r!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{k (k - 1) (k - 2) \\cdots (k - r)}{(r + 1)!} + (r + 1)\\frac{k (k - 1) (k - 2) \\cdots (k - r + 1)}{(r + 1)!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{k(k - 1)(k - 2) \\cdots (k - r - 1) \\left[(k - r) + (r + 1)\\right]}{(r + 1)!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{k(k - 1)(k - 2) \\cdots (k - r - 1) \\left[k + 1\\right]}{(r + 1)!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{(k + 1)k(k - 1)(k - 2) \\cdots (k - r - 1)}{(r + 1)!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{(k + 1)k(k - 1)(k - 2) \\cdots (k - r - 1) \\cdots 1}{(r + 1)!(k - r)!} \\end{aligned} $$$$ \\begin{aligned} = \\frac{(k + 1)!}{(r + 1)!((k + 1) - (r + 1))!} \\end{aligned} $$$$ \\begin{aligned} = \\binom{k + 1}{r + 1} \\end{aligned} $$So now:\n$$ \\begin{aligned} = x^{k+1} + \\left[\\frac{k!}{1!(k - 1)!} + \\frac{k!}{0!k!}\\right] x^{k}y + \\left[\\frac{k!}{2!(k - 2)!} + \\frac{k!}{1!(k - 1)!} \\right] x^{k-1}y^2 + \\cdots + \\left[\\frac{k!}{r!(k - r)!} + \\frac{k!}{(r - 1)!(k - (r - 1))!} \\right] x^{(k - r) + 1} y^r + \\cdots + y^{k + 1} \\end{aligned} $$By the previous proof $\\frac{k!}{r!(k - r)!} + \\frac{k!}{(r + 1)!(k - (r + 1))!} = \\binom{k + 1}{r + 1}$, therefore:\n$$ \\begin{aligned} = x^{k+1} + \\binom{k + 1}{1} x^{k}y + \\binom{k + 1}{2} x^{k-1}y^2 + \\cdots + \\binom{k + 1}{r!} x^{(k - r) + 1} y^r + \\cdots + y^{k + 1} \\end{aligned} $$$$ \\begin{aligned} = x^{k+1} + \\binom{k + 1}{1} x^{(k + 1) - 1}y + \\binom{k + 1}{2} x^{(k + 1) - 2}y^2 + \\cdots + \\binom{k + 1}{r} x^{(k + 1) - r} y^r + \\cdots + y^{k + 1} \\end{aligned} $$$$ \\begin{aligned} = \\sum_{r = 0}^{k + 1} \\binom{k + 1}{r}x^{(k + 1) - r}y^r \\end{aligned} $$","probability#Probability":"Basic Concepts Given an experiment that has one or more outcomes that are equally likely to occur. Then the set $S$ of all possible outcomes of a given experiment is called the sample space for the experiment. For example, the sample space for the experiment of tossing a consists of the outcomes $H$ (heads) and $T$ (tails). This can be written in set notation as:\n$$ \\begin{aligned} S = \\{H, T\\} \\end{aligned} $$Any subset of the sample space is called an event. To represent the number of outcomes that belong to event $E$ we use the notation $n(E)$.\nThe notation $P(E)$ is used for the probability of an event $E$.\nProbability of Event E In a sample space with equally likely outcomes, the probability of an event $E$, written $P(E)$ is given by:\n$$ \\begin{aligned} P(E) = \\frac{n(E)}{n(S)} \\end{aligned} $$where $n(E)$ is the number of outcomes in sample space $S$ that belong to event $E$, and $n(S)$ is the total number of outcomes in sample space $S$.\nComplements and Venn Diagrams The set of all outcomes in the sample space that do not belong to event $E$ is called the complement of $E$, written $E’$. By definition:\n$$ \\begin{aligned} E \\cup E' = S \\end{aligned} $$$$ \\begin{aligned} E \\cap E' = \\emptyset \\end{aligned} $$Probability concepts can be illustrated using Venn Diagrams, as shown in FIGURE 23.\nOdds The odds in favor of an event $E$ are expressed as the ratio of $P(E)$ to $P(E’)$, or as the fraction $\\frac{P(E)}{P(E’)}$.\nIf the odds favoring event $E$ are $m$ to $n$, then:\n$$ \\begin{aligned} P(E) = \\frac{m}{m + n} \\end{aligned} $$and\n$$ \\begin{aligned} P(E') = \\frac{n}{m + n} \\end{aligned} $$Union of Two Events Two events $H$ and $K$ that cannot occur simultaneously are said to be mutually exclusive, therefore $H \\cap K = \\emptyset$ is always true. This suggests the following proprety:\nFor any events $E$ and $F$:\n$$ \\begin{aligned} P(E \\text{ or } F) = P(E \\cup F) = P(E) + P(F) - P(E \\cap F) \\end{aligned} $$Properties of Probability For any events $E$ and $F$ the following hold:\n$0 \\leq P(E) \\leq 1$ $P(\\text{a certain event}) = 1$ $P(\\text{an impossible event}) = 0$ $P(E’) = 1 - P(E)$ $P(E \\text{ or } F) = P(E \\cup F) = P(E) + P(F) - P(E \\cap F)$ Binomial Probability An experiment that consists of repeated independent trials, which only has two outcomes (success and failure) is called a binomial experiment.\nLet the probability of success in one trial be $p$, such that the probability of failure becomes $1 - p$. Then the probability of $r$ successes in $n$ trials is:\n$$ \\begin{aligned} \\binom{n}{r} p^r (1 - p)^r \\end{aligned} $$","sequences-and-series#Sequences and Series":"Sequences A sequence is a function that has a set of natural numbers as its domain.\nInstead of using a funcion notation to indicate a sequence $f$, we use $a_n$, where $a_n = f(n)$.\nThe elements in the range of a sequence are called the terms of the sequence, and they are ordered.\nThe general term of the $n$th term of the sequence is $a_n$.\nA sequence is a finite sequence if the domain is a finite set ${1, 2, 3, 4, \\cdots, n}$, where $n$ is a natural number. An infinite sequence has the set of a ll natural numbers as its domain.\nIf the terms of an infinite sequence get closer to some real number, the sequence is said to be convergent and to converge to that real number (see Figure 3). A sequence that does not converte to some number is divergent.\nSome sequences are defined by a recursive definition, a definition in which each term is defined as an expression involving the previous term or terms.\nSeries The sum of the terms of a sequence is called a series.\nA finite series is an expression of the form:\n$$ \\begin{aligned} S_n = a_1 + a_2 + a_3 + \\cdots + a_n = \\sum_{i=1}^n a_i \\end{aligned} $$An infinite series is an expression of the form:\n$$ \\begin{aligned} S_{\\infty} = a_1 + a_2 + a_3 + \\cdots + a_n + \\cdots = \\sum_{i=1}^{\\infty} a_i \\end{aligned} $$Summation Properties If $a_1, a_2, a_3, \\cdots, a_n$ and $b_1, b_2, b_3, \\cdots, b_n$ are two sequences, and $c$ is a constante, then for every positive integer $n$, the following hold:\n$$ \\begin{aligned} \\sum_{i=1}^n c = n c \\end{aligned} $$$$ \\begin{aligned} \\sum_{i=1}^n ca_i = c \\sum_{i=1}^n a_i \\end{aligned} $$$$ \\begin{aligned} \\sum_{i=1}^n (a_i + b_i) = \\sum_{i=1}^n a_i + \\sum_{i=1}^n b_i \\end{aligned} $$$$ \\begin{aligned} \\sum_{i=1}^n (a_i - b_i) = \\sum_{i=1}^n a_i - \\sum_{i=1}^n b_i \\end{aligned} $$Summation Rules $$ \\begin{aligned} \\sum_{i=1}^n i = 1 + 2 + \\cdots + n = \\frac{n(n + 1)}{2} \\end{aligned} $$$$ \\begin{aligned} \\sum_{i=1}^n i^2 = 1^2 + 2^2 + \\cdots + n^2 = \\frac{n(n + 1)(2n + 1)}{6} \\end{aligned} $$$$ \\begin{aligned} \\sum_{i=1}^n i^3 = 1^3 + 2^3 + \\cdots + n^3 = \\frac{n^2(n + 1)^2}{4} \\end{aligned} $$","the-binomial-theorem#The Binomial Theorem":"Binomial Coefficient Generalizing, we find that the coefficient for the term of the expansion of $(x + y)^n$ in which the variable part is $x^ry^{n -r}$, where $r \\leq n$ is:\n$$ \\begin{aligned} \\binom{n}{r} = \\frac{n!}{r!(n - r)!} \\end{aligned} $$which is equivalent to $C(n ,r)$. This number is called the binomial coefficient and is often written as $\\binom{n}{r}$.\nPascal’s Triangle If we only write the coffiencients for the expansion of $(x + y)^n$ we obtain the following pattern:\nSuch that each number in the triangle is the sum of the two numbers directly above it. This triangular array of numbers is called Pascal’s Triangle.\nThe Binomial Theorem Our observations about the expansion of $(x + y)^n$ are summarized as follows:\nThere are $n + 1$ terms in the expansion. The first term is $x^n$ and the last term is $y^n$ In each term, the exponent on $x$ decreases by $1$, and the exponent on $y$ increases by $1$. The sum of the exponents on $x$ and $y$ in any term is $n$ The coefficient of the term with $x^ry^{n - r}$ o $x^{n - r}y^r$ is $\\binom{n}{r}$ From these observations the binomial theorem is derived:\nFor any positive integer $n$:\n$$ \\begin{aligned} (x + y)^n = x^n + \\binom{n}{1} x^{n-1}y + \\binom{n}{2}x^{n-2}y^2 + \\cdots + \\binom{n}{r}x^{n - r}y^r + \\cdots + \\binom{n}{n - 1}xy^{n - 1} + y^n \\end{aligned} $$$$ \\begin{aligned} (x + y)^n = \\sum_{r=0}^n \\binom{n}{r}x^{n - r}y^r \\end{aligned} $$rth Term of a Binomial Expansion The $r$th term of the binomial expansion of $(x + y)^n$, where $n \\geq r - 1$ is:\n$$ \\begin{aligned} \\binom{n}{r - 1} x^{n - (r - 1)} y^{r - 1} \\end{aligned} $$"},"title":"Further Topics in Algebra"},"/notes/math/agaa/12_appendix/":{"data":{"":"","polar-form-of-conic-sections#Polar Form of Conic Sections":"Polar Forms of Conic Sections A polar equation of the form:\n$$ \\begin{aligned} r = \\frac{ep}{1 \\pm e \\cos \\theta} \\end{aligned} $$or\n$$ \\begin{aligned} r = \\frac{ep}{1 \\pm e \\sin \\theta} \\end{aligned} $$has a conic section as its graph. The eccentricity is $e$ (where $e \u003e 0$), and $|p|$ is the distance between the pole (focus) and the directrix.\nWe can verify that those equations satisfy the definition of a conic section. Consider FIGURE 1, where the directrix is vertical and $p \u003e 0$ units to the right of the focus $F(0, 0º)$. Let $P(r, \\theta)$ be a point on the graph, then the distance between $P$ and the directrix is obtained as:\n$$ \\begin{aligned} PP' = |p - x| \\end{aligned} $$$$ \\begin{aligned} = |p - r \\cos \\theta| \\end{aligned} $$We substitute $r$ by $\\frac{ep}{1 \\pm e \\cos \\theta}$.\n$$ \\begin{aligned} = |p - \\left(\\frac{ep}{1 \\pm e \\cos \\theta} \\right) \\cos \\theta| \\end{aligned} $$$$ \\begin{aligned} = |\\frac{(1 + e \\cos \\theta) - ep\\cos \\theta}{1 \\pm e \\cos \\theta} | \\end{aligned} $$$$ \\begin{aligned} = |\\frac{p + ep \\cos \\theta - ep\\cos \\theta}{1 \\pm e \\cos \\theta}| \\end{aligned} $$$$ \\begin{aligned} = |\\frac{p}{1 \\pm e \\cos \\theta}| \\end{aligned} $$Given:\n$$ \\begin{aligned} r = \\frac{ep}{1 \\pm e \\cos \\theta} \\end{aligned} $$Then we can multiply each side by $\\frac{1}{e}$\n$$ \\begin{aligned} \\frac{r}{e} = \\frac{p}{1 \\pm e \\cos \\theta} \\end{aligned} $$We substitute this expression for $\\frac{r}{e}$:\n$$ \\begin{aligned} PP' = |\\frac{p}{1 \\pm e \\cos \\theta}| = |\\frac{r}{e}| = \\frac{|r|}{|e|} = \\frac{|r|}{e} \\end{aligned} $$Note that $e \u003e 0$, therefore $|e| = e$.\nThe distance between the pole and $P$ is $PF = |r|$, so the ratio of $PF$ to $PP’$ is:\n$$ \\begin{aligned} \\frac{PF}{PP'} = \\frac{|r|}{\\frac{|r|}{e}} = e \\end{aligned} $$Thus, by definition, the graph has eccentricity $e$ and must be a conic.\nIn the previous discussion, we assumed a vertical directrix to the right of the pole. There a re three other possible situations:\nEquation Directrix $r = \\frac{ep}{1 + e \\cos \\theta}$ vertical, $p$ units to the right of the pole $r = \\frac{ep}{1 - e \\cos \\theta}$ vertical, $p$ units to the left of the pole $r = \\frac{ep}{1 + e \\sin \\theta}$ horizontal, $p$ units above the pole $r = \\frac{ep}{1 - e \\sin \\theta}$ horizontal, $p$ units below the pole ","rotation-of-axes#Rotation of Axes":"Derivation of Rotation Equations Given a $xy$-coordinate system having origin $O$. If we rotate the axes about $O$ through an angle $\\theta$, the new coordinate system is called a rotation of the $xy$-system.\nLet $P$ be any point other than the origin, with coordinates $(x, y)$ in the $xy$-system and $(x’, y’)$ in the $x’y’$-system (See FIGURE 1). Let $OP = r$ and $\\alpha$ be the angle made by $OP$ and the $x’$ axis. Then the following holds:\n$$ \\begin{aligned} \\cos (\\theta + \\alpha) = \\frac{OA}{r} = \\frac{x}{r} \\end{aligned} $$$$ \\begin{aligned} \\sin (\\theta + \\alpha) = \\frac{AP}{r} = \\frac{y}{r} \\end{aligned} $$$$ \\begin{aligned} \\cos (\\alpha) = \\frac{OB}{r} = \\frac{x'}{r} \\end{aligned} $$$$ \\begin{aligned} \\sin (\\alpha) = \\frac{PB}{r} = \\frac{y'}{r} \\end{aligned} $$Such that we can rewrite the statements as follows:\n$$ \\begin{aligned} x = r \\cos (\\theta + \\alpha) \\end{aligned} $$$$ \\begin{aligned} y = r \\sin (\\theta + \\alpha) \\end{aligned} $$$$ \\begin{aligned} x' = r \\cos \\alpha \\end{aligned} $$$$ \\begin{aligned} y' = r \\sin \\alpha \\end{aligned} $$Therefore:\n$$ \\begin{aligned} x = r \\cos (\\theta + \\alpha) \\end{aligned} $$$$ \\begin{aligned} = r (\\cos\\theta \\cos\\alpha - \\sin\\theta \\sin \\alpha) \\end{aligned} $$$$ \\begin{aligned} = \\cos\\theta (r\\cos\\alpha) - \\sin\\theta (r\\sin \\alpha) \\end{aligned} $$$$ \\begin{aligned} = \\cos\\theta x' - \\sin\\theta y' \\end{aligned} $$The same goes for $y$\n$$ \\begin{aligned} y = r \\sin (\\theta + \\alpha) \\end{aligned} $$$$ \\begin{aligned} = r (\\sin\\theta \\cos\\alpha + \\cos\\theta \\sin \\alpha) \\end{aligned} $$$$ \\begin{aligned} = \\sin\\theta (r\\cos\\alpha) + \\cos\\theta (r\\sin \\alpha) \\end{aligned} $$$$ \\begin{aligned} = \\sin\\theta x' + \\cos\\theta y' \\end{aligned} $$Angle of Rotation The $xy$-term is removed from the standard equation:\n$$ \\begin{aligned} Ax^2 + Bxy + Cy^2 + Dx + Ey + F = 0 \\end{aligned} $$by a rotation of the axes through an angle $\\theta$, $0º \u003c \\theta \u003c 90º$, where:\n$$ \\begin{aligned} \\cot 2\\theta = \\frac{A - C}{B} \\end{aligned} $$Equations of Conics with xy-Term If the standard second-degree equation:\n$$ \\begin{aligned} Ax^2 + Bxy + Cy^2 + Dx + Ey + F = 0 \\end{aligned} $$has a graph, it will be one of the following:\nA circle or an ellipse (or a point) if $B^2 - 4AC \u003c 0$ A parabola (or one line or two parallel lines) if $B^2 - 4AC = 0$ A hyperbola (or two intersecting lines) if $B^2 - 4AC \u003e 0$ A straight line if $A = B = C = 0$ and $D \\neq 0$ or $E \\neq 0$ ","vectors-in-space#Vectors in Space":"Rectangular Coordinates in Space On a three dimensional space, we associate each point with an ordered triple $(x, y, z)$ (see FIGURE 1). The region of three-dimensional space where are coordinates are positive is called the first octant. There are eight octants in all.\nDistance Formula If $P_1(x_1, y_1, z_1)$ and $P_2(x_2, y_2, z_2)$ are two points in a three-dimensional coordinate system, then the distance between $P_1$ and $P_2$ is given by:\n$$ \\begin{aligned} d(P_1, P_2) = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2} \\end{aligned} $$Vectors in Space We denote a vector $\\textbf{v}$ in space with initial point $O$ at the origin as:\n$$ \\begin{aligned} \\textbf{v} = \\langle a, b, c \\rangle \\end{aligned} $$Using the unit vectors $\\textbf{i} = \\langle 1, 0, 0 \\rangle$, $\\textbf{j} = \\langle 0, 1, 0 \\rangle$ and $\\textbf{k} = \\langle 0, 0, 1 \\rangle$, we can represent $\\textbf{v}$ as:\n$$ \\begin{aligned} \\textbf{v} = a\\textbf{i} + b \\textbf{j} + c \\textbf{k} \\end{aligned} $$where the scalars $a$, $b$ and $c$ are the components of vector $\\textbf{v}$.\nNot all vectors are position vectors, and they are computed differently. For example, the component form of vector $\\textbf{PQ}$ is represented as follows:\n$$ \\begin{aligned} \\textbf{PQ} = \\langle x_2 - x_1, y_2 - y_1, z_2 - z_1 \\rangle \\end{aligned} $$ As FIGURE 2 suggests, $\\textbf{PQ}$ is equal to the following position vector:\n$$ \\begin{aligned} \\textbf{OR} = (x_2 - x_1)\\textbf{i} + (y_2 - y_1)\\textbf{j} + (z_2 - z_1)\\textbf{k} \\end{aligned} $$Vector Definitions and Operations If $\\textbf{v} = a\\textbf{i} + b\\textbf{j} + c\\textbf{k}$ and $\\textbf{w} = d\\textbf{i} + e \\textbf{j} + f\\textbf{k}$ are vectors and $g$ is a scalar, the following hold.\n$\\textbf{v} = \\textbf{w}$ if and only if $a = d$, $b = e$ and $c = f$. $\\textbf{v} + \\textbf{w} = (a + d)\\textbf{i} + (b + e)\\textbf{j} + (c + f)\\textbf{k}$ $\\textbf{v} - \\textbf{w} = (a - d)\\textbf{i} + (b - e)\\textbf{j} + (c - f)\\textbf{k}$ $g\\textbf{v} = ga \\textbf{i} + gb \\textbf{j} + gc \\textbf{k}$ $|\\textbf{v}| = \\sqrt{a^2 + b^2 + c^2}$ $\\textbf{v} \\cdot \\textbf{w} = ad + be + cf$ Angle between Two Vectors If $\\theta$ is the angle between two nonzero vectors $\\textbf{v}$ and $\\textbf{w}$, where $0º \\leq \\theta \\leq 180º$, then:\n$$ \\begin{aligned} \\cos \\theta = \\frac{\\textbf{v} \\cdot \\textbf{w}}{|\\textbf{v}||\\textbf{w}|} \\end{aligned} $$Direction Angles in Space In three dimensions, a vector is determined by its magnitude and three direction angles. As shown in FIGURE 3:\n$\\alpha$ is the direction angle between $\\textbf{v}$ and the positive $x$-axis $\\beta$ is the direction angle between $\\textbf{v}$ and the positive $y$-axis $\\gamma$ is the direction angle between $\\textbf{v}$ and the positive $z$-axis We can evaluate these angles using the expression for the cosine of the angle between two vectors. Note that $\\textbf{i} = \\langle 1, 0, 0 \\rangle$, $\\textbf{j} = \\langle 0, 1, 0 \\rangle$ and $\\textbf{k} = \\langle 0, 0, 1 \\rangle$, where each one has magnitude $1$. For $\\textbf{v} = a\\textbf{i} + b \\textbf{j} + c\\textbf{k}$:\n$$ \\begin{aligned} \\cos \\alpha = \\frac{\\textbf{v} \\cdot \\textbf{i}}{|\\textbf{v}||\\textbf{i}|} = \\frac{a}{|\\textbf{v}|} \\end{aligned} $$$$ \\begin{aligned} \\cos \\beta = \\frac{\\textbf{v} \\cdot \\textbf{j}}{|\\textbf{v}||\\textbf{j}|} = \\frac{b}{|\\textbf{v}|} \\end{aligned} $$$$ \\begin{aligned} \\cos \\gamma = \\frac{\\textbf{v} \\cdot \\textbf{k}}{|\\textbf{v}||\\textbf{k}|} = \\frac{c}{|\\textbf{v}|} \\end{aligned} $$These quantities, $\\cos \\alpha$, $\\cos \\beta$ and $\\cos \\gamma$ are called direction cosines. And they satisfy:\n$$ \\begin{aligned} \\cos^2 \\alpha + \\cos^2 \\beta + \\cos^2 \\gamma = 1 \\end{aligned} $$"},"title":"Appendix"},"/notes/math/cet/":{"data":{"":" Functions and Models Limits and Derivatives Limits and Derivatives The Tangent and Velocity Problems The Limit of a Function Calculating Limits Using the Limits Laws The Precise Definition of a Limit Continuity Limits at Infinity. Horizontal Asymptotes Derivatives and Rates of Change The Derivative as a Function "},"title":"Calculus Ealy Transcendentals"},"/notes/math/cet/01_functions/":{"data":{"":"","exponential-functions#Exponential Functions":"The Number e Figures 12 and 13 show the tangent lines to the graphs of $y = 2^x$ and $y = 3^x$ at the point $(0, 1)$. The slopes for these tangent lines are $m \\approx 0.7$ and $m \\approx 1.1$ respectively.\nSome formulas of calculus will be simplified if we choose the base $b$ so that the slope of the tangent line to $y = b^x$ at $(0, 1)$ is exactly $1$ (see Figure 14). Such a base is denoted by the letter $e$. This notation was chosen by the Swiss mathematician Leonhard Euler in 1727.","four-ways-to-represent-a-function#Four Ways to Represent a Function":"Representation of Functions We consider four different ways to represent a function:\nVerbally: by a description in words. Numerically: by a table of values. Visually: by a graph. Algebraically: by an explicit formula. A function with an explicit formula that approximates the behavior of a given “true” function its called a mathematical model.","inverse-functions-and-logarithms#Inverse Functions and Logarithms":"Inverse Functions We know that a function is one-to-one graphically by applying the horizontal line test.\nAny function $f$ has an inverse if and only if $f$ is one-to-one.\nCancellation Equations Given a function $f: A \\rightarrow B$ whose inverse $f^{-1}$ exists, then its cancellation equations are defined as follows:\n$$ \\begin{aligned} f^{-1}(f(x)) = x, \\forall x \\in A \\end{aligned} $$$$ \\begin{aligned} f(f^{-1}(x)) = x, \\forall x \\in B \\end{aligned} $$On the first cancellation equation $f^{-1}$ undoes what $f$ does, and viceversa for the second equation.\nGraphing the Inverse The process of finding the inverse gives us a method for obtaining the graph of $f^{-1}$ from the graph of $f$.\nSince $f(a) = b$ if and only if $f^{-1}(b) = a$ then the point $(a, b)$ is on the graph of $f$ if and only if the point $(b, a)$ is on the graph $f^{-1}$. But we get the point $(b, a)$ from $(a, b)$ by reflecting about the line $y = x$ (See Figure 8).\nSo the graph of $f^{-1}$ is obtained by reflecting the graph of $f$ about the line $y = x$.\nLogarithmic Functions If $b \u003e 0$ and $b \\neq 1$ then the exponential function $f(x) = b^x$ is either increasing or decreasing, and so it is one-to-one. Therefore its inverse exists and is called the logarithmic function with base $b$:\n$$ \\begin{aligned} \\log_b x = y \\leftrightarrow b^y = x \\end{aligned} $$If we apply the cancellation equations we obtain:\n$$ \\begin{aligned} \\log_b(b^x) = x, \\forall x \\in \\mathbb{R} \\end{aligned} $$$$ \\begin{aligned} b^{\\log_b x} = x, \\forall x \u003e 0 \\end{aligned} $$The logarithmic function has domain $(0, \\infty)$ and range $\\mathbb{R}$. Its graph is the reflection of the graph of $y = b^x$ about the line $y = x$ (See Figure 11).\nNatural Logarithms The logarithm with base $e$ is called the natural logarithm and is denoted as:\n$$ \\begin{aligned} \\log_e x = \\ln x \\end{aligned} $$If we apply the cancellation equations we obtain:\n$$ \\begin{aligned} \\ln(e^x) = x, x \\in \\mathbb{R} \\end{aligned} $$$$ \\begin{aligned} e^{\\ln x} = x, x \u003e 0 \\end{aligned} $$In particular if we set $x = 1$ we get:\n$$ \\begin{aligned} \\ln e = 1 \\end{aligned} $$Therefore:\n$$ \\begin{aligned} x^r = \\left(e^{\\ln(x)}\\right)^r = e^{r \\ln(x)} \\end{aligned} $$Inverse Trigonometric Functions Trigonometric functions are not one-to-one, as their are periodic function. However if their domain to an interval that “lats” one period of the function then it is one-to-on.\nInverse Sine Function The inverse of the sine function is denoted by $\\sin^{-1}$ or $\\arcsin$, and it is defined as:\n$$ \\begin{aligned} \\sin^{-1}(x) = y \\leftrightarrow \\sin y = x, -\\frac{\\pi}{2} \\leq y \\leq \\frac{\\pi}{2} \\end{aligned} $$As you can see the domain has been restricted to $[-\\frac{\\pi}{2}, \\frac{-pi}{2}]$ (See Figure 18).\nBy the cancellation equations we obtain:\n$$ \\begin{aligned} \\sin^{-1}(\\sin x) = x, -\\frac{\\pi}{2} \\leq x \\leq \\frac{\\pi}{2} \\end{aligned} $$$$ \\begin{aligned} \\sin(\\sin^{-1} x) = x, -1 \\leq x \\leq 1 \\end{aligned} $$The inverse sine function has domain $[-1, 1]$ and range $[-\\frac{\\pi}{2}, \\frac{\\pi}{2}]$ and its graph is shown on Figure 20.\nInverse Cosine Function The inverse of the cosine function is denoted by $\\cos^{-1}$ or $\\arccos$, and it is defined as:\n$$ \\begin{aligned} \\cos^{-1}(x) = y \\leftrightarrow \\cos y = x, 0 \\leq y \\leq \\pi \\end{aligned} $$As you can see the domain has been restricted to $[0, \\pi]$ (See Figure 21).\nBy the cancellation equations we obtain:\n$$ \\begin{aligned} \\cos^{-1}(\\cos x) = x, 0 \\leq x \\leq \\pi \\end{aligned} $$$$ \\begin{aligned} \\cos(\\cos^{-1} x) = x, -1 \\leq x \\leq 1 \\end{aligned} $$The inverse cosine function has domain $[-1, 1]$ and range $[0, \\pi]$ and its graph is shown on Figure 22.\nInverse Tangent Function The inverse of the tangent function is denoted by $\\tan^{-1}$ or $\\arctan$, and it is defined as:\n$$ \\begin{aligned} \\tan^{-1}(x) = y \\leftrightarrow \\tan y = x, -\\frac{\\pi}{2} \\leq y \\leq \\frac{\\pi}{2} \\end{aligned} $$As you can see the domain has been restricted to $[-\\frac{\\pi}{2}, \\frac{\\pi}{2}]$ (See Figure 23).\nBy the cancellation equations we obtain:\n$$ \\begin{aligned} \\tan^{-1}(\\tan x) = x, -\\frac{\\pi}{2} \\leq x \\leq \\frac{\\pi}{2} \\end{aligned} $$$$ \\begin{aligned} \\tan(\\tan^{-1} x) = x, -1 \\leq x \\leq 1 \\end{aligned} $$The inverse tangent function has domain $[-1, 1]$ and range $[-\\frac{\\pi}{2}, \\frac{\\pi}{2}]$ and its graph is shown on Figure 25.\nWe know that the lines $x = \\pm \\frac{\\pi}{2}$ are vertical asymptotes of the graph of the tangent function. Since the graph of $\\tan^{-1}$ is obtained by reflecting the graph of the restricted tangnet function about the line $y = x$, the the lines $y = \\frac{\\pi}{2}$ and $y = -\\frac{\\pi}{2}$ are horizontal asymptotes of the graph of $\\tan^{-1}$.\nOther Inverse Functions See for information about the remaning inverse trigonometric functions.","mathematical-models-a-catalog-of-essential-functions#Mathematical Models: A Catalog of Essential Functions":"Mathematical Model A mathematical model is a mathematical description (generally by the means of a function or an equation) of a real-world phenomenon. Its purpose is to understan the phenomenon and perhaps make predictions about future behaviour.\nThe process of mathematical modeling is a follows:\nFormulate a mathematical model by identifying the independent and dependent variables and making assumptions that simplify the phenomenon. Apply the mathematics that we know to derive mathematical conclusions. Take those mathematics conclusions and interpret them as information about the original real-world phenomenon. Test our predictions against real-world data. This process is illustrated on the following figure.\nIf there is no physical law or principle to help us formulate a model, we construct an empirical model that is a model that captures the basic trend of the data points.\nAlgebraic Function A function $f$ is an algebraic function if it can be constructed using algebraic operations (such as addition, substraction, multiplication, division and taking roots).\nFunctions that are not algebraic are called transcendental, these include trigonometric, exponential and logarithmic functions.\nFaimilies of Essential Functions and Their Graphs On the following table we show a summary of graphs of some families of essential functions.\nFunction Form Graph Linear Function $f(x) = mx + b$ Power Function $f(x) = x^n$ Root Function $f(x) = \\sqrt[n]{x}$ Reciprocal Function $f(x) = \\frac{1}{\\sqrt[n]{x}}$ Exponential Function $f(x) = b^x$ Logarithmic Function $f(x) = \\log_b x$ Trigonimetric Functions $f(x) = \\sin x$ Trigonimetric Functions $f(x) = \\cos x$ Trigonimetric Functions $f(x) = \\tan x$ ","new-functions-from-old-functions#New Functions from Old Functions":"See the following for the theory on function transformations:\nVertical and Horizontal Shifts of Graphs Stretching, Shrinking and Reflecting Graphs And for more information on Operations and Composition."},"title":"Functions and Models"},"/notes/math/cet/02_limits/":{"data":{"":"","calculating-limits-using-the-limits-laws#Calculating Limits Using the Limits Laws":"Properties of Limits Supporse that $c$ is a constant and the limits:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a} g(x) \\end{aligned} $$exist. Then:\nSum Law\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [f(x) + g(x)] = \\lim_{x \\rightarrow a} f(x) + \\lim_{x \\rightarrow a} g(x) \\end{aligned} $$Difference Law\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [f(x) - g(x)] = \\lim_{x \\rightarrow a} f(x) - \\lim_{x \\rightarrow a} g(x) \\end{aligned} $$Constant Multiple Law\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [cf(x)] = c\\lim_{x \\rightarrow a} f(x) \\end{aligned} $$Product Law\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [f(x) g(x)] = \\lim_{x \\rightarrow a} f(x) \\cdot \\lim_{x \\rightarrow a} g(x) \\end{aligned} $$Quotient Law\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [\\frac{f(x)}{g(x)}] = \\frac{\\lim_{x \\rightarrow a} f(x)}{\\lim_{x \\rightarrow a} g(x)} \\end{aligned} $$If we use the Product Law repeteadly with $g(x) = f(x)$, then we arrive at the Power Law:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} \\left[f(x)\\right]^n = [\\lim_{x \\rightarrow a} f(x)]^n \\end{aligned} $$Root Law\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} \\sqrt[n]{f(x)} = \\sqrt[n]{\\lim_{x \\rightarrow a} f(x)} \\end{aligned} $$Let’s now see two special limits:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} c = c \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a} x = a \\end{aligned} $$If we now let $f(x) = x$ on the Power Law and use $\\lim_{x \\rightarrow a} x = a$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} x^n = [\\lim_{x \\rightarrow a} x]^n = a^n \\end{aligned} $$If we now let $f(x) = x$ on the Root Law and use $\\lim_{x \\rightarrow a} x = a$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} \\sqrt[n]{x} = \\sqrt[n]{\\lim_{x \\rightarrow a} x} = \\sqrt[n]{a} \\end{aligned} $$where $n$ is a positive integer. Also, if $n$ is even then we assume that $a \u003e 0$.\nEvaluating Limits by Direct Substitution The Limit Laws prove that direct substitution can be used to obtain the value of a limit for polynomial and rational functions.\nIf $f$ is a polynomial or a rational function and $a$ is in the domain of $f$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = f(a) \\end{aligned} $$Functions that satisfy this property are said to be continuous at $a$. However, not all limits can be evaluated initially by direct substitution.\nLimit Equality If $f(x) = g(x)$ when $x \\neq a$, then $\\lim_{x \\rightarrow a} f(x) = \\lim_{x \\rightarrow a} g(a)$\nUsing One-Sided Limits We say:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = L \\end{aligned} $$if and only if\n$$ \\begin{aligned} \\lim_{x \\rightarrow a^{-}} f(x) = L = \\lim_{x \\rightarrow a^{+}} f(x) \\end{aligned} $$The Squeeze Theorem The following two theorems describe how the limits of functions are related when the values of one function are greater than (or equal to) those of another.\nIf $f(x) \\leq g(x)$ when $x$ is near $a$ (except possibly at $a$) and the limits of $f$ and $g$ both exist as $x$ approaches $a$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) \\leq \\lim_{x \\rightarrow a} g(x) \\end{aligned} $$The Squeeze Theorem states:\nIf $f(x) \\leq g(x) \\leq h(x)$ when $x$ is near $a$ (except possibly at $a$) and:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = \\lim_{x \\rightarrow a} h(x) = L \\end{aligned} $$then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} g(x) = L \\end{aligned} $$This theorem is illustrated on Figure 7. It says that if $g(x)$ is squeezed between $f(x)$ and $h(x)$ near $a$, and if $f$ and $h$ have the same limit $L$ at $a$, then $g$ is forced to have the same limit $L$ at $a$.","continuity#Continuity":"Continuity of a Function A function $f$ is continuous at a number $a$ if:\n$$ \\begin{aligned} \\lim_{x\\rightarrow a} f(x) = f(a) \\end{aligned} $$This definition implicitly requires:\n$f(a)$ is defined $\\lim_{x\\rightarrow a} f(x)$ exists $\\lim_{x\\rightarrow a} f(x) = f(a)$ This definition says that $f$ is continuous at $a$ if $f(x)$ approaches $f(a)$ as $x$ approaches $a$.\nAnd we say that $f$ is discontinuous at $a$ if $f$ is not continuous at $a$. We distinguish three cases of discontinuity:\nRemovable discontinuity Infinite discontinuity Jump discontinuity A function $f$ continuous from the right at a number $a$ if:\n$$ \\begin{aligned} \\lim_{x\\rightarrow a^{+}} f(x) = f(a) \\end{aligned} $$A function $f$ continuous from the left at a number $a$ if:\n$$ \\begin{aligned} \\lim_{x\\rightarrow a^{-}} f(x) = f(a) \\end{aligned} $$A function $f$ is continuous on an interval if it is continuous at every number on the interval.\nProperties of Continuous Functions If $f$ and $g$ are continuous at a number $a$ and $c$ is constant, then the following functions are also continuous at $a$:\n$f + g$ $f - g$ $cf$ $f\\cdot g$ $\\frac{f}{g}, g(a) \\neq 0$ Proof\nSince $f$ and $g$ are continuous at $a$ we have that:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = f(a) \\end{aligned} $$and\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} g(x) = g(a) \\end{aligned} $$by the Properties of Limits:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [f(x) + g(x)] = [\\lim_{x \\rightarrow a} f(x)] + [\\lim_{x \\rightarrow a} g(x)] \\end{aligned} $$$$ \\begin{aligned} = f(a) + g(a) = (f + g)(a) \\end{aligned} $$And thus, $f + g$ is continuous at $a$.\nContinuity of Polynomial and Rational Functions Any polynomial functions is continuous on $\\mathbb{R}$. Proof\nA polynomial is a function of the form:\n$$ \\begin{aligned} P(x) = c_nx^n + c_{n-1}x^{n-1} + \\cdots + c_1x + c_0 \\end{aligned} $$where $c_i \\in \\mathbb{R}$, we know that:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} c_0 = c_0 \\end{aligned} $$and\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} x^m = a^m, m = 1, 2, \\cdots, n \\end{aligned} $$therefore:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} P(x) = \\lim_{x \\rightarrow a} c_nx^n + c_{n-1}x^{n-1} + \\cdots + c_1x + c_0 \\end{aligned} $$by the Properties of Limits:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} P(x) = \\sum_{i = 0}^n \\lim_{x \\rightarrow a} c_i x^{i} \\end{aligned} $$$$ \\begin{aligned} = \\left(\\sum_{i = 1}^n \\lim_{x \\rightarrow a} c_i x^{i}\\right) + \\lim_{x \\rightarrow} c_0 \\end{aligned} $$$$ \\begin{aligned} = \\left(\\sum_{i = 1}^n c_i a^i\\right) + c_0 \\end{aligned} $$$$ \\begin{aligned} = P(a) \\end{aligned} $$Thus $P$ is continuous at $a$, where $a \\in \\mathbb{R}$.\nAny ration function is continuous whenever it is defined, that is, it is continuous on its domain. Proof\nA rational function is a function of the form:\n$$ \\begin{aligned} f(x) = \\frac{P(x)}{Q(x)} \\end{aligned} $$where $P$ and $Q$ are polynomials. The domain of $f$ is $D = {x \\in \\mathbb{R} | Q(x) \\neq 0}$. So we now, by the previous proof, that $P$ and $Q$ are continuous everywhere. Thus by the Properties of Continuous Functions $f$ is continuous at every number in $D$ (its domain).\nContinuous Functions The following types of functions are continuous on their domains:\nPolynomial functions Rational functions Root functions Trigonometric functions Inverse trigonometric functions Exponential functions Logarithmic functions Note that the inverse of a continuous one-to-one function is also continuous. Our geometric intuitions makes it seem plausible: we know that the graph of $f^{-1}$ is obtained by reflecting the graph of $f$ on the line $y = x$. So if the graph of $f$ has no break in it (the function is continuous), then the graph of $f^{-1}$ also has no break in it.\nContinuity of Composite Functions If $f$ is continuous at $b$ and $\\lim_{x \\rightarrow a} g(x) = b$, then $\\lim_{x \\rightarrow a} f(g(x)) = b$, that is:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(g(x)) = f\\left(\\lim_{x \\rightarrow a} g(x)\\right) \\end{aligned} $$If $g$ is continuous at $a$ and $f$ is continuous at $g(a)$, then the composite function $f \\circ g$, given by $(f \\circ g)(x) = f(g(x))$ is continuous at $a$\nProof\nSince $g$ is continuous at $a$ we have that:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} g(x) = g(a) \\end{aligned} $$Since $f$ is continuous at $b = g(a)$ we have that:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(g(x)) = f(b) = f(g(a)) \\end{aligned} $$thus $f \\circ g$ is continuous at $a$.\nThe Intermediate Value Theorem Suppose that $f$ is continuous at the closed interval $[a, b]$ and let $N$ be any number between $f(a)$ and $f(b)$, where $f(a) \\neq f(b)$. There there exists a number $c \\in (a, b)$, such that $f(c) = N$.\nThe Intermediate Value Theorem states that a continuous functions takes on every intermediate value between the function values $f(a)$ and $f(b)$ (See Figure 8).","derivatives-and-rates-of-change#Derivatives and Rates of Change":"Tangents The tangent line to the curve $y = f(x)$ at the point $P(a, f(a))$ is the line through $P$ with slope:\n$$ \\begin{aligned} m = \\lim_{x \\rightarrow a} \\frac{f(x) - f(a)}{x - a} \\end{aligned} $$Provided that this limit exists (See Figure 1).\nWe sometimes refer to the slope of the tangent line to a curve at a point as the slope of the curve at the point. If we zoom in far enough toward the point, the curve looks almost like a straight line (See Figure 2).\nThere is another expression for the slope of a tangent line. If $h = x - a$, then $x = a + h$, and so the slope of the secant line $PQ$ becomes:\n$$ \\begin{aligned} m_{PQ} = \\frac{f(a + h) - f(a)}{h} \\end{aligned} $$See Figure 3.\nNotice that as $x$ approaches $a$, then $h$ approaches $0$. Therefor3 the definition of the slope of the tangent line becomes:\n$$ \\begin{aligned} m = \\lim_{h \\rightarrow 0} \\frac{f(a + h) - f(a)}{h} \\end{aligned} $$ Velocities Suppose an object moves along a straight line following the equation $s = f(t)$, where $s$ is the displacement of the object from the origin at time $t$. The function $f$ that describes the motion is called position function.\nIn the time interval from $t = a$ to $t = a + h$ the change is position is $f(a + h) - f(a)$ (See Figure 5).\nThe average velocity over this time interval is:\n$$ \\begin{aligned} \\text{average velocity} = \\frac{\\text{displacement}}{\\text{time}} = \\frac{f(a + h) - f(a)}{h} \\end{aligned} $$Now suppose we compute the average velocities over shorter and shorter time intervals, that is, we let $h$ approach $0$. We define the velocity or instantaneous velocity $v(a)$ at time $t = a$ to be the limit of these average velocities:\n$$ \\begin{aligned} v(a) = \\lim_{h \\rightarrow 0} \\frac{f(a + h) - f(a)}{h} \\end{aligned} $$Provided that this limit exists.\nDerivatives Limits of the form:\n$$ \\begin{aligned} \\lim_{h \\rightarrow 0} \\frac{f(a + h) - f(a)}{h} \\end{aligned} $$arise whenever we calculate a rate of change in any of the sciences or engineering.\nThe derivative of a function $f$ at a number $a$, denoted by $f’(a)$ is:\n$$ \\begin{aligned} f'(a) = \\lim_{h \\rightarrow 0} \\frac{f(a + h) - f(a)}{h} \\end{aligned} $$if this limit exists.\nLetting $x = a + h \\leftrightarrow h = x - a$, then an equivalent way of this definition is:\n$$ \\begin{aligned} f'(a) = \\lim_{x \\rightarrow a} \\frac{f(x) - f(a)}{x - a} \\end{aligned} $$We defined the tangent line to the curve $y = f(x)$ at $P(a, f(a))$ to be the line that passes through $P$ and has slope $m$. By the previous definition this slope $m$ is the same as the derivative $f’(a)$.\nIf we use the point-slope form of the equation of a line, we can write an equation of the tangent line to the curve $y = f(x)$ at the point $(a, f(a))$:\n$$ \\begin{aligned} y - f(a) = f'(a)(x - a) \\end{aligned} $$Rates of Change Suppose that $y$ is a quantity that depends on another quantity $x$, we write $y = f(x)$. If $x$ changes to $x_1$ to $x_2$, then the change in $x$ is:\n$$ \\begin{aligned} \\Delta x = x_2 - x_1 \\end{aligned} $$And the corresponding change in $y$ is:\n$$ \\begin{aligned} \\Delta y = f(x_2) - f(x_1) \\end{aligned} $$The difference quotient is given by:\n$$ \\begin{aligned} \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_2) - f(x_1)}{x_2 - x_1} \\end{aligned} $$And is called the average rate of change of $y$ with respect to $x$ over the interval $[x_1, x_2]$. This can be interpreted as the slope of the secand line $PQ$ in Figure 8.\nBy analogy with velocity, if we consider the average rate of change over smaller and smaller intervals, letting $\\Delta x$ approach $0$. The limit of these average rates of change is called the (instantaneous) rate of change of $y$ with respect to $x$ at $x = x_1$. This can be interpreted as the slope of the tangent to the curve $y = f(x)$ at $P(x_1, f(x_1))$:\n$$ \\begin{aligned} \\lim_{\\Delta x \\rightarrow 0} \\frac{\\Delta y}{\\Delta x} = \\lim_{x_2 \\rightarrow x_1} \\frac{f(x_2) - f(x_1)}{x_2 - x_1} \\end{aligned} $$We recognize this limit as the derivative $f’(x_1)$ so the derivative of $f’(x_1)$ is the instantaneous rate of change of $y = f(x)$ with respect to $x$ when $x = x_1$.\nThis means that when the derivative is large the curve is steep (as at the point $P$ in Figure 9), therefore the $y$-values change rapidly. However, when the derivative is small, the curve is relatively flat (as at point $Q$) and the $y$-values change slowly.\nThen $f’(a)$ is the velocity of a particle at time $t = a$ and its speed is the absolute value of the velocity, $|f’(a)|$.","limits-at-infinity-horizontal-asymptotes#Limits at Infinity. Horizontal Asymptotes":"Intuitive Definition of a Limit at Infinity Let $f$ be a function defined on some interval $(a, \\infty)$, then:\n$$ \\begin{aligned} \\lim_{x\\rightarrow \\infty} f(x) = L \\end{aligned} $$means that the values of $f(x)$ can be made arbitrarily close to $L$ by requiring $x$ to be sufficiently large.\nGeometric illustration of this defintion are shown in Figure $2$.\nLet $f$ be a function defined on some interval $(-\\infty, a)$, then:\n$$ \\begin{aligned} \\lim_{x\\rightarrow -\\infty} f(x) = L \\end{aligned} $$means that the values of $f(x)$ can be made arbitrarily close to $L$ by requiring $x$ to be sufficiently large negative.\nThis definition is illustrated in Figure $3$.\nHorizontal Asymptote The line $y = L$ is called a horizontal asymptote of the curve $y = f(x)$ if either:\n$$ \\begin{aligned} \\lim_{x \\rightarrow \\infty} f(x) = L \\end{aligned} $$or\n$$ \\begin{aligned} \\lim_{x \\rightarrow -\\infty} f(x) = L \\end{aligned} $$ Evaluating Limits at Infinity Most of the Limit Laws also hold for limits at infinity, with the exception of Laws $10$ and $11$.\nLet’s see the following theorem on the limit at infinity of a rational function:\nIf $r \u003e 0$ is a rational number, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow \\infty} \\frac{1}{x^r} = 0 \\end{aligned} $$If $r \u003e 0$ is a rational number such that $x^r$ is defined for all $x$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow -\\infty} \\frac{1}{x^r} = 0 \\end{aligned} $$Infinite Limits at Infinity The notation:\n$$ \\begin{aligned} \\lim_{x \\rightarrow \\infty} f(x) = \\infty \\end{aligned} $$means that the values of $f(x)$ become large as $x$ becomes large. Similarly:\n$$ \\begin{aligned} \\lim_{x \\rightarrow -\\infty} f(x) = \\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow \\infty} f(x) = -\\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow -\\infty} f(x) = -\\infty \\end{aligned} $$In general, the Limit Laws cannot be applied to infinite limits, because $\\infty$ is not a number.\nPrecise Definition of a Limit at Infinity Let $f$ be a function defined on some interval $(a, \\infty)$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow \\infty} f(x) = L \\end{aligned} $$means that for every $\\epsilon \u003e 0$ there is a corresponding number $N$ such that:\n$$ \\begin{aligned} \\text{ if } x \u003e N \\text{ then } |f(x) - L| \u003c \\epsilon \\end{aligned} $$In words, this says that the values of $f(x)$ can be mace arbitrarily cloe to $L$ by requiring $x$ to be sufficiently lare.\nGraphically it says that by keeping $x$ large enough we can make the graph of $f$ lie between the given horizontal lines $y = L - \\epsilon$ and $y = L + \\epsilon$ as in Figure 14.\nLet $f$ be a function defined on some interval $(-\\infty, a)$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow -\\infty} f(x) = L \\end{aligned} $$means that for every $\\epsilon \u003e 0$ there is a corresponding number $N$ such that:\n$$ \\begin{aligned} \\text{ if } x \u003c N \\text{ then } |f(x) - L| \u003c \\epsilon \\end{aligned} $$This definition is illustrated on Figure 16.\nPrecise Definition of an Infinite Limit at Infinity Let $f$ be a function defined on some interval $(a, \\infty)$, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow \\infty} f(x) = \\infty \\end{aligned} $$means that for every positive number $M$ there is a corresponding positive number $N$ such that:\n$$ \\begin{aligned} \\text{ if } x \u003e N \\text{ then } f(x) \u003e M \\end{aligned} $$This definition is illustrated on Figure 19.\nSimilar definitions apply when the symbol $\\infty$ is replaced by $-\\infty$.","the-derivative-as-a-function#The Derivative as a Function":"Other Notations Some common alternative notations for th derive are as follows:\n$$ \\begin{aligned} f'(x) = y' = \\frac{dy}{dx} = \\frac{df}{fx} = \\frac{d}{dx} f(x) = Df(x) = D_x f(x) \\end{aligned} $$The symbols $D$ and $\\frac{d}{dx}$ are called differentiation operators because they indicate the operation of differentiation. The symbol $\\frac{dy}{dx}$ was introduced by Leibniz as a synonim for $f’(x)$. We can rewrite the definition of the derivative in Leibniz notation in the form:\n$$ \\begin{aligned} \\frac{dy}{dx} = \\lim_{\\Delta x \\rightarrow 0} \\frac{\\Delta y}{\\Delta x} \\end{aligned} $$To indicate the value of a derivative $\\frac{dy}{dx}$ in Leibniz notation at a specific number $a$, we use the notation:\n$$ \\begin{aligned} \\left.\\frac{dy}{dx}\\right|_{x=a} \\end{aligned} $$Theorems A function $f$ is differentiable at $a$ if $f’(a)$ exists. It is differentiable on an open interval $(a, b)$ if it is differentiable at every number in the interval.\nIf $f$ is differentiable $a$, then $f$ is continuous at $a$.\nProof:\nWe assume that $f$ is differentiable at $a$, so we have to prove that $f$ is continuous at $a$, that is we have to show:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = f(a) \\end{aligned} $$We will do this by showing that the difference $f(x) - f(a)$ approaches $0$. Then, multiplying and dividing $f(x) - f(a)$ by $x - a$\n$$ \\begin{aligned} f(x) - f(a) = \\frac{f(x) - f(a)}{x - a} (x - a) \\end{aligned} $$By the Limit Laws:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [f(x) - f(a)] = \\lim_{x \\rightarrow a} \\frac{f(x) - f(a)}{x - a} (x - a) \\end{aligned} $$$$ \\begin{aligned} = \\lim_{x \\rightarrow a} \\frac{f(x) - f(a)}{x - a} \\cdot \\lim_{x \\rightarrow a} (x - a) \\end{aligned} $$Because we know that $f$ is differentiable at $a$, then:\n$$ \\begin{aligned} f'(a) = \\lim_{x \\rightarrow a} \\frac{f(x) - f(a)}{x - a} \\end{aligned} $$exists, such that:\n$$ \\begin{aligned} = f'(a) \\cdot (a - a)= f'(a) \\cdot 0 = 0 \\end{aligned} $$Now we use this result to prove that $f$ is continuous:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = \\lim_{x \\rightarrow a} [f(a) + (f(x) - f(a))] \\end{aligned} $$$$ \\begin{aligned} = \\lim_{x \\rightarrow a} f(a) + \\lim_{x \\rightarrow a} [f(x) - f(a)] \\end{aligned} $$From our previous lemma we know that $\\lim_{x \\rightarrow a} [f(x) - f(a)] = 0$. Then:\n$$ \\begin{aligned} = \\lim_{x \\rightarrow a} f(a) + 0 = f(a) \\end{aligned} $$Therefore $f$ is continuous at $a$.\nNote that the converse of this theorem is false, that is, there are functions that are continuous but not differentiable.\nHow Can a Function Fail To Be Differentiable We consider three scenarios:\nIf the graph of a function $f$ has a corner or a kink in it, then the graph of $f$ has no tangent at this point and $f$ is not differentiable there. By the contrapositive of “If $f$ is differentiable at $a$, then $f$ is continuous at $a$” we know that if $f$ is not continuous at $a$ then $f$ is not differentiable at $a$. If the curve given by $f$ has a vertical tangent line when $x = a$, $f$ is continuous at $a$ and $\\lim_{x \\rightarrow a} |f’(x)| = \\infty$ then $f$ is not differentiable at $a$. Figure 7 illustrates the three possibilities:\nHigher Derivatives If $f$ is a differentiable function, then its derivative $f’$ is also a function, so $f’$ may have a derivative of its own, denoted by $(f’)’ = f’’$, called the second derivative of $f$. Using Leibniz notation:\n$$ \\begin{aligned} \\frac{d}{dx} \\left(\\frac{dy}{dx}\\right) = \\frac{d^2y}{dx^2} \\end{aligned} $$In general, we can interpret a second derivative as a rate of change of a rate of change. The most familiar example of this is acceleration. If $s(t)$ is the position function, we know that its first derivative represents the velocity $v(t)$:\n$$ \\begin{aligned} v(t) = s'(t) = \\frac{ds}{dt} \\end{aligned} $$The instantaneous rate of change of velocity with respect to time is called the acceleration $a(t)$. Thus the acceleration function is the derivative of the velocity function, that is the second derivative of the position function:\n$$ \\begin{aligned} a(t) = v'(t) = s''(t) \\end{aligned} $$or in Leibniz notation:\n$$ \\begin{aligned} a = \\frac{dv}{dt} = \\frac{d^2s}{dt^2} \\end{aligned} $$The third derivative $f’’’$ is the derivative of the second derivative $f’’’ = (f’’)’$. It can be interpreted as the slope of the curve $y = f’’(x)$ or as the rante of change of $f’’(x)$. Alternative notations are:\n$$ \\begin{aligned} y''' = f'''(x) = \\frac{d}{dx} \\left( \\frac{d^2y}{dx^2} \\right) = \\frac{d^3y}{dx^3} \\end{aligned} $$We can also interpret the third derivative physically. Given the position function $s(t)$ its third derivative is the derivative of the acceleration function and is called the jerk:\n$$ \\begin{aligned} j = \\frac{da}{dt} = \\frac{d^3s}{dt^3} \\end{aligned} $$It represents the rate of change of acceleration. It is named like so because a large jerk means a sudden change in acceleration, which causes an abrupt movement.\nIn general, the $n$th derivative of $f$ is denoted by $f^{(n)}$ and is obtained from $f$ by differentiating $n$ times. If $y = f(x)$, we write:\n$$ \\begin{aligned} y^{(n)} = f^{(n)}(x) = \\frac{d^n y}{dx^n} \\end{aligned} $$","the-limit-of-a-function#The Limit of a Function":"Limits Suppose $f(x)$ is defined when $x$ is near the number $a$, then we write:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = L \\end{aligned} $$If we can make the values of $f(x)$ arbitrarily close to $L$ by restricting $x$ to be sufficiently close to $a$ (on either side of $a$) but not equal to $a$ (See Figure 1).\nAn alternative notation is:\n$$ \\begin{aligned} f(x) \\rightarrow L \\text{ as } x \\rightarrow a \\end{aligned} $$Notice that we never consider $x = a$. In fact, $f(x)$ need not even be defined when $x = a$. The only thing that matters is how $f$ is defined near $a$.\nOne-Sided Limits The notation $t \\rightarrow 0^{-}$ indicates that we consider only values of $t$ that are less than 0. Likewise, $t \\rightarrow 0^{+}$ indicates that we consider only values of $t$ that are greater than 0.\nWe write:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a^{-}} f(x) = L \\end{aligned} $$and say that the left-hand limit of $f(x)$ as $x$ approaches $a$ is equal to $L$ if we can make the values of $f(x)$ arbitrarily clsoe to $L$ by restricting $x$ to be sufficiently close to $a$ with $x$ less than $a$.\nWe write:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a^{+}} f(x) = L \\end{aligned} $$and say that the right-hand limit of $f(x)$ as $x$ approaches $a$ is equal to $L$ if we can make the values of $f(x)$ arbitrarily clsoe to $L$ by restricting $x$ to be sufficiently close to $a$ with $x$ greater than $a$.\nSee Figure 6 for a graphical representation.\nBy both definitions, we see that the following is true:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = L \\leftrightarrow \\lim_{x \\rightarrow a^{-}} f(x) = L \\text{ and } \\lim_{x \\rightarrow a^{+}} f(x) = L \\end{aligned} $$How Can a Limit Fail to Exist? A limit fails to exist at a number $a$ if the left- and right-hand limits are not equal.\nWhen guessing the value of a limit it is easy to guess the wrong value if we use inapproapriate values of $x$. It is also hard to know when to stop calculating value (sometimes calculators and computers give the wrong values due to precission issues).\nInfinite Limits: Vertical Asymptotes Another way a limit at a number $a$ can fail to exist is when the function values grow arbitrarily large (in absolute value) as $x$ approaches $a$.\nLet $f$ be a function defined on both sides of $a$, except possible at $a$ itself, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = \\infty \\end{aligned} $$means that the values of $f(x)$ can be arbitrarily large by taking $x$ sufficiently close to $a$, but not equal to $a$ (See Figure 10).\nLet $f$ be a function defined on both sides of $a$, except possible at $a$ itself, then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = -\\infty \\end{aligned} $$means that the values of $f(x)$ can be arbitrarily large negative by taking $x$ sufficiently close to $a$, but not equal to $a$ (See Figure 11).\nThis does not mean that the limit exists, it simply expresses the particular way in which the limit does not exist.\nSimilar definitions can be given for one-sided limits:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a^{-}} f(x) = \\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a^{-}} f(x) = -\\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a^{+}} f(x) = \\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a^{+}} f(x) = -\\infty \\end{aligned} $$These are illustrated on the following figure:\nVertical Asymptotes The vertical line $x = a$ is called a vertical asymptotes of the curve $y = f(x)$ if at least one of the following statements is true:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = \\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = -\\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a^{-}} f(x) = \\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a^{-}} f(x) = -\\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a^{+}} f(x) = \\infty \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a^{+}} f(x) = -\\infty \\end{aligned} $$","the-precise-definition-of-a-limit#The Precise Definition of a Limit":"The Precise Definition of a Limit As motivation consier the following function:\n$$ \\begin{aligned} f(x) = \\begin{cases} 2x - 1 \u0026 \\text{ if } x \\neq 3 \\\\ 6 \u0026 \\text{ if } x = 3 \\\\ \\end{cases} \\end{aligned} $$Think about how close to $3$ does $x$ have to be so that $f(x)$ differs from $5$ less than $0.1$?\nWe know that the distance from $x$ to $3$ is $|x - 3|$ and the distance from $f(x)$ to $5$ is $|f(x) - 5|$, so out problem becomes:\n$$ \\begin{aligned} | f(x) - 5 | \u003c 0.1 \\text{ if } 0 \u003c | x - 3 | \u003c \\delta \\end{aligned} $$Notice that if:\n$$ \\begin{aligned} 0 \u003c |x - 3| \u003c \\frac{0.1}{2} = 0.5 \\end{aligned} $$then:\n$$ \\begin{aligned} |f(x) - 5| = |(2x - 1) - 5| = |2x - 6| = 2|x - 3| \u003c 2(0.05) = 0.1 \\end{aligned} $$that is:\n$$ \\begin{aligned} |f(x) - 5| \u003c 0.1 \\text { if } 0 \u003c |x - 3| \u003c 0.05 \\end{aligned} $$Thus an answer to the proposed problem is given by $\\delta = 0.05$. However, if we change the limit $0.1$ to $0.01$ by using the same method we find that $\\delta = 0.005$, such that:\n$$ \\begin{aligned} |f(x) - 5| \u003c 0.01 \\text { if } 0 \u003c |x - 3| \u003c 0.005 \\end{aligned} $$And similarly:\n$$ \\begin{aligned} |f(x) - 5| \u003c 0.001 \\text { if } 0 \u003c |x - 3| \u003c 0.0005 \\end{aligned} $$These values: $0.1, 0.01$ and $0.001$ are what we call error tolerances. But to actually compute the limit we must be able to find a $\\delta$ for any arbitrarily small positive number $\\epsilon$:\n$$ \\begin{aligned} |f(x) - 5| \u003c \\epsilon \\text { if } 0 \u003c |x - 3| \u003c \\delta = \\frac{\\epsilon}{2} \\end{aligned} $$This is the precise way of saying that $f(x)$ is close to $5$ when $x$ is close to $3$ because the previous statement says that we can make the values of $f(x)$ within an arbitrary distance $\\epsilon$ from $5$ by restricting $x$ to be within a distance $\\frac{\\epsilon}{2}$ from $3$ (See Figure 1).\nThe precise definition of a limit is as follows:\nLet $f$ be a function defined on some open interval that contains the number $a$, except possible at $a$ itself. Then we say that the limit of $f(x)$ as $x$ approaches $a$ is $L$ and we write:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = L \\end{aligned} $$if for every number $\\epsilon \u003e 0$ there is a number $\\delta \u003e 0$ such that:\n$$ \\begin{aligned} \\text{ if } 0 \u003c |x - a| \u003c \\delta \\text{ then } |f(x) - L| \u003c \\epsilon \\end{aligned} $$We can reformulate this definition in terms of intervals:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = L \\end{aligned} $$means that for every $\\epsilon \u003e 0$ we can find $\\delta \u003e 0$ such that if $x \\in (a - \\delta, a + \\delta)$ and $x \\neq a$, then $f(x) \\in (L - \\epsilon, L + \\epsilon)$ (See Figure 3).\nAlso we can interpret the definition geometrically in terms of the graph of a function. If $\\epsilon \u003e 0$ is given we draw horizontal lines $y = L + \\epsilon$ and $y = L - \\epsilon$ as well as the graph of $f$ (see Figure 4).\nIf $\\lim_{x \\rightarrow a} f(x) = L$ then we can find a number $\\delta \u003e 0$ such that if $x \\in (a - \\delta, a + \\delta)$ and $x \\neq a$, then the curve $y = f(x)$ lies between the lines $y = L - \\epsilon$ and $y = L + \\epsilon$ (see Figure 5). Once $\\delta$ has been found, then any smaller $\\delta$ will also work.\nNote that this process must work for every positive number $\\epsilon$, no matter how small (See Figure 6).\nOne-Sided Limits Precise Definition of Left-Hand Limit $$ \\begin{aligned} \\lim_{x \\rightarrow a^{-}} f(x) = L \\end{aligned} $$if for every number $\\epsilon \u003e 0$ there is a number $\\delta \u003e 0$ such that:\n$$ \\begin{aligned} \\text{ if } a - \\delta \u003c x \u003c a \\text{ then } |f(x) - L| \u003c \\epsilon \\end{aligned} $$that is, $x$ is restricted to lie in the left half of the interval $(a - \\delta, a + \\delta)$.\nPrecise Definition of Right-Hand Limit $$ \\begin{aligned} \\lim_{x \\rightarrow a^{+}} f(x) = L \\end{aligned} $$if for every number $\\epsilon \u003e 0$ there is a number $\\delta \u003e 0$ such that:\n$$ \\begin{aligned} \\text{ if } a \u003c x \u003c a + \\delta \\text{ then } |f(x) - L| \u003c \\epsilon \\end{aligned} $$that is, $x$ is restricted to lie in the right half of the interval $(a - \\delta, a + \\delta)$.\nLimit Laws Up until now we have used the precise definition of a limit to compute the limit of a given function. However if we were given a more complicated funtion a proof would require a great deal of ingenuity.\nFortunately we can use the Limit Laws, which can be proved using the definition of a limit. So the limits of complicated function can be found rigorously from the Limit Laws without resorting to the definition directly.\nProof of the Sum Law The Sum Law states that if the limits:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow a} g(x) \\end{aligned} $$exist. Then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [f(x) + g(x)] = \\lim_{x \\rightarrow a} f(x) + \\lim_{x \\rightarrow a} g(x) \\end{aligned} $$Proof\nLet $\\epsilon \u003e 0$ be given, we must find $\\delta \u003e 0$ such that:\n$$ \\begin{aligned} \\text{ if } 0 \u003c |x - a| \u003c \\delta \\text{ then } |f(x) + g(x) - (L + M)| \u003c \\epsilon \\end{aligned} $$By the means of the Triangle Inequality:\n$$ \\begin{aligned} | f(x) + g(x) - (L + M) | = | (f(x) - L) + (g(x) - M) | \\leq | f(x) - L | + | g(x) - M | \\end{aligned} $$We make $|f(x) + g(x) - (L + M)|$ less that $\\epsilon$ by letting:\n$$ \\begin{aligned} | f(x) - L | \u003c \\frac{\\epsilon}{2} \\end{aligned} $$and\n$$ \\begin{aligned} | g(x) - M | \u003c \\frac{\\epsilon}{2} \\end{aligned} $$Since $\\frac{\\epsilon}{2} \u003e 0$ and $\\lim_{x \\rightarrow a} f(x) = L$ there exists a number $\\delta_1 \u003e 0$ such that:\n$$ \\begin{aligned} \\text{ if } 0 \u003c |x - a| \u003c \\delta_1 \\text{ then } |f(x) - L| \u003c \\frac{\\epsilon}{2} \\end{aligned} $$Similarly, since $\\frac{\\epsilon}{2} \u003e 0$ and $\\lim_{x \\rightarrow a} g(x) = M$ there exists a number $\\delta_2 \u003e 0$ such that:\n$$ \\begin{aligned} \\text{ if } 0 \u003c |x - a| \u003c \\delta_2 \\text{ then } |g(x) - M| \u003c \\frac{\\epsilon}{2} \\end{aligned} $$Let $\\delta = \\min{\\delta_1, \\delta_2}$, notice:\n$$ \\begin{aligned} \\text{ if } 0 \u003c |x - a| \u003c \\delta \\text{ then } 0 \u003c |x - a| \u003c \\delta_1 \\text{ and } 0 \u003c |x - a| \u003c \\delta_2 \\end{aligned} $$and also:\n$$ \\begin{aligned} | f(x) - L | \u003c \\frac{\\epsilon}{2} \\text{ and } | g(x) - M | \u003c \\frac{\\epsilon}{2} \\end{aligned} $$And, therefore by the triangle inequality we showed before:\n$$ \\begin{aligned} |f(x) + g(x) - (L + M)| \\leq | f(x) - L | + | g(x) - M | \u003c \\frac{\\epsilon}{2} + \\frac{\\epsilon}{2} = \\epsilon \\end{aligned} $$Thus, by the definition of a limit:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} [f(x) + g(x)] = L + M \\end{aligned} $$Infinite Limits Let $f$ be a function defined on some open interval that contains the number $a$, except possibly at $a$ itself. Then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = \\infty \\end{aligned} $$means that for every postive number $M$ there is a positive number $\\delta$ such that:\n$$ \\begin{aligned} \\text{ if } 0 \u003c |x - a| \u003c \\delta \\text{ then } f(x) \u003e M \\end{aligned} $$This says that the values of $f(x)$ ca be made arbitrarily large (larger than any given number $M$) by requiring $x$ to be close enough to $a$ (See Figure 10).\nLet $f$ be a function defined on some open interval that contains the number $a$, except possibly at $a$ itself. Then:\n$$ \\begin{aligned} \\lim_{x \\rightarrow a} f(x) = -\\infty \\end{aligned} $$means that for every postive number $N$ there is a positive number $\\delta$ such that:\n$$ \\begin{aligned} \\text{ if } 0 \u003c |x - a| \u003c \\delta \\text{ then } f(x) \u003c N \\end{aligned} $$See Figure 11.","the-tangent-and-velocity-problems#The Tangent and Velocity Problems":"The Tangent Problem We can think of a tangent to a curve as a line that touches the curve an follows the same direction as the curve at the point of contact.\nLet’s look at the next example, where we want to find an equation for the tangent line to the parabola $y = x^2$ at point $P(1, 1)$. To do so we only need to know the slope $m$, however to find the slope of the line we need two points on the curve, and as of now we only have $P(1, 1)$.\nBut observe that we can compute an approximation by choosing a nearby point $Q(x, x^2)$ (see Figure 2) and computing the slope $m_{PQ}$ of the secant line $PQ$. (A secant line if a line that intersects a curve more than once):\n$$ \\begin{aligned} m_{PQ} = \\frac{x^2 - 1}{x - 1} \\end{aligned} $$ On the following tables we see that the closer $Q$ is to $P$, that is the closer $x$ is to $1$, then the closer $m_{PQ}$ is to $2$.\n$x$ $m_{PQ}$ $2$ $3$ $1.5$ $2.5$ $1.1$ $2.1$ $1.01$ $2.01$ $1.001$ $2.001$ $x$ $m_{PQ}$ $0$ $1$ $0.5$ $1.5$ $0.9$ $1.9$ $0.99$ $1.99$ $0.999$ $1.999$ This suggests that the slope of the tangent line is the limit of the slopes of the secant lines:\n$$ \\begin{aligned} \\lim_{Q \\rightarrow P} m_{PQ} = m \\end{aligned} $$$$ \\begin{aligned} \\lim_{x \\rightarrow 1} \\frac{x^2 - 1}{x - 1} = 2 \\end{aligned} $$Assuming that the slope of the tangent is indeed $2$, we define the equation of the tangent line through $(1, 1)$ as:\n$$ \\begin{aligned} y - 1 = 2(x - 1) \\end{aligned} $$$$ \\begin{aligned} y = 2x - 1 \\end{aligned} $$Figure 3 illustrates the process that occurs on this example. As $Q$ approaches $P$ the secant lines rotate about $P$ and approach the tangent line $\\mathcal{l}$.\nAnother method to approximate the slope of the tangent line at $P$ is to measure the sides of a triangle $ABC$ as in Figure 5:\nThis gives an estimate of the slope of the tangent line as:\n$$ \\begin{aligned}\n\\frac{AB}{BC} \\approx -\\frac{8.0 - 5.4}{0.06 - 0.02} = -65.0 \\end{aligned} $$ The Velocity Problem The instantaneous velocity is defined to be the limiting value of the average velocities over shorter and shorter time periods. Thus there is a close connection between the tangent problem and the velocity problem. If we draw the grapf of the distance function and we consider points $P(5, f(5))$ and $Q(5 + h, f(5 + h))$ (see Figure 6).\nThen the slope of the secant line $PQ$ is:\n$$ \\begin{aligned} m_{PQ} = \\frac{f(5 + h) - f(5)}{(5 + h) - 5} \\end{aligned} $$which is the same as the average velocity over the time interval $[5, 5 + h]$."},"title":"Limits and Derivatives"},"/notes/music/":{"data":{"":" Basic Adult Piano Course "},"title":"Music"},"/notes/music/abpci/":{"data":{"":" Notation Positions Intervals Chords Scales Keys Tidbits of Music "},"title":"Alfred Basic Piano Course I"},"/notes/music/abpci/01_notation/":{"data":{"":"","accent-sign#Accent Sign":"An accent sign mean that we have to play a note with special emphasis:","dotted-half-note#Dotted Half Note":"A dotted half note gets $3$ counts ($2$ counts for the half note, plus $1$ count for the dot).","dotted-quarter-notes#Dotted Quarter Notes":"A dotted quarter note is equivalent to a quarter note tied to a eighth note:","dynamic-signs#Dynamic Signs":"The signs that tell up how loud or soft to play are called dynamic signs. For example:\nA $\\textit{p (piano)}$ tells us to play soft.\nA $\\textit{mf (mezzoforte)}$ tells us to moderately loud.\nA $\\textit{f (forte)}$ tells us to play loud.\nA $\\textit{ff (fortissimo)}$ tells us to play very loud.\nA $\\textit{mp (mezzopiano)}$ tells us to play medium soft.","eighth-note-triplets#Eighth Note Triplets":"When three notes are grouped together with a figure $3$ bove of below the notes, the group is called a triplet.\nThe three notes of a eighth-note triplet group equal one quarter note.","eighth-notes#Eighth Notes":"Two eighth notes are played in the time of one quarter note.","half-step#Half Step":"A half step is the distance between a key and the key directly above or below it (black or white).","incomplete-measure#Incomplete Measure":"Some pieces begin with an incomplete measure, that is it has one missing count:","natural-sign#Natural Sign":"The natural sign cancels a sharp or flat, so a note after a natural sign is always a white key.","overlapping-pedal#Overlapping Pedal":"The following sign is used to indicate the overlapping pedal:\nAnd this is how you play it:","quarter-notes-and-half-notes#Quarter Notes and Half Notes":"Music is made up of short and long tones, which are writter with notes.\nA quarter note is written as follows:\nThis note has a count of $1$. A half note is written as follows:\nThis note has a count of $2$.","slur-and-legato-playing#Slur and Legato Playing":"A slur is a curved line over or under notes on different lines or spaces. Slurs means play legato (smoothly connected), they often divide the music intro phrases (a musical thougth or sentence).","staccato#Staccato":"The dot over or under the notes indicates the staccato touch, which means: make the note very short.","syncopated-notes#Syncopated Notes":"Notes that are played between the main beats of the measure and are held across the beat are called syncopated notes.","the-flat-sign#The Flat Sign":"The flat sign before a note means to play the next key to the left of said note.","the-grand-staff#The Grand Staff":"The bass staff and the treble staff, when joined together with a brace, make up the grand staff.","the-sharp-sign#The Sharp Sign":"The sharp sign before a note means to play the next key to the right (wether black or white).\nWhen a sharp appears before a note, it applies to that note for the rest of measure:","the-whole-note#The Whole Note":"A whole note is written as follows:\nThis noe has a count of $4$.","tied-notes#Tied Notes":"Whe notes on the same line of space are joined with a curved line, we call them tied notes. And the key is held down for the duration of both notes.","time-signature#Time Signature":"Music has numbers at the beginning of a score called the time signature. Where the upper $4$ means $4$ beats per measure and the lower $4$ means that a quarter note get one beat.","whole-step#Whole Step":"A whole step is equal to two half steps."},"title":"Notation"},"/notes/music/abpci/02_positions/":{"data":{"":"","do-position#Do Position":"Right Hand Do Position Place the right hand on the keyboard so that the 1st finger falls on Middle Do. The $4$ remaining fingers fall naturally on the next $4$ white keys:\nThe names of the $5$ keys are: do, re, mi, fa, sol.\nNotes for this position are writter on the trebble staff. See the following figure:\nThe treble clef sign is used for right hand notes.\nWe see that middle do is writter on a short line below the staff, which is called a leger line.\nLeft Hand Do Position This position is obtained by moving the left hand so that the $5$th finger falls on the Do below the middle Do. The remaning $4$ fingers fall naturally on the next $4$ white keys.\nNotes for this position are writter on the bass staff.\nRight Hand Extended Do Position This position is similar to the standard Do position, but modified as follows:\nSo now the first three fingers are on Do, Mi and Sol, while the last finger is on the next Do, an octave higher.","middle-do-position#Middle Do Position":"On this position the right hand is on Do Position, however the left hand is one key down from Sol Position, like so:\nSo both thumbs are over the middle Do.","sol-position#Sol Position":"Until now you have played only in the Do POSITION. Now you will move to the Sol POSITION:"},"title":"Positions"},"/notes/music/abpci/03_intervals/":{"data":{"":"","6ths#6ths":"When you skip 4 white keys then the interval is a 6th.","7ths#7ths":"When you skip 5 white keys then the interval is a 7th.","harmonic-interval#Harmonic Interval":"Notes played together make harmony. We call the intervals between these notes harmonic intervals.","harmonic-intervals-in-do-position#Harmonic Intervals in Do Position":"","harmonic-intervals-in-sol-position#Harmonic Intervals in Sol Position":"","melodic-interval#Melodic Interval":"Distances between tones are measured in intervals, called $2$nds, $3$rds, $4$ths, $5$ths, etc.\nNotes playes separately make a melody, and we call the intervals between these notes melodic intervals.","melodic-intervals-in-do-position#Melodic Intervals in Do Position":"","melodic-intervals-in-sol-position#Melodic Intervals in Sol Position":"","octave#Octave":"When you skip 6 white keys then the interval is an octave."},"title":"Intervals"},"/notes/music/abpci/04_chords/":{"data":{"":"","arpeggiated-progressions#Arpeggiated Progressions":"When a wavy line appears beside a chord, the chord is said to be arpeggiated, that is broken or rolled. This means that you should play the lower note first, and quickly add the next higher notes one at a time until the chord is complete.","chord-progressions#Chord Progressions":"When we change from one chord to another, we call this a CHORD PROGRESSION.\nTo make the chord progressions easier to play and sound better, the $IV$ and $V^7$ chords may be played in other positions by moving one or more of the higher chord tones down an octave. For example for the primary chords on Do Major:\nAnd the chord progressions for the primary chords Sol Major are:","chords-in-do-position#Chords in Do Position":"Do Major The Do Major Chord is made of three notes: Do, Mi and Sol.\nThe $\\textbf{Sol}^7$ chord is made of three notes: Si, Fa and Sol.\nSol7 Fa Major The Fa Major Chord is made of three notes: Do, Fa and La.","chords-in-sol-position#Chords in Sol Position":"Sol Major Re7 Do Major in Sol Position We know that the Do Major is composed of the following notes: Do, Mi, Sol. When you play the same notes of a chord in a different order, it’s still the same chord, but in what’s called an inversion. For example:\nRoot position of the Do major chord: Do (root), Mi, Sol. First inversion: Mi, Sol, Do (Mi is the lowest note). Second inversion: Sol, Do, Mi (Sol is the lowest note). ","major-3rd#Major 3rd":"A Major 3rd is an interval between two notes that are four half steps (semitones) apart. This interval gives a bright and happy sound. For example:","minor-3rd#Minor 3rd":"A Minor 3rd is an interval between two notes that are three half steps (semitones) apart. This interval gives a slightly darker or sadder sound. For example:","perfect-5th#Perfect 5th":"A Perfect 5th is a musical interval that spans seven half steps (or semitones) between two notes. For example:","primary-chords#Primary Chords":"The three most important chords in any key are those built on the 1st, 4th and 5th notes of the scale. These are called the PRIMARY CHORDS of the key.\nThe chords are identified by the roman numerals $\\textbf{I}$, $\\textbf{IV}$ and $\\textbf{V}$. The $\\textbf{V}$ chord usually adds the note a $7$th above the root to make a $\\textbf{V}^7$.\nPrimary Chords in Do Major The $\\textbf{I}$ chord is the Do Major Triad. The $\\textbf{IV}$ chord is the Fa Major Triad. The $\\textbf{V}$ chord is the $\\text{Sol}^7$ Major Triad. (Sol Major triad with an added $7$th). Primary Chords in Sol Major The $\\textbf{I}$ chord is Sol Major. The $\\textbf{IV}$ chord is the Do Major in Sol position. The $\\textbf{V}$ chord is the Re7 Major. Primary Chords in Fa Major The $\\textbf{I}$ chord is Fa Major. The $\\textbf{IV}$ chord is the Sib Major. The $\\textbf{V}$ chord is the Do Major. Primary Chords in Re Minor The $\\textbf{I}$ chord is Re Minor (Rem). The $\\textbf{IV}$ chord is the Sol Minor (Solm). The $\\textbf{V}$ chord is the La7. ","tetrachord#Tetrachord":"A tetrachord is a series of four notes having a pattern of:\nWhole step, whole step, half step","triads#Triads":"A triad is a 3-note chord. The three notes of a triad are:\nRoot Third Fifth The root is the note from which the triad gets its name. The root of a Do Triad is Do.\nTriads in root position are triads that have the root at the bottom.\nMajor Triads Major triads consist of a root a Major 3rd and a Perfect 5th.\nMinor Triads Major triads consist of a root a Minor 3rd and a Perfect 5th.\nAny Major triad may be changed to a minor triad by lowering the 3rd one half step."},"title":"Chords"},"/notes/music/abpci/05_scales/":{"data":{"":"","harmonic-scale#Harmonic Scale":"In the harmonic minor scale, the 7th tone is rained one semitone. You can see on the following image that the seventh tone is flat. This flat is not included in the key signature, but is written each time it occurs.","major-scales#Major Scales":"Do Major Scale The Do Major scale is constrcuted as follow:\nEach scale begins and ends on a note of the same name as the scale, called the key note.\nSol Major Scale The Sol Major Scale is also made up of two tetrachods, where the second tetrachord begins in Re:\nFa Major Scale The Fa Major Scale follows the following structure:","minor-scales#Minor Scales":"The La Harmonic Minor Scale This is the most frequently used minor scale.\nThe Re Harmonic Minor Scale "},"title":"Scales"},"/notes/music/abpci/06_keys/":{"data":{"":"","major-keys#Major Keys":"Key of Sol Major A piece based on the Sol major scale is in the KEY OF Sol MAJOR. Since fa is sharp in the Sol scale, every fa will be sharp in the key of Sol major. Instead of placing a sharp before every fa in the entire piece, the sharp is indicated at the beginning in the KEY SIGNATURE.\nKey of Fa Major A piece based on the Fa Major Scale has the following key signature:","minor-keys#Minor Keys":"Every Major key has a relative minor key that has the same key signature.\nThe relative minor being on the 6th tone of the major scale.\nRelative Minor of Do Major: La Minor The relative minor of Do Major is La Minor:\nBecause the key of Do Major and La Minor have the same key signature (no sharps and no flats) we say that they are relatives.\nThe minor scale shown above is called the natural minor scale.\nRelative Minor of Fa Major: Re Minor The Re Minor is the relative of Fa Major and both keys have the same signature (1 flat: Si). Remember the relative minor beings on the 6th tone of the major scale.\nThe minor scale shown above is the natural minor scale. That is, a scale that only uses the notes that are found in the relative major scale.","most-frequently-used-keys#Most Frequently Used Keys":"Major Keys Do Major Sol Major: 1 sharp on Fa. Fa Major: 1 flat on Si. Minor Keys (Harmonic Minors) La Minor: relative of Do Major. Re Minor: relative of Fa Major, 1 flat on Si. "},"title":"Keys"},"/notes/music/abpci/07_tidbits/":{"data":{"":"","blues#Blues":"Music cal led BLUES has long been a part of the of American musical heritage. We find it in the music of many popular song writers, in ballads, boogie and rock. Blues follows a basic formula, that is, a standard chord progression:\n4 measures of the I chord 2 measures of the IV chord 2 measures of the I chord 1 measure of the $V^7$ chord 2 measures of the IV chord 2 measures of the I chord "},"title":"Tidbits of Music"},"/notes/other/":{"data":{"":" Arch Linux Installation MacOS VM "},"title":"Other"},"/notes/other/mac_os/":{"data":{"":"Source","initial-setup#Initial setup":"Ubuntu/Debian:\n$ sudo apt-get install qemu uml-utilities virt-manager git \\ wget libguestfs-tools p7zip-full make dmg2img -y Fedora:\n$ sudo dnf install @virutalization Start libvirt service:\n$ sudo systemctl start libvirt $ sudo systemctl enable libvirt Add user to the kvm and libvirt groups (might be needed).\n$ sudo usermod -aG kvm $(whoami) $ sudo usermod -aG libvirt $(whoami) $ sudo usermod -aG input $(whoami) Note: Re-login after executing this command. Now edit /etc/libvirt/qemu.conf and set user and group to your user.\nClone this repository on your QEMU system. Files from this repository are used in the following steps.\n$ cd ~ $ git clone --depth 1 --recursive https://github.com/kholia/OSX-KVM.git $ cd OSX-KVM Note: with this you are installing your VM on $HOME.\nFetch macOS installer.\n$ ./fetch-macOS-v2.py On this step select Monterey.\nConvert the downloaded BaseSystem.dmg file into the BaseSystem.img file.\n$ dmg2img -i BaseSystem.dmg BaseSystem.img Create a virtual HDD image where macOS will be installed. If you change the name of the disk image from mac_hdd_ng.img to something else, the boot scripts will need to be updated to point to the new image name.\n$ qemu-img create -f qcow2 mac_hdd_ng.img 128G Be aware that the machine can easily reach that amount of memory.","installation#Installation":"CLI method (primary). Just run the OpenCore-Boot.sh script to start the installation process.\n$ ./OpenCore-Boot.sh Before installing go to Disk Utility inside the machine and erase the partition we are going to use for the virtual machine (the one that is roughly 128GB). For that click on Erase and select Mac OS extended (Journaled).\nOnce the erasing procedure is done, you can start the installation normally.\nEdit macOS-libvirt-Catalina.xml file and change the various file paths (search for CHANGEME strings in that file). The following command should do the trick usually.\n$ sed \"s/CHANGEME/$USER/g\" macOS-libvirt-Catalina.xml \u003e macOS.xml $ virt-xml-validate macOS.xml Create a VM on virt-manager by running the following command.\n$ virsh --connect qemu:///system define macOS.xml Launch virt-manager and start the macOS virtual machine.","post-installation#Post-installation":"Open virt-manager, select macOs and edit CPUs and memory so the virtual machine does not lag incredibly.\nPermissions bug (Might only happen in Fedora) If you get an error when starting the machine related to permissions, they are solved with:\n$ sudo setenforce Permissive If they are related with SELinux. If that is the case, refer to.\nUndo the previous command with:\n$ sudo setenforce Enforcing On your $HOME directory try to fix with:\n$ sudo chcon -R -u system_u -r object_r -t svirt_image_t OSX-KVM/ Screen resolution Execute the virtual machine and press ESC inmmediately. Select Device Management option and change OVMF to 1920x1080p resolution.\nEnter the virtual machine, once it has been booted open a terminal and write:\n$ diskutil list Select the disk where the EFI partition is location\n$ sudo diskutil mount disk1s1 $ vi /Volumes/EFI/EFI/OC/config.plist And edit the entry under Resolution to be 1920x1080@32. Reboot the machine.\nOnce rebooted go to System preferences \u003e Displays and check Show all resolutions and select 1920x1080.\nConnect to physical iphone Open virtual manager, and enter the configuration of the machine. Click on Add hardware and select USB host, now edit the xml entry just created and substitue the content with:\n\u003chostdev mode=\"subsystem\" type=\"usb\" managed=\"yes\"\u003e \u003csource\u003e \u003cvendor id=\"0x05ac\"/\u003e \u003cproduct id=\"0x12a8\"/\u003e \u003c/source\u003e \u003caddress type=\"usb\" bus=\"0\" port=\"1\"/\u003e \u003c/hostdev\u003e Where vendor id and product id is obtained through lsusb on the host machine:\n$ lsusb ... Bus 001 Device 004: ID 05ac:12a8 Apple, Inc. iPhone 5/5C/5S/6/SE ... Keyboard is locked If the keyboard seems to be captured when the machine starts, remove the entry on the machine hardware configuration that has this content or similar (This is my keyboard’s smart card, may not apply to your case.)\n\u003chostdev mode=\"subsystem\" type=\"usb\" managed=\"yes\"\u003e \u003csource\u003e \u003cvendor id=\"0x04f2\"/\u003e \u003cproduct id=\"0x1469\"/\u003e \u003c/source\u003e \u003caddress type=\"usb\" bus=\"0\" port=\"2\"/\u003e \u003c/hostdev\u003e Optimization Source\nOnly the following are actually important:\nAdd more video memory Open virtual manager, select macOs machine and open the configuration. Locate VGA and change the xml entry so that vgamem has the value 65536.\nSkip the GUI login screen (at your own risk!) $ defaults write com.apple.loginwindow autoLoginUser -bool true Disable spotlight indexing on macOS to heavily speed up Virtual Instances. $ sudo mdutil -i off -a Enable performance mode # check if enabled (should contain `serverperfmode=1`) $ nvram boot-args # turn on $ sudo nvram boot-args=\"serverperfmode=1 $(nvram boot-args 2\u003e/dev/null | cut -f 2-)\" Disable heavy login screen wallpaper $ sudo defaults write /Library/Preferences/com.apple.loginwindow DesktopPicture \"\" Reduce Motion \u0026 Transparency (could be faulty) defaults write com.apple.Accessibility DifferentiateWithoutColor -int 1 defaults write com.apple.Accessibility ReduceMotionEnabled -int 1 defaults write com.apple.universalaccess reduceMotion -int 1 defaults write com.apple.universalaccess reduceTransparency -int 1 defaults write com.apple.Accessibility ReduceMotionEnabled -int 1 To undo any of this changes refer to the reference material.\nGPU passthrough To be continued"},"title":"MacOS VM"},"/notes/other/rices/":{"data":{"":"","install#Install":"Place yourself inside the root of the repository:\ncd ArchInstaller Check out the configuration file, in case some values do not make sense to you:\ncat install_scripts/config.sh If you are satisfied with the configuration, simply execute:\ncd install_scripts \u0026\u0026 ./install.sh This will cause the installation to begin. It is mostly automatic, but sometimes you will have to enter a password here and there. So do not just let it execute by itself, because there are timeouts that will cause the installation to hault with an error.\nOnce this finished, reboot your computer. When the computer is up and running again, you will be met with a very minimal login interface. Log in with you user, and execute the following:\ncd /install_scripts \u0026\u0026 ./post_install This script prompts you to connect to a wifi access point. It also sets up some needed services (like lightdm!) and removes all the installation files used from you system so it is nice an clean. Well, now your arch linux is ready to go!","set-up#Set up":"Set the keyboard layout:\n$ loadkeys es Augment the size of the iso image:\n$ mount -o remount,size=1G /run/archiso/cowspace Download git:\n$ pacman -Syy \u0026\u0026 pacman -S git Configure git to store the credentials:\n$ git config --global credential.helper store Clone the repository:\ngit clone https://github.com/albamr09/ArchInstaller.git Now, you are good to go to start the installation process."},"title":"Arch Linux Installation"},"/notes/webdev/":{"data":{"":" Frontend Backend "},"title":"Web Development"},"/notes/webdev/back/":{"data":{"":" Node Django Spring Docker MongoDB "},"title":"Backend"},"/notes/webdev/back/django/":{"data":{"":"","apps#Apps":"Models The models can be thought of as objects, in the sense of OOP, that have certain attributes. This objects are then mapped by Django to the database of choice. To define new models, or modify existing model (e.g. the user model) you need to modify the models.py file in the root folder of every app that is created. Alternatively, you can centralize all of your models on the core app.\nAn example of a simple model is the following Tag model:\nclass Tag(models.Model): \"\"\"Tag to be used for a book\"\"\" # Define the attributes of the table name = models.CharField(max_length=255) # Define the relation between the tag and the user user = models.ForeignKey( settings.AUTH_USER_MODEL, on_delete=models.CASCADE, ) # Define the string representation of the Tag def __str__(self): return self.name Once the model is define, it needs to be registered on the admin.py file:\nadmin.site.register(models.Tag) Specifically when modifying existing models, you will need to extend the classes defined by Django (e.g. AbstractBaseUser, UserAdmin). For example:\nclass User(AbstractBaseUser, PermissionsMixin): \"\"\"Custom user model that suppors using email instead of username\"\"\" email = models.EmailField(max_length=255, unique=True) name = models.CharField(max_length=255) is_active = models.BooleanField(default=True) is_staff = models.BooleanField(default=False) objects = UserManager() Which has to be registered as follows:\nadmin.site.register(models.User, UserAdmin) Where UserAdmin is a class define in the admin.py file, that defines the custom User model:\nclass UserAdmin(BaseUserAdmin): ordering = ['id'] list_display = ['email', 'name'] # User edit page fields fieldsets = ( (None, {'fields': ('email', 'password')}), (_('Personal Info'), {'fields': ('name',)}), ( _('Permissions'), {'fields': ('is_active', 'is_staff', 'is_superuser')} ), (_('Important Dates'), {'fields': ('last_login',)}) ) # User create page fields add_fieldsets = ( (None, { 'classes': ('wide',), 'fields': ('email', 'password', 'password2') }), Admin This is the feature that allows you to manage your models, let it be create them, modify them or delete them. The functionality of the admin model is defined within the admin.py file on the root folder of every app that is created.\nIn order to create a superuser execute the following command:\n$ python manage.py createsuperuser On Docker:\n$ docker-compose run app sh -c \"python manage.py createsuperuser\" Then, you will be prompted to enter an email and a password. Once you have filled said fields, you can start the server with\n$ docker-compose up And enter to the admin page located on 127.0.0.1:8000/admin, where you can log in with your credentials.\nURLs Django allows us to define relative URLs on a very modular way. First off, we have the core file when it comes to URL definition: app/app/urls.py. Here we may have something like this:\nfrom django.contrib import admin from django.urls import path, include urlpatterns = [ path('admin/', admin.site.urls), path('api/user/', include('user.urls')), ] This example shows that the urlpatterns variable is a list that holds all of the urls defined in our project. The modularization comes from the way the URLs defined on the user’s app are specified. First we specify the endpoint for these URLs (namely api/user/), and then we pull all the relative URLs from the user’s app, defined on the file app/user/urls.py. Which are then concatenated with api/user/.\nThe URLs defined on the user app are as follows:\napp_name = 'user' urlpatterns = [ path('create/', views.CreateUserView.as_view(), name='create'), ] This the can be used like this:\n# Create user api endpoint dinamically CREATE_USER_URL = reverse('user:create') Serializers This files are defined to specify how to serialize (map to the database) the JSON objects received, in our case, from HTTP requests. For that we create, for each model, a class that extends serializers.ModelSerializer. In this class we define an inner class called Meta that tells the framework which fields does the object have and so allows the mapping to take place. You can also add extra arguments to this inner class, for example to restrict or exercise a stronger control on the fields.\nNext on, we have a simple example of our User Model serializer:\nfrom django.contrib.auth import get_user_model from rest_framework import serializers class UserSerializer(serializers.ModelSerializer): \"\"\"Serializer for the users object\"\"\" class Meta: \"\"\"Info about how to serialize the user model\"\"\" model = get_user_model() fields = ('email', 'password', 'name') # Extra requirements for the user model extra_kwargs = {'password': {'write_only': True, 'min_length': 5}} def create(self, validated_data): \"\"\"Create a new user with encrypted password and return it\"\"\" # validation_data: JSON data passed in the HTTP POST return get_user_model().objects.create_user(**validated_data) We can also serialize an object that is not related to a model per se, for example:\nclass AuthTokenSerializer(serializers.Serializer): \"\"\"Serializer for the user authentication object\"\"\" email = serializers.CharField() password = serializers.CharField( style={'input_type': 'password'}, trim_whitespace=False ) Views This is, on simple terms, a Python function that takes a Web request and returns a Web response. In our case, we will mostly use views for our API, so we use pre-make view that allows us to easily make an API that creates, updates, etc an object on the database using the serializer that we specify, for example, the API for creating a user is as follows:\nclass CreateUserView(generics.CreateAPIView): \"\"\"Create a new user in the system\"\"\" serializer_class = UserSerializer In case of wanting to update an object we extend generics.RetrieveUpdateAPIView instead of generics.CreateAPIView. Because this view is private, we need to indicate an authentication mechanism and the level of permissions the user has, in our case the authentication is made via token and the permissions are that the user needs to be logged in.\nclass ManageUserView(generics.RetrieveUpdateAPIView): \"\"\"Manage the authenticated user\"\"\" serializer_class = UserSerializer # Authentication mechanism by which the authentication happens authentication_classes = (authentication.TokenAuthentication,) permission_classes = (permissions.IsAuthenticated,) def get_object(self): \"\"\"Retrieve and return authentication user\"\"\" return self.request.user Actions Start the server Observe that this is executed on the docker-compose configuration file\n$ python manage.py runserver 0.0.0.0:8000 Sync Django settings (app/app/settings.py) $ python manage.py migrate On docker:\n$ docker-compose run app sh -c \"python manage.py migrate\" Sync changes made on models $ docker-compose run app sh -c \"python manage.py migrate\" On docker:\n$ docker-compose run app sh -c \"python manage.py makemigrations\" You can also specify the name off the app that contains the model\n$ python manage.py makemigrations app_name "},"title":"Django"},"/notes/webdev/back/docker/":{"data":{"":" Docker Basics Advanced Docker Concepts Container Orchestration "},"title":"Docker"},"/notes/webdev/back/docker/01_basics/":{"data":{"":"","cmd-vs-entrypoint#\u003ccode\u003eCMD\u003c/code\u003e vs \u003ccode\u003eENTRYPOINT\u003c/code\u003e":"Intro What are containers They are completely isolated environments, they have their own processes, network interfaces, etc. However they share the same os kernel.\nDocker uses LXC containers, which are very low lever, so Docker provides a high level tool that allows us to manage our containers easily.\nSharing the Kernel As we have said, Docker uses the system’s kernel, so it is capable of running any distributions whose underlying kernel is Linux (e.g. Docker running on Ubuntu can run a container based on Debian, Fedora, etc.)\nContainers vs Virtual Machines Containers: Application 1 Application 2 Libs/Dependencies 1 Libs/Dependencies 2 Container 1 Container 2 Docker OS Hardware Virtual Machines: Application 1 Application 2 Libs/Dependencies 1 Libs/Dependencies 2 OS 1 OS 2 Virtual Machine 1 Virtual Machine 2 Hypervisor Hardware The main differences are the use of Hypervisors in Virtual Machines and how on these, each instance has its own OS. Which results in needing more hardware resources. Also Virtual Machines have total isolation, as they use their own OS, which does not happen with containers, because these do share the same kernel.\nHowever the key is combining both technologies, so each virtual machine runs several applications hosted in different containers.\nContainer vs Image An image can be thought as a package or a template that is used to create one or more containers. That is to say, containers are running instances of images that are isolated and have their own environment.\nSet Up Install Docker In the current section we will lay out the steps to carry out in order to get docker up and running on an Arch Linux machine.\nDocker Engine Before installing anything we will update the system as follows\n$ sudo pacman -Syu When it is done updating we will proceed rebooting the system, and then we enable the loop module:\n$ sudo tee /etc/modules-load.d/loop.conf \u003c\u003c\u003c \"loop\" $ sudo modprobe loop Install using static binaries For reference go to the official documentation on Docker’s website.\nFirstly we will download the static binary archive on https://download.docker.com/linux/static/stable/. Once the file is downloaded extract it executing the following command, and substituting our docker-20.10.8 for your package’s version. $ tar xzvf docker-20.10.8.tgz Copy the binaries to your executable path (/usr/bin or /bin). This is optional. $ sudo cp docker/* /usr/bin/ Start docker’s daemon: $ sudo dockerd Finally run to check that the installation was correct (it will download an example image that outputs a message informing the user that the installation was successful, among other things). $ sudo docker run hello-world Official Repo This other approach will allows to have a docker service so we do not have to always run sudo dockerd \u0026 to start docker’s daemon.\nWe install Docker using pacman: $ sudo pacman -S docker Afterwards, we enable the docker service executing: $ sudo systemctl start docker.service $ sudo systemctl enable docker.service Finally run to check that the installation was correct (it will download an example image that outputs a message informing the user that the installation was successful, among other things). $ sudo docker run hello-world Configure Docker Running as normal user In order to use Docker as a normal user we need to add said user to the docker group.\nAdd the Docker group $ sudo groupadd docker Add your user to the Docker group $ sudo usermod -aG docker $USER Log out, log in and verify that it runs properly $ docker run hello-world Install Docker Compose Download the current stable release of Docker Compose. Mind you, this command downloads the 1.29.2 version, check the official page for new releases. {{{console\n$ sudo curl -L “https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)” -o /usr/local/bin/docker-compose\n}}}\nMake the binary executable $ sudo chmod +x /usr/local/bin/docker-compose Test the installation $ docker-compose --version docker-compose version 1.29.2, build 5becea4c Container RUN Basics Run a container from an image, the attached way, (i.e. it is not run on the background). $ docker run nginx If the image is not present on the host it will be downloaded from Docker Hub.\nWhen it is downloaded it runs and exits right away, because there is not application running in the container.\nTo run the container in the detach mode, so it run on the background:\n$ docker run -d nginx To bring the container to the foreground:\n$ docker attach ( container_id | container_name ) Run a container with a specific tag: $ docker run redis:4.0 This way we run the redis image where redis’s version is 4.0.\nRun a container listening to the standard input (because by default Docker does not listen for input): $ docker run -i \u003cimage_name\u003e This way we are running our container in interactive mode.\nIn order to attach a terminal:\n$ docker run -it \u003cimage_name\u003e Port Mapping Each container is assigned a port (e.g. 5000) and an internal IP by default (e.g. 127.17.0.2) but this IP is only accessible from the host. So to access it from outside, we would use our host’s IP (e.g. 192.168.1.5), however we still need to map our container’s port to a free port in our host.\nSo to map, for example, the port 5000 of our Docker container to the port 80 of our host:\n$ docker run -p 80:5000 \u003cimage_name\u003e And now, we can access the service running in our Docker container by heading to 192.168.1.5:80. This way all traffic in this specific URL will be routed to the port 5000 in our Docker container.\nVolume Mapping Our container has its own file system, so the changes made to data stored in it are only made in the container.\nIf you want certain data to persist (because when removing the Docker container the files stored within are also removed) you use the flag -v to map a certain file/folder in the container to a certain file/folder in our host:\n$ docker run -v /opt/datadir:/var/lib/mysql mysql In this particular example we store the data we saved in our MySQL database in a directory in our container (/var/lib/mysql), and we map this directory to a directory in our host (/opt/datadir) This way Docker mounts implicitly the folder in our host to the folder in the container.\nLinking If we have a web application that connects to a redis instance, we need to tell the web app’s container which redis instance to wait for (because there may be multiple). So, first we start the redis container:\n$ docker run -d --name=redis redis And now we start our web app’s container and we link it with the redis container:\n$ docker run -d --name=vote -p 5000:80 --link redis:redis voting-app The redis before the colon is the name of our redis container, and the redis after the name is the name used in the web app container.\nThis option is soon to be deprecated because new concepts are technologies are being introduced.\nInformation of a Container In order to get more detailed information about a certain container:\n$ docker inspect ( container_name | container_id ) Logs To see the logs of a container (usually printed to the stdout):\n$ docker log ( container_name | container_id ) LIST Lists all running containers and some information about it. $ docker ps To see all containers, even if they are not currently running:\n$ docker ps -a STOP Stop running a container who matches the id or the name provided: docker stop ( container_id | container_name ) REMOVE Removes a container permanently docker rm ( container_id | container_name ) Execute commands To execute a command after creating a new container: $ docker run ubuntu sleep 5 This commands starts the container and run the command sleep 5 and then exits.\nTo execute a command in a currently running container: $ docker exec ( container_id | container_name ) cat /etc/hosts Image Commands LIST Lists downloaded images: $ docker images Or alternatively:\n$ docker image ls REMOVE Remove an image $ docker rmi nginx You must stop and remove all the containers that are instances of the image before removing said image.\nDOWNLOAD To only download an image and not also run a container: $ docker pull nginx Create your own image First create a Dockerfile specifying all of the steps required to set up your application:\nFROM ubuntu RUN apt-get update RUN apt-get install python RUN pip install flask RUN pip install flask-mysql COPY . /opt/source-code ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask run Then build your image, to store locally:\n$ docker build Dockerfile -t mycustomapp Here we specify our Dockerfile as input for building the image and the tag of the image with the flag -t.\nTo make it available on the DockerHub:\n$ docker push mycustomapp Dockerfile This is configuration file that follows a certain syntax and tells Docker how to build the image. The syntax is the following:\nINSTRUCTION ARGUMENT In the previous example we have:\nFROM: defines the base image, which can be an OS or another image (every image have to be based off another image). RUN: run a particular command on the base image. COPY: copies files from the host system onto the Docker image. ENTRYPOINT: specifies the command that will be run when the container is started. Layered architecture Docker follows a layered architecture so each INSTRUCTION represents a different layer, which contains only the changes from the layer before, and may serve as a snapshot from which to start the build from a particular layer.\nAlso, Docker caches the layers, so if there is an error, the build would start from the last layer that did not produce a failure. Also, if you were to add additional steps, Docker would not start the build from scratch.\nCMD vs ENTRYPOINT CMD A command allows us to append to the command executed when the container start of the base image. For example, Ubuntu’s CMD is bash, so if we append sleep 5 our container will sleep for 5 seconds when started and then exit.\nFROM Ubuntu CMD sleep 5 The command can also be specified as CMD [\"sleep\", \"5\"].\nENTRYPOINT This other instruction also adds to the base image starting command, but this lets us add arguments from the command line, for example, if we define the following Dockerfile:\nFROM Ubuntu ENTRYPOINT [\"sleep\"] We build the image\n$ docker build Dockerfile -t ubuntu-sleeper And then we running with 10 as and argument:\n$ docker run ubuntu-sleeper 10 Our container will sleep for 10 seconds and then exit.\nTo define a default value for sleep, when no argument is passed from the command line, we use both ENTRYPOINT and CMD\nFROM Ubuntu ENTRYPOINT [\"sleep\"] CMD [\"5\"] To override the ENTRYPOINT command specified in the Dockerfile we use the flag --entrypoint:\n$ docker run --entrypoint sleep2.0 ubuntu-sleeper 10 Difference When using CMD when running:\n$ docker run ubuntu-sleeper sleep 10 The argument sleep 10 replaces entirely the starting command. However with ENTRYPOINT if we run:\n$ docker run ubuntu-sleeper 10 The argument 10 is passed and appended to the ENTRYPOINT command.","container#Container":"","environment-variables#Environment Variables":"In order to pass an environment variables to our container we run:\n$ docker run -e ENV_VAR=value \u003cimage_name\u003e This way we set up and environment variable within the container.\nIf you inspect a running container, you will be able to see the environment variables defined, inside the \"Env\" object:\n$ docker inspect \u003cimage_name\u003e { . . \"Config\": { \"Hostname\": \"51049352a8ee\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"ExposedPorts\": { \"3456/tcp\": {}, \"80/tcp\": {} }, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"NGINX_VERSION=1.19.10\", \"NJS_VERSION=0.5.3\", \"PKG_RELEASE=1\" ], \"Cmd\": [ \"nginx\", \"-g\", \"daemon off;\" ] . . . } ","image-commands#Image Commands":"","intro#Intro":"","set-up#Set Up":""},"title":"Docker Basics"},"/notes/webdev/back/docker/02_advanced/":{"data":{"":"","docker-compose#Docker Compose":"Build If we would like to tell Docker Compose to build a Docker build instead of pulling an image we use the build keyword inside a service instead of the image keyword. And we specify the location of the directory which contains the application code and a Dockerfile.\nvote: build: ./vote ports: - 5000:80 links: - redis Versions Different Docker Compose versions have different formats and functionality.\nVersion 2 From version 2 on, you must specify the Docker Compose version by adding to the top of the file:\nversion: 2 Also, all of the different containers should be listed under a sevices section.\nAnd now, links are no longer needed as Docker creates a virtual network and attaches all of the services to this network with the name of the service.\nFinally, a depends_on keyword is introduced to force a order of startup.","docker-compose-networks#Docker Compose Networks":"Let’s start with an example application, which is made up of five services:\nvoting-app: a front-end application for the user to vote. redis: and in-memory database to store the vote. worker: application in the back-end that processes the vote and stores it in the database. db: database in which the vote is stored. result-app: front-end application that shows the voting results. In this architecture we have two networks:\nfront-end: voting-app and result-app back-end: all the services. Therefore it is desirable to define two networks in our docker-compose and attach the networks to the services:\nversion: 2 services: redis: image: redis networks: - back-end db: image: postgres networks: - front-end vote: image: voting-app networks: - front-end - back-end result: image: result networks: - front-end - back-end worker: image: worker networks: - front-end - back-end networks: - front-end: - back-end: As you can see we define two networks: front-end and back-end (note that we have omitted the configuration of the networks) and then for each service we specify the network to which the service has access (also, observe that the configuration of the services has been trimmed down for readability purposes).","docker-engine#Docker Engine":"Containerization As we have seen all of our containers run on top of the same operative system, so it is a given that the processes will be handled by the same kernel. This means that the processes of our containers are run along with the rest of processes in the host machine, in other words the PIDs of all the processes must be different.\nWhat Docker does to isolate these processes is the container is using namespaces and maps the process id to another process id within the container, and that is visible only on this container.\ncgroups Because all docker containers share the hosts resources it could be possible that a container takes up all of the machine’s resources. So, to restrict the amount of resources used by a container Docker uses cgroups. You can specify the amount of CPU or RAM that the container is allowed to have:\n$ docker run --cpus=.5 ubuntu $ docker run --memory=100m ubuntu ","docker-on-windows-and-mac#Docker on Windows and Mac":"Windows Containers The options just discussed will only work for Linux applications and containers. In 2016 Microsoft announced support for Windows containers, there are two types:\nWindows Server Container: the containers share the kernel, as regular Linux containers do. Hyper-V isolation: each container is run within a highly optimized virtual machine, so complete kernel isolation between the containers and the underline host is guaranteed. Base Images Where in Linux we had the debian, ubuntu or alpine base images in windows we have two options:\nWindows Server Core Nano Server: this is a headless deploy of the Windows Server, that is, the lightweight option. ","docker-registry#Docker Registry":"Public Registry In the following example you are pulling the nginx image, which in reality is stored as nginx/nginx where the first nginx corresponds to the user name, and the second to the image name.\nimage: nginx This is a public image so it is stored in a public registry, usually in docker.io which is the default registry. So a more verbose configuration file would be:\nimage: docker.io/nginx/nginx Private Registry When you have applications that should no be made available to the public private registries are used.\nTo pull or use an image from a private registry:\nRegister into the private registry: $ docker login private-registry.io Run the image indicating the registry: $ docker run private-registry.io/apps/internal-app Deploy Private Registry A private registry is in itself a docker image, so first you have to have your registry image running:\n$ docker run -p 5000:5000 --name registry registry:2 So now you have your registry running on port 5000. The next step is to assign a tag to your image as follows:\n$ docker image tag my-image localhost:5000/my-image Where my-image is the name of the image and localhost:5000/my-image is the tag assigned.\nFinally you push your image to your registry\n$ docker push localhost:5000/my-image Now you can pull your image:\n$ docker pull localhost:5000/my-image $ docker pull 192.168.56.100:5000/my-image ","networking#Networking":"Bridge This is a private internal network created by Docker on the host. All containers can access each other using their internal IP (usually subnets of 172.17.0.3).\nTo access from outside you have to map a port of the container to a port of the host.\nhost Another way to configure the network is to associate the container to the host’s network, removing all kind of network isolation between the Docker host and the Docker container.\nThis way when you run a server on port 5000 it would automatically accessible from the host on the port 5000 without needing to map it to a host’s port.\nThis prevents you from using the same ports for different applications.\nnone The containers are not attached to any network and are, therefore, isolated from any other containers so they do not have any access to the external network or other containers.\nUser defined networks Because with the default internal network, the containers can access each other, it is sometimes desirable to create new internal networks:\n$ docker network create --drive bridge --subnet 172.18.0.0/16 \u003cnetwork_name\u003e To list the created networks:\n$ docker network ls Inspect network In order to see the network configuration use inspect and head to the Networks section:\n$ docker inspect ( container_name | container_id ) . . . \"MacAddress\": \"aa:bb:cc:dd:ee:ff\", \"Networks\": { \"bridge\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"24af0d...\", \"EndpointID\": \"3449a29...\", \"Gateway\": \"172.17.0.1\", \"IPAddress\": \"172.17.0.3\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:11:00:03\", \"DriverOpts\": null } } . . . Embedded DNS When containers in the same subnet may want to access each other, for that you could hard code the internal IP assigned to the containers. However this is not advisable, as this IP may change when the container is started in another occasion in the future.\nBecause of that all containers in a Docker host can resolve each other using their names. This is possible has a built-in DNS server for this purpose that runs at 172.0.0.11.","storage#Storage":"Layers Because of Docker’s layered architecture when creating very similar images that share a lot of instructions, it uses the cached layers and is, therefore more efficient by not building each image from scratch.\nFor example, when you update your application’s source code, only the instructions after the COPY instruction, this one included, from your Dockerfile is run.\nImage and Container Layers The layers created from each instruction on the Dockerfile constitute the image layers and are all read-only files.\nWhen you run your image a new layer is created, denoted by Container Layer which is a writable file which is a writable file. However, when the container is destroyed, this layer is removed. This is the reason why we use volumes for permanent storage.\nThis is needed because all the containers use the same image, so the changes made in the image by the different containers should not affect the image.\nCopy-on-write Also, the changes made on files stored in the image are not made on the original file. The file is copied to the Container Layer and the changes are made onto this copy.\nVolumes As we have said, we need volumes to store permanent data. So, first we create the volume:\n$ docker volume \u003cvolume_name\u003e Which is stored in /var/lib/docker/volumes\nVolume mounting Once we have created the volume, we specify that we want to mount this volume within our container:\n$ docker run -v \u003cvolume_name\u003e:/var/lib/mysql mysql If you run this same command, without creating the volume first, Docker will automatically create the volume for you.\nBind mounting If you want to mount another directory that is not inside /var/lib/docker/volumes, then you have to specify the whole directory’s (may be an absolute or relative path).\n$ docker run -v /data/mysql:/var/lib/mysql mysql Mount This is the new way to mount:\n$ docker run --mount type=bind,source=/data/mysql,target=/var/lib/mysql Which is preferred as it is more verbose.\nStorage Administration The responsible for all of these operations that happen under the hood are the storage drivers, which are chosen depending on the hosts’ OS:\nAUFS ZFS BTRFS Device Mapper Overlay Overlay2 "},"title":"Advanced Docker Concepts"},"/notes/webdev/back/docker/03_containers/":{"data":{"":"","container-orchestration#Container Orchestration":"When in production, it is often needed that several instances of containers are run (because of a heavy load on the application for example). So in these cases you need to monitor the instances as well as the host itself in case any of them crash.\nFor that we use container orchestration that offers a set of tools and scripts that allow us to manage the hosts and containers.\nThe typical approach is to create several instances of containers in different hosts, so if one fails the application can still offer the service. For example:\n$ docker service create --replicas=100 nodejs Some solutions let us automatically scale the number of containers depending on the demand. Others can help in automatically adding new hosts to support the user load.\nThey also provide complex networking between the containers as well as load balancing user requests across different hosts or sharing storage between the hosts, configuration management or security.\nThere are several solutions:\nDocker Swarm from Docker Kubernetes from Google MESOS from Apache. ","docker-swarm#Docker Swarm":"Docker Service Docker Services are one or more instances of application or services that run along the nodes in the Swarm cluster.\n$ docker services create --replicas=3 \u003cimage-name\u003e This creates three instances of my image and runs them in the nodes of the cluster.\nThis command must be run on the manager node, not on the worker nodes.\nIt is similar to the docker run command in terms of the options to pass (networks, ports, interactive mode, etc.)","kubernetes#Kubernetes":"Architecture A kubernetes cluster consists of several nodes, the worker nodes are where containers will be launched, so even if one node fails the application is still available.\nKubernetes clusters are managed by the master, which is a node that watches over worker nodes and is responsible of the orchestration of containers in the worker nodes.\nComponents When you install Kubernetes in your system you are actually installing:\nAPI Server: acts as the front-end for Kubernetes, so all of the programs talk to this server to interact with the kubernetes server. etcd: it is the distributed reliable key value store to store all data to manage the cluster. Scheduler: responsible for distributing work. Controller: responsible for noticing/responding to nodes/containers going down. Container Runtime: underline software used to run containers (e.g. Docker). kubelet: is the agent that runs in each node in the cluster, and is responsible of making sure the containers are running on the nodes as expected. One of the command line utilities used by Kubernetes is kubectl, that is the Kubernetes CLI and is used to deploy and manage applications on a kubernetes cluster."},"title":"Container Orchestration"},"/notes/webdev/back/mongodb/":{"data":{"":"","mongodb-commands#MongoDB Commands":"To log into MongoDB with the created user and database:\n$ mongo -u \u003cyour username\u003e -p \u003cyour password\u003e \\\\ --authenticationDatabase \u003cyour database name\u003e Or\n$ mongo -u \u003cyour username\u003e \\\\ --authenticationDatabase \u003cyour database name\u003e To connect to the database use the following URI:\nmongodb://YourUsername:YourPasswordHere@127.0.0.1:27017/your-database-name "},"title":"MongoDB"},"/notes/webdev/back/node/":{"data":{"":"","express#Express":" HTTP and Express Basics API Development and Middleware Database and Authentication ","nodejs#Node.js":" Intro and Basics Core Concepts and Patterns Modules and Networking ","projects#Projects":" Books Directory Basic Users System Real-time Chat Application Collaborative Drawing App Email Sender Video Streaming Platform Web Scraper "},"title":"Node.js"},"/notes/webdev/back/node/01_intro/":{"data":{"":"","globals#Globals":"Some global variables available\n__dirname: path of current directory __filename require: function to use modules module: info about current module process: info about the environment where the program is bein executed Note that in Node there is no window object like in Javascript.","introduction#Introduction":"Differences between to the browser and NodeJS | Browser | NodeJS | | DOM | No Dom | | Window | No Window | | Interactive Apps | Server Side Apps | | No Filesystem | Filesystem | | Fragmentation | Versions | | ES6 Modules | CommonJS |\nHow to get Node to evaluate our code REPL (Read, Eval, Print Loop)\n$ node Welcome to Node.js v16.9.1. Type \".help\" for more information. \u003e CLI executable\n$ node 00_app.js large number hey it is my first node app "},"title":"Intro and Basics"},"/notes/webdev/back/node/02_core/":{"data":{"":"","asynchronous-patterns#Asynchronous Patterns":"Blocking Code Imagine we have the following piece of code:\nconst http = require(\"http\"); const server = http.createServer((req, res) =\u003e { if (req.url === \"/\") { res.end(\"Home Page\"); } if (req.url === \"/about\") { // blocking code for (let i = 0; i \u003c 1000; i++) { for (let j = 0; j \u003c 1000; j++) { console.log(`${i} ${j}`); } } res.end(\"About Page\"); } res.end(\"Error Page\"); }); server.listen(5000, () =\u003e { console.log(\"Server listening on port : 5000....\"); }); Because inside the second conditional we have a nested for loop which is computationally expensive, when a user accesses the about page, the server is blocked, and so it prevents other users from loading any other page. That is essentially because JavaScript is single threaded, so by running the nested conditional, the thread is occupied for a period of time, during which the server will not be able to answer to any other request until it is freed.\nPromises A Promise is an object that represents the eventual completion (or failure) of an asynchronous operation and its resulting value. So, we can wrap the asynchronous readFile function with a Promise:\nconst { readFile, writeFile } = require(\"fs\"); const getText = (path) =\u003e { return new Promise((resolve, reject) =\u003e { readFile(path, \"utf8\", (err, data) =\u003e { if (err) { reject(err); } else { resolve(data); } }); }); }; The result of a Promise can be accessed as follows:\ngetText(\"./content/first.txt\") .then((result) =\u003e console.log(result)) .catch((err) =\u003e console.log(err)); And then, we can define an asynchronous function start that will wait for the execution of getText:\nconst start = async () =\u003e { try { const first = await getText(\"./content/first.txt\"); const second = await getText(\"./content/second.txt\"); console.log(first, second); } catch (error) { console.log(error); } }; Where you can see that we surround the call with a try-catch statement, which allows us to have more control over the execution flow\nNode’s Native Promises We can use the utils module in order to wrap functions with the Promise object:\nconst { readFile, writeFile } = require(\"fs\"); const util = require(\"util\"); const readFilePromise = util.promisify(readFile); const writeFilePromise = util.promisify(writeFile); const start = async () =\u003e { try { const first = await readFilePromise(\"./content/first.txt\", \"utf8\"); const second = await readFilePromise(\"./content/second.txt\", \"utf8\"); await writeFilePromise( \"./content/result-mind-grenade.txt\", `THIS IS AWESOME : ${first} ${second}`, { flag: \"a\" } ); console.log(first, second); } catch (error) { console.log(error); } }; But, we can also avoid importing the utils module, by adding .promises when importing the asynchronous functions:\nconst { readFile, writeFile } = require(\"fs\").promises; const start = async () =\u003e { try { const first = await readFile(\"./content/first.txt\", \"utf8\"); const second = await readFile(\"./content/second.txt\", \"utf8\"); await writeFile( \"./content/result-mind-grenade.txt\", `THIS IS AWESOME : ${first} ${second}`, { flag: \"a\" } ); console.log(first, second); } catch (error) { console.log(error); } }; start(); ","event-loop#Event Loop":"It is what allows Node.js to perform non-blocking I/O operations, despite the fact that JavaScript is single-threaded- by offloading operations to the system kernel whenever possible.\nThe Event Loop follows the next steps:\nAn asynchronous request is made by a user The Event Loop registers the callback of the request When the request is completed and we are ready to execute the callback the Event Loop stores the callback at the end of the execution line, meaning, once the immediate tasks are done (i.e. synchronous code) the callback is executed For example, we have the following code:\nconst { readFile, writeFile } = require(\"fs\"); console.log(\"started a first task\"); readFile(\"./content/first.txt\", \"utf8\", (err, result) =\u003e { if (err) { console.log(err); return; } console.log(result); console.log(\"completed first task\"); }); console.log(\"starting next task\"); Which outputs:\nstarted first task starting next task Hello this is first text file Completed first task So we can see that the synchronous code is run first, and then the callback of the asynchronous function readFile is called upon finishing reading the file. In the next example:\n// started operating system process console.log(\"first\"); setTimeout(() =\u003e { console.log(\"second\"); }, 0); console.log(\"third\"); // completed and exited operating system process Which outputs:\nfirst third second So even though the timeout is initialized to 0, because it is an asynchronous function it is offloaded and so it is put to the end of the execution line, and then it is executed after the synchronous code. It is important to note that the listen function of the http module is also asynchronous.","events#Events":"Event Emitter All objects which emit events are instances of EventEmitter, which is accessible from the events module:\nconst EventEmitter = require(\"events\"); const customEmitter = new EventEmitter(); customEmitter.on(\"response\", () =\u003e { console.log(\"some other logic here\"); }); customEmitter.emit(\"response\"); Here we can see that we create an EventEmitter object and we listen for the response event with customEmitter.on(). The latter function takes the name of the event as its first argument and the callback as its second. In order to emit a concrete event we use customEmitter.emit(), which takes the event name as its argument.\nMore Listeners We can have more than one listener:\nconst EventEmitter = require(\"events\"); const customEmitter = new EventEmitter(); customEmitter.on(\"response\", (name, id) =\u003e { console.log(`data recieved user ${name} with id:${id}`); }); customEmitter.on(\"response\", () =\u003e { console.log(\"some other logic here\"); }); customEmitter.emit(\"response\", \"john\", 34); Where the second listener define a callback that takes name and id as arguments. So when emitting the event we can pass those arguments to the emit function.\nTake into account that the functions’ order matter, if you emit and event before you listen for it, the event will never be registered.\nHTTP Events Because http.Server extends net.Server which then extends EventEmitter, we can use the methods discussed above. So we can listen for the event request to handle requests from the browser.\nconst http = require(\"http\"); // Using Event Emitter API const server = http.createServer(); // emits request event // subcribe to it / listen for it / respond to it server.on(\"request\", (req, res) =\u003e { res.end(\"Welcome\"); }); server.listen(5000); ","streams#Streams":"Streams on the Web When reading and writing files on servers, it is highly advisable to use chunks instead of the hole file, like so:\nvar http = require(\"http\"); var fs = require(\"fs\"); http .createServer(function (req, res) { const text = fs.readFileSync(\"./content/big.txt\", \"utf8\"); res.end(text); }) .listen(5000); Instead of this approach, we use streams, both for reading and for writing:\nvar http = require(\"http\"); var fs = require(\"fs\"); http .createServer(function (req, res) { const fileStream = fs.createReadStream(\"./content/big.txt\", \"utf8\"); fileStream.on(\"open\", () =\u003e { fileStream.pipe(res); }); fileStream.on(\"error\", (err) =\u003e { res.end(err); }); }) .listen(5000); Here, we see that we use the on method to listen for the open event. And then, we use pipe to write on the stream."},"title":"Core Concepts and Patterns"},"/notes/webdev/back/node/03_modules/":{"data":{"":"","http-1#HTTP":"HTTP Messages Request Message: what the user sends Response Message: what the server sends The messages have the following parts:\nInfo about the request: Request URL, Request Method (GET is the default method), Status Code, etc. Headers: meta information about the request/response, (e.g. “Content type: application/json” tells the browser that the body is json) Body: which is the request payload, or the content of the response. ","modules#Modules":"Exporting So we can treat the attribute exports as an object and pass it whatever values we would like to show to other app that import our module:\nmodule.exports = { value1: \"value1\", value2: \"value2\" }; Where value1 is the key of the attribute and 'value1' is its value, e.g.:\nconst name = \"John\"; const surname = \"Tuckey\"; module.exports = { Name: name, Surname: surname }; Also, if we only export one object it is sufficient to type:\nconst name = \"John\"; module.exports = name; Another way to export is to define explicitly the name of the attributes to export:\nmodule.exports.items = [\"item1\", \"item2\"]; const person = { name: \"bob\", }; module.exports.singlePerson = person; Importing Now, a module can be imported with the keyword require as follows:\nconst externalModule = require('./module') console.log(externalModule) { Name: 'John', Surname: 'Tukey' } Another type of syntax could be unrolling the attributes of the export object:\nconst { Name, Surname } = require(\"./module\"); Built-in Modules Some built-in modules are:\nOS PATH FS (Filesystem) HTTP Even though there are several more built-in modules.\nOS To import the OS built-in module we do:\nconst os = require(\"os\"); And we call it by:\nconsole.log(`The system uptime is ${os.uptime()} seconds`); FS We can also interact with the file system via the FS module. There are two ways to do so:\nAsynchronously, which is non-blocking Synchronously, that is blocking Synchronous To exemply both setups, we first de-structure the read and write synchronous methods from the FS module, and then we read and write files.\nconst { readFileSync, writeFileSync } = require(\"fs\"); // Read file with a given path and the corresponding encoding const first = readFileSync(\"./file.txt\", \"utf8\"); const second = readFileSync(\"./file2.txt\", \"utf8\"); // Write to a file given a path, the content is overwritten writeFileSync(\"./writeFile\", \"This content will be written\"); // Write to a file given a path, the content is appended writeFileSync(\"./writeFile\", \"This content will be written\", { flag: \"a\" }); Asynchronous Now, in order to access the file system asynchronously, we need a callback, and so we do:\nconst { readFileSync, writeFileSync } = require(\"fs\"); readFile(\"./file\", \"utf8\", (error, result) =\u003e { if (error) { console.log(error); return; } else { console.log(result); const first = result; // Here we can add another read call } }); writeFile(\"./file\", \"This is the content\", (error, result) =\u003e { if (error) { console.log(error); return; } else { console.log(result); } }); Where we specify a callback function with the ES6 syntax. Its first parameter is the error parameter and the second is the result of the operation.\nThe problem with synchronous calls is that they can be very time consuming and they halt the execution, which can be critical when working on time sensitive tasks or when several user call upon these type of functions at a time.\nHTTP To show the bare basics, we will set up a server:\nconst http = require(\"http\"); const server = http.createServer((request, response) =\u003e { response.write(\"This is the index!\"); response.end(); }); // Define the port server.listen(5000); That can be accessed on localhost:5000. Next, we can code something a little more complex, where the content handed as a response depends on the request:\nconst http = require(\"http\"); const server = http.createServer((request, response) =\u003e { if (request.url === \"/\") { response.end(\"This is the index\"); } else if (request.url === \"/about\") { response.end(\"This is the about\"); } else { response.end(\"404\"); } }); // Define the port server.listen(5000); ","npm#NPM":"Installing packages You can install a package locally within your project as a local dependency:\n$ nmp i \u003cpackageName\u003e Or you can install the package globally, so it can be accessed from any project:\n$ npm install -g \u003cpackageName\u003e If you want to specify a version for the package:\n$ npm install \u003cpackageName\u003e@1.0.0 Package.json This file stores important information about the project and the packages, it can be conceived as a manifest file. There are two ways to create it:\nManually: create package.json in the root folder of the project and define the properties of the project/packages. Using npm following the guide (add -y to skip the questions of the guide): $ npm init When the project is initialized, the package.json file is as follows:\n{ \"name\": \"08_project\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\" } Where all those properties are set up during the guide of npm init or set as default with the flag -y.\nAfter installing a dependency\n$ npm i lodash The following property is added:\n\"dependencies\": { \"lodash\": \"^4.17.21\" } And npm creates the folder node_modules, if it does not already exist, which stores the dependencies code. Also, in case of wanting to install dependencies needed only during the development process:\n$ npm i \u003cpackage\u003e -D $ npm i \u003cpackage\u003e --save-dev And so, the property devDependencies is created in pakage.json.\nScripts The object scripts, which is a property of package.json, can contain the definition of different actions, for example:\n\"scripts\": { \"start\": \"node app.js\" } So when running npm start our app.js will be executed. For some commands you will need to specify run and the command name as follows:\n$ npm run dev Nodemon This is a package that lets you hot reload your project without having to execute your app constantly. For that, after installing nodemon as a local or global dependency, we specify on package.json:\n\"scripts\": { \"dev\": \"nodemon app.js\" } If we want to run it:\n$ npm run dev Package-lock.json This file stores the dependencies version of the packages installed as dependencies, as to avoid installing newer version that can be the cause of bugs. Because within the package.json only our project’s dependencies’ versions are specified.\nUninstalling packages In order to uninstall the package we have a command, that follows the syntax:\n$ npm uninstall \u003cpackage\u003e We can also remove it from the dependencies object within package.json. So when you remove package-lock.json and the node_modules folder if you run\n$ npm install The package that was removed will not be installed.\nGit When using git or other version control tool, it is desirable to create a .gitignore and to specify to avoid the node_modules folder, since its size can get big very easily.\nSo, by just pushing the source code, including package.json, if we want to install all of the project’s dependencies’ again, on the root folder we run:\n$ npm install "},"title":"Modules and Networking"},"/notes/webdev/back/node/04_express_basics/":{"data":{"":"","express#Express":"Initializing Express App In order to do so we import the express module, and the we create the instance, more or less like we did with our HTTP servers:\nconst express = require(\"express\"); const app = express(); App Methods The app instance we just created has several methods, we now list the most common:\napp.get: HTTP method to read data. app.get(\"/\", (req, res) =\u003e { res.status(200).send(\"Home Page\"); }); app.post: HTTP method to insert data. app.put: HTTP method to update data. app.delete: HTTP method to delete data. app.all: Usually used to respond when we cannot locate a resource on the server. app.all(\"*\", (req, res) =\u003e { res.status(404).send(\"\u003ch1\u003eresource not found\u003c/h1\u003e\"); }); app.use: It is responsible for the middleware. app.listen: This method listens for any requests made to the server. app.listen(5000, () =\u003e { console.log(\"server is listening on port 5000...\"); }); Send HTML files To send HTML files as a response instead of plain text we have to use the sendFile method:\nconst express = require(\"express\"); const path = require(\"path\"); const app = express(); app.get(\"/\", (req, res) =\u003e { res.sendFile(path.resolve(__dirname, \"./index.html\")); }); app.listen(5000, () =\u003e { console.log(\"server is listening on port 5000...\"); }); Now, we have to import the external resources needed by the HTML file:\nconst express = require(\"express\"); const path = require(\"path\"); const app = express(); app.use(express.static(\"./public\")); app.get(\"/\", (req, res) =\u003e { res.sendFile(path.resolve(__dirname, \"./index.html\")); }); app.listen(5000, () =\u003e { console.log(\"server is listening on port 5000...\"); }); So we invoke app.use as to tell the server that there are static resources stored in the public folder.\nHowever, because in this case index.html is also a static file we can remove the sendFile method if we store index.html inside the public folder:\nconst express = require(\"express\"); const path = require(\"path\"); const app = express(); app.use(express.static(\"./public\")); app.listen(5000, () =\u003e { console.log(\"server is listening on port 5000...\"); }); ","http-basics#HTTP Basics":"Headers If we want to provide the metadata about the response we have to provide headers:\nconst http = require(\"http\"); const server = http.createServer((req, res) =\u003e { res.writeHead(200, { \"content-type\": \"text/html\" }); res.write(\"\u003ch1\u003ehome page\u003c/h1\u003e\"); res.end(); }); server.listen(5000); With writeHead we specify the headers, in our case we specify the status code (200: OK) and the content type of the response (text/html). The later are called MIME-types or media types.\nThen we specify the body of the response with write and finally we finalize the message with end.\nRequest Object The request object that is an argument of the createServer method has several attributes:\nreq.method: Allows you to obtain the method of the user’s request, i.e. GET, POST, PUT, etc. req.url: Contains the url of the user’s request. HTML File As we have seen the method write allows us to define the content of the body as HTML. However we do not need to write the HTML code inside the method we can also pass a file as input and the method will serve it’s content to the response.\nconst http = require(\"http\"); const { readFileSync } = require(\"fs\"); const homePage = readFileSync(\"./index.html\"); const server = http.createServer((req, res) =\u003e { res.writeHead(200, { \"content-type\": \"text/html\" }); res.write(homePage); res.end(); }); server.listen(5000); Observe that we user readFileSync, we do so because, for one this is an example, and also the file is only read once when the server is created, not every time the user hits the server.\nExternal resources When adding external resources to a given HTML file we also need to handle the request to those resources in our server.\nconst http = require(\"http\"); const { readFileSync } = require(\"fs\"); const homePage = readFileSync(\"./index.html\"); const homeStyles = readFileSync(\"./styles.css\"); const homeImage = readFileSync(\"./logo.svg\"); const server = http.createServer((req, res) =\u003e { // home page if (url === \"/\") { res.writeHead(200, { \"content-type\": \"text/html\" }); res.write(homePage); res.end(); } // styles else if (url === \"/styles.css\") { res.writeHead(200, { \"content-type\": \"text/css\" }); res.write(homeStyles); res.end(); } // image/logo else if (url === \"/logo.svg\") { res.writeHead(200, { \"content-type\": \"image/svg+xml\" }); res.write(homeImage); res.end(); } }); Note that the content types differ every time, with css we use text/css, with images we use image/svg+xml.","http-methods#HTTP Methods":"GET app.get(\"/api/people\", (res, req) =\u003e { res.status(200).json({ success: true, data: people }); }); POST Observe that we use a middleware provided by Express that lets us parse incoming requests with urlencoded payload, and another middleware function to parse json.\napp.use(express.urlencoded({ extended: false })); app.use(express.json()); app.post(\"/api/people\", (res, req) =\u003e { const { name } = req.body; if (!name) { return res .status(400) .json({ success: false, msg: \"Please provide a name\" }); } // Send array of people adding the new person (this is not permanent) res.status(201).json({ success: true, data: [...data, { name, id: data.length + 1 }], }); }); PUT app.put(\"/api/people/:id\", (res, req) =\u003e { // De-structure params const { id } = req.params; const { name } = req.body; const person = people.find((person) =\u003e person.id === Number(id)); // The person does not exist if (!person) { return res .status(400) .json({ success: false, msg: `no person with id: ${id}` }); } // Update the person data const newPeople = people.map((person) =\u003e { if (person.id === Number(id)) { person.name = name; } return person; }); res.status(200).json({ success: true, data: newPeople }); }); DELETE app.delete(\"/api/people/:id\", (res, req) =\u003e { // De-structure params const { id } = req.params; const { name } = req.body; const person = people.find((person) =\u003e person.id === Number(id)); // The person does not exist if (!person) { return res .status(400) .json({ success: false, msg: `no person with id: ${id}` }); } // Filter the person data const newPeople = people.filter((person) =\u003e person.id !== id); res.status(200).json({ success: true, data: newPeople }); }); ","query-strings#Query Strings":"We can use the query attribute from the request object in order to further filter our data. So whenever the user types localhost:5000/whateverendpoint?name=john, the request object passed as an argument of the callback defined for whateverendpoint will have the object {name: 'john'} stored in request.query.\napp.get(\"/whateverendpoint\", (req, res) =\u003e { console.log(req.query); }); Now we code the way to filter by the keywords search and limit:\napp.get(\"/api/v1/query\", (req, res) =\u003e { // De-structure keys const { search, limit } = req.query; // Get a copy of the products let sortedProducts = [...products]; // If search was specified if (search) { // Return only the products whose name start with sortedProducts = sortedProducts.filter((product) =\u003e { return product.name.startsWith(search); }); } // If limit was specified if (limit) { // Return as many products as the limit specified sortedProducts = sortedProducts.slice(0, Number(limit)); } // If no product matched the search if (sortedProducts.length \u003c 1) { return res.status(200).json({ sucess: true, data: [] }); } // Return the products filtered res.status(200).json(sortedProducts); }); So now, if we go to localhost:5000/api/v1/query?search=a\u0026limit=2 the server will return a JSON object that contains at most 2 products whose name start with an “a”.\nObserve, that in order to avoid error for sending more than one response (note that we have two res.json() in our function), we must add the return keyword after sending each response, then the method exits.","route-params#Route Params":"If, for example, we have a list of products, and we want to get a certain product by its id, we use route params. They can have any name, and are specified by :param. This is then stored in the request object.\napp.get(\"/api/products/:productID\", (req, res) =\u003e { // De-structure param const { productID } = req.params; // Filter products by id const singleProduct = products.find( (product) =\u003e product.id === Number(productID) ); // If it does not exist if (!singleProduct) { return res.status(404).send(\"Product Does Not Exist\"); } return res.json(singleProduct); }); Note that the route params are always strings, in our case we had to convert it to a Number. We can also have more that one route parameter like so:\napp.get(\"/api/products/:productID/reviews/:reviewID\", (req, res) =\u003e { res.send(\"hello world\"); }); Where we define productID and reviewID as route parameters, and can, therefore, filter by them.","routes#Routes":"Set Up In order to set up the routes for our project, we first create a folder called routes that will contain all the javascript files that control routing functionality. In this example we create two files within routes, people.js and auth.js.\nOnce we have created them, we include them as middleware to the specific endpoints (/api/people for people.js and /login for auth.js), as follows:\nconst express = require(\"express\"); const app = express(); const people = require(\"./routes/people\"); const auth = require(\"./routes/auth\"); app.use(\"/api/people\", people); app.use(\"/login\", auth); app.listen(5000, () =\u003e { console.log(\"Server is listening on port 5000....\"); }); Router Let’s focus now on people.js than controls the routing of /api/people. For that we import the controller of this endpoint and we specify the functions to execute for the different HTTP methods and for the different routes.\n/: This is the default endpoint /api/people there we specify that the logic for a get request is contained in the getPeople function. /:d: This endpoint allows for specifying an id as a parameter. const express = require(\"express\"); const router = express.Router(); const { getPeople, createPerson, createPersonPostman, updatePerson, deletePerson, } = require(\"../controllers/people\"); router.route(\"/\").get(getPeople).post(createPerson); router.route(\"/:id\").put(updatePerson).delete(deletePerson); module.exports = router; Controller The people controller contains:\nlet { people } = require(\"../data\"); const getPeople = (req, res) =\u003e { res.status(200).json({ success: true, data: people }); }; const createPerson = (req, res) =\u003e { const { name } = req.body; if (!name) { return res .status(400) .json({ success: false, msg: \"please provide name value\" }); } res.status(201).send({ success: true, person: name }); }; const createPersonPostman = (req, res) =\u003e { const { name } = req.body; if (!name) { return res .status(400) .json({ success: false, msg: \"please provide name value\" }); } res.status(201).send({ success: true, data: [...people, name] }); }; const updatePerson = (req, res) =\u003e { const { id } = req.params; const { name } = req.body; const person = people.find((person) =\u003e person.id === Number(id)); if (!person) { return res .status(404) .json({ success: false, msg: `no person with id ${id}` }); } const newPeople = people.map((person) =\u003e { if (person.id === Number(id)) { person.name = name; } return person; }); res.status(200).json({ success: true, data: newPeople }); }; const deletePerson = (req, res) =\u003e { const person = people.find((person) =\u003e person.id === Number(req.params.id)); if (!person) { return res .status(404) .json({ success: false, msg: `no person with id ${req.params.id}` }); } const newPeople = people.filter( (person) =\u003e person.id !== Number(req.params.id) ); return res.status(200).json({ success: true, data: newPeople }); }; module.exports = { getPeople, createPerson, createPersonPostman, updatePerson, deletePerson, }; "},"title":"HTTP and Express Basics"},"/notes/webdev/back/node/05_express_dev/":{"data":{"":"","api-vs-ssr#API vs SSR":"In Express when we talk about APIs we are talking about HTTP interfaces to interact our data.\nThe main differences between APIs and Server Side Rendering (SSR) are:\nAPI SSR Content type JSON Template What is sent Send data Send template Method res.json() res.render() ","environment-variables#Environment Variables":"Installing In order to pass environment variables, like MongoDB credentials, to our app we can use a third party package called cross-env:\n$ npm install --save-dev cross-env And then we can pass environment variables as arguments to our node application like so:\nnpx cross-env NODE_ENV=development node app.js And the environment variables can be accessed from our app as follows:\nconsole.log(process.env.NODE_ENV); Command To make it easier we can modify our package.json scripts to pass these variables for us:\n{ \"name\": \"project\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"app.js\", \"scripts\": { \"dev\": \"npx cross-env NODE_ENV=development node app\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\" } And we start the application with:\n$ npm dev File Another way to do it is using a .env file:\nNODE_ENV=development PORT=3000 HOST=localhost To pass those variables to Node.js we use the eval command:\n$ eval $(cat .env) node app And we can also include it to package.json.\n{ \"name\": \"project\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"app.js\", \"scripts\": { \"dev\": \"eval $(cat .env) node app\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\" } dotenv In case of not wanting to use commands that are exclusive to our operative system, we can use the package dotenv\n$ npm install --save-dev dotenv And in our app we do:\nrequire(\"dotenv\").config(); ","json#JSON":"The method res.json() allows us to return a array of objects as the body of the HTTP response:\nconst express = require(\"express\"); const app = express(); app.get(\"/\", (req, res) =\u003e { res.json([{ name: \"john\" }, { name: \"susan\" }]); }); app.listen(5000, () =\u003e { console.log(\"Server is listening on port 5000....\"); }); We can also pass a JSON file to res.json():\nconst express = require(\"express\"); const app = express(); const { products } = require(\"./data\"); app.get(\"/\", (req, res) =\u003e { res.json(products); }); app.listen(5000, () =\u003e { console.log(\"Server is listening on port 5000....\"); }); Where data.js contains:\nconst products = [ { id: 1, name: \"albany sofa\", image: \"product-3.jpg\", price: 39.95, desc: `I'm baby direct trade farm-to-table hell of`, }, ]; module.exports = products; ","middleware#Middleware":"Apply Middleware with app.use In order to apply a certain middleware to all the routes we first save the logger on a separate file named logger.js, then we import it into our main app, and we specify its usage as a middleware by app.use.\nconst express = require(\"express\"); const logger = require(\"./logger\"); const app = express(); app.use(logger); With this our logger will be executed every time the user accesses our server. We can also specify an argument like so:\nconst express = require(\"express\"); const logger = require(\"./logger\"); const app = express(); app.use(\"/api/\", logger); This tells Express to only use the middleware for the /api route and all its subdomains (i.e. /api/*).\nApply Multiple Middleware We now define a new middleware function, that goes by the name of authorize.js, we import it into our app.js and we add it as middleware by using an array.\nconst express = require(\"express\"); const logger = require(\"./logger\"); const authorize = require(\"./authorize\"); const app = express(); app.use([logger, authorize]); Note that the order matters, meaning the first middleware executed is logger, in this instance, and then the control flow is passed to authorize.\nWe can also define more than one middleware function on one concrete end-point:\napp.get(\"/api\", [logger, authorize], (req, res) =\u003e { res.send(\"API Home Page\"); }); As we can see, we have specified two middleware functions, namely logger and authorize by using an array.\nExample const authorize = (req, res, next) =\u003e { // De-structure user object const { user } = req.query; if (user == \"alice\") { req.user = { name: \"alice\", id: 3 }; // Yield control flow next(); } else { res.status(401).send(\"Unauthorized\"); } }; As you can see the authorize middleware function creates a new object within the request object, which can be accessed from the next middleware, or from the server.","view-engines#View Engines":"EJS Installing We will use EJS in this example. First we download it:\n$ npm install ejs Set Up Now we specify in our application that we want to use it:\nconst express = require(\"express\"); const app = express(); // Specify view engine and settings app.set(\"view engine\", \"ejs\"); app.set(\"views\", \"./views\"); We use the function set() that is used to specify app settings. There we define ejs as our view engine and then we indicate that the folder where our views are located is /views, which is the default folder. This means we could have omitted that last line and the functionality would remain the same.\nRendering Inside our root folder, we create the folder views and the file index.ejs which has the same syntax as HTML:\n\u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e \u003ctitle\u003eBlog Ninja | \u003c%= title %\u003e\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv class=\"blogs content\"\u003e \u003ch2\u003eAll Blogs\u003c/h2\u003e \u003c% if (blogs.length \u003e 0) { %\u003e \u003c% blogs.forEach(blog =\u003e { %\u003e \u003ch3 class=\"title\"\u003e\u003c%= blog.title %\u003e\u003c/h3\u003e \u003cp class=\"snippet\"\u003e\u003c%= blog.snippet %\u003e\u003c/p\u003e \u003c% }) %\u003e \u003c% } else { %\u003e \u003cp\u003eThere are no blogs to display...\u003c/p\u003e \u003c% } %\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e So in order to send this template as a response we do:\napp.get(\"/\", (req, res) =\u003e { const blogs = [ { title: \"Yoshi finds eggs\", snippet: \"Lorem ipsum dolor sit amet consectetur\", }, { title: \"Mario finds stars\", snippet: \"Lorem ipsum dolor sit amet consectetur\", }, { title: \"How to defeat bowser\", snippet: \"Lorem ipsum dolor sit amet consectetur\", }, ]; res.render(\"index\", { title: \"Home\", blogs }); }); Note that we define an array of blog objects, and we pass them as an argument to the template. Which then iterates over them to visualize each item."},"title":"API Development and Middleware"},"/notes/webdev/back/node/06_express_db/":{"data":{"":"","json-web-tokens#JSON Web Tokens":"Installation $ npm install jsonwebtoken Example of Usage We first create our Express application and so, we import express and jsonwebtoken. And then we start the server.\nconst express = require(\"express\"); const jwt = require(\"jsonwebtoken\"); const app = express(); app.listen(3000, () =\u003e { console.log(\"nodejs app running...\"); }); Now, we define two new endpoints: /api and /api/login.\napp.get(\"/api\", (req, res) =\u003e { res.json({ mensaje: \"Nodejs and JWT\", }); }); app.post(\"/api/login\", (req, res) =\u003e { const user = { id: 1, nombre: \"Henry\", email: \"henry@email.com\", }; jwt.sign({ user }, \"secretkey\", { expiresIn: \"32s\" }, (err, token) =\u003e { res.json({ token, }); }); }); Where we use the sign method to create a new token.\nSo, if we want to define an endpoint that requires authentication we do:\n// Middleware function verifyToken(req, res, next) { const bearerHeader = req.headers[\"authorization\"]; if (typeof bearerHeader !== \"undefined\") { const bearerToken = bearerHeader.split(\" \")[1]; req.token = bearerToken; next(); } else { res.sendStatus(403); } } app.post(\"/api/posts\", verifyToken, (req, res) =\u003e { jwt.verify(req.token, \"secretkey\", (error, authData) =\u003e { if (error) { res.sendStatus(403); } else { res.json({ mensaje: \"Post fue creado\", authData, }); } }); }); Where verifyToken is a middleware function that gets the token from the header, and then we use the verify method to check if the token is valid.","mocking-mongodb#Mocking MongoDB":"MongoMemoryServer As we have mentioned we need MongoMemoryServer, so we install it as a development depencendy. For that we head to our node app’s root folder and we execute:\n$ npm install mongodb-memory-server-core --save-dev Docker So, now we create our Dockerfile, which holds our app source code, and where we install mongodb:\nFROM alpine:latest MAINTAINER albamr09 # Install dependencies RUN apk add --no-cache nodejs npm # Install mongodb RUN echo 'http://dl-cdn.alpinelinux.org/alpine/v3.6/main' \u003e\u003e /etc/apk/repositories RUN echo 'http://dl-cdn.alpinelinux.org/alpine/v3.6/community' \u003e\u003e /etc/apk/repositories RUN apk update RUN apk add mongodb RUN apk add mongodb-tools RUN mkdir -p /data/db/ RUN chmod -R 777 /data/db # Add common user RUN adduser -D user #RUN useradd --create-home --shell /bin/bash user # Create app directory WORKDIR /home/user/src/ # Change permissions RUN chown -R user:user /home/user/src/ RUN chmod -R 755 /home/user/src/ USER user # Copy with user as owner COPY --chown=user:user ./package*.json ./ # Install app dependencies RUN npm install # Copy and override src folder COPY . . Note that this version of MongoDB is 3.4.4, mainly because we are using the alpine image. This version may not coincide with our MongoDB Docker image, and is not desirable. So make sure (or force) that you are installing the save versions.\nMongoMemoryServer Configuration Also, we only need to install it for those images that are not supported by MongoDB. Furthermore, if instead of the package mongo-memory-server-core we install mongo-memory-server, the latter will include a post-install hook that will install MongoDB if it is not already installed on the system.\nIn case of manually installing MongoDB we have to let know MongoMemoryServer where the binary lays. So, within our package.json file we add:\n\"config\": { \"mongodbMemoryServer\": { \"systemBinary\": \"/usr/bin/mongod\", \"version\": \"3.4.4\" } Example of Usage We, now, exemplify how to mock our database in our tests:\nconst { MongoMemoryServer } = require('mongodb-memory-server-core'); const mongoose = require('mongoose'); const UserModel = require('../../models/user'); const userData = { 'name': 'test', 'email': 'test@test.com', 'password': 'test1234', 'username': 'testname' }; describe('User Model Tests', ()=\u003e { let mongoServer; beforeAll(async () =\u003e { mongoServer = await MongoMemoryServer.create(); await mongoose.connect(mongoServer.getUri(), { useNewUrlParser: true, useUnifiedTopology: true, }).catch(error =\u003e console.log(error)); }); afterAll(async () =\u003e { await mongoServer.stop(); await mongoose.connection.close(); }); afterEach(() =\u003e { mongoose.connection.collections['users'].drop( function() {}); }); it('Create a new user', async ()=\u003e { const user = new UserModel(userData); const savedUser = await user.save(); expect(savedUser._id).toBeDefined(); expect(savedUser.name).toBe(userData.name); expect(savedUser.email).toBe(userData.email); expect(savedUser.password).toBe(userData.password); expect(savedUser.username).toBe(userData.username); }) it('Create a user with invalid fields', async ()=\u003e { var invalidUserData = {...userData}; delete invalidUserData.email; const user = new UserModel(invalidUserData); let error; try{ const savedUser = await user.save(); error = savedUser; }catch(err){ error = err; } expect(error).toBeInstanceOf(mongoose.Error.ValidationError); expect(error.errors.email).toBeDefined(); }) it('Create user that already exists', async ()=\u003e{ await new UserModel(userData).save(); let error; try{ const repeatedUser = new UserModel(userData); await repeatedUser.save(); }catch(err){ error = err; } expect(error).toBeDefined(); expect(error.code).toBe(11000); }) it('Create user with undefined fields', async ()=\u003e{ var newUserData = {...userData}; delete newUserData.name; const user = new UserModel(newUserData); await user.save(); expect(user._id).toBeDefined(); expect(user.name).toBeUndefined(); }) } ","mongodb#MongoDB":"Intro It is a NoSQL which is structured in collections, where each collection would be used to store a particular type of data in the form of documents:\n| Blog Collection | | Blog document | | Blog document | | Blog document |\nHere each document represent a single item of data, for example, each Blog document represents one blog. The data is contained inside the documents in a very similar fashion to JSON objects, so the documents consist of key-value pairs like so:\n{ \"id\": ObjectId(12345), \"title\": \"Opening party\", \"snippet\": \"All about...\", \"body\": \"Lorem ipsum\" } Set Up We can either install MongoDB locally or we can use a cloud database which is already hosted for us. For the latter we will use MongoDB Atlas.\nThere we create a cluster and inside this new cluster we create a new collection called Blog.\nThen we create a user accessing the Security -\u003e Database Access section.\nOnce we have our user created, we specify a way to connect to the database, by heading to Clusters -\u003e Connect your application. We then copy the Connection String that we will use as the database URI. Observe that this URI needs you to input your password.\nMongoose Now we need to actually connect to the database, we could use the MongoDB API package and use the MongoDB API, however we will use Mongoose that makes it easier to interact with the database.\nMongoose is a ODM (Object Document Mapping) library, which means that it maps the standard MongoDB API providing a much easier way to connect to and interact with the database.\nIt does this by allowing us to create simple data models which have query methods to create, get, delete and update database documents.\nFor that we first have to create a Schema for the document which define the structure of a type of data or document. For example:\nBlog Schema: - title(string), required - snippet(string), required - body(string), required Next, what we do is to create a Model based on that Schema, the Model is what actually allows us to communicate with a particular database collection. Each Model has static methods get, save, delete, etc, that allow us to manage the data.\nInstalling $ npm install mongoose === Connect to MongoDB ===\nSo, now, we import the Mongoose package and we use our database URI to connect to it, remember to change password and cluster_name to the values you specified for your database.\nconst express = require('express'); const morgan = require('morgan'); const mongoose = require('mongoose'); // express app const app = express(); // connect to mongodb \u0026 listen for requests const dbURI = \"mongodb+srv://user:\u003cpassword\u003e@test.mongodb.net/\u003ccluster_name\u003e mongoose.connect(dbURI, { useNewUrlParser: true, useUnifiedTopology: true }) .then(result =\u003e app.listen(3000)) .catch(err =\u003e console.log(err)); The connect method is an asynchronous function, so it will execute a callback function when it finished connecting, or an error if the connection failed. In our case, we proceed to start our server when the database is ready.\nCreate Models \u0026 Schemas Once we have successfully connected to our database, we will create our Blog Schema. For that, we first create a folder called models and inside it we create blog.js that will contain the following code:\nconst mongoose = require(\"mongoose\"); const Schema = mongoose.Schema; const blogSchema = new Schema( { title: { type: String, required: true, }, snippet: { type: String, required: true, }, body: { type: String, required: true, }, }, { timestamps: true } ); const Blog = mongoose.model(\"Blog\", blogSchema); module.exports = Blog; As you can see, we first import mongoose and the Schema object that we use to define the Blog Schema.\nIn order to create a new Blog Schema we create a new Schema object and we specify the different properties and restrictions. We also set and object of options, where we specify that we want MongoDB to save the timestamps of updates, creations, etc.\nNext we created a model that is based in the Schema we just created with the function model and we pass it the Model name (this name is then pluralized, as to then look up the collection that matches it) and the Schema instance.\nGetting/Saving Data In order to work we data, we must import the Model we just created.\nconst express = require('express'); const morgan = require('morgan'); const mongoose = require('mongoose'); const Blog = require('./models/blog'); // express app const app = express(); // connect to mongodb \u0026 listen for requests const dbURI = \"mongodb+srv://user:\u003cpassword\u003e@test.mongodb.net/\u003ccluster_name\u003e mongoose.connect(dbURI, { useNewUrlParser: true, useUnifiedTopology: true }) .then(result =\u003e app.listen(3000)) .catch(err =\u003e console.log(err)); app.get('/blogs', (req, res) =\u003e { Blog.find() .then(result =\u003e { res.send(result); }) .catch(err =\u003e { console.log(err); }); }); app.get('/blogs/:id', (req, res) =\u003e { const id = req.params.id; Blog.findById(id) .then(result =\u003e { res.send(result); }) .catch(err =\u003e { console.log(err); }); }); Here we use the find and findById methods to interact with our database.\nIn order to create or delete new Blogs:\napp.post(\"/blogs\", (req, res) =\u003e { const blog = new Blog(req.body); blog .save() .then((result) =\u003e { res.redirect(\"/blogs\"); }) .catch((err) =\u003e { console.log(err); }); }); app.delete(\"/blogs/:id\", (req, res) =\u003e { const id = req.params.id; Blog.findByIdAndDelete(id) .then((result) =\u003e { res.json({ redirect: \"/blogs\" }); }) .catch((err) =\u003e { console.log(err); }); }); In the POST method we create a new Blog object using the objects from the request body, and then we save it in our database. On the other hand, in order to delete a Blog we pass the id as a parameter, we search for it on the database and we delete it."},"title":"Database and Authentication"},"/notes/webdev/back/spring/":{"data":{"":" Intro and Core Framework Spring MVC Spring Hibernate Spring Rest Spring Boot Spring Thymeleaf Maven Spring Security Spring AOP "},"title":"Spring"},"/notes/webdev/back/spring/01/":{"data":{"":"Spring Docs","core-framework#Core Framework":" Spring With XML Configuration Java Annotations Spring Configuration with Java Code ","set-up#Set Up":"Requirements:\nJDK Java Application Server (i.e. Tomcat) Java Integrated Development Environment (IDE) Spring 5 JAR files (download manually or use Maven) ","spring-framework#Spring Framework":"Spring Projects Spring modules built on top of the core Spring Framework:\nSpring Boot Spring Cloud Spring Batch etc Spring Projects","xml-configuration-file#XML Configuration File":"Configure Spring Container with an XML file First we create the config file \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- Define your beans here --\u003e \u003cbean id=\"myCoach\" class=\"com.luv2code.springdemo.TrackCoach\"\u003e \u003c/bean\u003e \u003c/beans\u003e Then we create the Spring container in our application: package com.springdemo; /** Class to create a spring container using xml files **/ import org.springframework.context.support.ClassPathXmlApplicationContext; public class MyApp { public static void main(String[] args) { // load the spring configuration file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // retrieve bean from spring container by its id Coach theCoach = context.getBean(\"myCoach\", Coach.class); // call methods on the bean System.out.println(theCoach.getDailyWorkout()); // close the context context.close(); } } "},"title":"Intro and Core Framework"},"/notes/webdev/back/spring/01/01_xml_config/":{"data":{"":"","bean-life-cycle#Bean Life Cycle":"Define Methods First of all we define the methods in our bean:\npackage com.springdemo; public class TrackCoach implements Coach { private FortuneService fortuneService; public TrackCoach() { } public TrackCoach(FortuneService fortuneService) { this.fortuneService = fortuneService; } @Override public String getDailyWorkout() { return \"Run a hard 5k\"; } @Override public String getDailyFortune() { return \"Just Do It: \" + fortuneService.getFortune(); } // add an init method public void doMyStartupStuff() { System.out.println(\"TrackCoach: inside method doMyStartupStuff\"); } // add a destroy method public void doMyCleanupStuffYoYo() { System.out.println(\"TrackCoach: inside method doMyCleanupStuffYoYo\"); } } Configure Hooks in the Configuration File Once the initialization and clean-up methods have been defined, we configure them in our configuration file:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- Define your beans here --\u003e \u003c!-- define the dependency --\u003e \u003cbean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\"\u003e \u003c/bean\u003e \u003c!-- Note the new tag \"scope\" --\u003e \u003cbean id=\"myCoach\" class=\"com.springdemo.TrackCoach\" init-method=\"doMyStartupStuff\" destroy-method=\"doMyCleanupStuffYoYo\"\u003e \u003c!-- set up constructor injection --\u003e \u003cconstructor-arg ref=\"myFortuneService\" /\u003e \u003c/bean\u003e \u003c/beans\u003e Main Method Now in our App, we create the bean to check that our methods are being called:\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class BeanLifeCycleDemoApp { public static void main(String[] args) { // load the spring configuration file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"beanLifeCycle-applicationContext.xml\"); // retrieve bean from spring container Coach theCoach = context.getBean(\"myCoach\", Coach.class); System.out.println(theCoach.getDailyWorkout()); // close the context context.close(); } } Notes When using XML configuration, I want to provide additional details regarding the method signatures of the init-method and destroy-method .\nAccess modifier: The method can have any access modifier (public, protected, private) Return type: The method can have any return type. However, “void’ is most commonly used. If you give a return type just note that you will not be able to capture the return value. As a result, “void” is commonly used. Method name: The method can have any method name. Arguments: The method can not accept any arguments. The method should be no-arg. ","bean-scopes#Bean Scopes":"Intro The scope of a bean refers to the life cycle of the bean:\nHow long does it live How many instances are created How is the bean shared The default scope of the bean is a Singleton:\nThe Spring container creates only one instance of the bean It is cached in memory All requests to the bean will return a shared reference to the same bean Other scopes are:\nA singleton scope is good for stateless data A prototype scope is good for stateful data (the container returns a new bean for each request). Note that for this type of bean, Spring does not call the destroy method. Specify Scope in XML Config File \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- Define your beans here --\u003e \u003c!-- define the dependency --\u003e \u003cbean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\"\u003e \u003c/bean\u003e \u003c!-- Note the new tag \"scope\" --\u003e \u003cbean id=\"myCoach\" class=\"com.springdemo.TrackCoach\" scope=\"prototype\"\u003e \u003c!-- set up constructor injection --\u003e \u003cconstructor-arg ref=\"myFortuneService\" /\u003e \u003c/bean\u003e \u003c/beans\u003e Main Method Now, from our application we do:\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class BeanScopeDemoApp { public static void main(String[] args) { // load the spring configuration file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"beanScope-applicationContext.xml\"); // retrieve bean from spring container Coach theCoach = context.getBean(\"myCoach\", Coach.class); Coach alphaCoach = context.getBean(\"myCoach\", Coach.class); // check if they are the same boolean result = (theCoach == alphaCoach); // print out the results System.out.println(\"\\nPointing to the same object: \" + result); System.out.println(\"\\nMemory location for theCoach: \" + theCoach); System.out.println(\"\\nMemory location for alphaCoach: \" + alphaCoach + \"\\n\"); // close the context context.close(); } } Observe, the result variable should be set to false, because we are using the prototype scope. Also the values of the memory location for the two objects should be distinct for that same reason.\nHowever if we were using scope=\"singleton\", then result should be true, and both objects should have the same memory location.","dependency-injection#Dependency Injection":"Injection Types There are several injection types in Spring. The more common are:\nConstructor Injection Setter Injection Injecting Literal Values Inject Values From a Properties File Constructor Injection Create Dependency Object package com.springdemo; public interface FortuneService { public String getFortune(); } Next we create the dependency class than implements the interface:\npackage com.springdemo; public class HappyFortuneService implements FortuneService { @Override public String getFortune() { return \"Today is your lucky day!\"; } } Establish Dependency Let’s also update the Coach Interface to add a method getDailyFortune (note that all classes that implement this interface have to implement this new method):\npackage com.springdemo; public interface Coach { public String getDailyWorkout(); public String getDailyFortune(); } Now create a constructor for the dependency in the class that has the dependency\npackage com.springdemo; public class BaseballCoach implements Coach { // define a private field for the dependency private FortuneService fortuneService; // define a constructor for dependency injection public BaseballCoach(FortuneService theFortuneService) { fortuneService = theFortuneService; } @Override public String getDailyWorkout() { return \"Spend 30 minutes on batting practice\"; } @Override public String getDailyFortune() { // use my fortuneService to get a fortune return fortuneService.getFortune(); } } Configuration File Finally define the dependency in the configuration file:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- Define your beans here --\u003e \u003c!-- define the dependency --\u003e \u003cbean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\"\u003e \u003c/bean\u003e \u003c!-- Bean with the dependency --\u003e \u003cbean id=\"myCoach\" class=\"com.springdemo.TrackCoach\"\u003e \u003c!-- Set up constructor injection, note ref=id of bean --\u003e \u003cconstructor-arg ref=\"myFortuneService\" /\u003e \u003c/bean\u003e \u003c/beans\u003e Behind the scenes, Spring framework does:\npackage com.springdemo; public class MyApp { public static void main(String[] args) { // Create object // From the bean with id = myFortuneService in the config file HappyFortuneService myFortuneService = new HappyFortuneService(); // Add dependency via constructor // From the bean with id = myCoach in the config file TrackCoach myCoach = new TrackCoach(fortuneService); } } Main Method We do not need to make any modifications to the app, when we create the Coach bean using Spring, the framework deals with the dependency injection:\npackage com.luv2code.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class HelloSpringApp { public static void main(String[] args) { // load the spring configuration file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // retrieve bean from spring container (with the dependency) Coach theCoach = context.getBean(\"myCoach\", Coach.class); // call methods on the bean System.out.println(theCoach.getDailyWorkout()); // let's call our new method for fortunes System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } Setter Injection Create Dependency Object Refer to Create Dependency Object\nDefine dependency We include a setter method that takes the dependency as an argument like:\npackage com.springdemo; public class CricketCoach implements Coach { private FortuneService fortuneService; // create a no-arg constructor public CricketCoach() { System.out.println(\"CricketCoach: inside no-arg constructor\"); } // our setter method public void setFortuneService(FortuneService fortuneService) { System.out.println(\"CricketCoach: inside setter method - setFortuneService\"); this.fortuneService = fortuneService; } @Override public String getDailyWorkout() { return \"Practice fast bowling for 15 minutes\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } Configuration File \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- Define your beans here --\u003e \u003c!-- define the dependency --\u003e \u003cbean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\"\u003e \u003c/bean\u003e \u003cbean id=\"myCoach\" class=\"com.springdemo.TrackCoach\"\u003e \u003c!-- set up constructor injection --\u003e \u003cconstructor-arg ref=\"myFortuneService\" /\u003e \u003c/bean\u003e \u003cbean id=\"myCricketCoach\" class=\"com.springdemo.CricketCoach\"\u003e \u003c!-- set up setter injection --\u003e \u003c!-- ref: references the id of the bean we define previously --\u003e \u003c!-- name: name of the setter method set\u003cname\u003e, where the first letter of the name is capitalized --\u003e \u003cproperty name=\"fortuneService\" ref=\"myFortuneService\" /\u003e \u003c/bean\u003e \u003c/beans\u003e Behind the scenes, Spring framework does:\npackage com.springdemo; public class MyApp { public static void main(String[] args) { // Create object // From the bean with id = myFortuneService in the config file HappyFortuneService myFortuneService = new HappyFortuneService(); // From the bean with id = myCricketCoach in the config file CricketCoach myCricketCoach = new CricketCoach(fortuneService); // Add dependency via setter myCricketCoach.setFortuneService(myFortuneService); } } Main Method Now, on the main method of our Spring App, we create the object by reading the config file, and Spring automatically injects the dependency via the setter method:\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class SetterDemoApp { public static void main(String[] args) { // load the spring configuration file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // retrieve bean from spring container CricketCoach theCoach = context.getBean(\"myCricketCoach\", CricketCoach.class); // call methods on the bean System.out.println(theCoach.getDailyWorkout()); System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } Injecting Literal Values Define the Attributes First we define the attributes emailAddress and team in the object. Also we create the set and get methods for both of them:\npackage com.luv2code.springdemo; public class CricketCoach implements Coach { private FortuneService fortuneService; // add new fields for emailAddress and team private String emailAddress; private String team; public CricketCoach() { System.out.println(\"CricketCoach: inside no-arg constructor\"); } /** SETTERS AND GETTERS **/ public String getEmailAddress() { return emailAddress; } public void setEmailAddress(String emailAddress) { System.out.println(\"CricketCoach: inside setter method - setEmailAddress\"); this.emailAddress = emailAddress; } public String getTeam() { return team; } public void setTeam(String team) { System.out.println(\"CricketCoach: inside setter method - setTeam\"); this.team = team; } /** Setter Injection **/ public void setFortuneService(FortuneService fortuneService) { System.out.println(\"CricketCoach: inside setter method - setFortuneService\"); this.fortuneService = fortuneService; } @Override public String getDailyWorkout() { return \"Practice fast bowling for 15 minutes\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } Configuration File Now we define the properties in the configuration file:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- Define your beans here --\u003e \u003c!-- define the dependency --\u003e \u003cbean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\"\u003e \u003c/bean\u003e \u003cbean id=\"myCoach\" class=\"com.springdemo.TrackCoach\"\u003e \u003c!-- set up constructor injection --\u003e \u003cconstructor-arg ref=\"myFortuneService\" /\u003e \u003c/bean\u003e \u003cbean id=\"myCricketCoach\" class=\"com.springdemo.CricketCoach\"\u003e \u003c!-- set up setter injection --\u003e \u003c!-- ref: references the id of the bean we define previously --\u003e \u003c!-- name: name of the setter method set\u003cname\u003e, where the first letter of the name is capitalized --\u003e \u003cproperty name=\"fortuneService\" ref=\"myFortuneService\" /\u003e \u003c!-- inject literal values, where name is the name of the attribute in the bean and value is the value to set the value to --\u003e \u003cproperty name=\"emailAddress\" value=\"email@email.com\" /\u003e \u003cproperty name=\"team\" value=\"Best Team\" /\u003e \u003c/bean\u003e \u003c/beans\u003e Main Method Now in the main method of our app we can call the getters and setters for these new attributes:\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class SetterDemoApp { public static void main(String[] args) { // load the spring configuration file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // retrieve bean from spring container CricketCoach theCoach = context.getBean(\"myCricketCoach\", CricketCoach.class); // retrieve attribute values System.out.println(theCoach.getTeam()); System.out.println(theCoach.getEmailAddress()); // close the context context.close(); } } Inject Values from the Properties Files Create the properties file Let’s define our properties inside a properties file sport.properties:\nfoo.email=myeasycoach@email.com foo.team=Royal Challengers Bangalore Load the properties file Now we load the properties file using the context tag inside our config file:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- load the properties file: sport.properties --\u003e \u003ccontext:property-placeholder location=\"classpath:sport.properties\"/\u003e \u003c!-- Define your beans here --\u003e \u003c!-- define the dependency --\u003e \u003cbean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\"\u003e \u003c/bean\u003e \u003cbean id=\"myCoach\" class=\"com.springdemo.TrackCoach\"\u003e \u003c!-- set up constructor injection --\u003e \u003cconstructor-arg ref=\"myFortuneService\" /\u003e \u003c/bean\u003e \u003cbean id=\"myCricketCoach\" class=\"com.springdemo.CricketCoach\"\u003e \u003c!-- set up setter injection --\u003e \u003c!-- ref: references the id of the bean we define previously --\u003e \u003c!-- name: name of the setter method set\u003cname\u003e, where the first letter of the name is capitalized --\u003e \u003cproperty name=\"fortuneService\" ref=\"myFortuneService\" /\u003e \u003c!-- inject literal values, where name is the name of the attribute in the bean and value is the value to set the value to --\u003e \u003c!-- Note that we are now referencing the values from the properties file --\u003e \u003cproperty name=\"emailAddress\" value=\"${foo.email})\" /\u003e \u003cproperty name=\"team\" value=\"${foo.team}\" /\u003e \u003c/bean\u003e \u003c/beans\u003e Main Method In the main method, we create our object as usual, and if we invoke the getter methods, we retrieve the values passed in the property file:\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class SetterDemoApp { public static void main(String[] args) { // load the spring configuration file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // retrieve bean from spring container CricketCoach theCoach = context.getBean(\"myCricketCoach\", CricketCoach.class); // retrieve attribute values from property file System.out.println(theCoach.getTeam()); System.out.println(theCoach.getEmailAddress()); // close the context context.close(); } } ","inversion-of-control#Inversion of Control":"The Spring container (generally known as ApplicationContext) has two main functions:\nCreate and manage objects (Inversion of control) Inject object’s dependencies (Dependency Injection) So Inversion Control is externalizing the construction and management of objects which will be handled by and object factory. This is illustrated in the following image:\nMyApp has the main method MyApp asks Spring to retrieve the appropiate object based on a configuration file or an annotation, instead of having to code it manually like: package com.springdemo; public class MyApp { public static void main(String[] args) { Coach theCoach = new TrackCoach(); // call methods on the bean System.out.println(theCoach.getDailyWorkout()); } } Where we have defined an interface Coach that is implemented by both TrackCoach and BaseballCoach\npackage com.springdemo; public interface Coach { public String getDailyWorkout(); } package com.springdemo; public class TrackCoach implements Coach { @Override public String getDailyWorkout() { return \"Run a hard 5k\"; } } To avoid this approach we create a Spring container. To configure a Spring container we can use:\nXML configuration file (legacy) Java Annotations Java Source Code However what is a Spring Bean?\nA “Spring Bean” is simply a Java object.\nWhen Java objects are created by the Spring Container, then Spring refers to them as “Spring Beans”. Spring Beans are created from normal Java classes just like Java objects.\nWhy do we specify the Coach interface in getBean()?\nWhen we pass the interface to the method, behind the scenes Spring will cast the object for you.\ncontext.getBean(\"myCoach\", Coach.class) However, there are some slight differences than normal casting.\nBehaves the same as getBean(String), but provides a measure of type safety by throwing a BeanNotOfRequiredTypeException if the bean is not of the required type.\nThis means that ClassCastException can’t be thrown on casting the result correctly, as can happen with getBean(String)."},"title":"Spring With XML Configuration"},"/notes/webdev/back/spring/01/02_java_annotations/":{"data":{"":"Java Annotations are special labels added to classes. They provide metadata about the class, and can be processed at compile time or run-time for special processing.\nWe use annotations to minimize the XML configuration.\nSpring scans the classes to find Beans and configure them internally (as we have done with the XML configuration).\nIn order to use this approach we need to:\nEnable component scanning in our Spring configuration file and Add the @Component annotation to our class ","dependency-injection#Dependency Injection":"Which dependency to use Choose a style and stay consistent in your project. You get the same functionality regardless of the type of dependency injection you use.\nConstructor Injection Define Dependency as Component package com.springdemo; import org.springframework.stereotype.Component; // We tell spring this is a bean @Component public class HappyFortuneService implements FortuneService { @Override public String getFortune() { return \"Today is your lucky day!\"; } } Specify Dependency package com.springdemo; import org.springframework.stereotype.Component; import org.springframework.beans.factory.annotation.Autowired; @Component public class TennisCoach implements Coach { private FortuneService fortuneService; // We tell spring to search for beans (classes with @Component annotation) // that implement the FortuneService interface @Autowired public TennisCoach(FortuneService theFortuneService) { fortuneService = theFortuneService; } @Override public String getDailyWorkout() { return \"Practice your backhand volley\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } The main method and the configuration files remain unchanged.\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class AnnotationDemoApp { public static void main(String[] args) { // read spring config file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // get the bean from spring container Coach theCoach = context.getBean(\"tennisCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // call method to get daily fortune System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } Setter Injection Define Dependency as Component package com.springdemo; import org.springframework.stereotype.Component; // We tell spring this is a bean @Component public class HappyFortuneService implements FortuneService { @Override public String getFortune() { return \"Today is your lucky day!\"; } } Specify Dependency We now create a setter method in our class for the injection:\npackage com.springdemo; import org.springframework.stereotype.Component; import org.springframework.beans.factory.annotation.Autowired; @Component public class TennisCoach implements Coach { private FortuneService fortuneService; public TennisCoach() {} // We tell spring to search for beans (classes with @Component annotation) // that implement the FortuneService interface @Autowired public setFortuneService(FortuneService fortuneService){ this.fortuneService = fortuneService; } @Override public String getDailyWorkout() { return \"Practice your backhand volley\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } The main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class AnnotationDemoApp { public static void main(String[] args) { // read spring config file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // get the bean from spring container Coach theCoach = context.getBean(\"tennisCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // call method to get daily fortune System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } Field Injection Define Dependency as Component package com.springdemo; import org.springframework.stereotype.Component; // We tell spring this is a bean @Component public class HappyFortuneService implements FortuneService { @Override public String getFortune() { return \"Today is your lucky day!\"; } } Specify Dependency package com.springdemo; import org.springframework.stereotype.Component; import org.springframework.beans.factory.annotation.Autowired; @Component public class TennisCoach implements Coach { // We tell spring to search for beans (classes with @Component annotation) // that implement the FortuneService interface @Autowired private FortuneService fortuneService; public TennisCoach() {} @Override public String getDailyWorkout() { return \"Practice your backhand volley\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } The main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class AnnotationDemoApp { public static void main(String[] args) { // read spring config file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // get the bean from spring container Coach theCoach = context.getBean(\"tennisCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // call method to get daily fortune System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } Method Injection Define Dependency as Component package com.springdemo; import org.springframework.stereotype.Component; // We tell spring this is a bean @Component public class HappyFortuneService implements FortuneService { @Override public String getFortune() { return \"Today is your lucky day!\"; } } Specify Dependency We now create a setter method in our class for the injection:\npackage com.springdemo; import org.springframework.stereotype.Component; import org.springframework.beans.factory.annotation.Autowired; @Component public class TennisCoach implements Coach { private FortuneService fortuneService; public TennisCoach() {} // We tell spring to search for beans (classes with @Component annotation) // that implement the FortuneService interface @Autowired public anyMethod(FortuneService fortuneService){ this.fortuneService = fortuneService; } @Override public String getDailyWorkout() { return \"Practice your backhand volley\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } The main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class AnnotationDemoApp { public static void main(String[] args) { // read spring config file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // get the bean from spring container Coach theCoach = context.getBean(\"tennisCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // call method to get daily fortune System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } Inject properties file using Java annotations Create a properties file We create new text file: src/sport.properties\nfoo.email=myeasycoach@luv2code.com foo.team=Silly Java Coders Load the properties We load the properties in the configuration XML file. For that we add the line:\n\u003ccontext:property-placeholder location=\"classpath:sport.properties\"/\u003e Inject Values Lastly we inject the properties values into our bean like so:\n@Value(\"${foo.email}\") private String email; @Value(\"${foo.team}\") private String team; Qualifier Annotation Define Dependency as Component package com.springdemo; import org.springframework.stereotype.Component; // We tell spring this is a bean @Component public class HappyFortuneService implements FortuneService { @Override public String getFortune() { return \"Today is your lucky day!\"; } } Specify Dependency package com.springdemo; import org.springframework.stereotype.Component; import org.springframework.beans.factory.annotation.Autowired; @Component public class TennisCoach implements Coach { // We tell spring to search for beans (classes with @Component annotation) // that implement the FortuneService interface whose name is \"happyFortuneService\" // (note this is the default name of the component if you set one explicitly you // will have to specify that one in the Qualifier annotation) @Autowired @Qualifier(\"happyFortuneService\") private FortuneService fortuneService; public TennisCoach() {} @Override public String getDailyWorkout() { return \"Practice your backhand volley\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } The main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class AnnotationDemoApp { public static void main(String[] args) { // read spring config file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // get the bean from spring container Coach theCoach = context.getBean(\"tennisCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // call method to get daily fortune System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } Qualifier in Constructor package com.springdemo; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.stereotype.Component; @Component public class TennisCoach implements Coach { private FortuneService fortuneService; // define a default constructor public TennisCoach() { System.out.println(\"\u003e\u003e TennisCoach: inside default constructor\"); } @Autowired public TennisCoach(@Qualifier(\"happyFortuneService\") FortuneService theFortuneService) { System.out.println(\"\u003e\u003e TennisCoach: inside constructor using @autowired and @qualifier\"); fortuneService = theFortuneService; } } ","inversion-of-control#Inversion of Control":"Enable Component Scanning We remove all of the beans we defined, and enable component scanning:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- add entry to enable component scanning --\u003e \u003ccontext:component-scan base-package=\"com.springdemo\" /\u003e \u003c/beans\u003e Now Spring will scan recursively all of the files in this package.\nAdd @Component Annotation to Classes We add the @Component annotation to our classes (note we do not add it to the interfaces like Coach).\npackage com.springdemo; import org.springframework.stereotype.Component; @Component // We can also set the explicit name like // @Component(\"myTennisCoach\") public class TennisCoach implements Coach { @Override public String getDailyWorkout() { return \"Practice your backhand volley\"; } } Note that we can name the component explicitly or by default.\nMain Method In our application we do not really need to change anything. We create our bean the same way we did before. The only thing to note is that if we set the name of the Component explicitly, then when we instantiate the bean, we should refer to it by said name.\npackage com.springdemo; import org.springframework.context.support.ClassPathXmlApplicationContext; public class AnnotationDemoApp { public static void main(String[] args) { // read spring config file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // get the bean from spring container // If we set the name explicitly Coach theCoach = context.getBean(\"myTennisCoach\", Coach.class); // Else Coach theCoach = context.getBean(\"tennisCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // close the context context.close(); } } ","life-cycle#Life Cycle":"Notes Access modifier: The method can have any access modifier (public, protected, private)\nReturn type: The method can have any return type. However, “void’ is most commonly used. If you give a return type just note that you will not be able to capture the return value. As a result, “void” is commonly used.\nMethod name: The method can have any method name.\nArguments: The method can not accept any arguments. The method should be no-arg.","scopes#Scopes":"To explicitly specify scopes with Java Annotations you do as follows:\npackage com.springdemo; import org.springframework.stereotype.Component; import org.springframework.context.annotation.Scope; @Component @Scope(\"singleton\") public class TennisCoach implements Coach { ... or\npackage com.springdemo; import org.springframework.stereotype.Component; import org.springframework.context.annotation.Scope; @Component @Scope(\"prototype\") public class TennisCoach implements Coach { ... Refer to more information about scopes are in Bean Scopes:"},"title":"Java Annotations"},"/notes/webdev/back/spring/01/03_configuration_with_java/":{"data":{"":"We are now going to use Java to configure our application instead of using XML, to do that we follow the next steps:\nCreate a Java class and annotate as @Configuration Add Component scanning support with @ComponentScan (optional), which is XML we did as: \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" ....\u003e \u003c!-- add entry to enable component scanning --\u003e \u003ccontext:component-scan base-package=\"com.springdemo\" /\u003e \u003c/beans\u003e ","configuration-with-java#Configuration With Java":"Create Configuration Class package com.springdemo; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; // 1. Define configuration class @Configuration // 2. Add component scanning support @ComponentScan(\"com.springdemo\") public class SportConfig { } Load the Configuration Class package com.springdemo; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class JavaConfigDemoApp { public static void main(String[] args) { // read spring config java class AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(SportConfig.class); // get the bean from spring container Coach theCoach = context.getBean(\"tennisCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // call method to get the daily fortune System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } ","inversion-of-control#Inversion of Control":"Create the Bean package com.springdemo; // Note there are no special annotations public class SwimCoach implements Coach { private FortuneService fortuneService; public SwimCoach(FortuneService theFortuneService) { fortuneService = theFortuneService; } @Override public String getDailyWorkout() { return \"Swim 1000 meters as a warm up.\"; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } } We also create the SadFortuneService Bean:\npackage com.springdemo; import org.springframework.stereotype.Component; @Component public class SadFortuneService implements FortuneService { @Override public String getFortune() { return \"Today is a sad day :(\"; } } Define the Bean in the Configuration Class package com.springdemo; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class SportConfig { // define bean for our sad fortune service @Bean public FortuneService sadFortuneService() { return new SadFortuneService(); } // define bean for our swim coach AND inject dependency // without springs dependency injection @Bean public Coach swimCoach() { SwimCoach mySwimCoach = new SwimCoach(sadFortuneService()); return mySwimCoach; } } The @Bean annotation tells Spring that we are creating a bean component manually. We didn’t specify a scope so the default scope is singleton. public Coach swimCoach(){ specifies that the bean will bean id of “swimCoach”. The @Bean annotation will intercept any requests for “swimCoach” bean. Since we didn’t specify a scope, the bean scope is singleton. So now in our main method:\nMain Method package com.luv2code.springdemo; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class JavaConfigDemoApp { public static void main(String[] args) { // read spring config java class AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(SportConfig.class); // get the bean from spring container by its id Coach theCoach = context.getBean(\"swimCoach\", Coach.class); // call a method on the bean System.out.println(theCoach.getDailyWorkout()); // call method to get the daily fortune System.out.println(theCoach.getDailyFortune()); // close the context context.close(); } } ","load-properties-from-file#Load Properties from File":"Create the File First, we create the file sport.properties\nfoo.email=myeasycoach@luv2code.com foo.team=Awesome Java Coders Load the File Now, we load the file from our Configuration class:\npackage com.springdemo; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.PropertySource; import org.springframework.context.support.PropertySourcesPlaceholderConfigurer; @Configuration @PropertySource(\"classpath:sport.properties\") public class SportConfig { // define bean for our sad fortune service @Bean public FortuneService sadFortuneService() { return new SadFortuneService(); } // define bean for our swim coach AND inject dependency @Bean public Coach swimCoach() { SwimCoach mySwimCoach = new SwimCoach(sadFortuneService()); return mySwimCoach; } } Inject Values We inject the values at field level in our Bean:\npackage com.springdemo; import org.springframework.beans.factory.annotation.Value; public class SwimCoach implements Coach { private FortuneService fortuneService; @Value(\"${foo.email}\") private String email; @Value(\"${foo.team}\") private String team; ... "},"title":"Spring Configuration with Java Code"},"/notes/webdev/back/spring/02/":{"data":{"":"Spring MVC is a framework for building web applications in Java based on the Model-View-Controller design patter.\nThe Front Controller is known as DispatcherServlet: It is part of the Spring Framework Pre-processes and delegates requests from the web browser to your controllers The MVC pattern is made up of: Model objects: contains the data View templates: UI of the app that displays data (most common templates: JSP + JSLT) Controller classes: business logic (handle request, access db, etc.) It includes the features of the Core Spring Framework (Inversion of Control and Dependency Injection)","add-css-and-js#Add CSS and JS":"Here are the steps on how to access static resources in a Spring MVC. For example, you can use this to access images, css, JavaScript files etc.\nYou can configure references to static resources in the spring-mvc-demo-servlet.xml.\nAdd the following entry to your Spring MVC configuration file: spring-mvc-demo-servlet.xml \u003cmvc:resources mapping=\"/resources/**\" location=\"/resources/\"\u003e\u003c/mvc:resources\u003e Now in your view pages, you can access the static files using this syntax: \u003cimg src=\"${pageContext.request.contextPath}/resources/images/spring-logo.png\"\u003e ","configuration#Configuration":"Configuration on web.xml We have to add an entry for our Front Controller: DispatcherServlet\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cweb-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" id=\"WebApp_ID\" version=\"3.1\"\u003e \u003cdisplay-name\u003espring-mvc-demo\u003c/display-name\u003e \u003cabsolute-ordering /\u003e \u003c!-- Step 1: Configure Spring MVC Dispatcher Servlet --\u003e \u003cservlet\u003e \u003c!-- Name to reference this servlet --\u003e \u003cservlet-name\u003edispatcher\u003c/servlet-name\u003e \u003cservlet-class\u003eorg.springframework.web.servlet.DispatcherServlet\u003c/servlet-class\u003e \u003c!-- File of configuration of spring application --\u003e \u003cinit-param\u003e \u003cparam-name\u003econtextConfigLocation\u003c/param-name\u003e \u003cparam-value\u003e/WEB-INF/spring-mvc-demo-servlet.xml\u003c/param-value\u003e \u003c/init-param\u003e \u003cload-on-startup\u003e1\u003c/load-on-startup\u003e \u003c/servlet\u003e \u003c!-- Step 2: Set up URL mapping for Spring MVC Dispatcher Servlet --\u003e \u003cservlet-mapping\u003e \u003cservlet-name\u003edispatcher\u003c/servlet-name\u003e \u003c!-- For any url that comes in pass it to the \"dispatcher\" servlet --\u003e \u003curl-pattern\u003e/\u003c/url-pattern\u003e \u003c/servlet-mapping\u003e \u003c/web-app\u003e Configuration on spring-mvc-demo-servlet.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"\u003e \u003c!-- Step 3: Add support for component scanning --\u003e \u003ccontext:component-scan base-package=\"com.springdemo\" /\u003e \u003c!-- Step 4: Add support for conversion, formatting and validation support --\u003e \u003cmvc:annotation-driven/\u003e \u003c!-- Step 5: Define Spring MVC view resolver --\u003e \u003cbean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\u003e \u003c!-- Specify where to look for view files --\u003e \u003cproperty name=\"prefix\" value=\"/WEB-INF/view/\" /\u003e \u003cproperty name=\"suffix\" value=\".jsp\" /\u003e \u003c/bean\u003e \u003c/beans\u003e ","controller#Controller":"Create Controller Class package com.springdemo.mvc; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; // Add controller annotation @Controller public class HomeController { // Add request mapping: this method controls the request coming to this url @RequestMapping(\"/\") public String showPage() { // Name of the view that is returned: note they are stored in WEB-INF/view/ return \"main-menu\"; } } Now, we can create the view. Inside WEB-INF/view we create a file main-menu.jsp:\n\u003c!DOCTYPE\u003e \u003chtml\u003e \u003cbody\u003e \u003ch2\u003eSpring MVC Demo - Home Page\u003c/h2\u003e \u003c/body\u003e \u003c/html\u003e ","forms#Forms":" Form Tags Form Validation ","model#Model":"Example Controller package com.springdemo.mvc; import javax.servlet.http.HttpServletRequest; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.RequestMapping; @Controller public class HelloWorldController { // new a controller method to read form data and // add data to the model @RequestMapping(\"/processFormVersionTwo\") // the HttpServletRequest allows you to retrieve information from the request (like the parameters of a form) // the model is our Model where we will store data public String parseString(HttpServletRequest request, Model model) { // read the request parameter from the HTML form String theName = request.getParameter(\"studentName\"); // convert the data to all caps theName = theName.toUpperCase(); // create the message String result = \"Yo! \" + theName; // add message attribute to the model model.addAttribute(\"message\", result); return \"helloworld\"; } } View Now, on the view, we can access the Model data:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003cbody\u003e Hello World of Spring! \u003cbr\u003e\u003cbr\u003e Student name: ${param.studentName} \u003cbr\u003e\u003cbr\u003e \u003c!-- Access model data by the attribute's name--\u003e The message: ${message} \u003c/body\u003e \u003c/html\u003e ","read-html-form-data#Read HTML Form Data":"Controller package com.springdemo.mvc; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; @Controller public class HelloWorldController { // need a controller method to show the initial HTML form @RequestMapping(\"/showForm\") // The method name can be anything public String showForm() { return \"helloworld-form\"; } // need a controller method to process the HTML form @RequestMapping(\"/processForm\") public String processForm() { return \"helloworld\"; } } View We create WEB-INF/view/helloworld-form.jsp\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eHello World - Input Form\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003c!-- The action is the request url --\u003e \u003cform action=\"processForm\" method=\"GET\"\u003e \u003cinput type=\"text\" name=\"studentName\" placeholder=\"What's your name?\" /\u003e \u003cinput type=\"submit\" /\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e And we create WEB-INF/view/helloworld-form.jsp\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003cbody\u003e Hello World of Spring! \u003cbr\u003e\u003cbr\u003e \u003c!-- name of HTML form field from previous jsp view --\u003e Student name: ${param.studentName} \u003c/body\u003e \u003c/html\u003e ","request-params-and-request-mappings#Request Params and Request Mappings":"Request Params Spring provides for a specific annotation that allows you to retrieve request parameters directly without using the HttpServletRequest object. Given the form:\npackage com.springdemo.mvc; import javax.servlet.http.HttpServletRequest; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; @Controller public class HelloWorldController { @RequestMapping(\"/processFormVersionThree\") public String processFormVersionThree( // We use the annotation to obtain the parameter @RequestParam(\"studentName\") String theName, Model model) { // convert the data to all caps theName = theName.toUpperCase(); // create the message String result = \"Hey My Friend from v3! \" + theName; // add message to the model model.addAttribute(\"message\", result); return \"helloworld\"; } } Controller Request Mappings They serve as a parent mapping for the controller All request mappings on methods in the controller are relative For example:\npackage com.springdemo.mvc; import javax.servlet.http.HttpServletRequest; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; @Controller // This is the request mapping for the controller @RequestMapping(\"/hello\") public class HelloWorldController { // Both of these request mappings are relative to the parent mapping // that is the mapping translates to domain/hello/showForm // need a controller method to show the initial HTML form @RequestMapping(\"/showForm\") public String showForm() { return \"helloworld-form\"; } // need a controller method to process the HTML form @RequestMapping(\"/processForm\") public String processForm() { return \"helloworld\"; } } "},"title":"Spring MVC"},"/notes/webdev/back/spring/02/01_form_tags/":{"data":{"":"","check-box#Check Box":"Controller Add a Model to the controller method for the form and create the model attribute, that holds the data and performs data binding package com.springdemo.mvc; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/student\") public class StudentController { // Request to show the view that contains the form @RequestMapping(\"/showForm\") public String showForm(Model theModel) { // create a student object Student theStudent = new Student(); // add student object to the model theModel.addAttribute(\"student\", theStudent); return \"student-form\"; } // Process the submit event on the form @RequestMapping(\"/processForm\") // We obtain the model attribute with the following annotation public String processForm(@ModelAttribute(\"student\") Student theStudent) { // Now we can retrieve the updated information from the form System.out.println(\"theStudent: \" + theStudent.getFirstName() + \" \" + theStudent.getLastName()); return \"student-confirmation\"; } } View Setting the HTML for data binding: For student-form.jsp: \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Registration Form\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cform:form action=\"processForm\" modelAttribute=\"student\"\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name: \u003cform:input path=\"lastName\" /\u003e \u003cbr\u003e\u003cbr\u003e Country: \u003c!-- Drop down list of country options --\u003e \u003c!-- We specify the variable where we store the selected value in the student object: which is country --\u003e \u003cform:select path=\"country\"\u003e \u003c!-- This is a list that was populated when we created the student object --\u003e \u003c!-- Remember Spring calls student.getCountryOptions() --\u003e \u003cform:options items=\"${student.countryOptions}\" /\u003e \u003c/form:select\u003e \u003cbr\u003e\u003cbr\u003e \u003cbr\u003e\u003cbr\u003e Favorite Language: Java \u003cform:radiobutton path=\"favoriteLanguage\" value=\"Java\" /\u003e C# \u003cform:radiobutton path=\"favoriteLanguage\" value=\"C#\" /\u003e PHP \u003cform:radiobutton path=\"favoriteLanguage\" value=\"PHP\" /\u003e Ruby \u003cform:radiobutton path=\"favoriteLanguage\" value=\"Ruby\" /\u003e \u003cbr\u003e\u003cbr\u003e Operating Systems: \u003c!-- The \"path\" specifies the name of the property we are going to bind the radiobutton to, in this case \"operatingSystems\" --\u003e \u003c!-- Note these can also be populated from the Student class or using a properties file --\u003e Linux \u003cform:checkbox path=\"operatingSystems\" value=\"Linux\" /\u003e Mac OS \u003cform:checkbox path=\"operatingSystems\" value=\"Mac OS\" /\u003e MS Windows \u003cform:checkbox path=\"operatingSystems\" value=\"MS Window\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e * For `student-confirmation.jsp`: \u003c%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Confirmation\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e The student is confirmed: ${student.firstName} ${student.lastName} \u003cbr\u003e\u003cbr\u003e Selected coutry: ${student.country} ${student.lastName} \u003cbr\u003e\u003cbr\u003e \u003c!-- Obtain the value using the binded variable inside the student object --\u003e Favorite language: ${student.favoriteLanguage} \u003cbr\u003e\u003cbr\u003e Operating Systems: \u003c!-- Create an unordered list of the selected values in the checkbox --\u003e \u003cul\u003e \u003cc:forEach var=\"temp\" items=\"${student.operatingSystems}\"\u003e \u003cli\u003e ${temp} \u003c/li\u003e \u003c/c:forEach\u003e \u003c/ul\u003e \u003c/body\u003e \u003c/html\u003e Model The model attribute “student” is populated with an instance of the following Student class:\npackage com.springdemo.mvc; import java.util.LinkedHashMap; public class Student { private String firstName; private String lastName; private String country; private LinkedHashMap\u003cString, String\u003e countryOptions; private String favoriteLanguage; // Attribute bound to the checkbox (multiple options so it is an array) private String[] operatingSystems; public Student() { // populate country options: used ISO country code countryOptions = new LinkedHashMap\u003c\u003e(); countryOptions.put(\"BR\", \"Brazil\"); countryOptions.put(\"FR\", \"France\"); countryOptions.put(\"DE\", \"Germany\"); countryOptions.put(\"IN\", \"India\"); countryOptions.put(\"US\", \"United States of America\"); // We can also populate the favoriteLanguage options from here // in the same manner we did with the country options } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getCountry() { return country; } public void setCountry(String country) { this.country = country; } public LinkedHashMap\u003cString, String\u003e getCountryOptions() { return countryOptions; } public String getFavoriteLanguage() { return favoriteLanguage; } public void setFavoriteLanguage(String favoriteLanguage) { this.favoriteLanguage = favoriteLanguage; } // Setter and getter handlers for the new bound attribute public String[] getOperatingSystems() { return operatingSystems; } public void setOperatingSystems(String[] operatingSystems) { this.operatingSystems = operatingSystems; } } ","drop-down-lists#Drop Down Lists":"Controller Add a Model to the controller method for the form and create the model attribute, that holds the data and performs data binding package com.springdemo.mvc; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/student\") public class StudentController { // Request to show the view that contains the form @RequestMapping(\"/showForm\") public String showForm(Model theModel) { // create a student object Student theStudent = new Student(); // add student object to the model theModel.addAttribute(\"student\", theStudent); return \"student-form\"; } // Process the submit event on the form @RequestMapping(\"/processForm\") // We obtain the model attribute with the following annotation public String processForm(@ModelAttribute(\"student\") Student theStudent) { // Now we can retrieve the updated information from the form System.out.println(\"theStudent: \" + theStudent.getFirstName() + \" \" + theStudent.getLastName()); return \"student-confirmation\"; } } View Setting the HTML for data binding: For student-form.jsp: \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Registration Form\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cform:form action=\"processForm\" modelAttribute=\"student\"\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name: \u003cform:input path=\"lastName\" /\u003e \u003cbr\u003e\u003cbr\u003e Country: \u003c!-- Drop down list of country options --\u003e \u003c!-- We specify the variable where we store the selected value in the student object: which is country --\u003e \u003cform:select path=\"country\"\u003e \u003c!-- This is a list that was populated when we created the student object --\u003e \u003c!-- Remember Spring calls student.getCountryOptions() --\u003e \u003cform:options items=\"${student.countryOptions}\" /\u003e \u003c/form:select\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e * For `student-confirmation.jsp`: \u003c%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Confirmation\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e The student is confirmed: ${student.firstName} ${student.lastName} \u003c!-- Obtain the value saved in the coutry variable inside the student's object (corresponds to the selected value) --\u003e Selected coutry: ${student.country} ${student.lastName} \u003c/body\u003e \u003c/html\u003e Model The model attribute “student” is populated with an instance of the following Student class:\npackage com.springdemo.mvc; import java.util.LinkedHashMap; public class Student { private String firstName; private String lastName; private String country; private LinkedHashMap\u003cString, String\u003e countryOptions; public Student() { // populate country options: used ISO country code countryOptions = new LinkedHashMap\u003c\u003e(); countryOptions.put(\"BR\", \"Brazil\"); countryOptions.put(\"FR\", \"France\"); countryOptions.put(\"DE\", \"Germany\"); countryOptions.put(\"IN\", \"India\"); countryOptions.put(\"US\", \"United States of America\"); } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getCountry() { return country; } // Setter and getter handlers for the new binded attribute public void setCountry(String country) { this.country = country; } public LinkedHashMap\u003cString, String\u003e getCountryOptions() { return countryOptions; } } Country options from a properties file We create WEB-INF/countries.properties: BR=Brazil FR=France CO=Colombia IN=India Update configuration’s file spring-mvc-dmo-servlet.xml header (to use a new set of Spring tags: utils): \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:util=\"http://www.springframework.org/schema/util\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd\"\u003e Load the country options properties file in the Spring configuration file, with a bean id equal to “countryOptions”: \u003cutil:properties id=\"countryOptions\" location=\"classpath:../countries.properties\" /\u003e Inject properties inside our controller: @Value(\"#{countryOptions}\") private Map\u003cString, String\u003e countryOptions; Add countryOptions as an attribute of the model inside the controller method: @RequestMapping(\"/showForm\") public String showForm(Model theModel) { // create a student object Student Student theStudent = new Student(); // add student object to the model theModel.addAttribute(\"student\", theStudent); // add the country options to the model theModel.addAttribute(\"theCountryOptions\", countryOptions); return \"student-form\"; } Update the view as follows: \u003cform:select path=\"country\"\u003e \u003cform:options items=\"${theCountryOptions}\" /\u003e \u003c/form:select\u003e ","radio-buttons#Radio Buttons":"Controller Add a Model to the controller method for the form and create the model attribute, that holds the data and performs data binding package com.springdemo.mvc; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/student\") public class StudentController { // Request to show the view that contains the form @RequestMapping(\"/showForm\") public String showForm(Model theModel) { // create a student object Student theStudent = new Student(); // add student object to the model theModel.addAttribute(\"student\", theStudent); return \"student-form\"; } // Process the submit event on the form @RequestMapping(\"/processForm\") // We obtain the model attribute with the following annotation public String processForm(@ModelAttribute(\"student\") Student theStudent) { // Now we can retrieve the updated information from the form System.out.println(\"theStudent: \" + theStudent.getFirstName() + \" \" + theStudent.getLastName()); return \"student-confirmation\"; } } View Setting the HTML for data binding: For student-form.jsp: \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Registration Form\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cform:form action=\"processForm\" modelAttribute=\"student\"\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name: \u003cform:input path=\"lastName\" /\u003e \u003cbr\u003e\u003cbr\u003e Country: \u003c!-- Drop down list of country options --\u003e \u003c!-- We specify the variable where we store the selected value in the student object: which is country --\u003e \u003cform:select path=\"country\"\u003e \u003c!-- This is a list that was populated when we created the student object --\u003e \u003c!-- Remember Spring calls student.getCountryOptions() --\u003e \u003cform:options items=\"${student.countryOptions}\" /\u003e \u003c/form:select\u003e \u003cbr\u003e\u003cbr\u003e \u003cbr\u003e\u003cbr\u003e Favorite Language: \u003c!-- The \"path\" specifies the name of the property we are going to bind the radiobutton to, in this case \"favoriteLanguage\" --\u003e \u003c!-- Note these can also be populated from the Student class or using a properties file --\u003e Java \u003cform:radiobutton path=\"favoriteLanguage\" value=\"Java\" /\u003e C# \u003cform:radiobutton path=\"favoriteLanguage\" value=\"C#\" /\u003e PHP \u003cform:radiobutton path=\"favoriteLanguage\" value=\"PHP\" /\u003e Ruby \u003cform:radiobutton path=\"favoriteLanguage\" value=\"Ruby\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e * For `student-confirmation.jsp`: \u003c%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Confirmation\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e The student is confirmed: ${student.firstName} ${student.lastName} \u003cbr\u003e\u003cbr\u003e Selected coutry: ${student.country} ${student.lastName} \u003cbr\u003e\u003cbr\u003e \u003c!-- Obtain the value using the binded variable inside the student object --\u003e Favorite language: ${student.favoriteLanguage} \u003c/body\u003e \u003c/html\u003e Model The model attribute “student” is populated with an instance of the following Student class:\npackage com.springdemo.mvc; import java.util.LinkedHashMap; public class Student { private String firstName; private String lastName; private String country; private LinkedHashMap\u003cString, String\u003e countryOptions; // Property we are going to bind to the radio buttons private String favoriteLanguage; public Student() { // populate country options: used ISO country code countryOptions = new LinkedHashMap\u003c\u003e(); countryOptions.put(\"BR\", \"Brazil\"); countryOptions.put(\"FR\", \"France\"); countryOptions.put(\"DE\", \"Germany\"); countryOptions.put(\"IN\", \"India\"); countryOptions.put(\"US\", \"United States of America\"); // We can also populate the favoriteLanguage options from here // in the same manner we did with the country options } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getCountry() { return country; } public void setCountry(String country) { this.country = country; } public LinkedHashMap\u003cString, String\u003e getCountryOptions() { return countryOptions; } // Setter and getter handlers for the new binded attribute public String getFavoriteLanguage() { return favoriteLanguage; } public void setFavoriteLanguage(String favoriteLanguage) { this.favoriteLanguage = favoriteLanguage; } } ","reference-spring-mvc-form-tags#Reference Spring MVC Form Tags":"To use these tags in your web page you have to specify the spring namespace at the beginning of the JSP file:\n\u003c!-- Reference to the namespace --\u003e \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e\u003c/head\u003e \u003cbody\u003e \u003c/body\u003e \u003c/html\u003e Text Fields Drop Down Lists Radio Buttons CheckBox ","text-fields#Text Fields":"Controller Add a Model to the controller method for the form and create the model attribute, that holds the data and perfoms data binding package com.springdemo.mvc; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/student\") public class StudentController { // Request to show the view that contains the form @RequestMapping(\"/showForm\") public String showForm(Model theModel) { // create a student object Student theStudent = new Student(); // add student object to the model theModel.addAttribute(\"student\", theStudent); return \"student-form\"; } // Process the submit event on the form @RequestMapping(\"/processForm\") // We obtain the model attribute with the following annotation public String processForm(@ModelAttribute(\"student\") Student theStudent) { // Now we can retrieve the updated information from the form System.out.println(\"theStudent: \" + theStudent.getFirstName() + \" \" + theStudent.getLastName()); return \"student-confirmation\"; } } View Setting the HTML for data binding: For student-form.jsp: \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Registration Form\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003c!-- Note the modelAttribute equals the attribute we added to the model in the controller--\u003e \u003cform:form action=\"processForm\" modelAttribute=\"student\"\u003e \u003c!-- To retrieve the data this maps to student.getFirstName() --\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name: \u003cform:input path=\"lastName\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e When we submit Spring will call student.setFirstName() and student.setLastName() to save the data in the Student object, so we can retrieve it from our controller method.\n* For `student-confirmation.jsp`: \u003c%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %\u003e \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eStudent Confirmation\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003c!-- Obtain data from the model: note we use the attribute's name (i.e. student) to access the object --\u003e The student is confirmed: ${student.firstName} ${student.lastName} \u003c/body\u003e \u003c/html\u003e Model The model attribute “student” is populated with an instance of the following Student class:\npackage com.springdemo.mvc; import java.util.LinkedHashMap; public class Student { private String firstName; private String lastName; public Student() {} public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } } "},"title":"Form Tags"},"/notes/webdev/back/spring/02/02_form_validation/":{"data":{"":"","custom-validation#Custom Validation":"Create a Custom Java Annotation Create Annotation Clas package com.springdemo.mvc.validation; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; import javax.validation.Constraint; import javax.validation.Payload; // Specify the class that holds the validation logic @Constraint(validatedBy = CourseCodeConstraintValidator.class) // Where you can use this annotation: on a method or on a field @Target( { ElementType.METHOD, ElementType.FIELD } ) @Retention(RetentionPolicy.RUNTIME) // Note the @interface (it is needed to create the annotation) public @interface CourseCode { // define default course code public String value() default \"LUV\"; // define default error message public String message() default \"must start with LUV\"; // define default groups public Class\u003c?\u003e[] groups() default {}; // define default payloads public Class\u003c? extends Payload\u003e[] payload() default {}; } Create Validator Class This class holds the validation logic\npackage com.springdemo.mvc.validation; import javax.validation.ConstraintValidator; import javax.validation.ConstraintValidatorContext; // Implements the previous ConstraintValidator interface, with generics: \u003cAnnotation Interface, Data Type\u003e public class CourseCodeConstraintValidator implements ConstraintValidator\u003cCourseCode, String\u003e { private String coursePrefix; @Override public void initialize(CourseCode theCourseCode) { // Obtain prefix from the \"value\" attribute of our annotation coursePrefix = theCourseCode.value(); } @Override // Called when we use the @Valid annotation public boolean isValid(String theCode, ConstraintValidatorContext theConstraintValidatorContext) { boolean result; // Validation logic if (theCode != null) { result = theCode.startsWith(coursePrefix); } else { result = true; } return result; } } Add Custom Validation public class Customer { private String firstName; @NotNull(message=\"is required\") @Size(min=1, message=\"is required\") private String lastName; @NotNull(message=\"is required\") @Min(value=0, message=\"must be greater than or equal to zero\") @Max(value=10, message=\"must be less than or equal to 10\") private Integer freePasses; @Pattern(regexp=\"^[a-zA-Z0-9]{5}\", message=\"only 5 chars/digits\") private String postalCode; // Use our custom validation tag @CourseCode(value=\"TOPS\", message=\"must start with TOPS\") private String courseCode; Perform Validation on Controller package com.springdemo.mvc; import javax.validation.Valid; import org.springframework.beans.propertyeditors.StringTrimmerEditor; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.validation.BindingResult; import org.springframework.web.bind.WebDataBinder; import org.springframework.web.bind.annotation.InitBinder; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/customer\") public class CustomerController { // add an initbinder ... to convert trim input strings // remove leading and trailing whitespace // resolve issue for our validation @InitBinder //@InitBinder annotation works as a pre-processor // It will pre-process each web request to our controller public void initBinder(WebDataBinder dataBinder) { // Trim strings (true: empty strings to null) StringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true); // For every string class apply the trim editor dataBinder.registerCustomEditor(String.class, stringTrimmerEditor); } @RequestMapping(\"/showForm\") public String showForm(Model theModel) { theModel.addAttribute(\"customer\", new Customer()); return \"customer-form\"; } @RequestMapping(\"/processForm\") // @Valid: Tells spring to perform validation on the customer object // BindingResult: results of the validation will be placed in BindingResult public String processForm( @Valid @ModelAttribute(\"customer\") Customer theCustomer, BindingResult theBindingResult) { System.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\"); // Check if validation was sucessfull if (theBindingResult.hasErrors()) { // If not sucessfull send back return \"customer-form\"; } else { // If sucessfull return \"customer-confirmation\"; } } } When performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute.\nDisplay error on HTML \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eCustomer Registration Form\u003c/title\u003e \u003cstyle\u003e .error {color:red} \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ci\u003eFill out the form. Asterisk (*) means required.\u003c/i\u003e \u003cbr\u003e\u003cbr\u003e \u003cform:form action=\"processForm\" modelAttribute=\"customer\"\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name (*): \u003cform:input path=\"lastName\" /\u003e \u003cform:errors path=\"lastName\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e Free passes: \u003cform:input path=\"freePasses\" /\u003e \u003cform:errors path=\"freePasses\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e Postal Code: \u003cform:input path=\"postalCode\" /\u003e \u003cform:errors path=\"postalCode\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003c!-- The message shown equals the messages from both of the validation annotations defined for the courseCode attribute in the Customer class --\u003e Course Code: \u003cform:input path=\"courseCode\" /\u003e \u003cform:errors path=\"courseCode\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e ","handle-string-input-in-integer-field#Handle String Input in Integer Field":"Create a custom message Create a properties file in resources/messages.properties\n// ErrorType.SpringModelAttributeName.FieldName typeMismatch.customer.freePasses=Invalid number Specify Properties file in Configuration We add the following in our configuration file spring-mvc-demo-servlet.xml\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"\u003e \u003ccontext:component-scan base-package=\"com.luv2code.springdemo\" /\u003e \u003cmvc:annotation-driven/\u003e \u003cbean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\u003e \u003cproperty name=\"prefix\" value=\"/WEB-INF/view/\" /\u003e \u003cproperty name=\"suffix\" value=\".jsp\" /\u003e \u003c/bean\u003e \u003c!-- Load custom message resources --\u003e \u003cbean id=\"messageSource\" class=\"org.springframework.context.support.ResourceBundleMessageSource\"\u003e \u003c!-- Path where the properties file is stored --\u003e \u003cproperty name=\"basenames\" value=\"resources/messages\" /\u003e \u003c/bean\u003e \u003c/beans\u003e ","number-range-validation#Number Range Validation":"Add Validation Rule to Bean We create a Customer class, whose freePasses variable must be a number between 0 and 10.\npublic class Customer { private String firstName; @NotNull(message=\"is required\") @Size(min=1, message=\"is required\") private String lastName; // Minimum value we will expect @Min(value=0, message=\"must be greater than or equal to zero\") // Maximum value we will expect @Max(value=10, message=\"must be less than or equal to 10\") private int freePasses; ... Perform Validation in the Controller We also\npackage com.springdemo.mvc; import javax.validation.Valid; import org.springframework.beans.propertyeditors.StringTrimmerEditor; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.validation.BindingResult; import org.springframework.web.bind.WebDataBinder; import org.springframework.web.bind.annotation.InitBinder; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/customer\") public class CustomerController { // add an initbinder ... to convert trim input strings // remove leading and trailing whitespace // resolve issue for our validation @InitBinder //@InitBinder annotation works as a pre-processor // It will pre-process each web request to our controller public void initBinder(WebDataBinder dataBinder) { // Trim strings (true: empty strings to null) StringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true); // For every string class apply the trim editor dataBinder.registerCustomEditor(String.class, stringTrimmerEditor); } @RequestMapping(\"/showForm\") public String showForm(Model theModel) { theModel.addAttribute(\"customer\", new Customer()); return \"customer-form\"; } @RequestMapping(\"/processForm\") // @Valid: Tells spring to perform validation on the customer object // BindingResult: results of the validation will be placed in BindingResult public String processForm( @Valid @ModelAttribute(\"customer\") Customer theCustomer, BindingResult theBindingResult) { System.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\"); // Check if validation was sucessfull if (theBindingResult.hasErrors()) { // If not sucessfull send back return \"customer-form\"; } else { // If sucessfull return \"customer-confirmation\"; } } } When performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute.\nDisplay error on HTML \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eCustomer Registration Form\u003c/title\u003e \u003cstyle\u003e .error {color:red} \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ci\u003eFill out the form. Asterisk (*) means required.\u003c/i\u003e \u003cbr\u003e\u003cbr\u003e \u003cform:form action=\"processForm\" modelAttribute=\"customer\"\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name (*): \u003cform:input path=\"lastName\" /\u003e \u003c!-- The message shown equals the messages from both of the validation annotations defined for the lastName attribute in the Customer class --\u003e \u003cform:errors path=\"lastName\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e Free passes: \u003cform:input path=\"freePasses\" /\u003e \u003c!-- The message shown equals the messages from both of the validation annotations defined for the freePasses attribute in the Customer class --\u003e \u003cform:errors path=\"freePasses\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e ","required-validation#Required Validation":"Add Validation Rule to Bean We create a Customer class, whose lastName attribute must be non-null, that is, lastName is a required attribute:\npackage com.springdemo.mvc; import javax.validation.constraints.NotNull; import javax.validation.constraints.Size; public class Customer { private String firstName; // Validation annotation @NotNull(message=\"is required\") @Size(min=1, message=\"is required\") private String lastName; public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } } Note that if we wanted to make an integer required, we must use the wrapper java classes (i.e. Integer), that will be able to handle empty strings as inputs and nulls. The primitive types will throw an exception.\nPerform Validation in the Controller We also\npackage com.springdemo.mvc; import javax.validation.Valid; import org.springframework.beans.propertyeditors.StringTrimmerEditor; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.validation.BindingResult; import org.springframework.web.bind.WebDataBinder; import org.springframework.web.bind.annotation.InitBinder; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/customer\") public class CustomerController { // add an initbinder ... to convert trim input strings // remove leading and trailing whitespace // resolve issue for our validation @InitBinder //@InitBinder annotation works as a pre-processor // It will pre-process each web request to our controller public void initBinder(WebDataBinder dataBinder) { // Trim strings (true: empty strings to null) StringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true); // For every string class apply the trim editor dataBinder.registerCustomEditor(String.class, stringTrimmerEditor); } @RequestMapping(\"/showForm\") public String showForm(Model theModel) { theModel.addAttribute(\"customer\", new Customer()); return \"customer-form\"; } @RequestMapping(\"/processForm\") // @Valid: Tells spring to perform validation on the customer object // BindingResult: results of the validation will be placed in BindingResult public String processForm( @Valid @ModelAttribute(\"customer\") Customer theCustomer, BindingResult theBindingResult) { System.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\"); // Check if validation was sucessfull if (theBindingResult.hasErrors()) { // If not sucessfull send back return \"customer-form\"; } else { // If sucessfull return \"customer-confirmation\"; } } } When performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute.\nDisplay error on HTML \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eCustomer Registration Form\u003c/title\u003e \u003cstyle\u003e .error {color:red} \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ci\u003eFill out the form. Asterisk (*) means required.\u003c/i\u003e \u003cbr\u003e\u003cbr\u003e \u003cform:form action=\"processForm\" modelAttribute=\"customer\"\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name (*): \u003cform:input path=\"lastName\" /\u003e \u003c!-- We use the error form tag to display an error when the input is not valid --\u003e \u003c!-- The message shown equals the messages from both of the validation annotations defined for the lastName attribute in the Customer class --\u003e \u003cform:errors path=\"lastName\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e ","set-up#Set up":"Add Hibernate's library (Hibernate Validator)for Bean Validation which is fully compliant with Java's Bean Validation API.\nRequired Validation Number Range Validation Validation with Regular Expressions Handle String in Integer Field Custom Validation ","validation-with-regular-expressions#Validation with Regular Expressions":"Add Validation Rule to Bean We create a Customer class, whose freePasses variable must be a number between 0 and 10.\npublic class Customer { private String firstName; @NotNull(message=\"is required\") @Size(min=1, message=\"is required\") private String lastName; @Min(value=0, message=\"must be greater than or equal to zero\") @Max(value=10, message=\"must be less than or equal to 10\") private int freePasses; // Define the regular expression for the postalCode attribute @Pattern(regexp=\"^[a-zA-Z0-9]{5}\", message=\"only 5 chars/digits\") private String postalCode; ... Perform Validation in the Controller We also\npackage com.springdemo.mvc; import javax.validation.Valid; import org.springframework.beans.propertyeditors.StringTrimmerEditor; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.validation.BindingResult; import org.springframework.web.bind.WebDataBinder; import org.springframework.web.bind.annotation.InitBinder; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(\"/customer\") public class CustomerController { // add an initbinder ... to convert trim input strings // remove leading and trailing whitespace // resolve issue for our validation @InitBinder //@InitBinder annotation works as a pre-processor // It will pre-process each web request to our controller public void initBinder(WebDataBinder dataBinder) { // Trim strings (true: empty strings to null) StringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true); // For every string class apply the trim editor dataBinder.registerCustomEditor(String.class, stringTrimmerEditor); } @RequestMapping(\"/showForm\") public String showForm(Model theModel) { theModel.addAttribute(\"customer\", new Customer()); return \"customer-form\"; } @RequestMapping(\"/processForm\") // @Valid: Tells spring to perform validation on the customer object // BindingResult: results of the validation will be placed in BindingResult public String processForm( @Valid @ModelAttribute(\"customer\") Customer theCustomer, BindingResult theBindingResult) { System.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\"); // Check if validation was sucessfull if (theBindingResult.hasErrors()) { // If not sucessfull send back return \"customer-form\"; } else { // If sucessfull return \"customer-confirmation\"; } } } When performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute.\nDisplay error on HTML \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eCustomer Registration Form\u003c/title\u003e \u003cstyle\u003e .error {color:red} \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ci\u003eFill out the form. Asterisk (*) means required.\u003c/i\u003e \u003cbr\u003e\u003cbr\u003e \u003cform:form action=\"processForm\" modelAttribute=\"customer\"\u003e First name: \u003cform:input path=\"firstName\" /\u003e \u003cbr\u003e\u003cbr\u003e Last name (*): \u003cform:input path=\"lastName\" /\u003e \u003cform:errors path=\"lastName\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e Free passes: \u003cform:input path=\"freePasses\" /\u003e \u003cform:errors path=\"freePasses\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e Postal Code: \u003cform:input path=\"postalCode\" /\u003e \u003c!-- The message shown equals the messages from both of the validation annotations defined for the postalCode attribute in the Customer class --\u003e \u003cform:errors path=\"postalCode\" cssClass=\"error\" /\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" value=\"Submit\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e "},"title":"Form Validation"},"/notes/webdev/back/spring/03_hibernate/":{"data":{"":"Is a framework for persisting/saving Java objects in a database\nHandles all of the low-level SQL Minimizes the amount JDBC code to develop Provides the Object-to-Relational Mapping (ORM): The developer defines a mapping between a Java class and a database table Hibernate uses JDBC for all database communications:","configure-hibernate-with-annotations#Configure Hibernate with Annotations":"Add Hibernate Configuration File We create the following hibernate.cfg.xml file:\n\u003c!DOCTYPE hibernate-configuration PUBLIC \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\"\u003e \u003chibernate-configuration\u003e \u003c!-- A session factory allows us to get sessions objects to connect to the database --\u003e \u003csession-factory\u003e \u003c!-- JDBC Database connection settings --\u003e \u003cproperty name=\"connection.driver_class\"\u003ecom.mysql.cj.jdbc.Driver\u003c/property\u003e \u003cproperty name=\"connection.url\"\u003ejdbc:mysql://localhost:3306/hb_student_tracker?useSSL=false\u0026amp;serverTimezone=UTC\u003c/property\u003e \u003cproperty name=\"connection.username\"\u003ehbstudent\u003c/property\u003e \u003cproperty name=\"connection.password\"\u003ehbstudent\u003c/property\u003e \u003c!-- JDBC connection pool settings ... using built-in test pool --\u003e \u003cproperty name=\"connection.pool_size\"\u003e1\u003c/property\u003e \u003c!-- Select our SQL dialect --\u003e \u003cproperty name=\"dialect\"\u003eorg.hibernate.dialect.MySQLDialect\u003c/property\u003e \u003c!-- Echo the SQL to stdout --\u003e \u003cproperty name=\"show_sql\"\u003etrue\u003c/property\u003e \u003c!-- Set the current session context --\u003e \u003cproperty name=\"current_session_context_class\"\u003ethread\u003c/property\u003e \u003c/session-factory\u003e \u003c/hibernate-configuration\u003e Annotate Java Class Hibernate deals with the concept of Entity, which is basically a Java Class with its attributes, setters and getters, that is mapped to a database table with the help of annotations.\nNote that there are two ways of configuring the mapping:\nXML Config file (legacy) Java Annotations (modern, preferred) With Java Annotations we have to follow these steps:\nMap the class to a database table // Let spring know this is an entity we want to map to a database table @Entity // Provides the actual name of the table (observe in this case it is optional // because the name of the class = the name of the database table) @Table(name=\"student\") public class Student { ... } Map the fields to database columns public class Student { // Primary key @Id // How to generate primary key @GeneratedValue(strategy=GenerationType.IDENTITY) // Column name (also not needed if the name in the database and the name here are the same) @Column(name=\"id\") private int id; @Column(name=\"first_name\") private String firstName; @Column(name=\"last_name\") private String lastName; @Column(name=\"email\") private String email; ... } Some other ID Generation Strategies are:\nAUTO: pick the appropiate strategy for the given database IDENTITY: assign primary keys using database identidy column SEQUENCE: assign primary keys using a database sequence TABLE: assign primary keys using an uderlying database table to ensure uniqueness You can also create your custom generator ","database-concepts#Database Concepts":"Cascade Types PERSIST: if entity is persisted/saved, the related entity will also be persisted REMOVE: if entity is removed/deleted, the related entity will also be deleted REFRESH: if entity is refreshed, the related entity will also be refreshed DETACH: if entity is detached (not associated with session), the related entity will also be detached MERGE: if entity is merged, the related entity will also be merged ALL: all of the above cascade types By default, no operations are cascaded.","database-operations#Database Operations":"Save Java Object To save a Java Object:\npublic ... { try { // create a student object Student tempStudent = new Student(\"Paul\", \"Doe\", \"paul@luv2code.com\"); // start a transaction session.beginTransaction(); // save the student object session.save(tempStudent); // commit transaction session.getTransaction().commit(); } finally { factory.close(); } } Read Java Object public ... { try { // From the student created and saved previously // find out the student's id: primary key // now get a new session and start transaction session = factory.getCurrentSession(); session.beginTransaction(); // retrieve student based on the id: primary key System.out.println(\"\\nGetting student with id: \" + tempStudent.getId()); // Get from the DB by the primary key of the student Student myStudent = session.get(Student.class, tempStudent.getId()); // commit the transaction session.getTransaction().commit(); } finally { factory.close(); } } Query Java Object Hibernate has a query language for retrieving objects: HQL which is similar to SQL.\npublic class QueryStudentDemo { public static void main(String[] args) { // create session factory ... // create session Session session = factory.getCurrentSession(); try { // start a transaction session.beginTransaction(); // Note we use the Java object name for the table name // and the name of the attribute in the class for the name // of the column (firstName istd of first_name) // query students: lastName='Doe' OR firstName='Daffy' theStudents = session.createQuery(\"from Student s where\" + \" s.lastName='Doe' OR s.firstName='Daffy'\").getResultList(); // query students where email LIKE '%gmail.com' theStudents = session.createQuery(\"from Student s where\" + \" s.email LIKE '%gmail.com'\").getResultList(); // commit transaction session.getTransaction().commit(); } finally { factory.close(); } } Update Java Objects public class UpdateStudentDemo { public static void main(String[] args) { // create session factory ... // create session Session session = factory.getCurrentSession(); try { // Update one student int studentId = 1; // now get a new session and start transaction session = factory.getCurrentSession(); session.beginTransaction(); Student myStudent = session.get(Student.class, studentId); // Update name of student myStudent.setFirstName(\"Scooby\"); // commit the transaction session.getTransaction().commit(); // Update several students session = factory.getCurrentSession(); session.beginTransaction(); // update email for all students System.out.println(\"Update email for all students\"); session.createQuery(\"update Student set email='foo@gmail.com'\") .executeUpdate(); // commit the transaction session.getTransaction().commit(); } finally { factory.close(); } } } Delete Java Objects public class DeleteStudentDemo { public static void main(String[] args) { // create session factory ... // create session Session session = factory.getCurrentSession(); try { int studentId = 1; // now get a new session and start transaction session = factory.getCurrentSession(); session.beginTransaction(); // retrieve student based on the id: primary key Student myStudent = session.get(Student.class, studentId); // delete the student session.delete(myStudent); // delete student id=2 session.createQuery(\"delete from Student where id=2\").executeUpdate(); // commit the transaction session.getTransaction().commit(); } finally { factory.close(); } } } ","eager-vs-lazy-loading#Eager vs Lazy Loading":"Default Fetch Types Mapping Defaul Fetch Type @OneToOne FetchType.EAGER @OneToMany FetchType.LAZY @ManyToOne FetchType.EAGER @ManyToMany FetchType.LAZY Specify Fetch Type on Entity We can specify the fetching type on the Entity as follows:\n@Entity @Table(name=\"instructor\") public class Instructor { @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @OneToOne(cascade=CascadeType.ALL) @JoinColumn(name=\"instructor_detail_id\") private InstructorDetail instructorDetail; // Specify fetch type (only load the courses on demand, their retrieval // is delayed) @OneToMany(fetch=FetchType.LAZY, mappedBy=\"instructor\", cascade= {CascadeType.PERSIST, CascadeType.MERGE, CascadeType.DETACH, CascadeType.REFRESH}) private List\u003cCourse\u003e courses; ... Avoid Closed Session Exception To avoid the error we use the JOIN FETCH (we do override lazy loading with eager loading) of HQL:\npublic class FetchJoinDemo { public static void main(String[] args) { // create session factory SessionFactory factory = ... // create session Session session = factory.getCurrentSession(); try { // start a transaction session.beginTransaction(); // Hibernate query with HQL to avoid exception of lazy loading when closing session // get the instructor from db int theId = 1; Query\u003cInstructor\u003e query = session.createQuery(\"select i from Instructor i \" + \"JOIN FETCH i.courses \" + \"where i.id=:theInstructorId\", Instructor.class); // set parameter on query query.setParameter(\"theInstructorId\", theId); // execute query and get instructor Instructor tempInstructor = query.getSingleResult(); System.out.println(\"luv2code: Instructor: \" + tempInstructor); // commit transaction session.getTransaction().commit(); // close the session session.close(); System.out.println(\"\\nluv2code: The session is now closed!\\n\"); // get courses for the instructor System.out.println(\"luv2code: Courses: \" + tempInstructor.getCourses()); System.out.println(\"luv2code: Done!\"); } finally { // add clean up code session.close(); factory.close(); } } } ","many-to-many-relationship#Many To Many Relationship":"Entities We now code the two entities:\npackage com.hibernate.demo.entity; // annotate the class as an entity and map to db table @Entity @Table(name=\"course\") public class Course { // define the fields // annotate the fields with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"title\") private String title; // Set up one to many relationship @ManyToOne(cascade= // On delete course, do not delete instructor {CascadeType.PERSIST, CascadeType.MERGE, CascadeType.DETACH, CascadeType.REFRESH}) @JoinColumn(name=\"instructor_id\") private Instructor instructor; // Set up unidirectional one to many relationship @OneToMany(fetch=FetchType.LAZY, cascade=CascadeType.ALL) @JoinColumn(name=\"course_id\") private List\u003cReview\u003e reviews; // Set up many to many relationship with lazy loading // so only Courses are retrieved, and the students associated // are obtained only if needed @ManyToMany(fetch=FetchType.LAZY, cascade= {CascadeType.PERSIST, CascadeType.MERGE, CascadeType.DETACH, CascadeType.REFRESH}) // Specifying the join table, and the corresponding // foreign keys @JoinTable( // table name name=\"course_student\", // this entity's pk joinColumns=@JoinColumn(name=\"course_id\"), // related entity's pk inverseJoinColumns=@JoinColumn(name=\"student_id\") ) private List\u003cStudent\u003e students; public Course() { } ... // Setters and getters } And now the Student:\npackage com.hibernate.demo.entity; @Entity @Table(name=\"student\") public class Student { @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"first_name\") private String firstName; @Column(name=\"last_name\") private String lastName; @Column(name=\"email\") private String email; // Set up many to many relationship with lazy loading // so only Students are retrieved, and the courses associated // are obtained only if needed @ManyToMany(fetch=FetchType.LAZY, cascade= {CascadeType.PERSIST, CascadeType.MERGE, CascadeType.DETACH, CascadeType.REFRESH}) // Specifying the join table, and the corresponding // foreign keys @JoinTable( // table name name=\"course_student\", // this entity's pk joinColumns=@JoinColumn(name=\"student_id\"), // related entity's pk inverseJoinColumns=@JoinColumn(name=\"course_id\") ) private List\u003cCourse\u003e courses; // constructor, getters, setters .... Main App To test our code, we are going to get a Course and add it to a Student:\npackage com.hibernate.demo; public class CreateDemo { public static void main(String[] args) { // create session factory // ... // create session Session session = factory.getCurrentSession(); try { // start a transaction session.beginTransaction(); // get the student mary from database int studentId = 2; Student tempStudent = session.get(Student.class, studentId); // create more courses Course tempCourse1 = new Course(\"Rubik's Cube - How to Speed Cube\"); Course tempCourse2 = new Course(\"Atari 2600 - Game Development\"); // add student to courses tempCourse1.addStudent(tempStudent); tempCourse2.addStudent(tempStudent); // save the courses session.save(tempCourse1); session.save(tempCourse2); // commit transaction session.getTransaction().commit(); } finally { session.close(); factory.close(); } } } ","one-to-many-relationship#One To Many Relationship":"Unidirectional Here we demonstrate how to implement a unidirectional one to many relationship between two entities:\nWell, first of all you have to define the two database tables corresponding to these two entities.\nEntities We now code the two entities:\npackage com.hibernate.demo.entity; // annotate the class as an entity and map to db table @Entity @Table(name=\"course\") public class Course { // define the fields // annotate the fields with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"title\") private String title; // Set up one to many relationship @ManyToOne(cascade= // On delete course, do not delete instructor {CascadeType.PERSIST, CascadeType.MERGE, CascadeType.DETACH, CascadeType.REFRESH}) @JoinColumn(name=\"instructor_id\") private Instructor instructor; // Set up unidirectional one to many relationship @OneToMany(fetch=FetchType.LAZY, cascade=CascadeType.ALL) @JoinColumn(name=\"course_id\") private List\u003cReview\u003e reviews; public Course() { } ... // Setters and getters } And now the Review:\npackage com.hibernate.demo.entity; @Entity @Table(name=\"review\") public class Review { @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"comment\") private String comment; public Review() { } Note that there is no reference in the Review to the Course.\nMain App To test our code, we are going to get a Course and the list of Review objects associated. The test main app is the following:\npackage com.hibernate.demo; public class CreateDemo { public static void main(String[] args) { // create session factory // ... // create session Session session = factory.getCurrentSession(); try { // start a transaction session.beginTransaction(); // get the course int theId = 10; Course tempCourse = session.get(Course.class, theId); // Get reviews tempCourse.getReviews(); // commit transaction session.getTransaction().commit(); } finally { session.close(); factory.close(); } } } Bidirectional Now we will define the following relationship:\nLet’s now see how to code a bidirectional relationship:\nEntities package com.hibernate.demo.entity; /** annotate the class as an entity and map to db table **/ @Entity @Table(name=\"instructor\") public class Instructor { // define the fields and annotate the fields // with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"first_name\") private String firstName; @Column(name=\"last_name\") private String lastName; @Column(name=\"email\") private String email; // Set up mapping to InstructorDetail entity // Note the cascade type @OneToOne(cascade=CascadeType.ALL) // Define the foreign key @JoinColumn(name=\"instructor_detail_id\") private InstructorDetail instructorDetail; // Bidirectional relationship with courses // the mapping information is in the instructor // property in the Course class @OneToMany(mappedBy=\"instructor\", // On delete instructor, do not delete courses cascade= {CascadeType.PERSIST, CascadeType.MERGE, CascadeType.DETACH, CascadeType.REFRESH}) private List\u003cCourse\u003e courses; public Instructor() { } ... // Setters and getters } And now the Course class:\npackage com.hibernate.demo.entity; // annotate the class as an entity and map to db table @Entity @Table(name=\"course\") public class Course { // define the fields // annotate the fields with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"title\") private String title; // Set up one to many relationship @ManyToOne(cascade= // On delete course, do not delete instructor {CascadeType.PERSIST, CascadeType.MERGE, CascadeType.DETACH, CascadeType.REFRESH}) @JoinColumn(name=\"instructor_id\") private Instructor instructor; public Course() { } ... // Setters and getters } Main App In our test main app we are going to search for an InstructorDetail object, and we are going to retrieve the related Instructor object:\npackage com.hibernate.demo; public class GetInstructorDetailDemo { public static void main(String[] args) { session = factory.getCurrentSession(); try { // start a transaction session.beginTransaction(); // get the instructor from db int theId = 1; Instructor tempInstructor = session.get(Instructor.class, theId); // create some courses Course tempCourse1 = new Course(\"Air Guitar - The Ultimate Guide\"); Course tempCourse2 = new Course(\"The Pinball Masterclass\"); // add courses to instructor tempInstructor.add(tempCourse1); tempInstructor.add(tempCourse2); // save the courses session.save(tempCourse1); session.save(tempCourse2); // commit transaction session.getTransaction().commit(); } catch(Exception exc){ exc.printStackTrace(); } finally { // Finish session session.close(); // Remove factory factory.close(); } } } ","one-to-one-relationship#One To One Relationship":"Unidirectional Here we demonstrate how to implement a unidirectional one to one relationship between two entities:\nWell, first of all you have to define the two database tables corresponding to these two entities.\nEntities We now code the two entities:\npackage com.hibernate.demo.entity; /** annotate the class as an entity and map to db table **/ @Entity @Table(name=\"instructor\") public class Instructor { // define the fields and annotate the fields // with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"first_name\") private String firstName; @Column(name=\"last_name\") private String lastName; @Column(name=\"email\") private String email; // Set up mapping to InstructorDetail entity // Note the cascade type @OneToOne(cascade=CascadeType.ALL) // Define the foreign key @JoinColumn(name=\"instructor_detail_id\") private InstructorDetail instructorDetail; public Instructor() { } ... // Setters and getters } Note the specification of the Cascade Type. And now the InstructorDetail:\npackage com.hibernate.demo.entity; // annotate the class as an entity and map to db table @Entity @Table(name=\"instructor_detail\") public class InstructorDetail { // define the fields // annotate the fields with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"youtube_channel\") private String youtubeChannel; @Column(name=\"hobby\") private String hobby; public InstructorDetail() { } ... // Setters and getters } Main App To test our code, we are going to create an Instructor object and an InstructorDetail object and save them. The test main app is the following:\npackage com.hibernate.demo; public class CreateDemo { public static void main(String[] args) { // create session factory // ... // create session Session session = factory.getCurrentSession(); try { // create the objects Instructor tempInstructor = new Instructor(\"Madhu\", \"Patel\", \"madhu@mail.com\"); InstructorDetail tempInstructorDetail = new InstructorDetail( \"http://www.youtube.com\", \"Guitar\"); // associate the objects tempInstructor.setInstructorDetail(tempInstructorDetail); // start a transaction session.beginTransaction(); // save the instructor // // Note: this will ALSO save the details object // because of CascadeType.ALL // session.save(tempInstructor); // commit transaction session.getTransaction().commit(); } finally { factory.close(); } } } Bidirectional Now we will define the following Bidirectional One To One relationship:\nLet’s now see how to code a bidirectional relationship:\nEntities package com.hibernate.demo.entity; /** annotate the class as an entity and map to db table **/ @Entity @Table(name=\"instructor\") public class Instructor { // define the fields and annotate the fields // with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"first_name\") private String firstName; @Column(name=\"last_name\") private String lastName; @Column(name=\"email\") private String email; // Set up mapping to InstructorDetail entity // Note the cascade type @OneToOne(cascade=CascadeType.ALL) // Define the foreign key @JoinColumn(name=\"instructor_detail_id\") private InstructorDetail instructorDetail; public Instructor() { } ... // Setters and getters And now the InstructorDetail:\npackage com.hibernate.demo.entity; // annotate the class as an entity and map to db table @Entity @Table(name=\"instructor_detail\") public class InstructorDetail { // define the fields // annotate the fields with db column names @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=\"id\") private int id; @Column(name=\"youtube_channel\") private String youtubeChannel; @Column(name=\"hobby\") private String hobby; // add @OneToOne annotation // mappedBy refers to the instructorDetail property // in the Instructor class // This uses the information from the Instructor class in @JoinColumn // to define the mapping @OneToOne(mappedBy=\"instructorDetail\", // Different cascade types cascade={ CascadeType.DETACH, CascadeType.MERGE, CascadeType.PERSIST, CascadeType.REFRESH}) private Instructor instructor; public InstructorDetail() { } ... // Setters and getters } Main App In our test main app we are going to search for an InstructorDetail object, and we are going to retrieve the related Instructor object:\npackage com.hibernate.demo; public class GetInstructorDetailDemo { public static void main(String[] args) { session = factory.getCurrentSession(); try { // start a transaction session.beginTransaction(); // get the instructor detail object int theId = 2999; InstructorDetail tempInstructorDetail = session.get(InstructorDetail.class, theId); // print the associated instructor System.out.println(\"the associated instructor: \" + tempInstructorDetail.getInstructor()); // commit transaction session.getTransaction().commit(); } catch(Exception exc){ exc.printStackTrace(); } finally { // Finish session session.close(); // Remove factory factory.close(); } } } ","sessions#Sessions":"There are two key components when it comes to session handling:\nSessionFactory: reads the hibernate configuration file, creates sessions objects, and is created only once in the application and reused over and over again Session: is a wrapper around a JDBC connection, which is the main object used to save/retrieve objects. This object is created multiple times. So to create a SessionFactory and then create Session from it:\npublic class Demo { public static void main(String[] args) { // create session factory SessionFactory factory = new Configuration() // configuration file in src/ (if it is not specified, hibernate will look for a file named hibernate.cfg.xml) .configure(\"hibernate.cfg.xml\") // Class that was annotated to be mapped .addAnnotatedClass(Student.class) // You can add multiple classes .addAnnotatedClass(...) // Create the factory .buildSessionFactory(); // create session Session session = factory.getCurrentSession(); try { // Use session object to perform CRUD operations } finally { // Delete session factory factory.close(); } } } "},"title":"Spring Hibernate"},"/notes/webdev/back/spring/04_spring_rest/":{"data":{"":"","exception-handling#Exception Handling":"Create Error Response Class package com.springdemo.rest; public class StudentErrorResponse { private int status; private String message; private long timeStamp; public StudentErrorResponse() { } public StudentErrorResponse(int status, String message, long timeStamp) { this.status = status; this.message = message; this.timeStamp = timeStamp; } public int getStatus() { return status; } public void setStatus(int status) { this.status = status; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } public long getTimeStamp() { return timeStamp; } public void setTimeStamp(long timeStamp) { this.timeStamp = timeStamp; } } Create Exception Class package com.springdemo.rest; public class StudentNotFoundException extends RuntimeException { public StudentNotFoundException(String message, Throwable cause) { super(message, cause); } public StudentNotFoundException(String message) { super(message); } public StudentNotFoundException(Throwable cause) { super(cause); } } Rest Service with Exception What we need to know is:\nDefine an exception handler method with @ExceptionHandler annotation The exception handler will return a Response Entity Response Entity is a wrapper for the HTTP response object ResposneEntity provides a fine-grained control to specify: HTTP status code HTTP headers Response body package com.springdemo.rest; import java.util.ArrayList; import java.util.List; import javax.annotation.PostConstruct; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import com.springdemo.entity.Student; @RestController @RequestMapping(\"/api\") public class StudentRestController { private List\u003cStudent\u003e theStudents; // define @PostConstruct to load the student data ... only once! @PostConstruct public void loadData() { theStudents = new ArrayList\u003c\u003e(); theStudents.add(new Student(\"Poornima\", \"Patel\")); theStudents.add(new Student(\"Mario\", \"Rossi\")); theStudents.add(new Student(\"Mary\", \"Smith\")); } // define endpoint for \"/students\" - return list of students @GetMapping(\"/students\") public List\u003cStudent\u003e getStudents() { return theStudents; } // define endpoint for \"/students/{studentId}\" - return student at index @GetMapping(\"/students/{studentId}\") public Student getStudent(@PathVariable int studentId) { // just index into the list ... keep it simple for now // check the studentId against list size if ( (studentId \u003e= theStudents.size()) || (studentId \u003c 0) ) { throw new StudentNotFoundException(\"Student id not found - \" + studentId); } return theStudents.get(studentId); } // Tag it as an exception handling method @ExceptionHandler // Type of response body Exception type to handle public ResponseEntity\u003cStudentErrorResponse\u003e handleException(StudentNotFoundException exc) { StudentErrorResponse error = new StudentErrorResponse(); // json error object error.setStatus(HttpStatus.NOT_FOUND.value()); error.setMessage(exc.getMessage()); error.setTimeStamp(System.currentTimeMillis()); // return response with the error object and the status code return new ResponseEntity\u003c\u003e(error, HttpStatus.NOT_FOUND); } // Another exception handler @ExceptionHandler // Catch any exception thrown public ResponseEntity\u003cStudentErrorResponse\u003e handleException(Exception exc) { StudentErrorResponse error = new StudentErrorResponse(); error.setStatus(HttpStatus.BAD_REQUEST.value()); error.setMessage(exc.getMessage()); error.setTimeStamp(System.currentTimeMillis()); return new ResponseEntity\u003c\u003e(error, HttpStatus.BAD_REQUEST); } } Global Exception Handler Instead of having the exception handling methods in every controller, we defined them globally. For that we use ControllerAdvice that acts as a filter between the requests and the controller. It:\nPre-processes requests to controllers Post-processes responses to handle exceptions So, we create a class with the @ControllerAdvice annotation:\npackage com.springdemo.rest; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.ControllerAdvice; import org.springframework.web.bind.annotation.ExceptionHandler; @ControllerAdvice public class StudentRestExceptionHandler { // add exception handling code here // Add an exception handler using @ExceptionHandler @ExceptionHandler public ResponseEntity\u003cStudentErrorResponse\u003e handleException(StudentNotFoundException exc) { // create a StudentErrorResponse StudentErrorResponse error = new StudentErrorResponse(); error.setStatus(HttpStatus.NOT_FOUND.value()); error.setMessage(exc.getMessage()); error.setTimeStamp(System.currentTimeMillis()); // return ResponseEntity return new ResponseEntity\u003c\u003e(error, HttpStatus.NOT_FOUND); } // add another exception handler ... to catch any exception (catch all) @ExceptionHandler public ResponseEntity\u003cStudentErrorResponse\u003e handleException(Exception exc) { // create a StudentErrorResponse StudentErrorResponse error = new StudentErrorResponse(); error.setStatus(HttpStatus.BAD_REQUEST.value()); error.setMessage(exc.getMessage()); error.setTimeStamp(System.currentTimeMillis()); // return ResponseEntity return new ResponseEntity\u003c\u003e(error, HttpStatus.BAD_REQUEST); } } And now we modify the controller to make use of this paradigm:\npackage com.springdemo.rest; import java.util.ArrayList; import java.util.List; import javax.annotation.PostConstruct; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import com.springdemo.entity.Student; @RestController @RequestMapping(\"/api\") public class StudentRestController { private List\u003cStudent\u003e theStudents; // define @PostConstruct to load the student data ... only once! @PostConstruct public void loadData() { theStudents = new ArrayList\u003c\u003e(); theStudents.add(new Student(\"Poornima\", \"Patel\")); theStudents.add(new Student(\"Mario\", \"Rossi\")); theStudents.add(new Student(\"Mary\", \"Smith\")); } // define endpoint for \"/students\" - return list of students @GetMapping(\"/students\") public List\u003cStudent\u003e getStudents() { return theStudents; } // define endpoint for \"/students/{studentId}\" - return student at index @GetMapping(\"/students/{studentId}\") public Student getStudent(@PathVariable int studentId) { // just index into the list ... keep it simple for now // check the studentId against list size if ( (studentId \u003e= theStudents.size()) || (studentId \u003c 0) ) { throw new StudentNotFoundException(\"Student id not found - \" + studentId); } return theStudents.get(studentId); } } ","java-json-data-binding#Java JSON Data Binding":"Set Up Add Jackson Project as a dependency in the maven file:\n\u003cdependencies\u003e \u003c!-- TODO: Add your dependency here --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.fasterxml.jackson.core\u003c/groupId\u003e \u003cartifactId\u003ejackson-databind\u003c/artifactId\u003e \u003cversion\u003e2.10.0.pr1\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e Create POJO Class We now create the class we are going to convert to JSON (Serialize):\npackage com.jackson.json.demo; public class Student { private int id; private String firstName; private String lastName; private boolean active; public Student() { } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public boolean isActive() { return active; } public void setActive(boolean active) { this.active = active; } } Main App Now, to test it we are going to create a Student object by reading from a JSON object:\npackage com.jackson.json.demo; import java.io.File; import com.fasterxml.jackson.databind.ObjectMapper; public class Driver { public static void main(String[] args) { try { // create object mapper ObjectMapper mapper = new ObjectMapper(); // read JSON file and map/convert to Java POJO: // data/sample-lite.json Student theStudent = mapper.readValue( new File(\"data/sample-lite.json\"), Student.class); } catch (Exception exc) { exc.printStackTrace(); } } } Nested Objects But, how can we read nested properties inside a json file, like the following:\n{ \"id\": 14, \"firstName\": \"Mario\", \"lastName\": \"Rossi\", \"active\": true, \"address\": { \"street\": \"100 Main St\", \"city\": \"Philadelphia\", \"state\": \"Pennsylvania\", \"zip\": \"19103\", \"country\": \"USA\" }, \"languages\": [\"Java\", \"C#\", \"Python\", \"Javascript\"] } As you can see the address property has properties inside it. What we are going to do is create a new attribute address inside the Student object, which will be a POJO object in itself.\npackage com.jackson.json.demo; public class Student { private int id; private String firstName; private String lastName; private boolean active; private Address address; private String[] languages; public Student() { } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public boolean isActive() { return active; } public void setActive(boolean active) { this.active = active; } public Address getAddress() { return address; } public void setAddress(Address address) { this.address = address; } public String[] getLanguages() { return languages; } public void setLanguages(String[] languages) { this.languages = languages; } } We also need to create the Address class:\npackage com.jackson.json.demo; public class Address { private String street; private String city; private String state; private String zip; private String country; public Address() { } public String getStreet() { return street; } public void setStreet(String street) { this.street = street; } public String getCity() { return city; } public void setCity(String city) { this.city = city; } public String getState() { return state; } public void setState(String state) { this.state = state; } public String getZip() { return zip; } public void setZip(String zip) { this.zip = zip; } public String getCountry() { return country; } public void setCountry(String country) { this.country = country; } } Ignore Unknwon Properties To ignore properties from the JSON file that cannot be mapped to an attribute in the POJO we use the annotation:\npackage com.jackson.json.demo; @JsonIgnoreProperties(ignoreUnkown=true) public class Student { private int id; private String firstName; ","pojos-as-json#POJOs as JSON":"Create POJO We are going to create the Student entity:\npackage com.springdemo.entity; public class Student { private String firstName; private String lastName; public Student() { } public Student(String firstName, String lastName) { this.firstName = firstName; this.lastName = lastName; } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } } Create Service We now code the logic that handles the controller.\npackage com.springdemo.rest; import java.util.ArrayList; import java.util.List; import javax.annotation.PostConstruct; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import com.luv2code.springdemo.entity.Student; @RestController @RequestMapping(\"/api\") public class StudentRestController { private List\u003cStudent\u003e theStudents; // define @PostConstruct to load the student data ... only once! @PostConstruct public void loadData() { theStudents = new ArrayList\u003c\u003e(); theStudents.add(new Student(\"Poornima\", \"Patel\")); theStudents.add(new Student(\"Mario\", \"Rossi\")); theStudents.add(new Student(\"Mary\", \"Smith\")); } // define endpoint for \"/students\" - return list of students @GetMapping(\"/students\") public List\u003cStudent\u003e getStudents() { return theStudents; } // define endpoint for \"/students/{studentId}\" - return student at index @GetMapping(\"/students/{studentId}\") public Student getStudent(@PathVariable int studentId) { // just index into the list ... keep it simple for now return theStudents.get(studentId); } } Note that the endpoint \"/students/{studentId}\" has a path variable studentId","spring-rest-controller#Spring Rest Controller":"Hello World To exemplify how to set up a REST Controller in Spring we will create an application that upong request sends back a Hello World! message:\nConfiguration First of all, make sure you have the Jackson project, MVC and REST and also Servlet libraries as a maven dependency or as a library in your classpath.\n\u003cdependencies\u003e \u003c!-- Add Spring MVC and REST support --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-webmvc\u003c/artifactId\u003e \u003cversion\u003e5.0.5.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c!-- Add Jackson for JSON converters --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.fasterxml.jackson.core\u003c/groupId\u003e \u003cartifactId\u003ejackson-databind\u003c/artifactId\u003e \u003cversion\u003e2.9.9.2\u003c/version\u003e \u003c/dependency\u003e \u003c!-- Add Servlet support for Spring's AbstractAnnotationConfigDispatcherServletInitializer --\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e \u003cversion\u003e3.1.0\u003c/version\u003e \u003c/dependency\u003e \u003c!-- Add support for JSP ... get rid of Eclipse error --\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet.jsp\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet.jsp-api\u003c/artifactId\u003e \u003cversion\u003e2.3.1\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e General We create a configuration class as follows:\npackage com.springdemo.config; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.EnableWebMvc; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; // Mark it as a configuration class @Configuration @EnableWebMvc // Enable component scanning in our source code @ComponentScan(\"com.springdemo\") public class DemoAppConfig implements WebMvcConfigurer { } Servlet Initializer We have to specify the configuration of our servlet, for this we extend AbstractAnnotationConfigDispatcherServletInitializer:\npackage com.springdemo.config; import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer; public class MySpringMvcDispatcherServletInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class\u003c?\u003e[] getRootConfigClasses() { // TODO Auto-generated method stub return null; } @Override protected Class\u003c?\u003e[] getServletConfigClasses() { // Specify our config class return new Class[] { DemoAppConfig.class }; } @Override protected String[] getServletMappings() { return new String[] { \"/\" }; } } Controller For this we need to create our server with the controller that handles this request:\npackage com.springdemo.rest; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/test\") public class DemoRestController { // add code for the \"/hello\" endpoint @GetMapping(\"/hello\") public String sayHello() { return \"Hello World!\"; } } "},"title":"Spring REST"},"/notes/webdev/back/spring/05_spring_boot/":{"data":{"":"Spring Boot is a framework that:\nMake it easier to get started with Spring development Minimize the amount of manual configuration Perform auto-configuration based on props files and JAR classpath Help to resolve dependency conflicts (Maven or Gradle) Provide an embedded HTTP server so you can get started quickly To create a new project you just have to go to Spring Initiliazr, where you simply select your dependencies and lets you create a maven/gradle project and import it into an IDE.\nSo now our app is a jar file, and it includes the source code and also the embedded http server, so can be ran from the command line, from your IDE, etc. However if you want to export your code as a war file, you can also do that by exporting only your source code, without the embedded server.\nWith the jar file you can run your application by executing:\n$ java -jar app.jar ","application-properties-1#Application Properties":"Configuring the Spring Boot Server Some properties offered by Spring are:\nCore ## Log levels severity mapping logging.level.org.springframework=DEBUG logging.level.org.hibernate=TRACE logging.level.org.luv2code=INFO ## Log file name logging.file=date.log Web ## HTTP Server port server.port=7070 ## Context path of the application server.servlet.context-path=/my-app ## Default HTTP Session timeout server.servlet.session.timeout=15m Actuator Properties ## Endpoints to include by name or wildcard management.endpoints.web.exposure.include=* ## Endpoints to exclude by name or wildcard management.endpoints.web.exposure.exclude=beans,mapping Security ## Default username spring.security.user.name=admin ## Password for default user spring.security.user.password=mypass Data Properties ## JDBC URL of the database spring.datasource.url=jdbc:mysql://localhost:3306/myapp ## Login username of the database spring.datasource.username=alba ## Login password of the database spring.datasource.password=testpass ","jpa#JPA":"Until now, to manage data we have been using the EntityManager along with the Hibernate API. However now we are going to use the Standard JPA API.\nThe JPA API methods are similar to Native Hibernate API. It also supports a query language JPQL (JPA Query Language)\nComparing Hibernate to JPA:\nExample: for managing employees with JPA, we first create the Data Access Object:\npackage com.springboot.cruddemo.dao; import java.util.List; import javax.persistence.EntityManager; import javax.persistence.Query; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Repository; import com.luv2code.springboot.cruddemo.entity.Employee; @Repository public class EmployeeDAOJpaImpl implements EmployeeDAO { private EntityManager entityManager; @Autowired public EmployeeDAOJpaImpl(EntityManager theEntityManager) { entityManager = theEntityManager; } @Override public List\u003cEmployee\u003e findAll() { // create a query Query theQuery = entityManager.createQuery(\"from Employee\"); // execute query and get result list List\u003cEmployee\u003e employees = theQuery.getResultList(); // return the results return employees; } @Override public Employee findById(int theId) { // get employee Employee theEmployee = entityManager.find(Employee.class, theId); // return employee return theEmployee; } @Override public void save(Employee theEmployee) { // save or update the employee Employee dbEmployee = entityManager.merge(theEmployee); // update with id from db ... so we can get generated id for save/insert theEmployee.setId(dbEmployee.getId()); } @Override public void deleteById(int theId) { // delete object with primary key Query theQuery = entityManager.createQuery( \"delete from Employee where id=:employeeId\"); theQuery.setParameter(\"employeeId\", theId); theQuery.executeUpdate(); } } And then we call it from the Employee Service:\npackage com.springboot.cruddemo.service; import java.util.List; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import com.springboot.cruddemo.dao.EmployeeDAO; import com.springboot.cruddemo.entity.Employee; @Service public class EmployeeServiceImpl implements EmployeeService { private EmployeeDAO employeeDAO; @Autowired public EmployeeServiceImpl(@Qualifier(\"employeeDAOJpaImpl\") EmployeeDAO theEmployeeDAO) { employeeDAO = theEmployeeDAO; } @Override @Transactional public List\u003cEmployee\u003e findAll() { return employeeDAO.findAll(); } @Override @Transactional public Employee findById(int theId) { return employeeDAO.findById(theId); } @Override @Transactional public void save(Employee theEmployee) { employeeDAO.save(theEmployee); } @Override @Transactional public void deleteById(int theId) { employeeDAO.deleteById(theId); } } This class implements the following interface:\npackage com.springboot.cruddemo.service; import java.util.List; import com.springboot.cruddemo.entity.Employee; public interface EmployeeService { public List\u003cEmployee\u003e findAll(); public Employee findById(int theId); public void save(Employee theEmployee); public void deleteById(int theId); } ","rest-controller#Rest Controller":"Create Controller The controller is the same as in Spring REST:\npackage com.springboot.demo.mycoolapp.rest; import java.time.LocalDateTime; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class FunRestController { // expose \"/\" that return \"Hello World\" @GetMapping(\"/\") public String sayHello() { return \"Hello World! Time on server is \" + LocalDateTime.now(); } Main App The SpringBootApplication is made up of three annotations:\nAuto configuration (@EnableAutoConfiguration) Component scanning (@ComponentScan) Additional configuration (@Configuration) package com.springboot.demo.mycoolapp; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; // Annotation to tell Spring this is an spring application @SpringBootApplication public class MycoolappApplication { public static void main(String[] args) { // Boostrap spring boot application SpringApplication.run(MycoolappApplication.class, args); } } ","spring-boot-actuator#Spring Boot Actuator":"Add security First you need to add Spring Security as a dependency in your pom.xml:\n... \u003cdependencies\u003e ... \u003c!-- SECURITY --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e ... \u003c/dependencies\u003e ... Now, when we access some endpoints like /actuator/beans Spring will prompt a login to grant access to the endpoint.\nThe default user name is “user” The password will be printed on the console where you start the application To override these defaults edit the application.properties file as follows:\nspring.security.user.name=alba spring.security.user.password=mypassword We can also exclude endpoints by adding the following declarations to the application.properties file:\nmanagement.endpoints.web.exposure.exclude=health,info ","spring-boot-devtools#Spring Boot DevTools":"Spring Boot Dev Tools automatically restart your application when code is updated. The only thing you need to do is add the module to the dependencies:\n... \u003cdependencies\u003e \u003c!-- ADD SUPPORT FOR AUTOMATIC RELOADING --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-devtools\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e ... ","spring-boot-project-structure#Spring Boot Project Structure":"Application Properties By default, Spring Boot will load properties from: application.properties in the src project directory. We inject it in our code the same way we did it with Spring\nStatic Content By default, Spring Boot wil load static resources from \"/static\" directory\nTesting Unit tests are stored on the src directory under the /test folder","spring-boot-starters#Spring Boot Starters":"Spring Boot Starter Parent This is a special starter that provides defaults:\nDefault compiler level UTF-8 source encoding You include it in your pom.xml file as follows:\n... \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.1.2.RELEASE\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cdependencies\u003e ... \u003c/dependencies\u003e ... If you want to override a default, you use properties:\n... \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.1.2.RELEASE\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003c!-- Override default java version --\u003e \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003c/properties\u003e \u003cdependencies\u003e ... \u003c/dependencies\u003e ... ","spring-data-jpa#Spring Data JPA":"Create Repository So now the Employee DAO is as follows:\npackage com.springboot.cruddemo.dao; import org.springframework.data.jpa.repository.JpaRepository; import com.springboot.cruddemo.entity.Employee; public interface EmployeeRepository extends JpaRepository\u003cEmployee, Integer\u003e { } Use Repository And the Employee Service is:\npackage com.springboot.cruddemo.service; import java.util.List; import java.util.Optional; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import com.springboot.cruddemo.dao.EmployeeRepository; import com.springboot.cruddemo.entity.Employee; @Service public class EmployeeServiceImpl implements EmployeeService { // Here we make use of the above implemented repository private EmployeeRepository employeeRepository; @Autowired public EmployeeServiceImpl(EmployeeRepository theEmployeeRepository) { employeeRepository = theEmployeeRepository; } @Override public List\u003cEmployee\u003e findAll() { return employeeRepository.findAll(); } @Override public Employee findById(int theId) { Optional\u003cEmployee\u003e result = employeeRepository.findById(theId); Employee theEmployee = null; if (result.isPresent()) { theEmployee = result.get(); } else { // we didn't find the employee throw new RuntimeException(\"Did not find employee id - \" + theId); } return theEmployee; } @Override public void save(Employee theEmployee) { employeeRepository.save(theEmployee); } @Override public void deleteById(int theId) { employeeRepository.deleteById(theId); } } This EmployeeService implements the interface:\npackage com.springboot.cruddemo.service; import java.util.List; import com.springboot.cruddemo.entity.Employee; public interface EmployeeService { public List\u003cEmployee\u003e findAll(); public Employee findById(int theId); public void save(Employee theEmployee); public void deleteById(int theId); } ","spring-data-rest#Spring Data Rest":"Configuration You can specify the name of the endpoint that is exposed (by the default is the plural of the entity) with: @RepositoryRestResource(path=\"members\") public interface EmployeeRepository extends JpaRepository\u003cEmployee, Integer\u003e { } The default number of elements returned are 20, then we can use pagination to retrieve the next ones with query parameters (?page=0). Some properties available to tweak in application.properties are: spring.data.rest.base-path: Base path used to expose repository resources spring.data.rest.default-page-size: Default size pages spring.data.rest.max-page-size: Maximum size of pages Sorting You can sort by the property names of your entity. On the Employee example we have firstName, lastName and email, therefore we can do:\nhttp://localhost:8080/employees?sort=firstName\nor\nhttp://localhost:8080/employees?sort=firstName,desc"},"title":"Spring Boot"},"/notes/webdev/back/spring/06_thymeleaf/":{"data":{"":"","overview#Overview":"Placement In Spring Boot, your Thymeleaf template files go in src/main/resources/templates. And for web apps, Thymeleaf templates have an .html extension.\nExample Given the following controller:\n@Controller public class DemoController { // create a mapping for \"/hello\" @GetMapping(\"/hello\") public String sayHello(Model theModel) { theModel.addAttribute(\"theDate\", new java.util.Date()); return \"helloworld\"; } } We create the corresponding template helloworld.html:\n\u003c!DOCTYPE html\u003e \u003chtml xmlns:th=\"http://www.thymeleaf.org\"\u003e \u003chead\u003e \u003ctitle\u003eThymeleaf Demo\u003c/title\u003e \u003c/head\u003e \u003c!-- We obtain the date from the model --\u003e \u003cbody\u003e \u003cp th:text=\"'Time on the server is ' + ${theDate}\" /\u003e \u003c/body\u003e \u003c/html\u003e To add styles, we create a css files in src/main/resources/static/css, and then we reference the styles:\n\u003c!DOCTYPE html\u003e \u003chtml xmlns:th=\"http://www.thymeleaf.org\"\u003e \u003chead\u003e \u003ctitle\u003eThymeleaf Demo\u003c/title\u003e \u003c!-- reference CSS file --\u003e \u003clink rel=\"stylesheet\" th:href=\"@{/css/demo.css}\" /\u003e \u003c/head\u003e \u003cbody\u003e \u003cp th:text=\"'Time on the server is ' + ${theDate}\" class=\"funny\" /\u003e \u003c/body\u003e \u003c/html\u003e ","tables-in-thymeleaf#Tables in Thymeleaf":"Controller We create a controller for Employee, to list and add employees.\npackage com.springboot.thymeleafdemo.controller; import java.util.ArrayList; import java.util.List; import javax.annotation.PostConstruct; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import com.springboot.thymeleafdemo.model.Employee; @Controller @RequestMapping(\"/employees\") public class EmployeeController { // load employee data private List\u003cEmployee\u003e theEmployees; @PostConstruct private void loadData() { // create employees Employee emp1 = new Employee(1, \"Leslie\", \"Andrews\", \"leslie@luv2code.com\"); Employee emp2 = new Employee(2, \"Emma\", \"Baumgarten\", \"emma@luv2code.com\"); Employee emp3 = new Employee(3, \"Avani\", \"Gupta\", \"avani@luv2code.com\"); // create the list theEmployees = new ArrayList\u003c\u003e(); // add to the list theEmployees.add(emp1); theEmployees.add(emp2); theEmployees.add(emp3); } // add mapping for \"/list\" @GetMapping(\"/list\") public String listEmployees(Model theModel) { // add to the spring model theModel.addAttribute(\"employees\", theEmployees); return \"list-employees\"; } } Entity We create the entity Employee:\npackage com.springboot.thymeleafdemo.model; public class Employee { private int id; private String firstName; private String lastName; private String email; public Employee() { } public Employee(int id, String firstName, String lastName, String email) { this.id = id; this.firstName = firstName; this.lastName = lastName; this.email = email; } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } @Override public String toString() { return \"Employee [id=\" + id + \", firstName=\" + firstName + \", lastName=\" + lastName + \", email=\" + email + \"]\"; } } Template Finally we create the template for list-employees.html:\n\u003c!DOCTYPE html\u003e \u003chtml lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"\u003e \u003chead\u003e \u003c!-- Required meta tags --\u003e \u003cmeta charset=\"utf-8\" /\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" /\u003e \u003c!-- Bootstrap CSS --\u003e \u003clink rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css\" integrity=\"sha384-GJzZqFGwb1QTTN6wy59ffF1BuGJpLSa9DkKMp0DgiMDm4iYMj70gZWKYbI706tWS\" crossorigin=\"anonymous\" /\u003e \u003ctitle\u003eEmployee Directory\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv class=\"container\"\u003e \u003ch3\u003eEmployee Directory\u003c/h3\u003e \u003chr /\u003e \u003ctable class=\"table table-bordered table-striped\"\u003e \u003cthead class=\"thead-dark\"\u003e \u003ctr\u003e \u003cth\u003eFirst Name\u003c/th\u003e \u003cth\u003eLast Name\u003c/th\u003e \u003cth\u003eEmail\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003c!-- for loop for all employees, stored in the model --\u003e \u003ctr th:each=\"tempEmployee : ${employees}\"\u003e \u003ctd th:text=\"${tempEmployee.firstName}\" /\u003e \u003ctd th:text=\"${tempEmployee.lastName}\" /\u003e \u003ctd th:text=\"${tempEmployee.email}\" /\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e "},"title":"Spring Thymeleaf"},"/notes/webdev/back/spring/07_spring_maven/":{"data":{"":"","#":"Standard Directory Structure ","additional-repositories#Additional Repositories":"If Maven does not find some dependency in your local repository it goes to the central repository to search for it. But what if the dependency is not in the central repository. Then we have to define the repository in our pom.xml:","maven-archetypes#Maven Archetypes":"Archetypes are used to create new Maven projects, you can think of them as starter projects. Some archetypes are:\nFor standalone projects: maven-archetype-quickstart For web projects: maven-archetype-webapp ","pom-file-structure#POM File Structure":"Project Coordinates Project coordinates uniquely identify a project:\nWhere:\nGroup ID: name of company, group or organization Artifact ID: name for the project Version: a specific release version Dependency Coordinates To add a given dependency project, we need:\nGroup ID Artifact ID Optional: version (best practice to include the version) Find Dependencies Search Maven Maven Repository","private-repositories#Private Repositories":"If you want to create repositories with restricted access you can:\nSet up your own private Maven Repository in your server, that is secure with credentials: id/password Some Maven repository manager products are:\nArchiva Artifactory Nexus If you do not want to create your own server, there are also cloud based solutions like:\nPackage Cloud My Maven Repo "},"title":"Spring Maven"},"/notes/webdev/back/spring/08_spring_security/":{"data":{"":"","authorization#Authorization":"Create Controllers We create a basic controller for every endpoint:\npackage com.springsecurity.demo.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; @Controller public class DemoController { // add request mapping for index page @GetMapping(\"/\") public String showHome() { return \"home\"; } // add request mapping for /leaders @GetMapping(\"/leaders\") public String showLeaders() { return \"leaders\"; } // add request mapping for /systems @GetMapping(\"/systems\") public String showSystems() { return \"systems\"; } } We also create a controller for the /acess-denied endpoint:\npackage com.springsecurity.demo.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; @Controller public class LoginController { @GetMapping(\"/showMyLoginPage\") public String showMyLoginPage() { // return \"plain-login\"; return \"fancy-login\"; } // add request mapping for /access-denied @GetMapping(\"/access-denied\") public String showAccessDenied() { return \"access-denied\"; } } Define User Roles and Restrict Accessand Restrict Access In our configuration file we had saved in-memory a list of users with some defined roles, we are going to update it to have more roles. We are also going to define the authorization scheme we showed earlier.\npackage com.springsecurity.demo.config; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.User.UserBuilder; @Configuration @EnableWebSecurity public class DemoSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // add our users for in memory authentication UserBuilder users = User.withDefaultPasswordEncoder(); // add more roles auth.inMemoryAuthentication() .withUser(users.username(\"john\").password(\"test123\").roles(\"EMPLOYEE\")) .withUser(users.username(\"mary\").password(\"test123\").roles(\"EMPLOYEE\", \"MANAGER\")) .withUser(users.username(\"susan\").password(\"test123\").roles(\"EMPLOYEE\", \"ADMIN\")); } @Override protected void configure(HttpSecurity http) throws Exception { // Handle requests http.authorizeRequests() // Set role for index page .antMatchers(\"/\").hasRole(\"EMPLOYEE\") // Set role for leaders page .antMatchers(\"/leaders/**\").hasRole(\"MANAGER\") // Set role for systems page .antMatchers(\"/systems/**\").hasRole(\"ADMIN\") .and() .formLogin() .loginPage(\"/showMyLoginPage\") .loginProcessingUrl(\"/authenticateTheUser\") .permitAll() .and() .logout().permitAll() // also define the page where the user is redirected if it does not have access to the resource it requests .and() .exceptionHandling().accessDeniedPage(\"/access-denied\"); } } Display Content based on Roles In our home page, we add two conditionals so only managers can see the link to the leaders page, and only admins can see the link to the systems page:\n\u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c%@ taglib prefix=\"security\" uri=\"http://www.springframework.org/security/tags\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eluv2code Company Home Page\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ch2\u003eluv2code Company Home Page\u003c/h2\u003e \u003chr\u003e \u003cp\u003e Welcome to the luv2code company home page! \u003c/p\u003e \u003chr\u003e \u003c!-- display user name and role --\u003e \u003cp\u003e User: \u003csecurity:authentication property=\"principal.username\" /\u003e \u003cbr\u003e\u003cbr\u003e Role(s): \u003csecurity:authentication property=\"principal.authorities\" /\u003e \u003c/p\u003e \u003c!-- Check if user has the manager role, if so show the link --\u003e \u003csecurity:authorize access=\"hasRole('MANAGER')\"\u003e \u003c!-- Add a link to point to /leaders ... this is for the managers --\u003e \u003cp\u003e \u003ca href=\"${pageContext.request.contextPath}/leaders\"\u003eLeadership Meeting\u003c/a\u003e (Only for Manager peeps) \u003c/p\u003e \u003c/security:authorize\u003e \u003c!-- Check if user has the admin role, if so show the link --\u003e \u003csecurity:authorize access=\"hasRole('ADMIN')\"\u003e \u003c!-- Add a link to point to /systems ... this is for the admins --\u003e \u003cp\u003e \u003ca href=\"${pageContext.request.contextPath}/systems\"\u003eIT Systems Meeting\u003c/a\u003e (Only for Admin peeps) \u003c/p\u003e \u003c/security:authorize\u003e \u003chr\u003e \u003c!-- Add a logout button --\u003e \u003cform:form action=\"${pageContext.request.contextPath}/logout\" method=\"POST\"\u003e \u003cinput type=\"submit\" value=\"Logout\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e ","basic-security#Basic Security":"Create Security Spring Initializer Spring security provides support for security initialization. Your security code is used to initialize the servlet container. There is a special class to register the Spring Security Filters.\nYou need this class for the Spring Security Filters to “activate”. Next we show an example:\npackage com.springsecurity.demo.config; import org.springframework.security.web.context.AbstractSecurityWebApplicationInitializer; public class SecurityWebApplicationInitializer extends AbstractSecurityWebApplicationInitializer { } Create Spring Security Configuration (@Configuration) Now we create our spring security configuration file:\npackage com.springsecurity.demo.config; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.User.UserBuilder; // Tell spring this is a configuration file @Configuration @EnableWebSecurity public class DemoSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // add our users for in memory authentication (this is for test purposes only, you would usually retrieve this information encrypted from the database) UserBuilder users = User.withDefaultPasswordEncoder(); // Use the AuthenticationManagerBuilder given by Spring to handle authentication auth .inMemoryAuthentication() .withUser(users.username(\"john\").password(\"test123\").roles(\"EMPLOYEE\")) .withUser(users.username(\"mary\").password(\"test123\").roles(\"MANAGER\")) .withUser(users.username(\"susan\").password(\"test123\").roles(\"ADMIN\")); } } ","cross-site-request-forgery#Cross Site Request Forgery":"How to see the CSRF token? When your jsp with the \u003cform:form\u003e tag is processed into an html page, you will be able to see the token inside the form tag:","custom-login-form#Custom Login Form":"Create the form We create the login page /showMyLoginPage as follows:\n\u003c!-- Reference the spring and jsp tags --\u003e \u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eCustom Login Page\u003c/title\u003e \u003cstyle\u003e .failed { color: red; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch3\u003eMy Custom Login Page\u003c/h3\u003e \u003c!-- The form points to the endpoint specified preivously: \"authenticateTheUser\" --\u003e \u003c!-- contextPath is the domain of our app, i.e. localhost:8080 --\u003e \u003cform:form action=\"${pageContext.request.contextPath}/authenticateTheUser\" method=\"POST\"\u003e \u003c!-- Check for login error --\u003e \u003cc:if test=\"${param.error != null}\"\u003e \u003ci class=\"failed\"\u003eSorry! You entered invalid username/password.\u003c/i\u003e \u003c/c:if\u003e \u003cp\u003e User name: \u003cinput type=\"text\" name=\"username\" /\u003e \u003c/p\u003e \u003cp\u003e Password: \u003cinput type=\"password\" name=\"password\" /\u003e \u003c/p\u003e \u003cinput type=\"submit\" value=\"Login\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e Note that Spring appends a parameter error when the user fails to login. That is what we use as a condition to show our error message, that is, we check if param.error exists.\nAlso, Spring security defines default names for login form fields:\nUser name field: username Password field: password Login Controller We also need a controller method for requests to /showMyLoginPage:\npackage com.springsecurity.demo.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; @Controller public class LoginController { @GetMapping(\"/showMyLoginPage\") public String showMyLoginPage() { // This is the custom-login.jsp we created in the previous section return \"custom-login\"; } } ","display-user-and-roles#Display User and Roles":"Add JSP Tag library as dependency First we add to our pom.xml file the JSP Tag Library:\n\u003c!-- Add Spring Security Taglibs support --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.security\u003c/groupId\u003e \u003cartifactId\u003espring-security-taglibs\u003c/artifactId\u003e \u003cversion\u003e${springsecurity.version}\u003c/version\u003e \u003c/dependency\u003e JSP page Then add the tag library to the jsp page, and we use its tags to access the user id and its role:\n\u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003c!-- Add tag library --\u003e \u003c%@ taglib prefix=\"security\" uri=\"http://www.springframework.org/security/tags\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eluv2code Company Home Page\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ch2\u003eluv2code Company Home Page\u003c/h2\u003e \u003chr\u003e \u003cp\u003e Welcome to the luv2code company home page! \u003c/p\u003e \u003chr\u003e \u003c!-- display user name and role --\u003e \u003cp\u003e User: \u003csecurity:authentication property=\"principal.username\" /\u003e \u003cbr\u003e\u003cbr\u003e Role(s): \u003csecurity:authentication property=\"principal.authorities\" /\u003e \u003c/p\u003e \u003chr\u003e \u003c!-- Add a logout button --\u003e \u003cform:form action=\"${pageContext.request.contextPath}/logout\" method=\"POST\"\u003e \u003cinput type=\"submit\" value=\"Logout\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e ","jdbc-database-authentication#JDBC Database Authentication":"Set Up Database The tables we have to create are the following:\nPassword Encryption In Spring Security 5, passwords are stored using a specific format:\n{id}encodedPassword The id references the operation used to encrypt the password:\nnoop: plain text. So the password is stored as follows in the database: {noop}test123 bcrypt: BCrypt password hashing. So the password is stored as follows in the database: {bcrypt}$2a$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW etc. Add Dependiencies We define the dependencies in our pom.xmlfile that are needed to add support to connect to databases:\n\u003c!-- Add MySQL and C3P0 support --\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e8.0.16\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.mchange\u003c/groupId\u003e \u003cartifactId\u003ec3p0\u003c/artifactId\u003e \u003cversion\u003e0.9.5.4\u003c/version\u003e \u003c/dependency\u003e JDBC Properties files Inside /src/main/resources we create the properties file persistence-mysql.properties for our database connections:\n# ## JDBC connection properties # jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/spring_security_demo_plaintext?useSSL=false jdbc.user=springstudent jdbc.password=springstudent # ## Connection pool properties # connection.pool.initialPoolSize=5 connection.pool.minPoolSize=5 connection.pool.maxPoolSize=20 connection.pool.maxIdleTime=3000 Spring Security Configuration We have to modify our main configuration class, to include our database properties file and create the datasource\npackage com.luv2code.springsecurity.demo.config; import java.beans.PropertyVetoException; import java.util.logging.Logger; import javax.sql.DataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.PropertySource; import org.springframework.core.env.Environment; import org.springframework.web.servlet.ViewResolver; import org.springframework.web.servlet.config.annotation.EnableWebMvc; import org.springframework.web.servlet.view.InternalResourceViewResolver; import com.mchange.v2.c3p0.ComboPooledDataSource; @Configuration @EnableWebMvc @ComponentScan(basePackages=\"com.luv2code.springsecurity.demo\") @PropertySource(\"classpath:persistence-mysql.properties\") public class DemoAppConfig { // set up variable to hold the properties @Autowired private Environment env; // set up a logger for diagnostics private Logger logger = Logger.getLogger(getClass().getName()); // define a bean for ViewResolver @Bean public ViewResolver viewResolver() { InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(\"/WEB-INF/view/\"); viewResolver.setSuffix(\".jsp\"); return viewResolver; } // define a bean for our security datasource @Bean public DataSource securityDataSource() { // create connection pool ComboPooledDataSource securityDataSource = new ComboPooledDataSource(); // set the jdbc driver class try { // Obtain driver from properties file securityDataSource.setDriverClass(env.getProperty(\"jdbc.driver\")); } catch (PropertyVetoException exc) { throw new RuntimeException(exc); } // Obtain database info from properties file logger.info(\"\u003e\u003e\u003e jdbc.url=\" + env.getProperty(\"jdbc.url\")); logger.info(\"\u003e\u003e\u003e jdbc.user=\" + env.getProperty(\"jdbc.user\")); // set database connection props securityDataSource.setJdbcUrl(env.getProperty(\"jdbc.url\")); securityDataSource.setUser(env.getProperty(\"jdbc.user\")); securityDataSource.setPassword(env.getProperty(\"jdbc.password\")); // set connection pool props securityDataSource.setInitialPoolSize( getIntProperty(\"connection.pool.initialPoolSize\")); securityDataSource.setMinPoolSize( getIntProperty(\"connection.pool.minPoolSize\")); securityDataSource.setMaxPoolSize( getIntProperty(\"connection.pool.maxPoolSize\")); securityDataSource.setMaxIdleTime( getIntProperty(\"connection.pool.maxIdleTime\")); return securityDataSource; } // need a helper method // read environment property and convert to int private int getIntProperty(String propName) { String propVal = env.getProperty(propName); // now convert to int int intPropVal = Integer.parseInt(propVal); return intPropVal; } } Now in our security configuration we do two things:\nInject the datasource we defined previouly that holds authentication information Tell Spring to use JDBC for authentication package com.springsecurity.demo.config; import javax.sql.DataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.User.UserBuilder; @Configuration @EnableWebSecurity public class DemoSecurityConfig extends WebSecurityConfigurerAdapter { // add a reference to our security data source @Autowired private DataSource securityDataSource; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // use jdbc authentication auth.jdbcAuthentication().dataSource(securityDataSource); } @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\"/\").hasRole(\"EMPLOYEE\") .antMatchers(\"/leaders/**\").hasRole(\"MANAGER\") .antMatchers(\"/systems/**\").hasRole(\"ADMIN\") .and() .formLogin() .loginPage(\"/showMyLoginPage\") .loginProcessingUrl(\"/authenticateTheUser\") .permitAll() .and() .logout().permitAll() .and() .exceptionHandling().accessDeniedPage(\"/access-denied\"); } } ","log-out#Log Out":"Configuration To our existing configuration we add:\npackage com.springsecurity.demo.config; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.User.UserBuilder; @Configuration @EnableWebSecurity public class DemoSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // add our users for in memory authentication UserBuilder users = User.withDefaultPasswordEncoder(); auth.inMemoryAuthentication() .withUser(users.username(\"john\").password(\"test123\").roles(\"EMPLOYEE\")) .withUser(users.username(\"mary\").password(\"test123\").roles(\"MANAGER\")) .withUser(users.username(\"susan\").password(\"test123\").roles(\"ADMIN\")); } @Override protected void configure(HttpSecurity http) throws Exception { // Here is the control of the access to web path http.authorizeRequests() // Require authentication for every request .anyRequest().authenticated() .and() .formLogin() .loginPage(\"/showMyLoginPage\") .loginProcessingUrl(\"/authenticateTheUser\") .permitAll(); // Add logout functionality .and() .logout().permitAll() } } The default url for logging out is /logout.\nLog Out Button Now we create the logout button in our home page:\n\u003c%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eluv2code Company Home Page\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ch2\u003eluv2code Company Home Page\u003c/h2\u003e \u003chr\u003e \u003cp\u003e Welcome to the luv2code company home page! \u003c/p\u003e \u003c!-- Add a logout button: it point to \"/logout\" endpoint --\u003e \u003cform:form action=\"${pageContext.request.contextPath}/logout\" method=\"POST\"\u003e \u003cinput type=\"submit\" value=\"Logout\" /\u003e \u003c/form:form\u003e \u003c/body\u003e \u003c/html\u003e Note that the logout logic is handled directly by spring, what it does is:\nInvalidate the user’s HTTP session and remove cookies, etc. Sends the user back to the login page Appends a logout parameter: ?logout ","overview#Overview":" Spring Security is implemented using Servlet filters in the background There are two methods of securing a Web App: Declarative Programmatic Servlet Filters Servlet filters are used to pre-process/post-process web requests.\nThey can route web requests based on security logic. Spring provides a bulk of security functionality with servlet filters. This is described in the following picture:\nWe can see Spring intercepts the request to /mytopsecretstuff and uses the app’s security configuration, alongside information about the user, passwords and roles to pre and post-process the request.\nSpring Security in Action Next we show a flowchart of the pre-processing made by Spring Security Filters:\nIf the resource is protected we go to step (2), else we go to step (4) If the user is authenticated we go to step (3), else we go to step (6) If the user is authorized to access the resource we go to step (4), else we go to step (5) The resource is shown to the user The access to the resource is denied We send the user to the login page, if the user logins correctly we go to step (3) Declarative Security You define your application’s security constraints in configuration. For that, you can either:\nUse all Java configuration (@Configuration) Use a Spring configuration file (XML) Programmatic Security You can also do it programmatically:\nSpring Security provides an API for custom application coding. It also provides greater customization for specific apps. Authentication/Authorization Information about users/passwords/roles, etc can be stored:\nIn-memory JDBC LDAP Custom etc Maven Dependencies To use this framework, you have to add the following dependency to your project:\n\u003cdependencies\u003e ... \u003c!-- Spring Security --\u003e \u003c!-- spring-security-web and spring-security-config --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.security\u003c/groupId\u003e \u003cartifactId\u003espring-security-web\u003c/artifactId\u003e \u003cversion\u003e${springsecurity.version}\u003c/version\u003e \u003c/dependency\u003e ... \u003cdependencies\u003e Java Configuration Web App Initializer Spring MVC provides support for web app initialization, and makes sure your code is automatically detected. Your code is used to initialize the servlet container.\nAs an example:\npackage com.springsecurity.demo.config; import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer; public class MySpringMvcDispatcherServletInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class\u003c?\u003e[] getRootConfigClasses() { // TODO Auto-generated method stub return null; } @Override // Tell spring where the configuration for the servlet is protected Class\u003c?\u003e[] getServletConfigClasses() { return new Class[] { DemoAppConfig.class }; } @Override // Map the servlet to the path \"/\" protected String[] getServletMappings() { return new String[] { \"/\" }; } } Here is the correspondence with the xml servlet configuration file:"},"title":"Spring Security"},"/notes/webdev/back/spring/09_spring_aop/":{"data":{"":"","after-advice#After Advice":"This advice runs always when the method is completed (like a finally clause inside a try catch).\nFor example if we want to always run the advice afterFinallyFindAccountsAdvice when the method findAccounts inside AccountDAO finishes:\npackage com.aopdemo.aspect; import java.util.List; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.After; import org.aspectj.lang.annotation.AfterReturning; import org.aspectj.lang.annotation.AfterThrowing; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import com.aopdemo.Account; @Aspect @Component @Order(2) public class MyDemoLoggingAspect { @After(\"execution(* com.aopdemo.dao.AccountDAO.findAccounts(..))\") public void afterFinallyFindAccountsAdvice(JoinPoint theJoinPoint) { // print out which method we are advising on String method = theJoinPoint.getSignature().toShortString(); System.out.println(\"\\n=====\u003e\u003e\u003e Executing @After (finally) on method: \" + method); } } ","afterreturning-advice#AfterReturning Advice":"This advice is run after the method is done executing, and it executed successfully.\nThe flow of this advice is the following:\nSo for example, if you want to have an advice run everytime we call the findAccounts method inside a concrete class, and we also want to print out the result we obtained we do the following:\npackage com.aopdemo.aspect; import java.util.List; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.AfterReturning; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import com.aopdemo.Account; @Aspect @Component @Order(2) public class MyDemoLoggingAspect { // add a new advice for @AfterReturning on the findAccounts method @AfterReturning( pointcut=\"execution(* com.aopdemo.dao.AccountDAO.findAccounts(..))\", // This is the parameter name of the list of accounts returned by findAccounts returning=\"result\") public void afterReturningFindAccountsAdvice( JoinPoint theJoinPoint, List\u003cAccount\u003e result) { // print out which method we are advising on String method = theJoinPoint.getSignature().toShortString(); System.out.println(\"\\n=====\u003e\u003e\u003e Executing @AfterReturning on method: \" + method); // print out the results of the method call System.out.println(\"\\n=====\u003e\u003e\u003e result is: \" + result); } } ","afterthrowing-advice#AfterThrowing Advice":"This advice is run whenever the target object throws and execption. For example:\npackage com.aopdemo.aspect; import java.util.List; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.AfterReturning; import org.aspectj.lang.annotation.AfterThrowing; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import com.luv2code.aopdemo.Account; @Aspect @Component @Order(2) public class MyDemoLoggingAspect { @AfterThrowing( pointcut=\"execution(* com.aopdemo.dao.AccountDAO.findAccounts(..))\", // Define the name of the parameter that holds the exception object throwing=\"theExc\") public void afterThrowingFindAccountsAdvice( JoinPoint theJoinPoint, Throwable theExc) { // print out which method we are advising on String method = theJoinPoint.getSignature().toShortString(); System.out.println(\"\\n=====\u003e\u003e\u003e Executing @AfterThrowing on method: \" + method); // log the exception System.out.println(\"\\n=====\u003e\u003e\u003e The exception is: \" + theExc); } } In this code sample we have the advice afterThrowingFindAccountsAdvice that is run whenever the method findAccounts inside AccountDAO throws an exception. We also make use of the throwing attribute that lets us map the exception object to a parameter inside our advice.","around-advice#Around Advice":"Exception Handling Inside an advice, to handle exceptions you can:\nHandle the exception inside the advice @Around(\"execution(** com.aopdemo.service.**.getFortune(..))\") public Object aroundGetFortune( ProceedingJoinPoint theProceedingJoinPoint) throws Throwable { // print out method we are advising on String method = theProceedingJoinPoint.getSignature().toShortString(); System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Around on method: \" + method); // get begin timestamp long begin = System.currentTimeMillis(); try { result = theProceedingJoinPoint.proceed(); } catch (Exception e) { // log the exception myLogger.warning(e.getMessage()); // give users a custom messagee result = \"Major accident! But no worries, \" + \"your private AOP helicopter is on the way!\"; } // get end timestamp long end = System.currentTimeMillis(); // compute duration and display it long duration = end - begin; System.out.println(\"\\n=====\u003e Duration: \" + duration / 1000.0 + \" seconds\"); return result; } Simply rethrow the exception @Around(\"execution(** com.aopdemo.service.**.getFortune(..))\") public Object aroundGetFortune( ProceedingJoinPoint theProceedingJoinPoint) throws Throwable { // print out method we are advising on String method = theProceedingJoinPoint.getSignature().toShortString(); System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Around on method: \" + method); // get begin timestamp long begin = System.currentTimeMillis(); try { result = theProceedingJoinPoint.proceed(); } catch (Exception e) { // log the exception myLogger.warning(e.getMessage()); // rethrow exception throw e; } // get end timestamp long end = System.currentTimeMillis(); // compute duration and display it long duration = end - begin; System.out.println(\"\\n=====\u003e Duration: \" + duration / 1000.0 + \" seconds\"); return result; } ","before-advice#Before Advice":"Add Dependencies We have to download the AspectJ jar file, because Spring AOP depends on some on their framework’s classes Create Target Object We create a DAO object:\npackage com.aopdemo.dao; import org.springframework.stereotype.Component; @Component public class AccountDAO { public void addAccount() { System.out.println( getClass() + \": DOING MY DB WORK: ADDING AN ACCOUNT\" ); } } Spring Configuration We now have to enable AOP proxying in our app configuration:\npackage com.aopdemo; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.EnableAspectJAutoProxy; @Configuration // Enable proxying to add before advice @EnableAspectJAutoProxy @ComponentScan(\"com.aopdemo\") public class DemoConfig { } Create Aspect with @Before Now it is time to create an aspect with @Before advice:\npackage com.aopdemo.aspect; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.springframework.stereotype.Component; @Aspect @Component public class MyDemoLoggingAspect { // this is where we add all of our related advices for logging // Here we specify we want to run this code before calling the // object method public void addAccount @Before(\"execution(public void addAccount())\") public void beforeAddAccountAdvice() { System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Before advice on addAccount()\"); } } Main App We now create a demo app:\npackage com.aopdemo; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import com.aopdemo.dao.AccountDAO; public class MainDemoApp { public static void main(String[] args) { // read spring config java class AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(DemoConfig.class); // get the bean from spring container AccountDAO theAccountDAO = context.getBean(\"accountDAO\", AccountDAO.class); // call the business method theAccountDAO.addAccount(); // do it again! System.out.println(\"\\nlet's call it again!\\n\"); // call the business method again theAccountDAO.addAccount(); // close the context context.close(); } } ","control-aspect-order#Control Aspect Order":"Refactor and Order We are going to create three aspects separate from each other as follows:\nSo with the ordering the aspect flow looks something like this:\nLog to Cloud Aspect package com.luv2code.aopdemo.aspect; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; @Aspect @Component // Set order @Order(1) public class MyCloudLogAsyncAspect { @Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\") public void logToCloudAsync() { System.out.println(\"\\n=====\u003e\u003e\u003e Logging to Cloud in async fashion\"); } } Logging Aspect package com.aopdemo.aspect; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; @Aspect @Component // Set the order @Order(2) public class MyDemoLoggingAspect { @Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\") public void beforeAddAccountAdvice() { System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Before advice on method\"); } } Analytics Aspect package com.aopdemo.aspect; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; @Aspect @Component // Set the order @Order(3) public class MyApiAnalyticsAspect { @Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\") public void performApiAnalytics() { System.out.println(\"\\n=====\u003e\u003e\u003e Performing API analytics\"); } } ","joinpoints#JoinPoints":"Display Method Signature To display the method signature we do the following:\npackage com.aopdemo.aspect; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import com.aopdemo.Account; @Aspect @Component @Order(2) public class MyDemoLoggingAspect { @Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\") public void beforeAddAccountAdvice(JoinPoint theJoinPoint) { System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Before advice on method\"); // display the method signature MethodSignature methodSig = (MethodSignature) theJoinPoint.getSignature(); System.out.println(\"Method: \" + methodSig); } } Display Method Arguments Also, to display the method arguments:\npackage com.aopdemo.aspect; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import com.aopdemo.Account; @Aspect @Component @Order(2) public class MyDemoLoggingAspect { @Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\") public void beforeAddAccountAdvice(JoinPoint theJoinPoint) { System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Before advice on method\"); // display method arguments // get args Object[] args = theJoinPoint.getArgs(); // loop through args for (Object tempArg : args) { System.out.println(tempArg); if (tempArg instanceof Account) { // downcast and print Account specific stuff Account theAccount = (Account) tempArg; System.out.println(\"account name: \" + theAccount.getName()); System.out.println(\"account level: \" + theAccount.getLevel()); } } } } ","overview#Overview":"Advantages Reusable modules Resolve code tangling Resolve code scatter Applied selectively based on configuration Disadvantages Too many aspects and app flow is hard to follow Minor performance cost for aspect execution Terminology Aspect: module of code for a cross-cutting concern (logging, security…) Advice: what action is takes and when it should be applied Joint Point: when to apply code during program execution Pointcut: a predicate expression for where advice should be applied Advice Types Before advice: run before the method After finally advice: run after the method (like finally clause in try catch) After returning advice: run after the method (success execution) After throwing advice: run after the method (if exception if thrown) Around advice: run before and after the method Weaving It refers to the connection being made between aspects and target objects to create an advised object. There are different types:\nCompile-time Load-time Run-time Note that the slowest is the run-time weaving\nBest Practices Keep the code inside the advices small Keep the code fast Do not perform any expensive/slow operations ","pointcut-declarations#Pointcut Declarations":"Create Pointcut Declaration We define the pointcut declaration with the Pointcut annotation and we bind it to an arbitrary method.\npackage com.aopdemo.aspect; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; @Aspect @Component public class MyDemoLoggingAspect { @Pointcut(\"execution(** com.aopdemo.dao.**.*(..))\") private void forDaoPackage() {} } Reuse Pointcut Declaration To reuse this declaration we simply call the method that is bound to the pointcut declaration:\npackage com.aopdemo.aspect; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; @Aspect @Component public class MyDemoLoggingAspect { @Pointcut(\"execution(** com.aopdemo.dao.**.*(..))\") private void forDaoPackage() {} // Reuse declaration @Before(\"forDaoPackage()\") public void beforeAddAccountAdvice() { System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Before advice on method\"); } // Reuse declaration @Before(\"forDaoPackage()\") public void performApiAnalytics() { System.out.println(\"\\n=====\u003e\u003e\u003e Performing API analytics\"); } } Combine Pointcut Declarations How can we apply multiple pointcut expressions to a single advice? Well we can combine pointcut expressions using logic operators:\nAND (\u0026\u0026) OR (||) NOT (!) For example:\n@Before(\"expressionOne() \u0026\u0026 expressionTwo()\") @Before(\"expressionOne() || expressionTwo()\") @Before(\"expressionOne() \u0026\u0026 !expressionTwo()\") Imagine we want to execute an advice for every method in the package except for getters and setters, then we do:\npackage com.aopdemo.aspect; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; @Aspect @Component public class MyDemoLoggingAspect { @Pointcut(\"execution(** com.aopdemo.dao.**.*(..))\") private void forDaoPackage() {} // create pointcut for getter methods @Pointcut(\"execution(** com.aopdemo.dao.**.get*(..))\") private void getter() {} // create pointcut for setter methods @Pointcut(\"execution(** com.aopdemo.dao.**.set*(..))\") private void setter() {} // create pointcut: include package ... exclude getter/setter @Pointcut(\"forDaoPackage() \u0026\u0026 !(getter() || setter())\") private void forDaoPackageNoGetterSetter() {} @Before(\"forDaoPackageNoGetterSetter()\") public void beforeAddAccountAdvice() { System.out.println(\"\\n=====\u003e\u003e\u003e Executing @Before advice on method\"); } @Before(\"forDaoPackageNoGetterSetter()\") public void performApiAnalytics() { System.out.println(\"\\n=====\u003e\u003e\u003e Performing API analytics\"); } } ","pointcut-expressions#Pointcut Expressions":"Execution Pointcut The expression pattern is the following:\nexecution(modifiers-pattern? return-type-pattern declaring-type-pattern? method-name-pattern(param-pattern) throws-pattern?) modifiers-pattern?: Spring AOP only supports public return-type-pattern: void, boolean, string, List, etc declaring-type-pattern?: the class name method-name-pattern(param-pattern): method name to match, and parameters type to match throws-pattern?: exception types to match If the parameter is optional it is followed by an ?. You can also add wildcards inside the patterns.\nMatch Methods Some examples are:\nMatch concrete method inside a class: @Before(\"execution(public void com.aopdemo.dao.AccountDAO.addAccount())\") Match a method inside any class: @Before(\"execution(public void addAccount())\") Match any method that starts with add: @Before(\"execution(public void add*())\") Match all methods inside a given package: @Before(\"execution(** com.aopdemo.dao.**.*(..))\") The first * denotes the return type, it can be anything The second * denotes the class name, it can be anything inside the package The third * denotes the method name, it can be anything Lastly, .. denotes the param-type, there can be 0 or more parameters Match Parameters There are the following parameter pattern wildcards:\n(): matches a method with no arguments ** (**): matches a method with one argument of any type (..): matches a method with 0 or more arguments of any type For example:\nMatch addAccount methods with no arguments: @Before(\"execution(* addAccount())\") Match addAcount methods with one Account parameter: @Before(\"execution(* addAccount(com.aopdemo.Account))\") Match addAcount methods with any number of parameters: @Before(\"execution(** addAccount(**))\") "},"title":"Spring AOP"},"/notes/webdev/front/":{"data":{"":" React GraphQL "},"title":"Frontend"},"/notes/webdev/front/graphql/":{"data":{"":" Bakend Frontend "},"title":"GraphQL"},"/notes/webdev/front/graphql/01_backend/":{"data":{"":"","file-structure#File Structure":"What is best practice is to separate the type definitions and the resolvers:\nTypeDefs: stored in schema.js for example. Resolvers: stored in a folder called resolvers, and then for each Resolver we create a file, for example for the Query resolver: const Category = { animals: (parent, args, { animals }) =\u003e { return animals.filter((animal) =\u003e { return animal.category === parent.id; }); }, }; module.exports = Category; Then we create an index.js inside the resolvers folder where we can import and export all of our Resolvers together:\nconst Query = require(\"./query\"); const Category = require(\"./category\"); const Animal = require(\"./animal\"); module.exports = { Query, Category, Animal, }; And we put everything together in our index.js inside the root folder:\nconst { ApolloServer } = require(\"apollo-server\"); const { mainCards, animals, categories } = require(\"./db\"); const typeDefs = require(\"./schema\"); const { Query, Category, Animal } = require(\"./resolvers/index\"); const server = new ApolloServer({ typeDefs, resolvers: { Query, Animal, Category, }, context: { mainCards, animals, categories, }, }); // The `listen` method launches a web server. server.listen().then(({ url }) =\u003e { console.log(`\u003e Server ready at ${url}`); }); We now use the context object in order to make our “database” available to all of the resolvers through ctx. (Note that we de-structure the object to the get animal object).","graphql-server#GraphQL Server":"GraphQL supports several languages, and has several servers that do mainly the same. Consult the official page for the one that suits your needs.\nWe are going to use apollo-server to demonstrate how to use GraphQL in a node.js application:\nSo, first, we install the apollo-server along with graphql dependency with npm:\n$ npm install apollo-server graphql Now we use graphql to define our type definitions:\nconst { ApolloServer, gql } = require('apollo-server'); const typeDefs = gql` type Book { title: String author: String } type Query { books: [Book] } And we also create our resolvers:\nconst resolvers = { Query: { books: () =\u003e books, } } Where books is an already defined array of books.\nFinally we create the actual server:\nconst server = new ApolloServer({typeDefs, resolvers}); server.listen().then(({ url }) =\u003e { console.log(`🚀 Server ready at ${url}`); }); ","intro#Intro":"Difference with APIs Whenever we use REST APIs and we hit specific endpoints, more often than not, we are going to retrieve some data that we have no use for. This is what is called overfetching.\nFor example when you access https://my-rest-api/animals you get an object with a list of animal objects, and you may not need all of the information of every animal.\nGraphQL solves this problem by:\nOnly having one endpoint. From this endpoint we use the graph query language to select whatever data that we want. For example, to retrieve the same information stated above:\nquery { animals { title ratings img price } } Which gets only the specified attributes for each animal.\nGraphQL also solves underfetching, which is the situation where you cannot get enough data with a call to only one endpoint, forcing you to call a second endpoint.\nFor example, if you want information about the animals and the categories you have to access https://my-rest-api/animals, and https://my-rest-api/categories, however with GraphQL:\nquery { animals { title ratings img price } categories { id title img } } ","mutations#Mutations":"TypeDef We create the type definition for the Mutation object (which is reserved in GraphQL to modify/add data, much like the Query object). In it, we define all the modifying functions we want, along with the data that must be provided to execute the modification, and also the type of object that is returned.\ntype Mutation { addAnimal( name: String! description: [String!]! parameter: String! category: String! ): Animal removeAnimal(id: ID!): Boolean! } With this we have defined the addAnimal method, which creates and animal by specifying the name, description, URL parameter and the category. This function will return an Animal object.\nWe have also defined the removeAnimal method, that only takes an id as a parameter and returns a Boolean.\nResolvers We now define the logic behind both of these methods, so we create a Mutation.js file as follows:\nconst { v4 } = require(\"uuid\"); const Mutation = { addAnimal: ( parent, { name, description, parameter, category }, { animals } ) =\u003e { let newAnimal = { id: v4(), name, description, parameter, category, }; // Only because this is an object: here we would create in the database animals.push(newAnimal); return newAnimal; }, removeAnimal: (parent, { id }, { animals }) =\u003e { // Here we would delete in the database let index = animals.findIndex((animal) =\u003e { return animal.id === id; }); animals.splice(index, 1); return true; }, }; module.exports = Mutation; Note that we de-structure the parameters from the args object for readability sake.","queries-typedefs-and-resolvers#Queries TypeDefs and Resolvers":"Data Specification Arrays: to define an array on TypeDefs or Queries you use []. type Book { author: [String] } Non nullable field: to specify that an attribute cannot be null you use !. type Book { author: String! author: [String]! // the array must not be null author: [String!]! // the elements of the array and the array must not be null } Queries Parameters: on the query object you add an argument between brackets (the ! specifies the argument must be provided). type Animal { id: ID! name: String! description: [String!]! } type Query { animals: [Animal!]! animal(id: String!): Animal } On the resolver we use the arg parameter to retrieve the parameter passed:\nconst resolvers = { Query: { animals: () =\u003e animals, animal: (parent, args, ctx) =\u003e { let animal = animals.find((animal) =\u003e { retunr animal.id === args.id }) return animal } } } ","relationships#Relationships":"One To Many We are now going to illustrate the situation where an animal belongs to only one category whilst a category contains several animals:\ntype Animal { id: ID! category: Category! name: String! parameter: String! } type Category { id: ID! name: String! animals: [Animal!]! parameter: String! } Where we have stored in our database the id of the category as a foreign key of the Animal entity.\nIn order to query for animals from a category we create a new resolver:\nconst resolvers = { Query: { animals: () =\u003e animals, animal: (parent, args, ctx) =\u003e { let animal = animals.find((animal) =\u003e { return animal.paramenter === args.id }) return animal } } Category: { animals: (parent, args, ctx) =\u003e { return animals.filter((animal) \u003e= { return animal.category == parent.id }) } } } So if we query for:\n{ category(parameter: \"mammal\"){ category animals { name } } } We get all the names of the animals that are mammals.\nThe parent object symbolizes the object resulting from category(parameter: \"mammal\"), this object will be a Category object and will have an id, that we will use in our resolver to filter the animals.\nObserve that the animals have a attribute called category, which is not the same as the type definition we have made for our Animal object, this attribute is defined on the database.\nNote that we have created a Category resolver that acts as the query resolver but for queries within the category object.\nWe, now, do the same for the animals, meaning we want to get the Category object that we specified in the Animal object, for that we create a new resolver:\nAnimal: { category: (parent, args, ctx) =\u003e { return categories.find((category) =\u003e { return category.id === parent.category }) } } So what we do is go through all of the categories until we find the one that has the same id.\n{ animal(parameter: \"cat\"){ name category { name } } And with this query we retrieve the name and the category name of a cat.","terminology#Terminology":"Schema It defines the data associated with an Entity:\ntype Person { id: ID! name: String! email: String! age: Int! phone: String gender: Boolean! } That is to say, it defines the type definitions of the data that conforms a given Entity.\nResolver The data that we get back is dependent on the resolvers. They are functions that return data that follow a certain schema, it does not need to follow the schema, but then when querying it, it may throw and error.\npeople(parent, args, ctx, info){ return[ { id: \"1\", name: \"Laith\", email: \"email@email.com\", age: 23, phone: \"623198135\", gender: true } ] } "},"title":"Backend"},"/notes/webdev/front/graphql/02_frontend/":{"data":{"":"","client#Client":"As well as with the server there are several clients for GraphQL within different languages and frameworks, visit the official page to check them out.\nWe are going to use Apollo Client so for that we need to install apollo and graphql on the client side of our application:\n$ npm install @apollo/client graphql In our case we are going to connect our client to React (Reference). So, first we import the necessary modules.\nimport React from \"react\"; import { render } from \"react-dom\"; import { ApolloClient, InMemoryCache, ApolloProvider, useQuery, gql, } from \"@apollo/client\"; const client = new ApolloClient({ uri: \"http://localhost:4000\", cache: new InMemoryCache(), }); function App() { return ( \u003cdiv\u003e \u003ch2\u003eMy first Apollo app 🚀\u003c/h2\u003e \u003c/div\u003e ); } render( \u003cApolloProvider client={client}\u003e {\" \"} \u003cApp /\u003e{\" \"} \u003c/ApolloProvider\u003e, document.getElementById(\"root\") ); We tell apollo that our GraphQL server is listening for request on our localhost on the port 4000.\nWhere apollo allows us to cache our queries, with the InMemoryCache module. That way we do not need to make the same request twice, because the data is cached in memory.\nAnd then, we wrap our app with the ApolloProvider, so all of our components have access to our client. Note that we pass our client as a prop.","fetch-data#Fetch Data":"Variables In order to make a query by passing parameters we do:\nconst ANIMAL_QUERY = gql` query ($slug: String!) { animal(slug: $slug) { title image stock description price } } `; Where $string is the variable we want to pass in, and we specify its type and the fact that it is required with String!.\nNow to make the query we do:\nfunction AnimalPage() { const { slug } = useParameters() const { loading, data, error } = useQuery( variables: { slug: 'cat' } ) } With variables we pass in all of the parameters needed in the query.","mutations#Mutations":"In order to execute a mutation from the client side we create a mutation request:\nconst ADD_ANIMAL_MUTATION = gql` mutation ( $name: String! $description: [String!] $parameter: String! $category: String! ) { addAnimal( name: $name description: $description parameter: $parameter category: $category ) } `; And now we use the useMutation hook to obtain the function that will be called in order to update our animal:\nimport { useMutation, gql } from \"@apollo/client\"; function Animal() { const [addAnimal] = useMutation(ADD_ANIMAL_MUTATION); return ( \u003cdiv\u003e \u003cbutton onClick={() =\u003e addAnimal({ variables: { name: \"cat\", description: [\"This is a description\"], parameter: \"cat\", category: \"mammal\", }, }) } /\u003e \u003c/div\u003e ); } With this we get the function addAnimal with the useMutation hook and we use it in our button, so when it is clicked we add a cat to our animal collection."},"title":"Frontend"},"/notes/webdev/front/react/":{"data":{"":" Basics Advanced Performance Optimization Redux "},"title":"React"},"/notes/webdev/front/react/01_basics/":{"data":{"":"","babel#Babel":"Babel is a Javascript compiler that converts ES7, ES6 to E5 so it can run smoothly in older browsers. This way we can use new features of ES7 and ES6 while maintaining compatibility.","children-in-props#Children in Props":"You can nest content inside your component. If we have the following:\nimport React from \"react\"; import ReactDom from \"react-dom\"; // CSS import \"./index.css\"; import Book from \"./Book\"; const singleBook = { title: \"Book title\", author: \"Book author\", }; ReactDom.render( \u003cBook {...singleBook}\u003e \u003cp\u003e I am nested!\u003c/p\u003e \u003c/Book\u003e, document.getElementById(\"root\") ); You can access the nested object from your component:\nimport React from \"react\"; // De-structure the children prop const Book = ({ title, author, children }) =\u003e { return ( \u003carticle className=\"book\"\u003e \u003ch1\u003e{title}\u003c/h1\u003e \u003ch4\u003e{author}\u003c/h4\u003e {children} \u003c/article\u003e ); }; export default Book; ","create-react-app#Create React App":"You do not need create-react-app to create a React app, but it makes it way easier:\nnpx create-react-app \u003capp-name\u003e cd \u003capp-name\u003e npm start ","css-in-jsx#CSS in JSX":"We can define the style inside JSX, for that we use the prop style. The first curly braces takes us back to javascript, and the second are to specify the creation of an object.\nAlso note that we do not write font-size but we use the React convention of writing fontSize\nconst Author = () =\u003e \u003ch4 style={{ fontSize: \"1px\" }}\u003eTest\u003c/h4\u003e; This level has higher preference (overrides) than the CSS imported from a CSS file.","event-basics#Event Basics":" List of all possible events To define an event we have to specify:\n*_ **attribute_: like onClick, onMouseHover, etc. *_ **eventHandler_: the function to apply. This can be specified as a reference or as an in-line function.\nNext, we present an example:\nimport React from 'react' const Book = ({ title, author }) =\u003e { const clickHandler = () =\u003e {alert('Hello!!')} return ( \u003carticle className='book'\u003e \u003c!-- Here we have the eventHandler as an in-line function --\u003e \u003ch1 onClick={() =\u003e alert('Hello!!')}\u003e{title}\u003c/h1\u003e \u003ch4\u003e{author}\u003c/h4\u003e \u003c!-- Here we have the eventHandler as a reference --\u003e \u003cbutton type=\"button\" onClick={clickHandler}\u003eThis is a button\u003c/button\u003e \u003c/article\u003e ); }; export default Book To pass an argument to the eventHandler we have to use a lambda function, else when we load the application will invoke the function clickHandler(author)\nimport React from 'react' const Book = ({ title, author }) =\u003e { const clickHandler = (author) =\u003e {alert(author)} return ( \u003carticle className='book'\u003e \u003ch1 onClick={() =\u003e alert('Hello!!')}\u003e{title}\u003c/h1\u003e \u003ch4\u003e{author}\u003c/h4\u003e \u003c!-- Wrap function with an in-line function --\u003e \u003cbutton type=\"button\" onClick={() =\u003e clickHandler(author)}\u003eThis is a button\u003c/button\u003e \u003c/article\u003e ); }; export default Book We can also access the event object from within the function, like:\nimport React from \"react\"; const Book = ({ title, author }) =\u003e { // You can always access the event object from an eventHandler const clickHandler = (author, e) =\u003e { console.log(e); }; return ( \u003carticle className=\"book\"\u003e \u003ch1 onClick={() =\u003e alert(\"Hello!!\")}\u003e{title}\u003c/h1\u003e \u003ch4\u003e{author}\u003c/h4\u003e \u003cbutton type=\"button\" onClick={() =\u003e clickHandler(author)}\u003e This is a button \u003c/button\u003e \u003c/article\u003e ); }; export default Book; ","file-structure#File Structure":" node_modules: folder that contains all of the dependencies package.json: is the manifest file for the project scripts start: runs the development server build: creates a production version for the project inside a folder called build, where the optimized files resulting of the build are stored. The rest of the files created by create-react-app are mostly useless:\nApp.js App.css App.test.js logo.svg serviceWorker.js setupTests.js Also all of the contents of index.js can be removed.","jsx-rules#JSX Rules":" Always return something Always return a single element or div, section, article or React.Fragment (does not create a div) enclosing the element Use camelCase for HTML attribute Use className instead of class Close every element ","list-of-components#List of Components":"React has one restriction for list of objects, and that is: they have to have a key. So, for example:\nimport React from \"react\"; import ReactDom from \"react-dom\"; // CSS import \"./index.css\"; import Book from \"./Book\"; // Data to create book object const books = [ { id: \"1\", title: \"Book title\", author: \"Book author\", }, { id: \"2\", title: \"Book title\", author: \"Book author\", }, ]; const bookList = books.map((book) =\u003e { // De-structure book object return \u003cBook key={book.id} {...book} /\u003e; }); ReactDom.render(\u003cdiv\u003ebookList\u003c/div\u003e, document.getElementById(\"root\")); ","npm#npm":"It is the Node Package Manager:\nCreate package.json (manifest) file, with the list of dependencies\n$ npm init Install package locally and add it to package.json, under the keyword “dependencies”\n$ npm install \u003cpackage name\u003e Install package globally (requires sudo)\n$ npm install -g \u003cpackage name\u003e Install package only for development\n$ npm install \u003cpackage name\u003e --save-dev The packages installed with be saved under the file node_modules\nTo install all the dependencies listed in package.json, just run:\n$ npm install Where the package.json is.","props#Props":"Spread operator Let’s define an object singleBook that contains all of the book’s properties and pass it to the Book component:\nimport React from \"react\"; import ReactDom from \"react-dom\"; // CSS import \"./index.css\"; import Book from \"./Book\"; const singleBook = { title: \"Book title\", author: \"Book author\", }; ReactDom.render( // Use the spread operator \u003cBook {...singleBook} /\u003e, document.getElementById(\"root\") ); ","start-in-indexjs#Start in index.js":"Keep in mind, index.js is the entry point:\nFirst of all refer to File Structure, and then basically remove everything from index.js, and replace it for:\nimport React from \"react\"; import ReactDom from \"react-dom\"; // CSS import \"./index.css\"; We use the ReactDom module to make use of the React DOM API, which let’s us render components, etc. Next we call ReactDom.render() to output our HTML:\nimport React from \"react\"; import ReactDom from \"react-dom\"; // CSS import \"./index.css\"; function Component() { return \u003ch4\u003e HI! \u003c/h4\u003e; } ReactDom.render(\u003cComponent /\u003e, document.getElementbyId(\"root\")); Note\nThe function must start with a capital letter The tag that encloses the component must be closed, so either: \u003cComponent/\u003e or \u003cComponent\u003e\u003c/ Component\u003e We use document.getElementbyId(\"root\"), this tells React where to place the component inside the HTML "},"title":"Basics"},"/notes/webdev/front/react/02_advanced/":{"data":{"":"","conditional-rendering#Conditional Rendering":"Short Circuit Evaluation Now, let’s see an example of Short Circuit Evaluation in action:\nimport React, { useState } from \"react\"; const ShortCircuit = () =\u003e { const [text, setText] = useState(\"\"); const [isError, setIsError] = useState(false); // If text is falsy, then return 'hello world' // else return text // const firstValue = text || 'hello world'; // If text is true, then return 'hello world' // else return text // const secondValue = text \u0026\u0026 'hello world'; return ( \u003c\u003e {/**If text is false, return h1 with 'john doe value'**/} \u003ch1\u003e{text || \"john doe\"}\u003c/h1\u003e {/**If text is true, return h1 with 'john doe value'**/} {text \u0026\u0026 \u003ch1\u003e'john doe'\u003c/h1\u003e} \u003c/\u003e ); }; export default ShortCircuit; Ternary operators We can also use ternary operators to render conditionally in React.\nimport React, { useState } from \"react\"; const ShortCircuit = () =\u003e { const [isError, setIsError] = useState(false); return ( \u003c\u003e \u003cbutton className=\"btn\" onClick={() =\u003e setIsError(!isError)}\u003e toggle error \u003c/button\u003e {/*Check the value of isError, if is error is true, return the first value after the ? else return the second value*/} {isError ? ( \u003cp\u003ethere is an error...\u003c/p\u003e ) : ( \u003cdiv\u003e \u003ch2\u003ethere is no error\u003c/h2\u003e \u003c/div\u003e )} \u003c/\u003e ); }; export default ShortCircuit; ","context-api#Context API":"Context API and useContext allows us to resolve the issue of the prop drilling. The context has two components:\nThe provider: works as a distributer The consumer We use them as follows:\nimport React, { useState, useContext } from 'react'; import { data } from '../../../data'; // Create context object const PersonContext = React.createContext(); const ContextAPI = () =\u003e { // State saved in the context const [people, setPeople] = useState(data); // Event handler saved in the context const removePerson = (id) =\u003e { setPeople((people) =\u003e { return people.filter((person) =\u003e person.id !== id); }); }; return ( {/*Wrap the components in the context provider, so all the nested components have access to the variables defined in the context object*/} \u003cPersonContext.Provider value={{ removePerson, people }}\u003e \u003ch3\u003eContext API / useContext\u003c/h3\u003e \u003cList /\u003e \u003c/PersonContext.Provider\u003e ); }; const List = () =\u003e { // Obtain data from the context with the useContext hook const mainData = useContext(PersonContext); return ( \u003c\u003e {mainData.people.map((person) =\u003e { return \u003cSinglePerson key={person.id} {...person} /\u003e; })} \u003c/\u003e ); }; const SinglePerson = ({ id, name }) =\u003e { // Obtain data from the context with the useContext hook const { removePerson } = useContext(PersonContext); return ( \u003cdiv className='item'\u003e \u003ch4\u003e{name}\u003c/h4\u003e \u003cbutton onClick={() =\u003e removePerson(id)}\u003eremove\u003c/button\u003e \u003c/div\u003e ); }; export default ContextAPI; ","controlled-inputs#Controlled Inputs":"Multiple inputs How can we define an event handler for the OnChange event that is generic, instead of defining one for each input? To showcase this scenario, we will use the same code as before, but with two new inputs. All of the inputs have the same OnChange event handler.\nimport React, { useState } from \"react\"; const ControlledInputs = () =\u003e { // Create a new state variable person, that holds the properties of the person we are currently creating const [person, setPerson] = useState({ firstName: \"\", email: \"\", age: \"\" }); // Array of people we have already created const [people, setPeople] = useState([]); // Generic event handler const handleChange = (e) =\u003e { // Obtain the name of the input/state variable const name = e.target.name; // Obtain the new value for the input const value = e.target.value; // Update the value of the property for the current person setPerson({ ...person, [name]: value }); }; const handleSubmit = (e) =\u003e { e.preventDefault(); if (person.firstName \u0026\u0026 person.email \u0026\u0026 person.age) { const newPerson = { ...person, id: new Date().getTime().toString() }; setPeople([...people, newPerson]); setPerson({ firstName: \"\", email: \"\", age: \"\" }); } }; return ( \u003c\u003e \u003carticle className=\"form\"\u003e \u003cform\u003e \u003cdiv className=\"form-control\"\u003e \u003clabel htmlFor=\"firstName\"\u003eName : \u003c/label\u003e \u003cinput type=\"text\" id=\"firstName\" name=\"firstName\" // Access the firstName of the person object value={person.firstName} // Generic event handler onChange={handleChange} /\u003e \u003c/div\u003e \u003cdiv className=\"form-control\"\u003e \u003clabel htmlFor=\"email\"\u003eEmail : \u003c/label\u003e \u003cinput type=\"email\" id=\"email\" name=\"email\" // Access the email of the person object value={person.email} // Generic event handler onChange={handleChange} /\u003e \u003c/div\u003e \u003cdiv className=\"form-control\"\u003e \u003clabel htmlFor=\"age\"\u003eAge : \u003c/label\u003e \u003cinput type=\"number\" id=\"age\" name=\"age\" // Access the age of the person object value={person.age} // Generic event handler onChange={handleChange} /\u003e \u003c/div\u003e \u003cbutton type=\"submit\" className=\"btn\" onClick={handleSubmit}\u003e add person \u003c/button\u003e \u003c/form\u003e \u003c/article\u003e \u003carticle\u003e {people.map((person) =\u003e { const { id, firstName, email, age } = person; return ( \u003cdiv key={id} className=\"item\"\u003e \u003ch4\u003e{firstName}\u003c/h4\u003e \u003cp\u003e{email}\u003c/p\u003e \u003cp\u003e{age}\u003c/p\u003e \u003c/div\u003e ); })} \u003c/article\u003e \u003c/\u003e ); }; export default ControlledInputs; ","custom-hooks#Custom Hooks":"Customs hooks allow us to avoid duplicating code that uses hooks and essentially in different places of your code. For example, the fetching function is very common, so we create a useFetch hook.\nWhen you define a custom hook, that is, if you define a function outside a component that uses hooks, you will have to name it use\u003cFunctionName\u003e, else you will get an error.\nimport React, { useState, useEffect } from \"react\"; // Import custom hook import { useFetch } from \"./2-useFetch\"; const url = \"https://course-api.com/javascript-store-products\"; const Example = () =\u003e { // Values returned by useFetch const { loading, products } = useFetch(url); return ( \u003cdiv\u003e \u003ch2\u003e{loading ? \"loading...\" : \"data\"}\u003c/h2\u003e \u003c/div\u003e ); }; export default Example; import { useState, useEffect, useCallback } from \"react\"; export const useFetch = (url) =\u003e { // State within the hook const [loading, setLoading] = useState(true); const [products, setProducts] = useState([]); // Functionality of the hook const getProducts = useCallback(async () =\u003e { const response = await fetch(url); const products = await response.json(); setProducts(products); setLoading(false); }, [url]); // Run whenever the url or the getProducts function changes useEffect(() =\u003e { getProducts(); }, [url, getProducts]); // Values returned by the custom hook return { loading, products }; }; Note we are using the hook useCallback (refer to Performance Optimization), we do this because we are specifying getProducts as a dependency for useEffect. However getProducts is created every time the state changes.\nSo when we call useEffect, we change the state, and therefore create the function getProducts, which triggers useEffect, thus the state changes, and we create getProducts, and so on and so forth.\nTo avoid this, we use useCallback, which will create the function whenever any of the dependencies in the list change. So this means, now getProducts is only created when the url changes. This allows us to avoid the infinite loop we ran into before.","prop-drilling#Prop Drilling":"Prop Drilling refers to the scenario where we have to pass props to anidated components recursively. Next up, we show and example\nimport React, { useState } from \"react\"; // Data import { data } from \"../../../data\"; // Outer component const PropDrilling = () =\u003e { // State passed as a prop const [people, setPeople] = useState(data); // Event handler passed as a prop const removePerson = (id) =\u003e { setPeople((people) =\u003e { return people.filter((person) =\u003e person.id !== id); }); }; return ( \u003csection\u003e \u003ch3\u003eprop drilling\u003c/h3\u003e {/** Pass props to the list elements **/} \u003cList people={people} removePerson={removePerson} /\u003e \u003c/section\u003e ); }; // Middle component const List = ({ people, removePerson }) =\u003e { return ( \u003c\u003e {people.map((person) =\u003e { { /** Pass props to the SinglePerson elements **/ } return ( \u003cSinglePerson key={person.id} {...person} removePerson={removePerson} /\u003e ); })} \u003c/\u003e ); }; // Inner component const SinglePerson = ({ id, name, removePerson }) =\u003e { return ( \u003cdiv className=\"item\"\u003e \u003ch4\u003e{name}\u003c/h4\u003e \u003cbutton onClick={() =\u003e removePerson(id)}\u003eremove\u003c/button\u003e \u003c/div\u003e ); }; export default PropDrilling; In these cases we can use the Context API","properties-of-hooks#Properties of Hooks":"All the hooks have the following properties:\nThey start with the word use The component where they are created must be named in uppercase They cannot be invoked inside a function/component body. You cannot call hooks conditionally ","proptypes#PropTypes":"Default Props In this other Product component, we show how to use defaultProps instead of conditional rendering.\nimport React from \"react\"; import PropTypes from \"prop-types\"; import defaultImage from \"./assets/default-image.jpeg\"; const Product = ({ image, name, price }) =\u003e { return ( \u003carticle className=\"product\"\u003e {/**Use conditional rendering in case the data does not exist **/} \u003cimg src={image.url} alt={name} /\u003e \u003ch4\u003e{name}\u003c/h4\u003e \u003cp\u003e${price}\u003c/p\u003e \u003c/article\u003e ); }; // Define the propTypes for the object Product.propTypes = { image: PropTypes.object.isRequired, name: PropTypes.string.isRequired, price: PropTypes.number.isRequired, }; Product.defaultProps = { name: \"default name\", price: 3.99, image: defaultImage, }; export default Product; ","react-router#React Router":"Links How do we navigate through our application, well by using Links. So, for example, in the Navbar:\nimport React from 'react'; import { Link } from 'react-router-dom'; const Navbar = () =\u003e { return ( \u003cnav\u003e \u003cul\u003e \u003cli\u003e \u003c!-- Specify the path --\u003e \u003cLink to='/'\u003eHome\u003c/Link\u003e \u003c/li\u003e \u003cli\u003e \u003c!-- Specify the path --\u003e \u003cLink to='/about'\u003eAbout\u003c/Link\u003e \u003c/li\u003e \u003cli\u003e \u003c!-- Specify the path --\u003e \u003cLink to='/people'\u003ePeople\u003c/Link\u003e \u003c/li\u003e \u003c/ul\u003e \u003c/nav\u003e ); }; export default Navbar; To pass a parameter to the link we can do the following:\nimport React, { useState } from 'react'; import { data } from '../../../data'; import { Link } from 'react-router-dom'; const People = () =\u003e { // List of people const [people, setPeople] = useState(data); return ( \u003cdiv\u003e \u003ch1\u003ePeople Page\u003c/h1\u003e {people.map((person) =\u003e { return ( \u003cdiv key={person.id} className='item'\u003e \u003ch4\u003e{person.name}\u003c/h4\u003e \u003c!-- Specify the path and pass the id of the current person as a parameter --\u003e \u003cLink to={`/person/${person.id}`}\u003eLearn More\u003c/Link\u003e \u003c/div\u003e ); })} \u003c/div\u003e ); }; export default People; Now in the Person component, we can fetch the parameter:\nimport React, { useState, useEffect } from 'react'; import { data } from '../../../data'; import { Link, useParams } from 'react-router-dom'; const Person = () =\u003e { // State const [name, setName] = useState('default name'); // useParams hook to fetch the parameter // the name of the parameter (id), is specified in the \"Route\" component // in our case the path to person was: /person/:id const { id } = useParams(); useEffect(() =\u003e { const newPerson = data.find((person) =\u003e person.id === parseInt(id)); setName(newPerson.name); }, []); return ( \u003cdiv\u003e \u003ch1\u003e{name}\u003c/h1\u003e \u003c!-- Go to the previous page of the list of people --\u003e \u003cLink to='/people' className='btn'\u003e Back To People \u003c/Link\u003e \u003c/div\u003e ); }; export default Person; ","useeffect#useEffect":"Dependencies The useEffect definition allows you to pass an array of dependencies:\nIf it is specified as []: useEffect will only be triggered in the first render If it is an array of state variables: it will be triggered every time the state variable is updated. import React, { useState, useEffect } from 'react'; const UseEffectBasics = () =\u003e { const [value, setValue] = useState(0); // Only trigger on first render // useEffect(() =\u003e { // document.title = `New Messages(${value})`; // }, []); // Call whenever value is updated useEffect(() =\u003e { document.title = `New Messages(${value})`; }, [value]); return ( \u003c\u003e \u003ch1\u003e{value}\u003c/h1\u003e \u003cbutton className='btn'}\u003e click me \u003c/button\u003e \u003c/\u003e ); }; export default UseEffectBasics; Clean up Function useEffect lets us define a function that is invoked once we exit the function:\nimport React, { useState, useEffect } from \"react\"; const UseEffectCleanup = () =\u003e { const [size, setSize] = useState(window.innerWidth); const checkSize = () =\u003e { setSize(window.innerWidth); }; useEffect(() =\u003e { console.log(\"useEffect\"); window.addEventListener(\"resize\", checkSize); // Clean up function return () =\u003e { console.log(\"cleanup\"); window.removeEventListener(\"resize\", checkSize); }; }, []); console.log(\"render\"); return ( \u003c\u003e \u003ch1\u003ewindow\u003c/h1\u003e \u003ch2\u003e{size} PX\u003c/h2\u003e \u003c/\u003e ); }; export default UseEffectCleanup; Fetch Data Up next we will show how to get data using useEffect.\nNote, if we do not specify the restriction of only triggering on the first render:\nuseEffect calls getUsers getUsers updates the state, and so the component re-renders Because there is a re-render, useEffect is called again Thus, we end in an infinite loop import React, { useState, useEffect } from \"react\"; const url = \"https://api.github.com/users\"; const UseEffectFetchData = () =\u003e { const [users, setUsers] = useState([]); const getUsers = async () =\u003e { const response = await fetch(url); const users = await response.json(); setUsers(users); }; useEffect(() =\u003e { getUsers(); // Specify [] so we only run useEffect on the first render. }, []); return ( \u003c\u003e \u003ch3\u003egithub users\u003c/h3\u003e \u003cul className=\"users\"\u003e {users.map((user) =\u003e { const { id, login, avatar_url, html_url } = user; return ( \u003cli key={id}\u003e \u003cimg src={avatar_url} alt={login} /\u003e \u003cdiv\u003e \u003ch4\u003e{login}\u003c/h4\u003e \u003ca href={html_url}\u003eprofile\u003c/a\u003e \u003c/div\u003e \u003c/li\u003e ); })} \u003c/ul\u003e \u003c/\u003e ); }; export default UseEffectFetchData; ","usereducer#useReducer":"An alternative to useState. Accepts a reducer of type (state, action) =\u003e newState, and returns the current state paired with a dispatch method.\nuseReducer is usually preferable to useState when you have complex state logic that involves multiple sub-values or when the next state depends on the previous one. useReducer also lets you optimize performance for components that trigger deep updates because you can pass dispatch down instead of callbacks.\nFor example:\nimport React, { useState, useReducer } from \"react\"; // Components import Modal from \"./Modal\"; // Data import { data } from \"../../../data\"; // Reducer dispatch function import { reducer } from \"./reducer\"; // Initial state for the reducer const defaultState = { people: [], isModalOpen: false, modalContent: \"\", }; const Index = () =\u003e { // Define state variables const [name, setName] = useState(\"\"); // Define reducer: (dispatch fuction, initial state) const [state, dispatch] = useReducer(reducer, defaultState); const handleSubmit = (e) =\u003e { // Avoid the re-rendering caused by the submit event e.preventDefault(); if (name) { const newItem = { id: new Date().getTime().toString(), name }; // Call reducer to update state dispatch({ type: \"ADD_ITEM\", payload: newItem }); setName(\"\"); } else { // Call reducer to update state dispatch({ type: \"NO_VALUE\" }); } }; const closeModal = () =\u003e { // Call reducer to update state dispatch({ type: \"CLOSE_MODAL\" }); }; return ( \u003c\u003e {/**Render Modal component conditionally **/} {state.isModalOpen \u0026\u0026 ( \u003cModal closeModal={closeModal} modalContent={state.modalContent} /\u003e )} {/** Form to add a new person to the reducer state variable **/} \u003cform onSubmit={handleSubmit} className=\"form\"\u003e \u003cdiv\u003e \u003cinput type=\"text\" value={name} onChange={(e) =\u003e setName(e.target.value)} /\u003e \u003c/div\u003e \u003cbutton type=\"submit\"\u003eadd \u003c/button\u003e \u003c/form\u003e {/** Show the people stored in the reducer state variable **/} {state.people.map((person) =\u003e { return ( \u003cdiv key={person.id} className=\"item\"\u003e \u003ch4\u003e{person.name}\u003c/h4\u003e \u003cbutton onClick={() =\u003e // Call reducer to update state dispatch({ type: \"REMOVE_ITEM\", payload: person.id }) } \u003e remove \u003c/button\u003e \u003c/div\u003e ); })} \u003c/\u003e ); }; export default Index; Now, let’s see the reducer function:\n/** Reducer function **/ export const reducer = (state, action) =\u003e { // Define logic for each type of action if (action.type === \"ADD_ITEM\") { // Add new person (action.payload) to existing people array (state.people) const newPeople = [...state.people, action.payload]; return { // Always copy the value from the previous state ...state, // Update the people array people: newPeople, isModalOpen: true, modalContent: \"item added\", }; } if (action.type === \"NO_VALUE\") { // Always copy the value from the previous state return { ...state, isModalOpen: true, modalContent: \"please enter value\" }; } if (action.type === \"CLOSE_MODAL\") { return { ...state, isModalOpen: false }; } if (action.type === \"REMOVE_ITEM\") { // Filter people array, by removing the person const newPeople = state.people.filter( (person) =\u003e person.id !== action.payload ); // Copy the previous state (...state) and update the people the array (newPeople) return { ...state, people: newPeople }; } throw new Error(\"no matching action type\"); }; ","useref#useRef":"useRef returns a mutable ref object whose .current property is initialized to the passed argument. Some properties:\nPreserves the value of the object Does not trigger re-render Assigned to DOM nodes/elements import React, { useEffect, useRef } from \"react\"; const UseRefBasics = () =\u003e { // Create the container const refContainer = useRef(null); const handleSubmit = (e) =\u003e { e.preventDefault(); // Print the value inside the input console.log(refContainer.current.value); }; useEffect(() =\u003e { // Focus on the input element whenever we render the application refContainer.current.focus(); }); return ( \u003c\u003e \u003cform className=\"form\" onSubmit={handleSubmit}\u003e \u003cdiv\u003e {/**The refContainer points to the input element**/} \u003cinput type=\"text\" ref={refContainer} /\u003e \u003c/div\u003e \u003cbutton type=\"submit\"\u003esubmit\u003c/button\u003e \u003c/form\u003e \u003c/\u003e ); }; export default UseRefBasics; ","usestate#useState":"Error In the next piece of code we show how, if we change the value of a variable in React, it does not change in our web app because it is not re-rendered:\nimport React from \"react\"; const ErrorExample = () =\u003e { let title = \"random title\"; const handleClick = () =\u003e { title = \"hello people\"; console.log(title); }; return ( \u003cReact.Fragment\u003e \u003ch2\u003e{title}\u003c/h2\u003e \u003cbutton type=\"button\" onClick={handleClick}\u003e change title \u003c/button\u003e \u003c/React.Fragment\u003e ); }; export default ErrorExample; That is why we will need to use the hook useState, so we change handle state changes.\nimport React, { useState } from \"react\"; const UseStateBasics = () =\u003e { const [text, setText] = useState(\"random title\"); const handleClick = () =\u003e { if (text === \"random title\") { setText(\"hello world\"); } else { setText(\"random title\"); } }; return ( \u003cReact.Fragment\u003e \u003ch1\u003e{text}\u003c/h1\u003e \u003cbutton type=\"button\" onClick={handleClick}\u003e change title \u003c/button\u003e \u003c/React.Fragment\u003e ); }; export default UseStateBasics; When we invoke useState we have to pass as an argument the initial value of the state variable. useState is a function that returns an array:\nThe first element: the state variable The second element: the handler that controls the value of the state value When using useState with objects, whenever you update one property of the object, you have to pass the object to the handler (with the spread operator), and then override the property you want to update:\nimport React, { useState } from \"react\"; const UseStateObject = () =\u003e { // Object const [person, setPerson] = useState({ name: \"peter\", age: 24, message: \"random message\", }); const changeMessage = () =\u003e { // Pass the person object with the spread operator // and override the message property setPerson({ ...person, message: \"hello world\" }); }; return ( \u003c\u003e \u003ch3\u003e{person.name}\u003c/h3\u003e \u003ch3\u003e{person.age}\u003c/h3\u003e \u003ch4\u003e{person.message}\u003c/h4\u003e \u003cbutton className=\"btn\" onClick={changeMessage}\u003e change message \u003c/button\u003e \u003c/\u003e ); }; export default UseStateObject; Asynchronous functions If we want to update a value asynchronally, and fetch the value of the state variable when the change happens, and not when the function is defined, then:\nimport React, { useState } from \"react\"; const UseStateCounter = () =\u003e { const [value, setValue] = useState(0); const reset = () =\u003e { setValue(0); }; const complexIncrease = () =\u003e { setTimeout(() =\u003e { // value is the value of the state variable when the timeout is defined // if you call it multiple times consecutively you get the same value, because they all get value = 0 // setValue(value + 1); // prevState is the value of the state variable when the timeout finished // if you call it multiple times consecutively you get different values, because value has already been updated // by another setTimeout. // if you call it multiple times setValue((prevState) =\u003e { return prevState + 1; }); }, 2000); }; return ( \u003c\u003e \u003csection style={{ margin: \"4rem 0\" }}\u003e \u003ch2\u003emore complex counter\u003c/h2\u003e \u003ch1\u003e{value}\u003c/h1\u003e \u003cbutton className=\"btn\" onClick={complexIncrease}\u003e increase later \u003c/button\u003e \u003c/section\u003e \u003c/\u003e ); }; export default UseStateCounter; "},"title":"Advanced"},"/notes/webdev/front/react/03_performance_optimization/":{"data":{"":"","reactmemo#React.memo":"React.memo stores a component, and only re-renders if the props of the component change (it memoizes the component). In the next example, that means that we only re-render BigList if products change, thus, we do not re-render any SingleProduct component unless products change.\nimport React, { useState, useCallback, useMemo } from \"react\"; // Custom hook import { useFetch } from \"useFetch\"; const url = \"https://course-api.com/javascript-store-products\"; const Index = () =\u003e { const { products } = useFetch(url); const [count, setCount] = useState(0); return ( \u003c\u003e \u003ch1\u003eCount : {count}\u003c/h1\u003e \u003cbutton className=\"btn\" onClick={() =\u003e setCount(count + 1)}\u003e click me \u003c/button\u003e \u003cBigList products={products} /\u003e \u003c/\u003e ); }; // Each time a prop or the state changes, the component re-renders, so all // the elements of the list are processed again. // However if we use React.memo we only re-render the component if products change const BigList = React.memo(({ products }) =\u003e { return ( \u003csection className=\"products\"\u003e {products.map((product) =\u003e { return \u003cSingleProduct key={product.id} {...product}\u003e\u003c/SingleProduct\u003e; })} \u003c/section\u003e ); }); const SingleProduct = ({ fields }) =\u003e { let { name, price } = fields; price = price / 100; const image = fields.image[0].url; return ( \u003carticle className=\"product\"\u003e \u003cimg src={image} alt={name} /\u003e \u003ch4\u003e{name}\u003c/h4\u003e \u003cp\u003e${price}\u003c/p\u003e \u003c/article\u003e ); }; export default Index; ","usecallback#useCallback":"What happens if we pass a function to BigList, well if the state changes (whichever variable of the state) then the function is created again, and so the function is different. Which means the props of BigList list changes, and causes React.memo to re-render the entire component. That is why we use useCallback.\nuseCallback allows us to define when to create a function, by specifying the dependencies like we did with useEffect:\nIf the dependency is []: then only create in the first render If there are variables in the []: create whenever those variables change If there is nothing: create always. Refer to Customs Hooks for an use case of useCallback inside the custom hook useFetch.\nimport React, { useState, useCallback, useMemo } from \"react\"; // Custom hook import { useFetch } from \"useFetch\"; const url = \"https://course-api.com/javascript-store-products\"; const Index = () =\u003e { const { products } = useFetch(url); const [count, setCount] = useState(0); const [cart, setCart] = useState(0); // We only create this function when we update the cart value // That is we memoize the function const addToCart = useCallback(() =\u003e { setCart(cart + 1); }, [cart]); return ( \u003c\u003e \u003ch1\u003eCount : {count}\u003c/h1\u003e \u003cbutton className=\"btn\" onClick={() =\u003e setCount(count + 1)}\u003e click me \u003c/button\u003e \u003cBigList products={products} addToCart={addToCart} /\u003e \u003c/\u003e ); }; // Each time a prop or the state changes, the component re-renders. Because now // addToCart is define with useCallback, the re-render is not triggered const BigList = React.memo(({ products, addToCart }) =\u003e { return ( \u003csection className=\"products\"\u003e {products.map((product) =\u003e { return ( \u003cSingleProduct key={product.id} {...product} addToCart={addToCart} \u003e\u003c/SingleProduct\u003e ); })} \u003c/section\u003e ); }); const SingleProduct = ({ fields, addToCart }) =\u003e { let { name, price } = fields; price = price / 100; const image = fields.image[0].url; return ( \u003carticle className=\"product\"\u003e \u003cimg src={image} alt={name} /\u003e \u003ch4\u003e{name}\u003c/h4\u003e \u003cp\u003e${price}\u003c/p\u003e \u003cbutton onClick={addToCart}\u003eadd to cart\u003c/button\u003e \u003c/article\u003e ); }; export default Index; ","usememo#useMemo":"Note that this hook deals with values (which is the traditional functionality of the idea of memoizing), whilst React.memo look for changes in the props.\nIn the next example we create a function that returns a value, and we memoize the function, so it only computes the value whenever the products change (the argument of the function), else it returns the value stored before:\nimport React, { useState, useCallback, useMemo } from 'react' // Custom hook import { useFetch } from 'useFetch' const url = 'https://course-api.com/javascript-store-products' // Define the function we are going to memoize const calculateMostExpensive = (data) =\u003e { return ( data.reduce((total, item) =\u003e { const price = item.fields.price if (price \u003e= total) { total = price } return total }, 0) / 100 ) } const Index = () =\u003e { const { products } = useFetch(url); const [count, setCount] = useState(0); const [cart, setCart] = useState(0); const addToCart = useCallback(() =\u003e { setCart(cart + 1) }, [cart]) // Memoize the function with useMemo const mostExpensive = useMemo(() =\u003e calculateMostExpensive(products), [ products, ]) return ( \u003c\u003e \u003ch1\u003eCount : {count}\u003c/h1\u003e \u003cbutton className='btn' onClick={() =\u003e setCount(count + 1)}\u003e click me \u003c/button\u003e \u003c!-- Show most expensive product --\u003e \u003ch1\u003eMost Expensive : ${mostExpensive}\u003c/h1\u003e \u003cBigList products={products} addToCart={addToCart}/\u003e \u003c/\u003e ) } const BigList = React.memo(({ products, addToCart }) =\u003e { return ( \u003csection className='products'\u003e {products.map((product) =\u003e { return ( \u003cSingleProduct key={product.id} {...product} addToCart={addToCart} \u003e\u003c/SingleProduct\u003e ) })} \u003c/section\u003e ) }) const SingleProduct = ({ fields, addToCart }) =\u003e { let { name, price } = fields price = price / 100 const image = fields.image[0].url return ( \u003carticle className='product'\u003e \u003cimg src={image} alt={name} /\u003e \u003ch4\u003e{name}\u003c/h4\u003e \u003cp\u003e${price}\u003c/p\u003e \u003cbutton onClick={addToCart}\u003eadd to cart\u003c/button\u003e \u003c/article\u003e ) } export default Index; "},"title":"Performance Optimization"},"/notes/webdev/front/react/04_redux/":{"data":{"":"","basics#Basics":"Handle an action The process of handling an action is the following:\nWe create an action object and dispatch it: The store forwards the action to the reducer: The reducer updates the state and returns it The store notifies the UI components of the change of the state Install Redux $ npm install redux react-redux First steps Inside src create a store folder Inside the store folder create an index.js that holds all of the React states in this file ","dispatch#Dispatch":"In order to dispatch actions in our reducers we do as follows:\nimport React from \"react\"; // Get dispatch hook import { useDispatch } from \"react-redux\"; // Get actions import { login, logout } from \"../features/user\"; function Login() { // Initialize dispatch hook const dispatch = useDispatch(); return ( \u003cdiv\u003e \u003cbutton onClick={() =\u003e { // Dispatch login action dispatch(login({ name: \"Pedro\", age: 20, email: \"pedro@gmail.com\" })); }} \u003e Login \u003c/button\u003e \u003cbutton onClick={() =\u003e { // Dispatch logout action dispatch(logout()); }} \u003e LOGOUT \u003c/button\u003e \u003c/div\u003e ); } export default Login; ","get-state#Get State":"In order to access the state saved in our state, we do the following:\nimport React from \"react\"; import { useSelector } from \"react-redux\"; function Profile() { // Use the useSelector hook const user = useSelector((state) =\u003e state.user.value); return ( \u003cdiv style={{ color: themeColor }}\u003e \u003ch1\u003e Profile Page\u003c/h1\u003e \u003c!--Obtain the user state--\u003e \u003cp\u003e Name: {user.name} \u003c/p\u003e \u003cp\u003e Age: {user.age}\u003c/p\u003e \u003cp\u003e Email: {user.email}\u003c/p\u003e \u003c/div\u003e ); } export default Profile; ","index-file#Index file":"In the following piece of code we create our store object, where we are going to save the state of our application. As you may note, in this store there are three slices defined. That is because we differentiate three different states (slices). So our store is defined as:\n{ user: {...} theme: {...} } import { configureStore } from \"@reduxjs/toolkit\"; // Different slices import userSlice from \"./features/userSlice.js\"; import themeSlice from \"./features/themeSlice.js\"; // Create store const store = configureStore({ reducer: { // In each case obtain the reducer user: userSlice.reducer, theme: themeSlice.reducer, }, }); export default store; Now, we have to wrap our application with our store:\nimport React from \"react\"; import ReactDOM from \"react-dom\"; import App from \"./App\"; // Import our store as a provider import { Provider } from \"react-redux\"; import store from \"./store\"; ReactDOM.render( \u003cReact.StrictMode\u003e \u003cProvider store={store}\u003e \u003cApp /\u003e \u003c/Provider\u003e \u003c/React.StrictMode\u003e, document.getElementById(\"root\") ); ","reducers-and-actions#Reducers and Actions":"Let’s now see an example of a reducer, more concretely the reducer of the user slice we defined previously:\n// Use create slice to define the slice import { createSlice } from \"@reduxjs/toolkit\"; // Define initial state const initialStateValue = { name: \"\", age: 0, email: \"\" }; export const userSlice = createSlice({ // Name of slice name: \"user\", // Initial state of reducer initialState: { value: initialStateValue }, // Possible reducers reducers: { login: (state, action) =\u003e { state.value = action.payload; }, logout: (state) =\u003e { state.value = initialStateValue; }, }, }); // De-structure actions export const { login, logout } = userSlice.actions; // Export reducer export default userSlice.reducer; "},"title":"Redux"},"/planner/":{"data":{"":"This is the planner page"},"title":"Planner"}}