[
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/Custom Login Form.html",
    "title": "Custom Login Form",
    "body": "\n\nBack\n\n\nCustom Login Form\n\n\n\n\nNow we are going to configure the security of the access to web path in application, login, logout, etc:\n\n\npackage com.springsecurity.demo.config;\n\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.core.userdetails.User;\nimport org.springframework.security.core.userdetails.User.UserBuilder;\n\n@Configuration\n@EnableWebSecurity\npublic class DemoSecurityConfig extends WebSecurityConfigurerAdapter {\n\n\t@Override\n\tprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n\n\t\t// add our users for in memory authentication\n\t\tUserBuilder users = User.withDefaultPasswordEncoder();\n\t\t\n\t\tauth.inMemoryAuthentication()\n\t\t\t.withUser(users.username(\"john\").password(\"test123\").roles(\"EMPLOYEE\"))\n\t\t\t.withUser(users.username(\"mary\").password(\"test123\").roles(\"MANAGER\"))\n\t\t\t.withUser(users.username(\"susan\").password(\"test123\").roles(\"ADMIN\"));\n\t}\n\n\t@Override\n\tprotected void configure(HttpSecurity http) throws Exception {\n          // Here is the control of the access to web path\n          http.authorizeRequests()\n          // Require authentication for every request\n            .anyRequest().authenticated()\n          // And for form login customize the login page shown\n            .and()\n            .formLogin()\n\t\t\t\t\t\t// Custom jsp page\n            .loginPage(\"/showMyLoginPage\")\n\t\t\t\t\t\t// You do not need to create a method in your controller for this endpoint, it is handled by spring\n            .loginProcessingUrl(\"/authenticateTheUser\")\n            .permitAll();\n\t\t\n\t}\n}\n\n\nCreate the form\n\n\nWe create the login page /showMyLoginPage as follows:\n\n\n<!-- Reference the spring and jsp tags -->\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %>  \n<html>\n<head>\n\t<title>Custom Login Page</title>\n\t<style>\n\t\t.failed {\n\t\t\tcolor: red;\n\t\t}\n\t</style>\n</head>\n<body>\n<h3>My Custom Login Page</h3>\n\t\t<!-- The form points to the endpoint specified preivously: \"authenticateTheUser\" -->\n\t\t<!-- contextPath is the domain of our app, i.e. localhost:8080 -->\n\t<form:form action=\"${pageContext.request.contextPath}/authenticateTheUser\"\n\t\t\t   method=\"POST\">\n\t\t<!-- Check for login error -->\n\t\t<c:if test=\"${param.error != null}\">\n\t\t\t<i class=\"failed\">Sorry! You entered invalid username/password.</i>\n\t\t</c:if>\n\t\t<p>\n\t\t\tUser name: <input type=\"text\" name=\"username\" />\n\t\t</p>\n\t\t<p>\n\t\t\tPassword: <input type=\"password\" name=\"password\" />\n\t\t</p>\n\t\t<input type=\"submit\" value=\"Login\" />\n\t</form:form>\n</body>\n</html>\n\n\n\nNote that Spring appends a parameter error when the user fails to login. That is what we use as a condition to show our error message, that is, we check if param.error exists.\n\n\n\nAlso, Spring security defines default names for login form fields:\n\n\n\n\nUser name field: username\n\n\nPassword field: password\n\n\n\nLogin Controller\n\n\nWe also need a controller method for requests to /showMyLoginPage:\n\n\npackage com.springsecurity.demo.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\n\n@Controller\npublic class LoginController {\n\n\t@GetMapping(\"/showMyLoginPage\")\n\tpublic String showMyLoginPage() {\n\t\t\n\t\t// This is the custom-login.jsp we created in the previous section\n\t\treturn \"custom-login\";\n\t\t\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/Display User and Roles.html",
    "title": "Display User and Roles",
    "body": "\n\nBack\n\n\nDisplay User and Roles\n\n\n\n\nIn this section we are going to show how to display in our jsp files the user id and its role:\n\n\nAdd JSP Tag library as dependency\n\n\nFirst we add to our pom.xml file the JSP Tag Library:\n\n\n\t\t<!-- Add Spring Security Taglibs support -->\n\t\t<dependency>\n\t\t    <groupId>org.springframework.security</groupId>\n\t\t    <artifactId>spring-security-taglibs</artifactId>\n\t\t    <version>${springsecurity.version}</version>\n\t\t</dependency>\t\n\n\nJSP page\n\n\nThen add the tag library to the jsp page, and we use its tags to access the user id and its role:\n\n\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<!-- Add tag library -->\n<%@ taglib prefix=\"security\" uri=\"http://www.springframework.org/security/tags\" %>\n<html>\n<head>\n\t<title>luv2code Company Home Page</title>\n</head>\n<body>\n\t<h2>luv2code Company Home Page</h2>\n\t<hr>\n\t<p>\n\tWelcome to the luv2code company home page!\n\t</p>\n\t<hr>\n\t<!-- display user name and role -->\n\t<p>\n\t\tUser: <security:authentication property=\"principal.username\" />\n\t\t<br><br>\n\t\tRole(s): <security:authentication property=\"principal.authorities\" />\n\t</p>\n\t<hr>\n\t<!-- Add a logout button -->\n\t<form:form action=\"${pageContext.request.contextPath}/logout\" \n\t\t\t   method=\"POST\">\n\t\t<input type=\"submit\" value=\"Logout\" />\n\t</form:form>\n</body>\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/Cross Site Request Forgery.html",
    "title": "Cross Site Request Forgery",
    "body": "\n\nBack\n\n\nCross Site Request Forgery\n\n\n\n\nSpring Security protects against Cross-Site Request Forgery. CSRF is a security attack where a website tricks you into executing an action on a web application that you are currently logged in. Protection from this type of attack is embedded in the Spring Security Filters.\n\n\n\nThis protection is enabled by default. Spring Security uses the Synchronizer Token Pattern, where each request includes a session cookie and a randomly generated token. So for request processing, Spring Security verifies the token before processing.\n\n\n\nHow to use it?\n\n\n\n\nFor form submissions use \"POST\" instead of \"GET\"\n\n\nThe Spring Security tag <form:form> automatically adds the CSRF token.\n\n\nIf you do not use the tag, you must manually add the CSRF token.\n\n\nIf you do not add the token you get an error message: 403 Forbidden, and further information about how the token cannot be null.\n\n\n\nHow to see the CSRF token?\n\n\nWhen your jsp with the <form:form> tag is processed into an html page, you will be able to see the token inside the form tag:\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/Java Configuration.html",
    "title": "Java Configuration",
    "body": "\n\nBack\n\n\nJava Configuration\n\n\n\n\nWe are going to show the DemoAppConfig.java that holds the base configuration of our application:\n\n\npackage com.springsecurity.demo.config;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.servlet.ViewResolver;\nimport org.springframework.web.servlet.config.annotation.EnableWebMvc;\nimport org.springframework.web.servlet.view.InternalResourceViewResolver;\n\n// Tell spring this is a configuration file\n@Configuration\n// Enables annotations\n@EnableWebMvc\n// Search for components in \"com.springsecurity.demo\" package\n@ComponentScan(basePackages=\"com.springsecurity.demo\")\npublic class DemoAppConfig {\n\n\t// define a bean for ViewResolver\n\t@Bean\n\tpublic ViewResolver viewResolver() {\n\t\t\n\t\tInternalResourceViewResolver viewResolver = new InternalResourceViewResolver();\n\t\t\n\t\tviewResolver.setPrefix(\"/WEB-INF/view/\");\n\t\tviewResolver.setSuffix(\".jsp\");\n\t\t\n\t\treturn viewResolver;\n\t}\n}\n\n\n\nAs you can see we have defined a ViewResolver that prepends /WEB-INF/view/ to every view, and appends .jsp to every view.\n\n\nWeb App Initializer\n\n\nSpring MVC provides support for web app initialization, and makes sure your code is automatically detected. Your code is used to initialize the servlet container. \n\n\n\nAs an example:\n\n\npackage com.springsecurity.demo.config;\n\nimport org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;\n\npublic class MySpringMvcDispatcherServletInitializer extends AbstractAnnotationConfigDispatcherServletInitializer {\n\n\t@Override\n\tprotected Class<?>[] getRootConfigClasses() {\n\t\t// TODO Auto-generated method stub\n\t\treturn null;\n\t}\n\n\t@Override\n\t// Tell spring where the configuration for the servlet is\n\tprotected Class<?>[] getServletConfigClasses() {\n\t\treturn new Class[] { DemoAppConfig.class };\n\t}\n\n\t@Override\n\t// Map the servlet to the path \"/\"\n\tprotected String[] getServletMappings() {\n\t\treturn new String[] { \"/\" };\n\t}\n\n}\n\n\n\nHere is the correspondence with the xml servlet configuration file:\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/Log Out.html",
    "title": "Log Out",
    "body": "\n\nBack\n\n\nLog Out\n\n\n\n\nWe are going to show in this section how to add the logout functionality to our Spring application.\n\n\nConfiguration\n\n\nTo our existing configuration we add:\n\n\npackage com.springsecurity.demo.config;\n\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.core.userdetails.User;\nimport org.springframework.security.core.userdetails.User.UserBuilder;\n\n@Configuration\n@EnableWebSecurity\npublic class DemoSecurityConfig extends WebSecurityConfigurerAdapter {\n\n\t@Override\n\tprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n\n\t\t// add our users for in memory authentication\n\t\tUserBuilder users = User.withDefaultPasswordEncoder();\n\t\t\n\t\tauth.inMemoryAuthentication()\n\t\t\t.withUser(users.username(\"john\").password(\"test123\").roles(\"EMPLOYEE\"))\n\t\t\t.withUser(users.username(\"mary\").password(\"test123\").roles(\"MANAGER\"))\n\t\t\t.withUser(users.username(\"susan\").password(\"test123\").roles(\"ADMIN\"));\n\t}\n\n\t@Override\n\tprotected void configure(HttpSecurity http) throws Exception {\n          // Here is the control of the access to web path\n          http.authorizeRequests()\n          // Require authentication for every request\n            .anyRequest().authenticated()\n            .and()\n            .formLogin()\n            .loginPage(\"/showMyLoginPage\")\n            .loginProcessingUrl(\"/authenticateTheUser\")\n            .permitAll();\n            // Add logout functionality\n            .and()\n            .logout().permitAll()\n\t\t\n\t}\n}\n\n\n\nThe default url for logging out is /logout.\n\n\nLog Out Button\n\n\nNow we create the logout button in our home page:\n\n\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<html>\n<head>\n\t<title>luv2code Company Home Page</title>\n</head>\n<body>\n\t<h2>luv2code Company Home Page</h2>\n\t<hr>\n\t<p>\n\tWelcome to the luv2code company home page!\n\t</p>\n\t<!-- Add a logout button: it point to \"/logout\" endpoint -->\n\t<form:form action=\"${pageContext.request.contextPath}/logout\" \n\t\t\t   method=\"POST\">\n\t\t<input type=\"submit\" value=\"Logout\" />\n\t</form:form>\n</body>\n</html>\n\n\n\nNote that the logout logic is handled directly by spring, what it does is:\n\n\n\n\nInvalidate the user's HTTP session and remove cookies, etc.\n\n\nSends the user back to the login page\n\n\nAppends a logout parameter: ?logout\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/Authorization.html",
    "title": "Authorization",
    "body": "\n\nBack\n\n\nAuthorization\n\n\n\n\nIn this section we are going to show how to restrict access based on roles. Our example follows the following scheme:\n\n\n\n\n\n\n\nWhere only MANAGERS and above can access the /leaders endpoint and only ADMINS can access the /systems endpoint.\n\n\nCreate Controllers\n\n\nWe create a basic controller for every endpoint:\n\n\npackage com.springsecurity.demo.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\n\n@Controller\npublic class DemoController {\n\n\t// add request mapping for index page \n\t@GetMapping(\"/\")\n\tpublic String showHome() {\n\t\t\n\t\treturn \"home\";\n\t}\n\t\n\t// add request mapping for /leaders\n\t@GetMapping(\"/leaders\")\n\tpublic String showLeaders() {\n\t\t\n\t\treturn \"leaders\";\n\t}\n\t\n\t// add request mapping for /systems\n\t@GetMapping(\"/systems\")\n\tpublic String showSystems() {\n\t\t\n\t\treturn \"systems\";\n\t}\n\t\n}\n\n\n\nWe also create a controller for the /acess-denied endpoint:\n\n\npackage com.springsecurity.demo.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\n\n@Controller\npublic class LoginController {\n\n\t@GetMapping(\"/showMyLoginPage\")\n\tpublic String showMyLoginPage() {\n\t\t\n\t\t// return \"plain-login\";\n\t\treturn \"fancy-login\";\n\t}\n\t\n\t// add request mapping for /access-denied\n\t@GetMapping(\"/access-denied\")\n\tpublic String showAccessDenied() {\n\t\t\n\t\treturn \"access-denied\";\n\t}\n}\n\n\nDefine User Roles and Restrict Accessand Restrict Access\n\n\nIn our configuration file we had saved in-memory a list of users with some defined roles, we are going to update it to have more roles. We are also going to define the authorization scheme we showed earlier.\n\n\npackage com.springsecurity.demo.config;\n\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.core.userdetails.User;\nimport org.springframework.security.core.userdetails.User.UserBuilder;\n\n@Configuration\n@EnableWebSecurity\npublic class DemoSecurityConfig extends WebSecurityConfigurerAdapter {\n\n  @Override\n  protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n\n    // add our users for in memory authentication\n    UserBuilder users = User.withDefaultPasswordEncoder();\n    \n    // add more roles\n    auth.inMemoryAuthentication()\n      .withUser(users.username(\"john\").password(\"test123\").roles(\"EMPLOYEE\"))\n      .withUser(users.username(\"mary\").password(\"test123\").roles(\"EMPLOYEE\", \"MANAGER\"))\n      .withUser(users.username(\"susan\").password(\"test123\").roles(\"EMPLOYEE\", \"ADMIN\"));\n  }\n  \n  @Override\n  protected void configure(HttpSecurity http) throws Exception {\n  \n    // Handle requests\n    http.authorizeRequests()\n      // Set role for index page\n      .antMatchers(\"/\").hasRole(\"EMPLOYEE\")\n      // Set role for leaders page\n      .antMatchers(\"/leaders/**\").hasRole(\"MANAGER\")\n      // Set role for systems page\n      .antMatchers(\"/systems/**\").hasRole(\"ADMIN\")\n      .and()\n      .formLogin()\n      .loginPage(\"/showMyLoginPage\")\n      .loginProcessingUrl(\"/authenticateTheUser\")\n      .permitAll()\n      .and()\n      .logout().permitAll()\n      // also define the page where the user is redirected if it does not have access to the resource it requests\n      .and()\n      .exceptionHandling().accessDeniedPage(\"/access-denied\");\n  }\n}\n\n\nDisplay Content based on Roles\n\n\nIn our home page, we add two conditionals so only managers can see the link to the leaders page, and only admins can see the link to the systems page:\n\n\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<%@ taglib prefix=\"security\" uri=\"http://www.springframework.org/security/tags\" %>\n<html>\n<head>\n\t<title>luv2code Company Home Page</title>\n</head>\n<body>\n\t<h2>luv2code Company Home Page</h2>\n\t<hr>\n\t<p>\n\tWelcome to the luv2code company home page!\n\t</p>\n\t<hr>\n\t<!-- display user name and role -->\n\t<p>\n\t\tUser: <security:authentication property=\"principal.username\" />\n\t\t<br><br>\n\t\tRole(s): <security:authentication property=\"principal.authorities\" />\n\t</p>\n\t<!-- Check if user has the manager role, if so show the link -->\n\t<security:authorize access=\"hasRole('MANAGER')\">\n\t\t<!-- Add a link to point to /leaders ... this is for the managers -->\n\t\t<p>\n\t\t\t<a href=\"${pageContext.request.contextPath}/leaders\">Leadership Meeting</a>\n\t\t\t(Only for Manager peeps)\n\t\t</p>\n\t</security:authorize>\t\n\t<!-- Check if user has the admin role, if so show the link -->\n\t<security:authorize access=\"hasRole('ADMIN')\">  \n\t\t<!-- Add a link to point to /systems ... this is for the admins -->\n\t\t<p>\n\t\t\t<a href=\"${pageContext.request.contextPath}/systems\">IT Systems Meeting</a>\n\t\t\t(Only for Admin peeps)\n\t\t</p>\n\t</security:authorize>\n\t<hr>\n\t<!-- Add a logout button -->\n\t<form:form action=\"${pageContext.request.contextPath}/logout\" \n\t\t\t   method=\"POST\">\n\t\t<input type=\"submit\" value=\"Logout\" />\n\t</form:form>\n</body>\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/JDBC Database Authentication.html",
    "title": "JDBC Database Authentication",
    "body": "\n\nBack\n\n\nJDBC Database Authentication\n\n\n\n\n\nSpring Security can read user account info from Database\n\n\nBy default, you have to follow Spring Security's predefined table schemas.\n\n\nYou can customize the table schemas, but you will be responsible for writing the code to access the data.\n\n\n\nSet Up Database\n\n\nThe tables we have to create are the following:\n\n\n\n\n\n\nPassword Encryption\n\n\nIn Spring Security 5, passwords are stored using a specific format:\n\n\n{id}encodedPassword\n\n\n\nThe id references the operation used to encrypt the password:\n\n\n\n\nnoop: plain text. So the password is stored as follows in the database:\n{noop}test123\n\n\n\nbcrypt: BCrypt password hashing. So the password is stored as follows in the database:\n{bcrypt}$2a$12$R9h/cIPz0gi.URNNX3kh2OPST9/PgBkqquzi.Ss7KIUgO2t0jWMUW\n\n\n\netc.\n\n\n\nAdd Dependiencies\n\n\nWe define the dependencies in our pom.xmlfile that are needed to add support to connect to databases:\n\n\n\t\t<!-- Add MySQL and C3P0 support -->\n\n\t\t<dependency>\n\t\t\t<groupId>mysql</groupId>\n\t\t\t<artifactId>mysql-connector-java</artifactId>\n\t\t\t<version>8.0.16</version>\n\t\t</dependency>\n\t\t\n\t\t<dependency>\n\t\t\t<groupId>com.mchange</groupId>\n\t\t\t<artifactId>c3p0</artifactId>\n\t\t\t<version>0.9.5.4</version>\n\t\t</dependency>\n\n\nJDBC Properties files\n\n\nInside /src/main/resources we create the properties file persistence-mysql.properties for our database connections:\n\n\n#\n# JDBC connection properties\n#\njdbc.driver=com.mysql.jdbc.Driver\njdbc.url=jdbc:mysql://localhost:3306/spring_security_demo_plaintext?useSSL=false\njdbc.user=springstudent\njdbc.password=springstudent\n\n#\n# Connection pool properties\n#\nconnection.pool.initialPoolSize=5\nconnection.pool.minPoolSize=5\nconnection.pool.maxPoolSize=20\nconnection.pool.maxIdleTime=3000\n\n\nSpring Security Configuration\n\n\nWe have to modify our main configuration class, to include our database properties file and create the datasource\n\n\npackage com.luv2code.springsecurity.demo.config;\n\nimport java.beans.PropertyVetoException;\nimport java.util.logging.Logger;\n\nimport javax.sql.DataSource;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.PropertySource;\nimport org.springframework.core.env.Environment;\nimport org.springframework.web.servlet.ViewResolver;\nimport org.springframework.web.servlet.config.annotation.EnableWebMvc;\nimport org.springframework.web.servlet.view.InternalResourceViewResolver;\n\nimport com.mchange.v2.c3p0.ComboPooledDataSource;\n\n@Configuration\n@EnableWebMvc\n@ComponentScan(basePackages=\"com.luv2code.springsecurity.demo\")\n@PropertySource(\"classpath:persistence-mysql.properties\")\npublic class DemoAppConfig {\n\n\t// set up variable to hold the properties\n\t@Autowired\n\tprivate Environment env;\n\t\n\t// set up a logger for diagnostics\n\tprivate Logger logger = Logger.getLogger(getClass().getName());\n\t\n\t\n\t// define a bean for ViewResolver\n\t@Bean\n\tpublic ViewResolver viewResolver() {\n\t\t\n\t\tInternalResourceViewResolver viewResolver = new InternalResourceViewResolver();\n\t\t\n\t\tviewResolver.setPrefix(\"/WEB-INF/view/\");\n\t\tviewResolver.setSuffix(\".jsp\");\n\t\t\n\t\treturn viewResolver;\n\t}\n\t\n\t// define a bean for our security datasource\n\t\n\t@Bean\n\tpublic DataSource securityDataSource() {\n\t\t\n\t\t// create connection pool\n\t\tComboPooledDataSource securityDataSource\n\t\t\t\t\t\t\t\t\t= new ComboPooledDataSource();\n\t\t\t\t\n\t\t// set the jdbc driver class\n\t\ttry {\n      // Obtain driver from properties file\n\t\t\tsecurityDataSource.setDriverClass(env.getProperty(\"jdbc.driver\"));\n\t\t} catch (PropertyVetoException exc) {\n\t\t\tthrow new RuntimeException(exc);\n\t\t}\n\t\t\n\t\t\n    // Obtain database info from properties file\n\t\tlogger.info(\">>> jdbc.url=\" + env.getProperty(\"jdbc.url\"));\n\t\tlogger.info(\">>> jdbc.user=\" + env.getProperty(\"jdbc.user\"));\n\t\t\n\t\t\n\t\t// set database connection props\n\t\tsecurityDataSource.setJdbcUrl(env.getProperty(\"jdbc.url\"));\n\t\tsecurityDataSource.setUser(env.getProperty(\"jdbc.user\"));\n\t\tsecurityDataSource.setPassword(env.getProperty(\"jdbc.password\"));\n\t\t\n\t\t// set connection pool props\n\t\tsecurityDataSource.setInitialPoolSize(\n\t\t\t\tgetIntProperty(\"connection.pool.initialPoolSize\"));\n\n\t\tsecurityDataSource.setMinPoolSize(\n\t\t\t\tgetIntProperty(\"connection.pool.minPoolSize\"));\n\n\t\tsecurityDataSource.setMaxPoolSize(\n\t\t\t\tgetIntProperty(\"connection.pool.maxPoolSize\"));\n\n\t\tsecurityDataSource.setMaxIdleTime(\n\t\t\t\tgetIntProperty(\"connection.pool.maxIdleTime\"));\n\t\t\n\t\treturn securityDataSource;\n\t}\n\t\n\t// need a helper method \n\t// read environment property and convert to int\n\t\n\tprivate int getIntProperty(String propName) {\n\t\t\n\t\tString propVal = env.getProperty(propName);\n\t\t\n\t\t// now convert to int\n\t\tint intPropVal = Integer.parseInt(propVal);\n\t\t\n\t\treturn intPropVal;\n\t}\n}\n\n\n\nNow in our security configuration we do two things:\n\n\n\n\nInject the datasource we defined previouly that holds authentication information\n\n\nTell Spring to use JDBC for authentication\n\n\n\npackage com.springsecurity.demo.config;\n\nimport javax.sql.DataSource;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.core.userdetails.User;\nimport org.springframework.security.core.userdetails.User.UserBuilder;\n\n@Configuration\n@EnableWebSecurity\npublic class DemoSecurityConfig extends WebSecurityConfigurerAdapter {\n\n\t// add a reference to our security data source\n\t@Autowired\n\tprivate DataSource securityDataSource;\n\t\n\t\n\t@Override\n\tprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n\n\t\t// use jdbc authentication \n\t\tauth.jdbcAuthentication().dataSource(securityDataSource);\n\t\t\n\t}\n\n\t@Override\n\tprotected void configure(HttpSecurity http) throws Exception {\n\n\t\thttp.authorizeRequests()\n\t\t\t.antMatchers(\"/\").hasRole(\"EMPLOYEE\")\n\t\t\t.antMatchers(\"/leaders/**\").hasRole(\"MANAGER\")\n\t\t\t.antMatchers(\"/systems/**\").hasRole(\"ADMIN\")\n\t\t\t.and()\n\t\t\t.formLogin()\n\t\t\t\t.loginPage(\"/showMyLoginPage\")\n\t\t\t\t.loginProcessingUrl(\"/authenticateTheUser\")\n\t\t\t\t.permitAll()\n\t\t\t.and()\n\t\t\t.logout().permitAll()\n\t\t\t.and()\n\t\t\t.exceptionHandling().accessDeniedPage(\"/access-denied\");\n\t\t\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/index.html",
    "title": "Overview",
    "body": "\n\nBack\n\n\nOverview\n\n\n\n\n\nSpring Security is implemented using Servlet filters in the background \n\n\nThere are two methods of securing a Web App:\n\n\n\nDeclarative\n\n\nProgrammatic\n\n\n\n\nServlet Filters\n\n\nServlet filters are used to pre-process/post-process web requests. \n\n\n\n\nThey can route web requests based on security logic.\n\n\nSpring provides a bulk of security functionality with servlet filters.\n\n\n\n\nThis is described in the following picture:\n\n\n\n\n\n\n\nWe can see Spring intercepts the request to /mytopsecretstuff and uses the app's security configuration, alongside information about the user, passwords and roles to pre and post-process the request.\n\n\nSpring Security in Action\n\n\nNext we show a flowchart of the pre-processing made by Spring Security Filters:\n\n\n\n\n\n\n\n\nIf the resource is protected we go to step (2), else we go to step (4)\n\n\nIf the user is authenticated we go to step (3), else we go to step (6)\n\n\nIf the user is authorized to access the resource we go to step (4), else we go to step (5)\n\n\nThe resource is shown to the user\n\n\nThe access to the resource is denied\n\n\nWe send the user to the login page, if the user logins correctly we go to step (3)\n\n\n\nDeclarative Security\n\n\nYou define your application's security constraints in configuration. For that, you can either:\n\n\n\n\nUse all Java configuration (@Configuration)\n\n\nUse a Spring configuration file (XML)\n\n\n\nProgrammatic Security\n\n\nYou can also do it programmatically:\n\n\n\n\nSpring Security provides an API for custom application coding.\n\n\nIt also provides greater customization for specific apps.\n\n\n\nAuthentication/Authorization\n\n\nInformation about users/passwords/roles, etc can be stored:\n\n\n\n\nIn-memory\n\n\nJDBC\n\n\nLDAP\n\n\nCustom\n\n\netc\n\n\n\nMaven Dependencies\n\n\nTo use this framework, you have to add the following dependency to your project:\n\n\n\t<dependencies>\n\n    ...\n\t\t<!-- Spring Security -->\n\t\t<!-- spring-security-web and spring-security-config -->\n\t\t\n\t\t<dependency>\n\t\t    <groupId>org.springframework.security</groupId>\n\t\t    <artifactId>spring-security-web</artifactId>\n\t\t    <version>${springsecurity.version}</version>\n\t\t</dependency>\n    \n    ...\n    \n\t<dependencies>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Security/Basic Security.html",
    "title": "Basic Security",
    "body": "\n\nBack\n\n\nBasic Security\n\n\n\nCreate Security Spring Initializer\n\n\nSpring security provides support for security initialization. Your security code is used to initialize the servlet container. There is a special class to register the Spring Security Filters.\n\n\n\nYou need this class for the Spring Security Filters to \"activate\". Next we show an example:\n\n\npackage com.springsecurity.demo.config;\n\nimport org.springframework.security.web.context.AbstractSecurityWebApplicationInitializer;\n\npublic class SecurityWebApplicationInitializer \n\t\t\t\t\t\textends AbstractSecurityWebApplicationInitializer {\n\n}\n\n\nCreate Spring Security Configuration (@Configuration)\n\n\nNow we create our spring security configuration file:\n\n\npackage com.springsecurity.demo.config;\n\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.core.userdetails.User;\nimport org.springframework.security.core.userdetails.User.UserBuilder;\n\n// Tell spring this is a configuration file\n@Configuration\n@EnableWebSecurity\npublic class DemoSecurityConfig extends WebSecurityConfigurerAdapter {\n\t@Override\n\tprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n\n\t\t// add our users for in memory authentication (this is for test purposes only, you would usually retrieve this information encrypted from the database)\n\t\tUserBuilder users = User.withDefaultPasswordEncoder();\n\t\t\n    // Use the AuthenticationManagerBuilder given by Spring to handle authentication\n\t\tauth\n\t\t\t.inMemoryAuthentication()\n\t\t\t.withUser(users.username(\"john\").password(\"test123\").roles(\"EMPLOYEE\"))\n\t\t\t.withUser(users.username(\"mary\").password(\"test123\").roles(\"MANAGER\"))\n\t\t\t.withUser(users.username(\"susan\").password(\"test123\").roles(\"ADMIN\"));\n\t}\n}\n\n\nAdd users, passwords and roles\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Configuration/Inversion of Control.html",
    "title": "Inversion of Control",
    "body": "\n\nBack\n\n\nInversion of Control\n\n\n\n\nTo define a bean, we now use our configuration class:\n\n\nCreate the Bean\n\npackage com.springdemo;\n\n// Note there are no special annotations\npublic class SwimCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\n\n\tpublic SwimCoach(FortuneService theFortuneService) {\n\t\tfortuneService = theFortuneService;\n\t}\n\t\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Swim 1000 meters as a warm up.\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n\n}\n\n\n\nWe also create the SadFortuneService Bean:\n\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class SadFortuneService implements FortuneService {\n\n\t@Override\n\tpublic String getFortune() {\n\t\treturn \"Today is a sad day :(\";\n\t}\n\n}\n\n\nDefine the Bean in the Configuration Class\n\npackage com.springdemo;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class SportConfig {\n\t\n\t// define bean for our sad fortune service\n\t@Bean\n\tpublic FortuneService sadFortuneService() {\n\t\treturn new SadFortuneService();\n\t}\n\t\n\t// define bean for our swim coach AND inject dependency\n  // without springs dependency injection\n\t@Bean\n\tpublic Coach swimCoach() {\n\t\tSwimCoach mySwimCoach = new SwimCoach(sadFortuneService());\n\t\t\n\t\treturn mySwimCoach;\n\t}\n\t\n}\n\n\n\n\nThe @Bean annotation tells Spring that we are creating a bean component manually. We didn't specify a scope so the default scope is singleton.\n\n\npublic Coach swimCoach(){ specifies that the bean will bean id of \"swimCoach\".\n\n\nThe @Bean annotation will intercept any requests for \"swimCoach\" bean. Since we didn't specify a scope, the bean scope is singleton.\n\n\n\n\nSo now in our main method:\n\n\nMain Method\n\npackage com.luv2code.springdemo;\n\nimport org.springframework.context.annotation.AnnotationConfigApplicationContext;\n\npublic class JavaConfigDemoApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config java class\n\t\tAnnotationConfigApplicationContext context = \n\t\t\t\tnew AnnotationConfigApplicationContext(SportConfig.class);\n\t\t\n\t\t// get the bean from spring container by its id\n\t\tCoach theCoach = context.getBean(\"swimCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t\t\t\t\n\t\t// call method to get the daily fortune\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t\t\n\t}\n\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Configuration/index.html",
    "title": "Spring Configuration with Java",
    "body": "\n\nBack\n\n\nSpring Configuration with Java\n\n\n\n\nWe are now going to use Java to configure our application instead of using XML, to do that we follow the next steps:\n\n\n\n\nCreate a Java class and annotate as @Configuration\n\n\nAdd Component scanning support with @ComponentScan (optional), which is XML we did as:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    ....>\n\t<!-- add entry to enable component scanning -->\n\t<context:component-scan base-package=\"com.springdemo\" />\n\n</beans>\n\n\n\nIn the main app read the Spring Java configuration class\n\n\n\n\n\n\n\nConfiguration With Java\n\n\n\n\n \n\n\nInversion of Control\n\n\nLoad Properties from File\n\n\nDependency Injection\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Configuration/Configuration With Java.html",
    "title": "Configuration With Java",
    "body": "\n\nBack\n\n\nConfiguration With Java\n\n\n\nCreate Configuration Class\n\npackage com.springdemo;\n\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.context.annotation.Configuration;\n\n// 1. Define configuration class\n@Configuration\n// 2. Add component scanning support\n@ComponentScan(\"com.springdemo\")\npublic class SportConfig {\n\t\n}\n\n\n\nLoad the Configuration Class\n\npackage com.springdemo;\n\nimport org.springframework.context.annotation.AnnotationConfigApplicationContext;\n\npublic class JavaConfigDemoApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config java class\n\t\tAnnotationConfigApplicationContext context = \n\t\t\t\tnew AnnotationConfigApplicationContext(SportConfig.class);\n\t\t\n\t\t// get the bean from spring container\n\t\tCoach theCoach = context.getBean(\"tennisCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t\t\t\t\n\t\t// call method to get the daily fortune\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t\t\n\t}\n\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Configuration/Load Properties from File.html",
    "title": "Load Properties from File",
    "body": "\n\nBack\n\n\nLoad Properties from File\n\n\nIn order to inject values read from a properties file we do the following:\n\n\nCreate the File\n\n\nFirst, we create the file sport.properties\n\n\nfoo.email=myeasycoach@luv2code.com\nfoo.team=Awesome Java Coders\n\n\nLoad the File\n\n\nNow, we load the file from our Configuration class:\n\n\npackage com.springdemo;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.PropertySource;\nimport org.springframework.context.support.PropertySourcesPlaceholderConfigurer;\n\n@Configuration\n@PropertySource(\"classpath:sport.properties\")\npublic class SportConfig {\n\t\n\t// define bean for our sad fortune service\n\t@Bean\n\tpublic FortuneService sadFortuneService() {\n\t\treturn new SadFortuneService();\n\t}\n\t\n\t// define bean for our swim coach AND inject dependency\n\t@Bean\n\tpublic Coach swimCoach() {\n\t\tSwimCoach mySwimCoach = new SwimCoach(sadFortuneService());\n\t\t\n\t\treturn mySwimCoach;\n\t}\n\t\n}\n\n\nInject Values\n\n\nWe inject the values at field level in our Bean:\n\n\npackage com.springdemo;\n\nimport org.springframework.beans.factory.annotation.Value;\n\npublic class SwimCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\n\n\t@Value(\"${foo.email}\")\n\tprivate String email;\n\t\n\t@Value(\"${foo.team}\")\n\tprivate String team;\n  ...\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/XML configuration file.html",
    "title": "Configure Spring Container with an XML file",
    "body": "\n\nBack\n\n\nConfigure Spring Container with an XML file\n\n\n\n\n\nFirst we create the config file\n\n\n\n<beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\">\n<!--  Define your beans here  -->\n<bean id=\"myCoach\" class=\"com.luv2code.springdemo.TrackCoach\"> </bean>\n</beans>\n\n\n\n\nThen we create the Spring container in our application:\n\n\n\npackage com.springdemo;\n\n/* Class to create a spring container using xml files */\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class MyApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// load the spring configuration file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\t\t\n\t\t// retrieve bean from spring container by its id\n\t\tCoach theCoach = context.getBean(\"myCoach\", Coach.class);\n\t\t\n\t\t// call methods on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Maven/POM File Structure.html",
    "title": "POM File Structure",
    "body": "\n\nBack\n\n\nPOM File Structure\n\n\n\n\nThe POM File has the following structure:\n\n\n\n\nProject metadata: information about the project\n\n\nDependencies: list of dependencies for the project\n\n\nPlug-ins: additional custom tasks to run (JUnit tests, reports, etc)\n\n\n\n\n\n\n\nProject Coordinates\n\n\nProject coordinates uniquely identify a project:\n\n\n\n\n\n\n\nWhere:\n\n\n\n\nGroup ID: name of company, group or organization\n\n\nArtifact ID: name for the project\n\n\nVersion: a specific release version\n\n\n\nDependency Coordinates\n\n\nTo add a given dependency project, we need:\n\n\n\n\nGroup ID\n\n\nArtifact ID\n\n\nOptional: version (best practice to include the version)\n\n\n\nFind Dependencies\n\n\nSearch Maven\nMaven Repository\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Maven/Overview.html",
    "title": "Maven",
    "body": "\n\nBack\n\n\nMaven\n\n\n\n\nMaven is a project management tool. The most popular use of Maven is for build management and dependencies.\n\n\n\nBehind the scenes what Maven does is:\n\n\n\n\nReads the configuration file of our application: pom.xml\n\n\nChecks on the local repository if the library is already stored (like a cache)\n\n\nIf not, it goes to the remote repository and searches for it\n\n\nThen it saves it to the local repository\n\n\nFinally it uses the downloaded library to build and run the application\n\n\n\n\n\n\n\n\nMaven also downloads the libraries' dependencies. And when you build and run your application, maven will handle the class/build path for you, based on the configuration file.\n\n\n\nStandard Directory Structure\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Maven/Private Repositories.html",
    "title": "Private Repositories",
    "body": "\n\nBack\n\n\nPrivate Repositories\n\n\n\n\nIf you want to create repositories with restricted access you can:\n\n\n\n\nSet up your own private Maven Repository in your server, that is secure with credentials: id/password\n\n\n\n\nSome Maven repository manager products are:\n\n\n\n\nArchiva\n\n\nArtifactory\n\n\nNexus\n\n\n\n\nIf you do not want to create your own server, there are also cloud based solutions like:\n\n\n\n\nPackage Cloud\n\n\nMy Maven Repo\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Maven/Maven Archetypes.html",
    "title": "Maven Archetypes",
    "body": "\n\nBack\n\n\nMaven Archetypes\n\n\n\n\nArchetypes are used to create new Maven projects, you can think of them as starter projects. Some archetypes are:\n\n\n\n\nFor standalone projects: maven-archetype-quickstart\n\n\nFor web projects: maven-archetype-webapp\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Maven/Additional Repositories.html",
    "title": "Additional Repositories",
    "body": "\n\nBack\n\n\nAdditional Repositories\n\n\n\n\nAs we have said, if Maven does not find some dependency in your local repository it goes to the central repository to search for it. But what if the dependency is not in the central repository. Then we have to define the repository in our pom.xml:\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Bean Scopes/Life Cycle.html",
    "title": "Bean Life Cycle",
    "body": "\n\nBack\n\n\nBean Life Cycle\n\n\n\n\nThe bean life cycle is as follows:\n\n\n\n\n\n\n\nAs you can see you can add method/hooks:\n\n\n\n\nAdd custom code during bean initialization \n\n\n\nCalling business logic methods\n\n\nSetting up handles to resources (db, sockets, etc)\n\n\n\nAdd custom code during bean destruction\n\n\n\nCalling business logic methods\n\n\nClean up handles to resources (db, sockets, etc)\n\n\n\n\nDefine Methods\n\n\nFirst of all we define the methods in our bean:\n\n\npackage com.springdemo;\n\npublic class TrackCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\n\n\tpublic TrackCoach() {\n\t\t\n\t}\n\t\n\tpublic TrackCoach(FortuneService fortuneService) {\n\t\tthis.fortuneService = fortuneService;\n\t}\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Run a hard 5k\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn \"Just Do It: \" + fortuneService.getFortune();\n\t}\n\n\t// add an init method\n\tpublic void doMyStartupStuff() {\n\t\tSystem.out.println(\"TrackCoach: inside method doMyStartupStuff\");\n\t}\n\t\n\t// add a destroy method\n\tpublic void doMyCleanupStuffYoYo() {\n\t\tSystem.out.println(\"TrackCoach: inside method doMyCleanupStuffYoYo\");\t\t\n\t}\n}\n\n\n\nConfigure Hooks in the Configuration File\n\n\nOnce the initialization and clean-up methods have been defined, we configure them in our configuration file:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\">\n\n\t<!-- Define your beans here -->\n\t\n\t<!-- define the dependency -->\n\t<bean id=\"myFortuneService\"\n\t  class=\"com.springdemo.HappyFortuneService\">\n\t</bean>\n\t  \n\t<!-- Note the new tag \"scope\" -->\n\t<bean id=\"myCoach\"\n\tclass=\"com.springdemo.TrackCoach\"\n\t\tinit-method=\"doMyStartupStuff\"\n\t\tdestroy-method=\"doMyCleanupStuffYoYo\">\t\n\t\t\n\t\t<!-- set up constructor injection -->\n\t\t<constructor-arg ref=\"myFortuneService\" />\n\t</bean>\n    \n</beans>\n\n\nMain Method\n\n\nNow in our App, we create the bean to check that our methods are being called:\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class BeanLifeCycleDemoApp {\n\t\n\tpublic static void main(String[] args) {\n\n\t\t// load the spring configuration file\n\t\tClassPathXmlApplicationContext context =\n\t\t\t\tnew ClassPathXmlApplicationContext(\"beanLifeCycle-applicationContext.xml\");\n\t\t\t\t\n\t\t// retrieve bean from spring container\n\t\tCoach theCoach = context.getBean(\"myCoach\", Coach.class);\n\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n\n}\n\n\nNotes\n\n\nWhen using XML configuration, I want to provide additional details regarding the method signatures of the init-method  and destroy-method .\n\n\n\n\nAccess modifier: The method can have any access modifier (public, protected, private)\n\n\nReturn type: The method can have any return type. However, \"void' is most commonly used. If you give a return type just note that you will not be able to capture the return value. As a result, \"void\" is commonly used.\n\n\nMethod name: The method can have any method name.\n\n\nArguments: The method can not accept any arguments. The method should be no-arg.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Bean Scopes/Bean Scopes and Life cycle.html",
    "title": "Spring Bean Scopes and Life Cycle",
    "body": "\n\nBack\n\n\nSpring Bean Scopes and Life Cycle\n\n\n\n\n\nScope\n\n\nLife Cycle\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Bean Scopes/Scope.html",
    "title": "Bean Scopes",
    "body": "\n\nBack\n\n\nBean Scopes\n\n\n\nIntro\n\n\nThe scope of a bean refers to the life cycle of the bean:\n\n\n\n\nHow long does it live\n\n\nHow many instances are created\n\n\nHow is the bean shared\n\n\n\n\n\n\nThe default scope of the bean is a Singleton:\n\n\n\n\nThe Spring container creates only one instance of the bean\n\n\nIt is cached in memory\n\n\nAll requests to the bean will return a shared reference to the same bean\n\n\n\n\nOther scopes are:\n\n\n\n\n\n\n\n\nA singleton scope is good for stateless data\n\n\nA prototype scope is good for stateful data (the container returns a new bean for each request). Note that for this type of bean, Spring does not call the destroy method.\n\n\n\n\n\nSpecify Scope in XML Config File\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\">\n\n  <!-- Define your beans here -->\n  \n  <!-- define the dependency -->\n  <bean id=\"myFortuneService\"\n    class=\"com.springdemo.HappyFortuneService\">\n  </bean>\n    \n  <!-- Note the new tag \"scope\" -->\n  <bean id=\"myCoach\"\n    class=\"com.springdemo.TrackCoach\"\n    scope=\"prototype\">\t\n    \n    <!-- set up constructor injection -->\n    <constructor-arg ref=\"myFortuneService\" />\n  </bean>\n    \n</beans>\n\n\nMain Method\n\n\nNow, from our application we do:\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class BeanScopeDemoApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// load the spring configuration file\n\t\tClassPathXmlApplicationContext context =\n\t\t\t\tnew ClassPathXmlApplicationContext(\"beanScope-applicationContext.xml\");\n\t\t\t\t\n\t\t// retrieve bean from spring container\n\t\tCoach theCoach = context.getBean(\"myCoach\", Coach.class);\n\n\t\tCoach alphaCoach = context.getBean(\"myCoach\", Coach.class);\n\t\t\n\t\t// check if they are the same\n\t\tboolean result = (theCoach == alphaCoach);\n\t\t\n\t\t// print out the results\n\t\tSystem.out.println(\"\\nPointing to the same object: \" + result);\n\t\t\n\t\tSystem.out.println(\"\\nMemory location for theCoach: \" + theCoach);\n\n\t\tSystem.out.println(\"\\nMemory location for alphaCoach: \" + alphaCoach + \"\\n\");\n\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n\n\nObserve, the result variable should be set to false, because we are using the prototype scope. Also the values of the memory location for the two objects should be distinct for that same reason.\n\n\n\nHowever if we were using scope=\"singleton\", then result should be true, and both objects should have the same memory location.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Resources.html",
    "title": "Add CSS and JS",
    "body": "\n\nBack\n\n\nAdd CSS and JS\n\n\n\n\nHere are the steps on how to access static resources in a Spring MVC. For example, you can use this to access images, css, JavaScript files etc.\n\n\n\nYou can configure references to static resources in the spring-mvc-demo-servlet.xml.\n\n\n\n\nAdd the following entry to your Spring MVC configuration file: spring-mvc-demo-servlet.xml\n\n\n\n<mvc:resources mapping=\"/resources/**\" location=\"/resources/\"></mvc:resources>\n\n\n\n\nNow in your view pages, you can access the static files using this syntax:\n\n\n\n<img src=\"${pageContext.request.contextPath}/resources/images/spring-logo.png\">\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Request Params and Request Mappings.html",
    "title": "Request Params and Request Mappings",
    "body": "\n\nBack\n\n\nRequest Params and Request Mappings\n\n\n\nRequest Params\n\n\nSpring provides for a specific annotation that allows you to retrieve request parameters directly without using the HttpServletRequest object. Given the form:\n\n\npackage com.springdemo.mvc;\n\nimport javax.servlet.http.HttpServletRequest;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\n\n@Controller\npublic class HelloWorldController {\n\n\t@RequestMapping(\"/processFormVersionThree\")\t\n\tpublic String processFormVersionThree(\n      // We use the annotation to obtain the parameter\n\t\t\t@RequestParam(\"studentName\") String theName, \n\t\t\tModel model) {\n\t\t\t\t\n\t\t// convert the data to all caps\n\t\ttheName = theName.toUpperCase();\n\t\t\n\t\t// create the message\n\t\tString result = \"Hey My Friend from v3! \" + theName;\n\t\t\n\t\t// add message to the model\n\t\tmodel.addAttribute(\"message\", result);\n\t\t\t\t\n\t\treturn \"helloworld\";\n\t}\t\n}\n\n\nController Request Mappings\n\n\n\nThey serve as a parent mapping for the controller\n\n\nAll request mappings on methods in the controller are relative \n\n\n\n\nFor example:\n\n\npackage com.springdemo.mvc;\n\nimport javax.servlet.http.HttpServletRequest;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\n\n@Controller\n// This is the request mapping for the controller\n@RequestMapping(\"/hello\")\npublic class HelloWorldController {\n\n\t// Both of these request mappings are relative to the parent mapping\n\t// that is the mapping translates to domain/hello/showForm\n\t// need a controller method to show the initial HTML form\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm() {\n\t\treturn \"helloworld-form\";\n\t}\n\t\t\n\t// need a controller method to process the HTML form\n\t@RequestMapping(\"/processForm\")\n\tpublic String processForm() {\n\t\treturn \"helloworld\";\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Validation with Regular Expressions.html",
    "title": "Validation with Regular Expressions",
    "body": "\n\nBack\n\n\nValidation with Regular Expressions\n\n\n\n\nIn this section we will show how to perform a validation with regular expressions.\n\n\nAdd Validation Rule to Bean\n\n\nWe create a Customer class, whose freePasses variable must be a number between 0 and 10.\n\n\npublic class Customer {\n\n\tprivate String firstName;\n\t\n\t@NotNull(message=\"is required\")\n\t@Size(min=1, message=\"is required\")\n\tprivate String lastName;\n  \n\t@Min(value=0, message=\"must be greater than or equal to zero\")\n\t@Max(value=10, message=\"must be less than or equal to 10\")\n\tprivate int freePasses;\n  \n  // Define the regular expression for the postalCode attribute\n  @Pattern(regexp=\"^[a-zA-Z0-9]{5}\", message=\"only 5 chars/digits\")\n\tprivate String postalCode;\n\t\n\t...\n\n\n\nPerform Validation in the Controller\n\n\nWe also \n\n\npackage com.springdemo.mvc;\n\nimport javax.validation.Valid;\n\nimport org.springframework.beans.propertyeditors.StringTrimmerEditor;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.validation.BindingResult;\nimport org.springframework.web.bind.WebDataBinder;\nimport org.springframework.web.bind.annotation.InitBinder;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/customer\")\npublic class CustomerController {\n\n\t// add an initbinder ... to convert trim input strings\n\t// remove leading and trailing whitespace\n\t// resolve issue for our validation\n\t\n\t@InitBinder\n\t//@InitBinder annotation works as a pre-processor \n\t// It will pre-process each web request to our controller\n\tpublic void initBinder(WebDataBinder dataBinder) {\n\t\t\n\t\t// Trim strings (true: empty strings to null)\n\t\tStringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true);\n\t\n\t\t// For every string class apply the trim editor\n\t\tdataBinder.registerCustomEditor(String.class, stringTrimmerEditor);\n\t}\n\t\n\t\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\ttheModel.addAttribute(\"customer\", new Customer());\n\t\t\n\t\treturn \"customer-form\";\n\t}\n\t\n\t@RequestMapping(\"/processForm\")\n\t// @Valid: Tells spring to perform validation on the customer object\n\t// BindingResult: results of the validation will be placed in BindingResult\n\tpublic String processForm(\n\t\t\t@Valid @ModelAttribute(\"customer\") Customer theCustomer,\n\t\t\tBindingResult theBindingResult) {\n\t\t\n\t\tSystem.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\");\n\t\t\n\t\t// Check if validation was sucessfull\n\t\tif (theBindingResult.hasErrors()) {\n\t\t\t// If not sucessfull send back\n\t\t\treturn \"customer-form\";\n\t\t}\n\t\telse {\n\t\t\t// If sucessfull\n\t\t\treturn \"customer-confirmation\";\n\t\t}\n\t}\n}\n\n\n\nWhen performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute. \n\n\nDisplay error on HTML\n\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<html>\n\n<head>\n\t<title>Customer Registration Form</title>\n\t\n\t<style>\n\t\t.error {color:red}\n\t</style>\n</head>\n<body>\n<i>Fill out the form. Asterisk (*) means required.</i>\n<br><br>\n\t<form:form action=\"processForm\" modelAttribute=\"customer\">\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name (*): <form:input path=\"lastName\" />\n\t\t<form:errors path=\"lastName\" cssClass=\"error\" />\n\t\t<br><br>\n\t\tFree passes: <form:input path=\"freePasses\" />\n\t\t<form:errors path=\"freePasses\" cssClass=\"error\" />\n    <br><br>\n\t\tPostal Code: <form:input path=\"postalCode\" />\n    <!-- The message shown equals the messages from both of the validation annotations defined \n    for the postalCode attribute in the Customer class -->\n\t\t<form:errors path=\"postalCode\" cssClass=\"error\" />\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n\n</body>\n\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Form Validation.html",
    "title": "Form Validation",
    "body": "\n\nBack\n\n\nForm Validation\n\n\n\n\nJava has a standard Bean Validation API that defines a metadata model and an API for entity validation.\n\n\n\nHere is a list of bean validation features you can check:\n\n\n\n\nrequired\n\n\nvalidate length\n\n\nvalidate numbers\n\n\nvalidate with regular expressions\n\n\ncustom validation\n\n\n\n\nSome Annotations to perform the validation are the following:\n\n\n\n\n\n\n\nSet up\n\n\nAdd Hibernate's library (Hibernate Validator)for Bean Validation which is fully compliant with Java's Bean Validation API.\n\n\n\n\n\n\nRequired Validation\n\n\nNumber Range Validation\n\n\nValidation with Regular Expressions\n\n\nHandle String in Integer Field\n\n\nCustom Validation\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Controller.html",
    "title": "Controller",
    "body": "\n\nBack\n\n\nController\n\nCreate Controller Class\n\npackage com.springdemo.mvc;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n// Add controller annotation\n@Controller\npublic class HomeController {\n\t\n\t// Add request mapping: this method controls the request coming to this url\n\t@RequestMapping(\"/\")\n\tpublic String showPage() {\n\t  // Name of the view that is returned: note they are stored in WEB-INF/view/\n\t\treturn \"main-menu\";\n\t}\n}\n\n\n\nNow, we create the view\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Form Tags.html",
    "title": "Form Tags",
    "body": "\n\nBack\n\n\nForm Tags\n\n\n\n\nForm Tags are configurable an reusable:\n\n\n\n\nThey can make use of data binding (you can automatically set and retrieve data from a Java object)\n\n\nYou can mix them in with you HTML web page\n\n\n\n\nSome examples are:\n\n\n\n\n\n\nReference Spring MVC Form Tags\n\n\nTo use these tags in your web page you have to specify the spring namespace at the beginning of the JSP file:\n\n\n<!-- Reference to the namespace -->\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<!DOCTYPE html>\n<html>\n<head></head>\n<body>\n</body>\n</html>\n\n\n\n\n\n\nText Fields\n\n\nDrop Down Lists\n\n\nRadio Buttons\n\n\nCheckBox\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Adding Data.html",
    "title": "Model",
    "body": "\n\nBack\n\n\nModel\n\n\n\n\nThe Model is a container for the application data. So in your controller you can put anything in the model (strings, objects, info from DB, etc). And then you view page (JSP) can access data from the model.\n\n\nExample\n\nController\n\npackage com.springdemo.mvc;\n\nimport javax.servlet.http.HttpServletRequest;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\npublic class HelloWorldController {\n  \n  // new a controller method to read form data and\n  // add data to the model\n  \n  @RequestMapping(\"/processFormVersionTwo\")\t\n  // the HttpServletRequest allows you to retrieve information from the request (like the parameters of a form)\n  // the model is our Model where we will store data\n  public String parseString(HttpServletRequest request, Model model) {\n    \n    // read the request parameter from the HTML form\n    String theName = request.getParameter(\"studentName\");\n    \n    // convert the data to all caps\n    theName = theName.toUpperCase();\n    \n    // create the message\n    String result = \"Yo! \" + theName;\n    \n    // add message attribute to the model\n    model.addAttribute(\"message\", result);\n    \t\t\n    return \"helloworld\";\n  }\n  \n}\n\n\nView\n\n\nNow, on the view, we can access the Model data:\n\n\n<!DOCTYPE html>\n<html>\n<body>\n  Hello World of Spring!\n  <br><br>\n  Student name: ${param.studentName}\n  <br><br>\n  <!-- Access model data by the attribute's name-->\n  The message: ${message}\n</body>\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Read HTML Form Data.html",
    "title": "Read HTML Form Data",
    "body": "\n\nBack\n\n\nRead HTML Form Data\n\n\n\n\nThe flow of our example will be the following:\n\n\n\n\nWhen the user accesses the URL /showForm, the browser will send a request to our controller, and our controller will return the corresponding view\n\n\n\n\n\n\n \n\n\nWhen the user hits submit on the form the action /processForm is passed to the browser that will send a request to our controller, and our controller will process the request\n\n\n\n\n\n\n\nController\n\npackage com.springdemo.mvc;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\npublic class HelloWorldController {\n\n\t// need a controller method to show the initial HTML form\n\t@RequestMapping(\"/showForm\")\n  // The method name can be anything\n\tpublic String showForm() {\n\t\treturn \"helloworld-form\";\n\t}\n\t\t\n\t// need a controller method to process the HTML form\n\t@RequestMapping(\"/processForm\")\n\tpublic String processForm() {\n\t\treturn \"helloworld\";\n\t}\n\t\t\n}\n\n\nView\n\n\nWe create WEB-INF/view/helloworld-form.jsp\n\n\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Hello World - Input Form</title>\n</head>\n\n<body>\n  <!-- The action is the request url -->\n\t<form action=\"processForm\" method=\"GET\">\n\t\t<input type=\"text\" name=\"studentName\"\n\t\t\tplaceholder=\"What's your name?\" />\n\t\t<input type=\"submit\" />\n\t</form>\n</body>\n</html>\n\n\n\nAnd we create WEB-INF/view/helloworld-form.jsp\n\n\n<!DOCTYPE html>\n<html>\n<body>\n  Hello World of Spring!\n  <br><br>\n  <!-- name of HTML form field from previous jsp view -->\n  Student name: ${param.studentName}\n</body>\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Text Fields.html",
    "title": "Text Fields",
    "body": "\n\nBack\n\n\nText Fields\n\n\n\n\nTo pass and bind data from input text fields to controllers an another views we use the Form Tag form:input along with form:form:\n\n\nController\n\n\n\nAdd a Model to the controller method for the form and create the model attribute, that holds the data and perfoms data binding\n\n\n\npackage com.springdemo.mvc;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/student\")\npublic class StudentController {\n\t\n\t// Request to show the view that contains the form\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\t// create a student object\n\t\tStudent theStudent = new Student();\n\t\t\n\t\t// add student object to the model\n\t\ttheModel.addAttribute(\"student\", theStudent);\n\t\t\n\t\treturn \"student-form\";\n\t}\n\t\n\t// Process the submit event on the form\n\t@RequestMapping(\"/processForm\")\n\t// We obtain the model attribute with the following annotation\n\tpublic String processForm(@ModelAttribute(\"student\") Student theStudent) {\n\t\t\n\t\t// Now we can retrieve the updated information from the form\n\t\tSystem.out.println(\"theStudent: \" + theStudent.getFirstName()\n\t\t\t\t\t\t\t+ \" \" + theStudent.getLastName());\n\t\t\n\t\treturn \"student-confirmation\";\n\t}\n}\n\n\nView\n\n\n\nSetting the HTML for data binding:\n\n\n\nFor student-form.jsp:\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Registration Form</title>\n</head>\n<body>\n\t<!-- Note the modelAttribute equals the attribute we added to the model in the controller-->\n\t<form:form action=\"processForm\" modelAttribute=\"student\">\n\t\t<!-- To retrieve the data this maps to student.getFirstName() -->\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name: <form:input path=\"lastName\" />\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n</body>\n\n</html>\n\n\n\n\n\n\nWhen we submit Spring will call student.setFirstName() and student.setLastName() to save the data in the Student object, so we can retrieve it from our controller method.\n\n\n\n\nFor student-confirmation.jsp:\n<%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Confirmation</title>\n</head>\n<body>\n\t<!-- Obtain data from the model: note we use the attribute's name (i.e. student) to access the object -->\n\tThe student is confirmed: ${student.firstName} ${student.lastName}\n</body>\n</html>\n\n\n\n\nModel\n\n\nThe model attribute \"student\" is populated with an instance of the following Student class:\n\n\npackage com.springdemo.mvc;\n\nimport java.util.LinkedHashMap;\n\npublic class Student {\n\n\tprivate String firstName;\n\tprivate String lastName;\n\t\t\n\tpublic Student() {}\n\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Custom Validation.html",
    "title": "Custom Validation",
    "body": "\n\nBack\n\n\nCustom Validation\n\n\n\nCreate a Custom Java Annotation\n\nCreate Annotation Clas\n\npackage com.springdemo.mvc.validation;\n\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\n\nimport javax.validation.Constraint;\nimport javax.validation.Payload;\n\n// Specify the class that holds the validation logic\n@Constraint(validatedBy = CourseCodeConstraintValidator.class)\n// Where you can use this annotation: on a method or on a field\n@Target( { ElementType.METHOD, ElementType.FIELD } )\n@Retention(RetentionPolicy.RUNTIME)\n// Note the @interface (it is needed to create the annotation)\npublic @interface CourseCode {\n\n\t// define default course code\n\tpublic String value() default \"LUV\";\n\t\n\t// define default error message\n\tpublic String message() default \"must start with LUV\";\n\t\n\t// define default groups\n\tpublic Class<?>[] groups() default {};\n\t\n\t// define default payloads\n\tpublic Class<? extends Payload>[] payload() default {};\n}\n\n\nCreate Validator Class\n\n\nThis class holds the validation logic\n\n\npackage com.springdemo.mvc.validation;\n\nimport javax.validation.ConstraintValidator;\nimport javax.validation.ConstraintValidatorContext;\n\n// Implements the previous ConstraintValidator interface, with generics: <Annotation Interface, Data Type>\npublic class CourseCodeConstraintValidator \n\timplements ConstraintValidator<CourseCode, String> {\n\n\tprivate String coursePrefix;\n\t\n\t@Override\n\tpublic void initialize(CourseCode theCourseCode) {\n\t\t// Obtain prefix from the \"value\" attribute of our annotation\n\t\tcoursePrefix = theCourseCode.value();\n\t}\n\n\t@Override\n\t// Called when we use the @Valid annotation\n\tpublic boolean isValid(String theCode, ConstraintValidatorContext theConstraintValidatorContext) {\n\n\t\tboolean result;\n\t\t\n\t\t// Validation logic\n\t\tif (theCode != null) {\n\t\t\tresult = theCode.startsWith(coursePrefix);\n\t\t}\n\t\telse {\n\t\t\tresult = true;\n\t\t}\n\t\t\n\t\treturn result;\n\t}\n}\n\n\n\nAdd Custom Validation\n\npublic class Customer {\n\n\tprivate String firstName;\n\t\n\t@NotNull(message=\"is required\")\n\t@Size(min=1, message=\"is required\")\n\tprivate String lastName;\n\n\t@NotNull(message=\"is required\")\n\t@Min(value=0, message=\"must be greater than or equal to zero\")\n\t@Max(value=10, message=\"must be less than or equal to 10\")\n\tprivate Integer freePasses;\n\n\t@Pattern(regexp=\"^[a-zA-Z0-9]{5}\", message=\"only 5 chars/digits\")\n\tprivate String postalCode;\n\t\n  // Use our custom validation tag\n\t@CourseCode(value=\"TOPS\", message=\"must start with TOPS\")\n\tprivate String courseCode;\n\n\nPerform Validation on Controller\n\npackage com.springdemo.mvc;\n\nimport javax.validation.Valid;\n\nimport org.springframework.beans.propertyeditors.StringTrimmerEditor;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.validation.BindingResult;\nimport org.springframework.web.bind.WebDataBinder;\nimport org.springframework.web.bind.annotation.InitBinder;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/customer\")\npublic class CustomerController {\n\n\t// add an initbinder ... to convert trim input strings\n\t// remove leading and trailing whitespace\n\t// resolve issue for our validation\n\t\n\t@InitBinder\n\t//@InitBinder annotation works as a pre-processor \n\t// It will pre-process each web request to our controller\n\tpublic void initBinder(WebDataBinder dataBinder) {\n\t\t\n\t\t// Trim strings (true: empty strings to null)\n\t\tStringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true);\n\t\n\t\t// For every string class apply the trim editor\n\t\tdataBinder.registerCustomEditor(String.class, stringTrimmerEditor);\n\t}\n\t\n\t\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\ttheModel.addAttribute(\"customer\", new Customer());\n\t\t\n\t\treturn \"customer-form\";\n\t}\n\t\n\t@RequestMapping(\"/processForm\")\n\t// @Valid: Tells spring to perform validation on the customer object\n\t// BindingResult: results of the validation will be placed in BindingResult\n\tpublic String processForm(\n\t\t\t@Valid @ModelAttribute(\"customer\") Customer theCustomer,\n\t\t\tBindingResult theBindingResult) {\n\t\t\n\t\tSystem.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\");\n\t\t\n\t\t// Check if validation was sucessfull\n\t\tif (theBindingResult.hasErrors()) {\n\t\t\t// If not sucessfull send back\n\t\t\treturn \"customer-form\";\n\t\t}\n\t\telse {\n\t\t\t// If sucessfull\n\t\t\treturn \"customer-confirmation\";\n\t\t}\n\t}\n}\n\n\n\nWhen performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute. \n\n\nDisplay error on HTML\n\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<html>\n\n<head>\n\t<title>Customer Registration Form</title>\n\t\n\t<style>\n\t\t.error {color:red}\n\t</style>\n</head>\n<body>\n<i>Fill out the form. Asterisk (*) means required.</i>\n<br><br>\n\t<form:form action=\"processForm\" modelAttribute=\"customer\">\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name (*): <form:input path=\"lastName\" />\n\t\t<form:errors path=\"lastName\" cssClass=\"error\" />\n\t\t<br><br>\n\t\tFree passes: <form:input path=\"freePasses\" />\n\t\t<form:errors path=\"freePasses\" cssClass=\"error\" />\n    <br><br>\n\t\tPostal Code: <form:input path=\"postalCode\" />\n\t\t<form:errors path=\"postalCode\" cssClass=\"error\" />\n\t\t<br><br>\n    <!-- The message shown equals the messages from both of the validation annotations defined \n    for the courseCode attribute in the Customer class -->\n\t\t\tCourse Code: <form:input path=\"courseCode\" />\n\t\t\t<form:errors path=\"courseCode\" cssClass=\"error\" />\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n\n</body>\n\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Drop Down Lists.html",
    "title": "Drop Down Lists",
    "body": "\n\nBack\n\n\nDrop Down Lists\n\n\n\n\nTo pass and bind data from drop down lists to controllers an another views we use the Form Tags form:select that encloses a set of options represented with form:option tags. And all these are surrounded by a form:form:\n\n\nController\n\n\n\nAdd a Model to the controller method for the form and create the model attribute, that holds the data and performs data binding\n\n\n\npackage com.springdemo.mvc;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/student\")\npublic class StudentController {\n\t\n\t// Request to show the view that contains the form\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\t// create a student object\n\t\tStudent theStudent = new Student();\n\t\t\n\t\t// add student object to the model\n\t\ttheModel.addAttribute(\"student\", theStudent);\n\t\t\n\t\treturn \"student-form\";\n\t}\n\t\n\t// Process the submit event on the form\n\t@RequestMapping(\"/processForm\")\n\t// We obtain the model attribute with the following annotation\n\tpublic String processForm(@ModelAttribute(\"student\") Student theStudent) {\n\t\t\n\t\t// Now we can retrieve the updated information from the form\n\t\tSystem.out.println(\"theStudent: \" + theStudent.getFirstName()\n\t\t\t\t\t\t\t+ \" \" + theStudent.getLastName());\n\t\t\n\t\treturn \"student-confirmation\";\n\t}\n}\n\n\nView\n\n\n\nSetting the HTML for data binding:\n\n\n\nFor student-form.jsp:\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Registration Form</title>\n</head>\n\n<body>\n\t<form:form action=\"processForm\" modelAttribute=\"student\">\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name: <form:input path=\"lastName\" />\n\t\t<br><br>\n\t\tCountry:\n\t\t<!-- Drop down list of country options -->\n\t\t<!-- We specify the variable where we store the selected value in the student object: which is country -->\n\t\t<form:select path=\"country\">\n\t\t\t<!-- This is a list that was populated when we created the student object -->\n\t\t\t<!-- Remember Spring calls student.getCountryOptions() -->\n\t\t\t<form:options items=\"${student.countryOptions}\" />\n\t\t</form:select>\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n</body>\n\n</html>\n\n\n\n\n\n\n\nFor student-confirmation.jsp:\n<%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Confirmation</title>\n</head>\n<body>\n\tThe student is confirmed: ${student.firstName} ${student.lastName}\n\t<!-- Obtain the value saved in the coutry variable inside the student's object (corresponds to the selected value) -->\n\tSelected coutry: ${student.country} ${student.lastName}\n</body>\n</html>\n\n\n\n\nModel\n\n\nThe model attribute \"student\" is populated with an instance of the following Student class:\n\n\npackage com.springdemo.mvc;\n\nimport java.util.LinkedHashMap;\n\npublic class Student {\n\n\tprivate String firstName;\n\tprivate String lastName;\n\t\n\tprivate String country;\n\t\n\tprivate LinkedHashMap<String, String> countryOptions;\n\t\n\tpublic Student() {\n\t\t\n\t\t// populate country options: used ISO country code\n\t\tcountryOptions = new LinkedHashMap<>();\n\t\t\n\t\tcountryOptions.put(\"BR\", \"Brazil\");\n\t\tcountryOptions.put(\"FR\", \"France\");\n\t\tcountryOptions.put(\"DE\", \"Germany\");\n\t\tcountryOptions.put(\"IN\", \"India\");\n\t\tcountryOptions.put(\"US\", \"United States of America\");\t\t\n\n\t}\n\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n\n\tpublic String getCountry() {\n\t\treturn country;\n\t}\n\n\t// Setter and getter handlers for the new binded attribute\n\tpublic void setCountry(String country) {\n\t\tthis.country = country;\n\t}\n\n\tpublic LinkedHashMap<String, String> getCountryOptions() {\n\t\treturn countryOptions;\n\t}\n}\n\n\nCountry options from a properties file\n\n\n\nWe create WEB-INF/countries.properties:\n\n\n\nBR=Brazil \nFR=France \nCO=Colombia \nIN=India\n\n\n\n\nUpdate configuration's file spring-mvc-dmo-servlet.xml header (to use a new set of Spring tags: utils):\n\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\" \n        xmlns:context=\"http://www.springframework.org/schema/context\" \n        xmlns:mvc=\"http://www.springframework.org/schema/mvc\" \n        xmlns:util=\"http://www.springframework.org/schema/util\" \n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n        xsi:schemaLocation=\"\n            http://www.springframework.org/schema/beans     \n            http://www.springframework.org/schema/beans/spring-beans.xsd     \n            http://www.springframework.org/schema/context     \n            http://www.springframework.org/schema/context/spring-context.xsd     \n            http://www.springframework.org/schema/mvc         \n            http://www.springframework.org/schema/mvc/spring-mvc.xsd \n            http://www.springframework.org/schema/util     \n            http://www.springframework.org/schema/util/spring-util.xsd\">\n\n\n\n\nLoad the country options properties file in the Spring configuration file, with a bean id equal to \"countryOptions\":\n\n\n\n<util:properties  id=\"countryOptions\" location=\"classpath:../countries.properties\" />\n\n\n\n\nInject properties inside our controller:\n\n\n\n@Value(\"#{countryOptions}\") \nprivate Map<String, String> countryOptions;\n\n\n\n\nAdd countryOptions as an attribute of the model inside the controller method:\n\n\n\n@RequestMapping(\"/showForm\") \npublic String showForm(Model theModel) { \n\n    // create a student object Student \n    Student theStudent = new Student();\n \n    // add student object to the model \n    theModel.addAttribute(\"student\", theStudent); \n\n    // add the country options to the model \n    theModel.addAttribute(\"theCountryOptions\", countryOptions); \n\n    return \"student-form\"; \n}\n\n\n\n\nUpdate the view as follows:\n\n\n\n<form:select path=\"country\"> \n <form:options items=\"${theCountryOptions}\" />\n</form:select>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Radio Buttons.html",
    "title": "Radio Buttons",
    "body": "\n\nBack\n\n\nRadio Buttons\n\n\n\n\nTo pass and bind data from radio buttons to controllers an another views we use the Form Tag form:radiobutton which is surrounded by a form:form:\n\n\nController\n\n\n\nAdd a Model to the controller method for the form and create the model attribute, that holds the data and performs data binding\n\n\n\npackage com.springdemo.mvc;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/student\")\npublic class StudentController {\n\t\n\t// Request to show the view that contains the form\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\t// create a student object\n\t\tStudent theStudent = new Student();\n\t\t\n\t\t// add student object to the model\n\t\ttheModel.addAttribute(\"student\", theStudent);\n\t\t\n\t\treturn \"student-form\";\n\t}\n\t\n\t// Process the submit event on the form\n\t@RequestMapping(\"/processForm\")\n\t// We obtain the model attribute with the following annotation\n\tpublic String processForm(@ModelAttribute(\"student\") Student theStudent) {\n\t\t\n\t\t// Now we can retrieve the updated information from the form\n\t\tSystem.out.println(\"theStudent: \" + theStudent.getFirstName()\n\t\t\t\t\t\t\t+ \" \" + theStudent.getLastName());\n\t\t\n\t\treturn \"student-confirmation\";\n\t}\n}\n\n\nView\n\n\n\nSetting the HTML for data binding:\n\n\n\nFor student-form.jsp:\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Registration Form</title>\n</head>\n\n<body>\n\t<form:form action=\"processForm\" modelAttribute=\"student\">\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name: <form:input path=\"lastName\" />\n\t\t<br><br>\n\t\tCountry:\n\t\t<!-- Drop down list of country options -->\n\t\t<!-- We specify the variable where we store the selected value in the student object: which is country -->\n\t\t<form:select path=\"country\">\n\t\t\t<!-- This is a list that was populated when we created the student object -->\n\t\t\t<!-- Remember Spring calls student.getCountryOptions() -->\n\t\t\t<form:options items=\"${student.countryOptions}\" />\n\t\t</form:select>\n\t\t<br><br>\n\t\t<br><br>\n\n\t\tFavorite Language:\n\t\t\n\t\t<!-- The \"path\" specifies the name of the property we are going to bind the radiobutton to, in this case \"favoriteLanguage\" -->\n\t\t<!-- Note these can also be populated from the Student class or using a properties file -->\n\t\tJava <form:radiobutton path=\"favoriteLanguage\" value=\"Java\" />\n\t\tC# <form:radiobutton path=\"favoriteLanguage\" value=\"C#\" />\n\t\tPHP <form:radiobutton path=\"favoriteLanguage\" value=\"PHP\" />\n\t\tRuby <form:radiobutton path=\"favoriteLanguage\" value=\"Ruby\" />\n\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n</body>\n\n</html>\n\n\n\n\n\n\n\nFor student-confirmation.jsp:\n<%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Confirmation</title>\n</head>\n<body>\n\tThe student is confirmed: ${student.firstName} ${student.lastName}\n\t<br><br>\n\tSelected coutry: ${student.country} ${student.lastName}\n\t<br><br>\n\t<!-- Obtain the value using the binded variable inside the student object -->\n\tFavorite language: ${student.favoriteLanguage}\n</body>\n</html>\n\n\n\n\nModel\n\n\nThe model attribute \"student\" is populated with an instance of the following Student class:\n\n\npackage com.springdemo.mvc;\n\nimport java.util.LinkedHashMap;\n\npublic class Student {\n\n\tprivate String firstName;\n\tprivate String lastName;\n\t\n\tprivate String country;\n\t\n\tprivate LinkedHashMap<String, String> countryOptions;\n\t\n\t// Property we are going to bind to the radio buttons\n\tprivate String favoriteLanguage;\n\t\n\tpublic Student() {\n\t\t\n\t\t// populate country options: used ISO country code\n\t\tcountryOptions = new LinkedHashMap<>();\n\t\t\n\t\tcountryOptions.put(\"BR\", \"Brazil\");\n\t\tcountryOptions.put(\"FR\", \"France\");\n\t\tcountryOptions.put(\"DE\", \"Germany\");\n\t\tcountryOptions.put(\"IN\", \"India\");\n\t\tcountryOptions.put(\"US\", \"United States of America\");\t\t\n\t\t\n\t\t// We can also populate the favoriteLanguage options from here\n\t\t// in the same manner we did with the country options\n\n\t}\n\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n\n\tpublic String getCountry() {\n\t\treturn country;\n\t}\n\n\tpublic void setCountry(String country) {\n\t\tthis.country = country;\n\t}\n\n\tpublic LinkedHashMap<String, String> getCountryOptions() {\n\t\treturn countryOptions;\n\t}\n\t\n\t// Setter and getter handlers for the new binded attribute\n\tpublic String getFavoriteLanguage() {\n\t\treturn favoriteLanguage;\n\t}\n\n\tpublic void setFavoriteLanguage(String favoriteLanguage) {\n\t\tthis.favoriteLanguage = favoriteLanguage;\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Handle String in Integer Field.html",
    "title": "Handle String Input in Integer Field",
    "body": "\n\nBack\n\n\nHandle String Input in Integer Field\n\n\n\n\nIf we want to avoid the trace returned by errors like inputting the wrong data type (string instead of int), we can define a custom message that will override those messages.\n\n\nCreate a custom message\n\n\nCreate a properties file in resources/messages.properties\n\n\n// ErrorType.SpringModelAttributeName.FieldName\ntypeMismatch.customer.freePasses=Invalid number\n\n\nSpecify Properties file in Configuration\n\n\nWe add the following in our configuration file spring-mvc-demo-servlet.xml\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n\txmlns:context=\"http://www.springframework.org/schema/context\"\n\txmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n\txsi:schemaLocation=\"\n\t\thttp://www.springframework.org/schema/beans\n    \thttp://www.springframework.org/schema/beans/spring-beans.xsd\n    \thttp://www.springframework.org/schema/context\n    \thttp://www.springframework.org/schema/context/spring-context.xsd\n    \thttp://www.springframework.org/schema/mvc\n        http://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n\t<context:component-scan base-package=\"com.luv2code.springdemo\" />\n\t<mvc:annotation-driven/>\n\t<bean\n\t\tclass=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n\t\t<property name=\"prefix\" value=\"/WEB-INF/view/\" />\n\t\t<property name=\"suffix\" value=\".jsp\" />\n\t</bean>\n\n\t  <!-- Load custom message resources -->\n    <bean id=\"messageSource\" \n          class=\"org.springframework.context.support.ResourceBundleMessageSource\">\n\t\t\t\t<!-- Path where the properties file is stored -->\n        <property name=\"basenames\" value=\"resources/messages\" />\n    </bean>\n</beans>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/CheckBox.html",
    "title": "Check Box",
    "body": "\n\nBack\n\n\nCheck Box\n\n\n\n\nTo pass and bind data from check boxes to controllers an another views we use the Form Tag form:checkbox which is surrounded by a form:form:\n\n\nController\n\n\n\nAdd a Model to the controller method for the form and create the model attribute, that holds the data and performs data binding\n\n\n\npackage com.springdemo.mvc;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/student\")\npublic class StudentController {\n\t\n\t// Request to show the view that contains the form\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\t// create a student object\n\t\tStudent theStudent = new Student();\n\t\t\n\t\t// add student object to the model\n\t\ttheModel.addAttribute(\"student\", theStudent);\n\t\t\n\t\treturn \"student-form\";\n\t}\n\t\n\t// Process the submit event on the form\n\t@RequestMapping(\"/processForm\")\n\t// We obtain the model attribute with the following annotation\n\tpublic String processForm(@ModelAttribute(\"student\") Student theStudent) {\n\t\t\n\t\t// Now we can retrieve the updated information from the form\n\t\tSystem.out.println(\"theStudent: \" + theStudent.getFirstName()\n\t\t\t\t\t\t\t+ \" \" + theStudent.getLastName());\n\t\t\n\t\treturn \"student-confirmation\";\n\t}\n}\n\n\nView\n\n\n\nSetting the HTML for data binding:\n\n\n\nFor student-form.jsp:\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Registration Form</title>\n</head>\n\n<body>\n\t<form:form action=\"processForm\" modelAttribute=\"student\">\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name: <form:input path=\"lastName\" />\n\t\t<br><br>\n\t\tCountry:\n\t\t<!-- Drop down list of country options -->\n\t\t<!-- We specify the variable where we store the selected value in the student object: which is country -->\n\t\t<form:select path=\"country\">\n\t\t\t<!-- This is a list that was populated when we created the student object -->\n\t\t\t<!-- Remember Spring calls student.getCountryOptions() -->\n\t\t\t<form:options items=\"${student.countryOptions}\" />\n\t\t</form:select>\n\t\t<br><br>\n\t\t<br><br>\n\t\tFavorite Language:\n\t\t\n\t\tJava <form:radiobutton path=\"favoriteLanguage\" value=\"Java\" />\n\t\tC# <form:radiobutton path=\"favoriteLanguage\" value=\"C#\" />\n\t\tPHP <form:radiobutton path=\"favoriteLanguage\" value=\"PHP\" />\n\t\tRuby <form:radiobutton path=\"favoriteLanguage\" value=\"Ruby\" />\n\t\t<br><br>\n\t\tOperating Systems:\n\t\t\n\t\t<!-- The \"path\" specifies the name of the property we are going to bind the radiobutton to, in this case \"operatingSystems\" -->\n\t\t<!-- Note these can also be populated from the Student class or using a properties file -->\n\t\tLinux <form:checkbox path=\"operatingSystems\" value=\"Linux\" />\n\t\tMac OS <form:checkbox path=\"operatingSystems\" value=\"Mac OS\" />\n\t\tMS Windows <form:checkbox path=\"operatingSystems\" value=\"MS Window\" />\t\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n</body>\n\n</html>\n\n\n\n\n\n\n\nFor student-confirmation.jsp:\n<%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %>\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>Student Confirmation</title>\n</head>\n<body>\n\tThe student is confirmed: ${student.firstName} ${student.lastName}\n\t<br><br>\n\tSelected coutry: ${student.country} ${student.lastName}\n\t<br><br>\n\t<!-- Obtain the value using the binded variable inside the student object -->\n\tFavorite language: ${student.favoriteLanguage}\n\t<br><br>\n\tOperating Systems:\n\t<!-- Create an unordered list of the selected values in the checkbox -->\n\t\t<ul>\n\t\t\t<c:forEach var=\"temp\" items=\"${student.operatingSystems}\">\n\t\t\t\t<li> ${temp} </li>\n\t\t\t</c:forEach>\n\t\t</ul>\n</body>\n</html>\n\n\n\n\nModel\n\n\nThe model attribute \"student\" is populated with an instance of the following Student class:\n\n\npackage com.springdemo.mvc;\n\nimport java.util.LinkedHashMap;\n\npublic class Student {\n\n\tprivate String firstName;\n\tprivate String lastName;\n\t\n\tprivate String country;\n\t\n\tprivate LinkedHashMap<String, String> countryOptions;\n\t\n\tprivate String favoriteLanguage;\n  \n  // Attribute bound to the checkbox (multiple options so it is an array)\n  private String[] operatingSystems;\n\t\n\tpublic Student() {\n\t\t\n\t\t// populate country options: used ISO country code\n\t\tcountryOptions = new LinkedHashMap<>();\n\t\t\n\t\tcountryOptions.put(\"BR\", \"Brazil\");\n\t\tcountryOptions.put(\"FR\", \"France\");\n\t\tcountryOptions.put(\"DE\", \"Germany\");\n\t\tcountryOptions.put(\"IN\", \"India\");\n\t\tcountryOptions.put(\"US\", \"United States of America\");\t\t\n\t\t\n\t\t// We can also populate the favoriteLanguage options from here\n\t\t// in the same manner we did with the country options\n\n\t}\n\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n\n\tpublic String getCountry() {\n\t\treturn country;\n\t}\n\n\tpublic void setCountry(String country) {\n\t\tthis.country = country;\n\t}\n\n\tpublic LinkedHashMap<String, String> getCountryOptions() {\n\t\treturn countryOptions;\n\t}\n\t\n\tpublic String getFavoriteLanguage() {\n\t\treturn favoriteLanguage;\n\t}\n\n\tpublic void setFavoriteLanguage(String favoriteLanguage) {\n\t\tthis.favoriteLanguage = favoriteLanguage;\n\t}\n  \n\t// Setter and getter handlers for the new bound attribute\n  public String[] getOperatingSystems() {\n\t\treturn operatingSystems;\n\t}\n\n\tpublic void setOperatingSystems(String[] operatingSystems) {\n\t\tthis.operatingSystems = operatingSystems;\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Required Validation.html",
    "title": "Required Validation",
    "body": "\n\nBack\n\n\nRequired Validation\n\n\n\n\nIn this section we will show how to perform a required validation.\n\n\nAdd Validation Rule to Bean\n\n\nWe create a Customer class, whose lastName attribute must be non-null, that is, lastName is a required attribute:\n\n\npackage com.springdemo.mvc;\n\nimport javax.validation.constraints.NotNull;\nimport javax.validation.constraints.Size;\n\npublic class Customer {\n\n\tprivate String firstName;\n\t\n  // Validation annotation\n\t@NotNull(message=\"is required\")\n\t@Size(min=1, message=\"is required\")\n\tprivate String lastName;\n\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n}\n\n\n\nNote that if we wanted to make an integer required, we must use the wrapper java classes (i.e. Integer), that will be able to handle empty strings as inputs and nulls. The primitive types will throw an exception.\n\n\n\nPerform Validation in the Controller\n\n\nWe also \n\n\npackage com.springdemo.mvc;\n\nimport javax.validation.Valid;\n\nimport org.springframework.beans.propertyeditors.StringTrimmerEditor;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.validation.BindingResult;\nimport org.springframework.web.bind.WebDataBinder;\nimport org.springframework.web.bind.annotation.InitBinder;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/customer\")\npublic class CustomerController {\n\n\t// add an initbinder ... to convert trim input strings\n\t// remove leading and trailing whitespace\n\t// resolve issue for our validation\n\t\n\t@InitBinder\n\t//@InitBinder annotation works as a pre-processor \n\t// It will pre-process each web request to our controller\n\tpublic void initBinder(WebDataBinder dataBinder) {\n\t\t\n\t\t// Trim strings (true: empty strings to null)\n\t\tStringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true);\n\t\n\t\t// For every string class apply the trim editor\n\t\tdataBinder.registerCustomEditor(String.class, stringTrimmerEditor);\n\t}\n\t\n\t\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\ttheModel.addAttribute(\"customer\", new Customer());\n\t\t\n\t\treturn \"customer-form\";\n\t}\n\t\n\t@RequestMapping(\"/processForm\")\n\t// @Valid: Tells spring to perform validation on the customer object\n\t// BindingResult: results of the validation will be placed in BindingResult\n\tpublic String processForm(\n\t\t\t@Valid @ModelAttribute(\"customer\") Customer theCustomer,\n\t\t\tBindingResult theBindingResult) {\n\t\t\n\t\tSystem.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\");\n\t\t\n\t\t// Check if validation was sucessfull\n\t\tif (theBindingResult.hasErrors()) {\n\t\t\t// If not sucessfull send back\n\t\t\treturn \"customer-form\";\n\t\t}\n\t\telse {\n\t\t\t// If sucessfull\n\t\t\treturn \"customer-confirmation\";\n\t\t}\n\t}\n}\n\n\n\nWhen performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute. \n\n\nDisplay error on HTML\n\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<html>\n\n<head>\n\t<title>Customer Registration Form</title>\n\t\n\t<style>\n\t\t.error {color:red}\n\t</style>\n</head>\n<body>\n<i>Fill out the form. Asterisk (*) means required.</i>\n<br><br>\n\t<form:form action=\"processForm\" modelAttribute=\"customer\">\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name (*): <form:input path=\"lastName\" />\n    <!-- We use the error form tag to display an error when the input is not valid -->\n    <!-- The message shown equals the messages from both of the validation annotations defined \n    for the lastName attribute in the Customer class -->\n\t\t<form:errors path=\"lastName\" cssClass=\"error\" />\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n\n</body>\n\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/View.html",
    "title": "View",
    "body": "\n\nBack\n\n\nView\n\n\n\nCreate View\n\n\nInside WEB-INF/view we create a file main-menu.jsp:\n\n\n<!DOCTYPE>\n<html>\n  <body>\n    <h2>Spring MVC Demo - Home Page</h2>\n  </body>\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/index.html",
    "title": "Spring MVC",
    "body": "\n\nBack\n\n\nSpring MVC\n\n\n\n\nSpring MVC is a framework for building web applications in Java based on the Model-View-Controller design patter.\n\n\n\n\n\n\n\n\nThe Front Controller is known as DispatcherServlet:\n\n\n\nIt is part of the Spring Framework\n\n\nPre-processes and delegates requests from the web browser to your controllers\n\n\n\nThe MVC pattern is made up of:\n\n\n\nModel objects: contains the data\n\n\nView templates: UI of the app that displays data (most common templates: JSP + JSLT)\n\n\nController classes: business logic (handle request, access db, etc.)\n\n\n\n\n\nIt includes the features of the Core Spring Framework (Inversion of Control and Dependency Injection)\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Number Validation.html",
    "title": "Number Range Validation",
    "body": "\n\nBack\n\n\nNumber Range Validation\n\n\n\n\nIn this section we will show how to perform a number range validation.\n\n\nAdd Validation Rule to Bean\n\n\nWe create a Customer class, whose freePasses variable must be a number between 0 and 10.\n\n\npublic class Customer {\n\n\tprivate String firstName;\n\t\n\t@NotNull(message=\"is required\")\n\t@Size(min=1, message=\"is required\")\n\tprivate String lastName;\n\n\t// Minimum value we will expect\n\t@Min(value=0, message=\"must be greater than or equal to zero\")\n\t// Maximum value we will expect\n\t@Max(value=10, message=\"must be less than or equal to 10\")\n\tprivate int freePasses;\n\t\n\t...\n\n\n\nPerform Validation in the Controller\n\n\nWe also \n\n\npackage com.springdemo.mvc;\n\nimport javax.validation.Valid;\n\nimport org.springframework.beans.propertyeditors.StringTrimmerEditor;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.validation.BindingResult;\nimport org.springframework.web.bind.WebDataBinder;\nimport org.springframework.web.bind.annotation.InitBinder;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/customer\")\npublic class CustomerController {\n\n\t// add an initbinder ... to convert trim input strings\n\t// remove leading and trailing whitespace\n\t// resolve issue for our validation\n\t\n\t@InitBinder\n\t//@InitBinder annotation works as a pre-processor \n\t// It will pre-process each web request to our controller\n\tpublic void initBinder(WebDataBinder dataBinder) {\n\t\t\n\t\t// Trim strings (true: empty strings to null)\n\t\tStringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true);\n\t\n\t\t// For every string class apply the trim editor\n\t\tdataBinder.registerCustomEditor(String.class, stringTrimmerEditor);\n\t}\n\t\n\t\n\t@RequestMapping(\"/showForm\")\n\tpublic String showForm(Model theModel) {\n\t\t\n\t\ttheModel.addAttribute(\"customer\", new Customer());\n\t\t\n\t\treturn \"customer-form\";\n\t}\n\t\n\t@RequestMapping(\"/processForm\")\n\t// @Valid: Tells spring to perform validation on the customer object\n\t// BindingResult: results of the validation will be placed in BindingResult\n\tpublic String processForm(\n\t\t\t@Valid @ModelAttribute(\"customer\") Customer theCustomer,\n\t\t\tBindingResult theBindingResult) {\n\t\t\n\t\tSystem.out.println(\"Last name: |\" + theCustomer.getLastName() + \"|\");\n\t\t\n\t\t// Check if validation was sucessfull\n\t\tif (theBindingResult.hasErrors()) {\n\t\t\t// If not sucessfull send back\n\t\t\treturn \"customer-form\";\n\t\t}\n\t\telse {\n\t\t\t// If sucessfull\n\t\t\treturn \"customer-confirmation\";\n\t\t}\n\t}\n}\n\n\n\nWhen performing Spring MVC validation, the location of the BindingResult parameter is very important. In the method signature, the BindingResult parameter must appear immediately after the model attribute. \n\n\nDisplay error on HTML\n\n<%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %>\n<html>\n\n<head>\n\t<title>Customer Registration Form</title>\n\t\n\t<style>\n\t\t.error {color:red}\n\t</style>\n</head>\n<body>\n<i>Fill out the form. Asterisk (*) means required.</i>\n<br><br>\n\t<form:form action=\"processForm\" modelAttribute=\"customer\">\n\t\tFirst name: <form:input path=\"firstName\" />\n\t\t<br><br>\n\t\tLast name (*): <form:input path=\"lastName\" />\n    <!-- The message shown equals the messages from both of the validation annotations defined \n    for the lastName attribute in the Customer class -->\n\t\t<form:errors path=\"lastName\" cssClass=\"error\" />\n\t\t<br><br>\n\t\tFree passes: <form:input path=\"freePasses\" />\n    <!-- The message shown equals the messages from both of the validation annotations defined \n    for the freePasses attribute in the Customer class -->\n\t\t<form:errors path=\"freePasses\" cssClass=\"error\" />\n\t\t<br><br>\n\t\t<input type=\"submit\" value=\"Submit\" />\n\t</form:form>\n\n</body>\n\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/MVC/Configuration.html",
    "title": "Configuration",
    "body": "\n\nBack\n\n\nConfiguration\n\n\n\n\n\nAdd configurations to file: WEB-INF/web.xml\n\n\n\nConfigure Spring MVC Dispatcher Servlet\n\n\nSet up URL mappings to Spring MVC Dispatcher Servlet\n\n\n\nAdd configurations to spring configuration file: WEB-INF/spring-mvc-demo-servlet.xml\n\n\n\nAdd support for Spring Component Scanning\n\n\nAdd support for conversion, formatting and validation\n\n\nConfigure Spring MVC View Resolver\n\n\n\n\n\n\nConfiguration on web.xml\n\n\nWe have to add an entry for our Front Controller: DispatcherServlet\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n\txmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n\txsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\"\n\tid=\"WebApp_ID\" version=\"3.1\">\n\n\t<display-name>spring-mvc-demo</display-name>\n\n\t<absolute-ordering />\n\n\t<!-- Step 1: Configure Spring MVC Dispatcher Servlet -->\n\t<servlet>\n\t\t<!-- Name to reference this servlet -->\n\t\t<servlet-name>dispatcher</servlet-name>\n\t\t<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n\t\t<!-- File of configuration of spring application -->\n\t\t<init-param>\n\t\t\t<param-name>contextConfigLocation</param-name>\n\t\t\t<param-value>/WEB-INF/spring-mvc-demo-servlet.xml</param-value>\n\t\t</init-param>\n\t\t<load-on-startup>1</load-on-startup>\n\t</servlet>\n  \n\t<!-- Step 2: Set up URL mapping for Spring MVC Dispatcher Servlet -->\n\t<servlet-mapping>\n\t\t<servlet-name>dispatcher</servlet-name>\n\t\t<!-- For any url that comes in pass it to the \"dispatcher\" servlet -->\n\t\t<url-pattern>/</url-pattern>\n\t</servlet-mapping>\n</web-app>\n\n\nConfiguration on spring-mvc-demo-servlet.xml\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n\txmlns:context=\"http://www.springframework.org/schema/context\"\n\txmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n\txsi:schemaLocation=\"\n\t\thttp://www.springframework.org/schema/beans\n    \thttp://www.springframework.org/schema/beans/spring-beans.xsd\n    \thttp://www.springframework.org/schema/context\n    \thttp://www.springframework.org/schema/context/spring-context.xsd\n    \thttp://www.springframework.org/schema/mvc\n        http://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n\t<!-- Step 3: Add support for component scanning -->\n\t<context:component-scan base-package=\"com.springdemo\" />\n\n\t<!-- Step 4: Add support for conversion, formatting and validation support -->\n\t<mvc:annotation-driven/>\n\n\t<!-- Step 5: Define Spring MVC view resolver -->\n\t<bean\n\t\tclass=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n\t\t<!-- Specify where to look for view files -->\n\t\t<property name=\"prefix\" value=\"/WEB-INF/view/\" />\n\t\t<property name=\"suffix\" value=\".jsp\" />\n\t</bean>\n\n</beans>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Thymeleaf/Tables.html",
    "title": "Tables in Thymeleaf",
    "body": "\n\nBack\n\n\nTables in Thymeleaf\n\n\n\n\nIn this section we are going to show how to create a table with Thymeleaf:\n\n\nController\n\n\nWe create a controller for Employee, to list and add employees.\n\n\npackage com.springboot.thymeleafdemo.controller;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport javax.annotation.PostConstruct;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\nimport com.springboot.thymeleafdemo.model.Employee;\n\n@Controller\n@RequestMapping(\"/employees\")\npublic class EmployeeController {\n\n\t// load employee data\n\t\n\tprivate List<Employee> theEmployees;\n\t\n\t@PostConstruct\n\tprivate void loadData() {\n\t\t\n\t\t// create employees\n\t\tEmployee emp1 = new Employee(1, \"Leslie\", \"Andrews\", \"leslie@luv2code.com\");\n\t\tEmployee emp2 = new Employee(2, \"Emma\", \"Baumgarten\", \"emma@luv2code.com\");\n\t\tEmployee emp3 = new Employee(3, \"Avani\", \"Gupta\", \"avani@luv2code.com\");\n\n\t\t// create the list\n\t\ttheEmployees = new ArrayList<>();\n\t\t\n\t\t// add to the list\n\t\ttheEmployees.add(emp1);\n\t\ttheEmployees.add(emp2);\n\t\ttheEmployees.add(emp3);\n\t\n\t}\n\t\n\t// add mapping for \"/list\"\n\n\t@GetMapping(\"/list\")\n\tpublic String listEmployees(Model theModel) {\n\t\t\n\t\t// add to the spring model\n\t\ttheModel.addAttribute(\"employees\", theEmployees);\n\t\t\n\t\treturn \"list-employees\";\n\t}\n}\n\n\nEntity\n\n\nWe create the entity Employee:\n\n\npackage com.springboot.thymeleafdemo.model;\n\npublic class Employee {\n\n\tprivate int id;\n\tprivate String firstName;\n\tprivate String lastName;\n\tprivate String email;\n\n\tpublic Employee() {\n\t\t\n\t}\n\n\tpublic Employee(int id, String firstName, String lastName, String email) {\n\t\tthis.id = id;\n\t\tthis.firstName = firstName;\n\t\tthis.lastName = lastName;\n\t\tthis.email = email;\n\t}\n\n\tpublic int getId() {\n\t\treturn id;\n\t}\n\n\tpublic void setId(int id) {\n\t\tthis.id = id;\n\t}\n\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n\n\tpublic String getEmail() {\n\t\treturn email;\n\t}\n\n\tpublic void setEmail(String email) {\n\t\tthis.email = email;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn \"Employee [id=\" + id + \", firstName=\" + firstName + \", lastName=\" + lastName + \", email=\" + email + \"]\";\n\t}\n\t\t\n}\n\n\nTemplate\n\n\nFinally we create the template for list-employees.html:\n\n\n<!DOCTYPE HTML>\n<html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\">\n<head>\n  <!-- Required meta tags -->\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n  <!-- Bootstrap CSS -->\n  <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css\" integrity=\"sha384-GJzZqFGwb1QTTN6wy59ffF1BuGJpLSa9DkKMp0DgiMDm4iYMj70gZWKYbI706tWS\" crossorigin=\"anonymous\">\n  <title>Employee Directory</title>\n</head>\n<body>\n  <div class=\"container\">\n    <h3>Employee Directory</h3>\n    <hr>\n    <table class=\"table table-bordered table-striped\">\n      <thead class=\"thead-dark\">\n      <tr>\n        <th>First Name</th>\n        <th>Last Name</th>\n        <th>Email</th>\n      </tr>\n      </thead>\n      <tbody>\n        <!-- for loop for all employees, stored in the model -->\n        <tr th:each=\"tempEmployee : ${employees}\">\n        <td th:text=\"${tempEmployee.firstName}\" />\t\n        <td th:text=\"${tempEmployee.lastName}\" />\t\n        <td th:text=\"${tempEmployee.email}\" />\t\n        </tr>\n      </tbody>\t\t\n    </table>\n  </div>\n</body>\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Thymeleaf/Overview.html",
    "title": "Overview",
    "body": "\n\nBack\n\n\nOverview\n\n\n\n\nThymeleaf is a Java templating engine. \n\n\n\nA thymeleaf template can be an HTML page with some thymeleaf expressions and include dynamic content from thymeleaf expressions.\n\n\n\nIn a web app, thymeleaf is processed on the server.\n\n\n\n\n\nTo use thymeleaf you have to include it in your dependencies:\n\n\n...\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-thymeleaf</artifactId>\n\t\t</dependency>\n...\n\n\nPlacement\n\n\nIn Spring Boot, your Thymeleaf template files go in src/main/resources/templates. And for web apps, Thymeleaf templates have an .html extension.\n\n\nExample\n\n\nGiven the following controller:\n\n\n@Controller\npublic class DemoController {\n\n\t// create a mapping for \"/hello\"\n\t@GetMapping(\"/hello\")\n\tpublic String sayHello(Model theModel) {\n\t\t\n\t\ttheModel.addAttribute(\"theDate\", new java.util.Date());\n\t\t\n\t\treturn \"helloworld\";\n\t}\n}\n\n\n\nWe create the corresponding template helloworld.html:\n\n\n<!DOCTYPE HTML>\n<html xmlns:th=\"http://www.thymeleaf.org\">\n<head>\n\t<title>Thymeleaf Demo</title>\n</head>\n<!-- We obtain the date from the model -->\n<body>\n\t<p th:text=\"'Time on the server is ' + ${theDate}\" />\n</body>\n</html>\n\n\n\nTo add styles, we create a css files in src/main/resources/static/css, and then we reference the styles:\n\n\n<!DOCTYPE HTML>\n<html xmlns:th=\"http://www.thymeleaf.org\">\n<head>\n\t<title>Thymeleaf Demo</title>\n\t<!-- reference CSS file -->\n\t<link rel=\"stylesheet\"\n\t\t  th:href=\"@{/css/demo.css}\" />\n</head>\n<body>\n\t<p th:text=\"'Time on the server is ' + ${theDate}\" class=\"funny\" />\n</body>\n</html>\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Field Injection.html",
    "title": "Field Injection",
    "body": "\n\nBack\n\n\nField Injection\n\n\n\n\nField Injection allows you to inject dependencies by setting field values on your class directly (even private ones). This is accomplished by using Java Reflection.\n\n\n\nFor this, we need to configure the Autowired annotation as follows:\n\n\n\n\nApply it directly to the field\n\n\n\n\nWhich saves us from using setter methods for dependency injection.\n\n\nDefine Dependency as Component\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\n\n// We tell spring this is a bean\n@Component\npublic class HappyFortuneService implements FortuneService {\n\n\t@Override\n\tpublic String getFortune() {\n\t\treturn \"Today is your lucky day!\";\n\t}\n\n}\n\n\nSpecify Dependency\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\nimport org.springframework.beans.factory.annotation.Autowired;\n\n@Component\npublic class TennisCoach implements Coach {\n\n  // We tell spring to search for beans (classes with @Component annotation) \n  // that implement the FortuneService interface\n  @Autowired\n\tprivate FortuneService fortuneService;\n\t\n\tpublic TennisCoach() {}\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice your backhand volley\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n\n}\n\n\n\nThe main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class AnnotationDemoApp {\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// get the bean from spring container\n\t\tCoach theCoach = context.getBean(\"tennisCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\n\t\t// call method to get daily fortune\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Setter Injection.html",
    "title": "Setter Injection",
    "body": "\n\nBack\n\n\nSetter Injection\n\n\n\nDefine Dependency as Component\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\n\n// We tell spring this is a bean\n@Component\npublic class HappyFortuneService implements FortuneService {\n\n\t@Override\n\tpublic String getFortune() {\n\t\treturn \"Today is your lucky day!\";\n\t}\n\n}\n\n\nSpecify Dependency\n\n\nWe now create a setter method in our class for the injection:\n\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\nimport org.springframework.beans.factory.annotation.Autowired;\n\n@Component\npublic class TennisCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\n\t\n\tpublic TennisCoach() {}\n  \n  // We tell spring to search for beans (classes with @Component annotation) \n  // that implement the FortuneService interface\n\t@Autowired\n  public setFortuneService(FortuneService fortuneService){\n    this.fortuneService = fortuneService;\n  }\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice your backhand volley\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n\n}\n\n\n\nThe main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class AnnotationDemoApp {\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// get the bean from spring container\n\t\tCoach theCoach = context.getBean(\"tennisCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\n\t\t// call method to get daily fortune\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Inject using Properties File.html",
    "title": "Inject properties file using Java annotations",
    "body": "\n\nBack\n\n\nInject properties file using Java annotations\n\n\nThis solution will show you how inject values from a properties file using annotations. The values will no longer be hard coded in the Java code.\n\n\nCreate a properties file\n\n\nWe create new text file:  src/sport.properties\n\n\nfoo.email=myeasycoach@luv2code.com\nfoo.team=Silly Java Coders\n\n\nLoad the properties\n\n\nWe load the properties in the configuration XML file. For that we add the line:\n\n\n<context:property-placeholder location=\"classpath:sport.properties\"/>\n\n\nInject Values\n\n\nLastly we inject the properties values into our bean like so:\n\n\n@Value(\"${foo.email}\")\nprivate String email;\n    \n@Value(\"${foo.team}\")\nprivate String team;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Dependency Injection.html",
    "title": "Dependency Injection",
    "body": "\n\nBack\n\n\nDependency Injection\n\n\n\n\nWe will introduce dependency injection with annotation using autowiring:\n\n\n\n\nSpring looks for a class that matches the attribute type (call or interface) (i.e. FortuneService)\n\n\nSpring will inject it automatically\n\n\nIf there are multiple implementations: tell Spring which specific bean to use with the Qualifier annotation\n\n\n\n\n\n\n\nConstructor Injection\n\n\nSetter Injection\n\n\nMethod Injection\n\n\nField Injection\n\n\nInject using Properties File\n\n\n\n\n\n\n\nQualifier Annotation\n\n\n\n\n\nWhich dependency to use\n\n\nChoose a style and stay consistent in your project. You get the same functionality regardless of the type of dependency injection you use.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Method Injection.html",
    "title": "Method Injection",
    "body": "\n\nBack\n\n\nMethod Injection\n\n\n\n\nOne thing to note is that you can add dependency injection on any method you want, does not have to be a setter method:\n\n\nDefine Dependency as Component\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\n\n// We tell spring this is a bean\n@Component\npublic class HappyFortuneService implements FortuneService {\n\n\t@Override\n\tpublic String getFortune() {\n\t\treturn \"Today is your lucky day!\";\n\t}\n\n}\n\n\nSpecify Dependency\n\n\nWe now create a setter method in our class for the injection:\n\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\nimport org.springframework.beans.factory.annotation.Autowired;\n\n@Component\npublic class TennisCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\n\t\n\tpublic TennisCoach() {}\n  \n  // We tell spring to search for beans (classes with @Component annotation) \n  // that implement the FortuneService interface\n\t@Autowired\n  public anyMethod(FortuneService fortuneService){\n    this.fortuneService = fortuneService;\n  }\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice your backhand volley\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n\n}\n\n\n\nThe main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class AnnotationDemoApp {\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// get the bean from spring container\n\t\tCoach theCoach = context.getBean(\"tennisCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\n\t\t// call method to get daily fortune\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Constructor Injection.html",
    "title": "Constructor Injection",
    "body": "\n\nBack\n\n\nConstructor Injection\n\n\n\nDefine Dependency as Component\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\n\n// We tell spring this is a bean\n@Component\npublic class HappyFortuneService implements FortuneService {\n\n\t@Override\n\tpublic String getFortune() {\n\t\treturn \"Today is your lucky day!\";\n\t}\n\n}\n\n\nSpecify Dependency\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\nimport org.springframework.beans.factory.annotation.Autowired;\n\n@Component\npublic class TennisCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\n\t\n  // We tell spring to search for beans (classes with @Component annotation) \n  // that implement the FortuneService interface\n\t@Autowired\n\tpublic TennisCoach(FortuneService theFortuneService) {\n\t\tfortuneService = theFortuneService;\n\t}\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice your backhand volley\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n\n}\n\n\n\nThe main method and the configuration files remain unchanged.\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class AnnotationDemoApp {\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// get the bean from spring container\n\t\tCoach theCoach = context.getBean(\"tennisCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\n\t\t// call method to get daily fortune\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Inversion of Control.html",
    "title": "Inversion of Control",
    "body": "\n\nBack\n\n\nInversion of Control\n\n\n\n\nLet's see how to make us of Inversion of Control with Annotations:\n\n\nEnable Component Scanning\n\n\nWe remove all of the beans we defined, and enable component scanning:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\">\n\n\t<!-- add entry to enable component scanning -->\n\n\t<context:component-scan base-package=\"com.springdemo\" />\n\n</beans>\n\n\n\nNow Spring will scan recursively all of the files in this package.\n\n\nAdd @Component Annotation to Classes\n\n\nWe add the @Component annotation to our classes (note we do not add it to the interfaces like Coach).\n\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\n\n@Component\n// We can also set the explicit name like\n// @Component(\"myTennisCoach\")\npublic class TennisCoach implements Coach {\n\t\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice your backhand volley\";\n\t}\n}\n\n\n\nNote that we can name the component explicitly or by default.\n\n\nMain Method\n\n\nIn our application we do not really need to change anything. We create our bean the same way we did before.\nThe only thing to note is that if we set the name of the Component explicitly, then when we instantiate the bean, we should refer to it by said name.\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class AnnotationDemoApp {\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// get the bean from spring container\n\t\t// If we set the name explicitly\n\t\tCoach theCoach = context.getBean(\"myTennisCoach\", Coach.class);\n    // Else\n\t\tCoach theCoach = context.getBean(\"tennisCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t\t\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/index.html",
    "title": "Java Annotations",
    "body": "\n\nBack\n\n\nJava Annotations\n\n\n\n\nJava Annotations are special labels added to classes. They provide metadata about the class, and can be processed at compile time or run-time for special processing.\n\n\n\nWe use annotations to minimize the XML configuration.\n\n\n\nSpring scans the classes to find Beans and configure them internally (as we have done with the XML configuration).\n\n\n\nIn order to use this approach we need to:\n\n\n\n\nEnable component scanning in our Spring configuration file and\n\n\nAdd the @Component annotation to our class\n\n\n\n\n\n\n\nInversion of Control\n\n\nDependency Injection\n\n\nScopes\n\n\nLife Cycles\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Life Cycles.html",
    "title": "Life Cycle",
    "body": "\n\nBack\n\n\nLife Cycle\n\n\n\n\nTo define methods to add when the beans is constructed or destroyed we use the PostConstruct and PreDestroy annotation.\n\n\npackage com.springdemo;\n\npublic class TrackCoach implements Coach {\n\t\n\tprivate FortuneService fortuneService;\n\t\n\tpublic TrackCoach() {\n\t\t\n\t}\n\t\n\tpublic TrackCoach(FortuneService fortuneService) {\n\t\tthis.fortuneService = fortuneService;\n\t}\n\t\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Run a hard 5k\";\n\t}\n\t\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn \"Just Do It: \" + fortuneService.getFortune();\n\t}\n\t\n\t// Run when the bean is done creating\n\t@PostConstruct\n\tpublic void doMyStartupStuff() {\n\t\tSystem.out.println(\"TrackCoach: inside method doMyStartupStuff\");\n\t}\n\t\n\t// Run before the bean is destroyed\n\t@PreDestroy\n\tpublic void doMyCleanupStuffYoYo() {\n\t\tSystem.out.println(\"TrackCoach: inside method doMyCleanupStuffYoYo\");\t\t\n\t}\n}\n\n\n\n\nRefer to more information about scopes are in Bean Life Cycle:\n\n\nNotes\n\n\n\nAccess modifier: The method can have any access modifier (public, protected, private)\n\n\n\n\n\nReturn type: The method can have any return type. However, \"void' is most commonly used. If you give a return type just note that you will not be able to capture the return value. As a result, \"void\" is commonly used.\n\n\n\n\n\nMethod name: The method can have any method name.\n\n\n\n\n\nArguments: The method can not accept any arguments. The method should be no-arg.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Qualifier Annotation.html",
    "title": "Qualifier",
    "body": "\n\nBack\n\n\nQualifier\n\n\n\n\nIn order to specify which specific implementation of an interface we want to use, when this interface is implemented by several beans, then we use the Qualifier annotation.\n\n\n\nThe Qualifier annotation can be used in any Dependency Injection implementation:\n\n\n\n\nConstructor Injection (has different syntax)\n\n\nSetter Injection\n\n\nMethod Injection\n\n\nField Injection\n\n\n\nDefine Dependency as Component\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\n\n// We tell spring this is a bean\n@Component\npublic class HappyFortuneService implements FortuneService {\n\n\t@Override\n\tpublic String getFortune() {\n\t\treturn \"Today is your lucky day!\";\n\t}\n\n}\n\n\nSpecify Dependency\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\nimport org.springframework.beans.factory.annotation.Autowired;\n\n@Component\npublic class TennisCoach implements Coach {\n\t\n\t// We tell spring to search for beans (classes with @Component annotation) \n\t// that implement the FortuneService interface whose name is \"happyFortuneService\"\n\t// (note this is the default name of the component if you set one explicitly you \n\t// will have to specify that one in the Qualifier annotation)\n\t@Autowired\n\t@Qualifier(\"happyFortuneService\")\n\tprivate FortuneService fortuneService;\n\t\n\tpublic TennisCoach() {}\n\t\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice your backhand volley\";\n\t}\n\t\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n}\n\n\n\nThe main method and the configuration files remain unchanged. And when we execute this piece of code, spring will automatically inject the dependency because of the Autowired annotation.\n\n\npackage com.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class AnnotationDemoApp {\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// get the bean from spring container\n\t\tCoach theCoach = context.getBean(\"tennisCoach\", Coach.class);\n\t\t\n\t\t// call a method on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\n\t\t// call method to get daily fortune\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n\n\nQualifier in Constructor\n\npackage com.springdemo;\nimport org.springframework.beans.factory.annotation.Autowired;\n\nimport org.springframework.beans.factory.annotation.Qualifier;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class TennisCoach implements Coach {\n\n    private FortuneService fortuneService;\n\n    // define a default constructor\n    public TennisCoach() {\n        System.out.println(\">> TennisCoach: inside default constructor\");\n    }\n    \n    @Autowired\n    public TennisCoach(@Qualifier(\"happyFortuneService\") FortuneService theFortuneService) {\n\n        System.out.println(\">> TennisCoach: inside constructor using @autowired and @qualifier\");\n        \n        fortuneService = theFortuneService;\n    }\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Java Annotations/Scopes.html",
    "title": "Scopes",
    "body": "\n\nBack\n\n\nScopes\n\n\n\n\nTo explicitly specify scopes with Java Annotations you do as follows:\n\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\nimport org.springframework.context.annotation.Scope;\n\n@Component\n@Scope(\"singleton\")\npublic class TennisCoach implements Coach {\n...\n\n\n\nor \n\n\npackage com.springdemo;\n\nimport org.springframework.stereotype.Component;\nimport org.springframework.context.annotation.Scope;\n\n@Component\n@Scope(\"prototype\")\npublic class TennisCoach implements Coach {\n...\n\n\n\nRefer to more information about scopes are in Bean Scopes:\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Controller.html",
    "title": "Rest Controller",
    "body": "\n\nBack\n\n\nRest Controller\n\n\n\n\nIn this section we are going to show how to create a REST controller in a Spring Boot application:\n\n\nCreate Controller\n\n\nThe controller is the same as in Spring REST:\n\n\npackage com.springboot.demo.mycoolapp.rest;\n\nimport java.time.LocalDateTime;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class FunRestController {\n\t\t\n\t// expose \"/\" that return \"Hello World\"\n\t\n\t@GetMapping(\"/\")\n\tpublic String sayHello() {\n\t\treturn \"Hello World! Time on server is \" + LocalDateTime.now();\n\t}\n\t\n\n\n\nMain App\n\n\nThe SpringBootApplication is made up of three annotations:\n\n\n\nAuto configuration (@EnableAutoConfiguration)\n\n\nComponent scanning (@ComponentScan)\n\n\nAdditional configuration (@Configuration)\n\n\n\npackage com.springboot.demo.mycoolapp;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n// Annotation to tell Spring this is an spring application\n@SpringBootApplication\npublic class MycoolappApplication {\n\n\tpublic static void main(String[] args) {\n\t\t// Boostrap spring boot application\n\t\tSpringApplication.run(MycoolappApplication.class, args);\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Spring Boot Project Structure.html",
    "title": "Spring Boot Project Structure",
    "body": "\n\nBack\n\n\nSpring Boot Project Structure\n\n\n\nApplication Properties\n\n\nBy default, Spring Boot will load properties from: application.properties in the src project directory. We inject it in our code the same way we did it with Spring\n\n\nStatic Content\n\n\nBy default, Spring Boot wil load static resources from \"/static\" directory\n\n\nTesting\n\n\nUnit tests are stored on the src directory under the /test folder\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Spring Data REST.html",
    "title": "Spring Data Rest",
    "body": "\n\nBack\n\n\nSpring Data Rest\n\n\n\n\nWhat if we want to also reduce the code for creating API, that is, what if Spring could create a REST API for us using our JPARepository, such that it would expose all of the basic REST API CRUD features automatically.\n\n\n\nWhat does it do? \n\n\n\n\nIt scans your project fro JPARepository\n\n\nIt exposes REST APIs for each entity type for your JPARepository\n\n\n\n\nSo now, we can remove our Employee services and our REST Controllers, because it is handled automatically by Spring. The only thing needed is adding Spring Data REST as a dependency:\n\n\n\t<dependencies>\n    ...\n\t\t<!-- Add dependency for Spring Data REST -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-data-rest</artifactId>\n\t\t</dependency>\n    ...\n\t</dependencies>\n\n\n\n\n\nTo sum up, now in your application you only will have:\n\n\n\n\nYour entity: Employee\n\n\nThe corresponding JPA Repository: EmployeeRepository\n\n\nDependency\n\n\nMain application\n\n\n\n\nThe first one applies to each entity your application has.\n\n\n\n\n\nSpring Data Rest is HATEOAS compliant (the responses include metadata about itself).\n\n\n\nConfiguration\n\n\n\nYou can specify the name of the endpoint that is exposed (by the default is the plural of the entity) with:\n@RepositoryRestResource(path=\"members\")\npublic interface EmployeeRepository extends JpaRepository<Employee, Integer> {\n}\n\n\n\nThe default number of elements returned are 20, then we can use pagination to retrieve the next ones with query parameters (?page=0).\n\n\nSome properties available to tweak in application.properties are:\n\n\n\nspring.data.rest.base-path: Base path used to expose repository resources\n\n\nspring.data.rest.default-page-size: Default size pages\n\n\nspring.data.rest.max-page-size: Maximum size of pages\n\n\n\n\nSorting\n\n\nYou can sort by the property names of your entity. On the Employee example we have firstName, lastName and email, therefore we can do:\n\n\n\nhttp://localhost:8080/employees?sort=firstName\n\n\n\nor \n\n\n\nhttp://localhost:8080/employees?sort=firstName,desc\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Spring Boot Actuator.html",
    "title": "Spring Boot Actuator",
    "body": "\n\nBack\n\n\nSpring Boot Actuator\n\n\n\n\nSpring Boot Actuator automatically exposes endpoints to monitor and manage your application. You only need to add the dependency to you pom.xml file:\n\n\n...\n\t<dependencies>\n\n    ...\n\n\t\t<!-- ADD SUPPORT FOR SPRING BOOT ACTUATOR -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-actuator</artifactId>\n\t\t</dependency>\n\t\t\t\t\n\t</dependencies>\n...\n\n\n\nThe endpoints are prefixed by /actuator, some of them are:\n\n\n\n\n/health: health information about your application\n\n\n/info: information about your project. By default it return an empty json object. You can add info through application.properties as follows:\n\n\n\ninfo.app.name=My Super Cool App\ninfo.app.description=A crazy fun app, yoohoo!\ninfo.app.version=1.0.0\n\n\n\n\n/auditevents: Audit events for your application\n\n\n/beans: List of all beans registered in the Spring application context\n\n\n/mappings: List of all @RequestMapping path\n\n\n\n\n\n\nBy default only /health and /info are exposed, to expose all actuator endpoints you need to specify on application.properties (you can also specify only the ones you want separated by commas): \n\n\nmanagement.endpoints.web.exposure.include=*\n\n\nAdd security\n\n\nFirst you need to add Spring Security as a dependency in your pom.xml: \n\n\n...\n\t<dependencies>\n\t\t...\n    <!-- SECURITY -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-security</artifactId>\n\t\t</dependency>\n\t\t...\n\t</dependencies>\n...\n\n\n\nNow, when we access some endpoints like /actuator/beans Spring will prompt a login to grant access to the endpoint.\n\n\n\n\nThe default user name is \"user\"\n\n\nThe password will be printed on the console where you start the application\n\n\n\n\nTo override these defaults edit the application.properties file as follows:\n\n\nspring.security.user.name=alba\nspring.security.user.password=mypassword\n\n\n\n\n\nWe can also exclude endpoints by adding the following declarations to the application.properties file:\n\n\nmanagement.endpoints.web.exposure.exclude=health,info\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Spring Data JPA.html",
    "title": "Spring Data JPA",
    "body": "\n\nBack\n\n\nSpring Data JPA\n\n\n\n\nWith JPA API we created a Employee DAO, however what if we need to create one for each entity we manage. Then we would duplicate a lot of code, because the calls to the API are basically the same. \n\n\n\nThat is what we use Spring Data JPA, we plug in the entity type and the primary key to the DAO, and Spring creates it an manages it for us.\n\n\n\n\nCreate Repository\n\n\nSo now the Employee DAO is as follows:\n\n\npackage com.springboot.cruddemo.dao;\n\nimport org.springframework.data.jpa.repository.JpaRepository;\n\nimport com.springboot.cruddemo.entity.Employee;\n\npublic interface EmployeeRepository extends JpaRepository<Employee, Integer> {\n}\n\n\nUse Repository\n\n\nAnd the Employee Service is:\n\n\npackage com.springboot.cruddemo.service;\n\nimport java.util.List;\nimport java.util.Optional;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport com.springboot.cruddemo.dao.EmployeeRepository;\nimport com.springboot.cruddemo.entity.Employee;\n\n@Service\npublic class EmployeeServiceImpl implements EmployeeService {\n\n  // Here we make use of the above implemented repository\n\tprivate EmployeeRepository employeeRepository;\n\t\n\t@Autowired\n\tpublic EmployeeServiceImpl(EmployeeRepository theEmployeeRepository) {\n\t\temployeeRepository = theEmployeeRepository;\n\t}\n\t\n\t@Override\n\tpublic List<Employee> findAll() {\n\t\treturn employeeRepository.findAll();\n\t}\n\n\t@Override\n\tpublic Employee findById(int theId) {\n\t\tOptional<Employee> result = employeeRepository.findById(theId);\n\t\t\n\t\tEmployee theEmployee = null;\n\t\t\n\t\tif (result.isPresent()) {\n\t\t\ttheEmployee = result.get();\n\t\t}\n\t\telse {\n\t\t\t// we didn't find the employee\n\t\t\tthrow new RuntimeException(\"Did not find employee id - \" + theId);\n\t\t}\n\t\t\n\t\treturn theEmployee;\n\t}\n\n\t@Override\n\tpublic void save(Employee theEmployee) {\n\t\temployeeRepository.save(theEmployee);\n\t}\n\n\t@Override\n\tpublic void deleteById(int theId) {\n\t\temployeeRepository.deleteById(theId);\n\t}\n\n}\n\n\n\nThis EmployeeService implements the interface:\n\n\npackage com.springboot.cruddemo.service;\n\nimport java.util.List;\n\nimport com.springboot.cruddemo.entity.Employee;\n\npublic interface EmployeeService {\n\n\tpublic List<Employee> findAll();\n\t\n\tpublic Employee findById(int theId);\n\t\n\tpublic void save(Employee theEmployee);\n\t\n\tpublic void deleteById(int theId);\n\t\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Spring Boot DevTools.html",
    "title": "Spring Boot DevTools",
    "body": "\n\nBack\n\n\nSpring Boot DevTools\n\n\n\n\nSpring Boot Dev Tools automatically restart your application when code is updated. The only thing you need to do is add the module to the dependencies:\n\n\n...\n\t<dependencies>\n\n\t\t<!-- ADD SUPPORT FOR AUTOMATIC RELOADING -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-devtools</artifactId>\n\t\t</dependency>\n\t\t\t\t\n\t</dependencies>\n...\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Application Properties.html",
    "title": "Application Properties",
    "body": "\n\nBack\n\n\nApplication Properties\n\n\n\n\nBy default Spring Boot reads information from a standard properties file in src/main/resources/application.properties. You can define any custom properties in this file and your app can access properties using the annotation @Value(We have done this before).\n\n\nConfiguring the Spring Boot Server\n\n\nSome properties offered by Spring are:\n\n\nCore\n\n# Log levels severity mapping\nlogging.level.org.springframework=DEBUG\nlogging.level.org.hibernate=TRACE\nlogging.level.org.luv2code=INFO\n\n# Log file name\nlogging.file=date.log\n\n\nWeb\n\n# HTTP Server port\nserver.port=7070\n\n# Context path of the application\nserver.servlet.context-path=/my-app\n\n# Default HTTP Session timeout\nserver.servlet.session.timeout=15m\n\n\nActuator Properties\n\n# Endpoints to include by name or wildcard\nmanagement.endpoints.web.exposure.include=*\n\n# Endpoints to exclude by name or wildcard\nmanagement.endpoints.web.exposure.exclude=beans,mapping\n\n\nSecurity\n\n# Default username\nspring.security.user.name=admin\n \n# Password for default user\nspring.security.user.password=mypass\n\n\nData Properties\n\n# JDBC URL of the database\nspring.datasource.url=jdbc:mysql://localhost:3306/myapp\n \n# Login username of the database\nspring.datasource.username=alba\n \n# Login password of the database\nspring.datasource.password=testpass\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/JPA.html",
    "title": "JPA",
    "body": "\n\nBack\n\n\nJPA\n\n\n\n\nUntil now, to manage data we have been using the EntityManager along with the Hibernate API. However now we are going to use the Standard JPA API.\n\n\n\nThe JPA API methods are similar to Native Hibernate API. It also supports a query language JPQL (JPA Query Language)\n\n\n\nComparing Hibernate to JPA:\n\n\n\n\n\n\n\n\n\nExample: for managing employees with JPA, we first create the Data Access Object:\n\n\npackage com.springboot.cruddemo.dao;\n\nimport java.util.List;\n\nimport javax.persistence.EntityManager;\nimport javax.persistence.Query;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Repository;\n\nimport com.luv2code.springboot.cruddemo.entity.Employee;\n\n@Repository\npublic class EmployeeDAOJpaImpl implements EmployeeDAO {\n\n\tprivate EntityManager entityManager;\n\t\n\t@Autowired\n\tpublic EmployeeDAOJpaImpl(EntityManager theEntityManager) {\n\t\tentityManager = theEntityManager;\n\t}\n\t\n\t@Override\n\tpublic List<Employee> findAll() {\n\n\t\t// create a query\n\t\tQuery theQuery = \n\t\t\t\tentityManager.createQuery(\"from Employee\");\n\t\t\n\t\t// execute query and get result list\n\t\tList<Employee> employees = theQuery.getResultList();\n\t\t\n\t\t// return the results\t\t\n\t\treturn employees;\n\t}\n\n\t@Override\n\tpublic Employee findById(int theId) {\n\n\t\t// get employee\n\t\tEmployee theEmployee = \n\t\t\t\tentityManager.find(Employee.class, theId);\n\t\t\n\t\t// return employee\n\t\treturn theEmployee;\n\t}\n\n\t@Override\n\tpublic void save(Employee theEmployee) {\n\n\t\t// save or update the employee\n\t\tEmployee dbEmployee = entityManager.merge(theEmployee);\n\t\t\n\t\t// update with id from db ... so we can get generated id for save/insert\n\t\ttheEmployee.setId(dbEmployee.getId());\n\t\t\n\t}\n\n\t@Override\n\tpublic void deleteById(int theId) {\n\n\t\t// delete object with primary key\n\t\tQuery theQuery = entityManager.createQuery(\n\t\t\t\t\t\t\t\"delete from Employee where id=:employeeId\");\n\t\t\n\t\ttheQuery.setParameter(\"employeeId\", theId);\n\t\t\n\t\ttheQuery.executeUpdate();\n\t}\n\n}\n\n\n\nAnd then we call it from the Employee Service:\n\n\npackage com.springboot.cruddemo.service;\n\nimport java.util.List;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.beans.factory.annotation.Qualifier;\nimport org.springframework.stereotype.Service;\nimport org.springframework.transaction.annotation.Transactional;\n\nimport com.springboot.cruddemo.dao.EmployeeDAO;\nimport com.springboot.cruddemo.entity.Employee;\n\n@Service\npublic class EmployeeServiceImpl implements EmployeeService {\n\n\tprivate EmployeeDAO employeeDAO;\n\t\n\t@Autowired\n\tpublic EmployeeServiceImpl(@Qualifier(\"employeeDAOJpaImpl\") EmployeeDAO theEmployeeDAO) {\n\t\temployeeDAO = theEmployeeDAO;\n\t}\n\t\n\t@Override\n\t@Transactional\n\tpublic List<Employee> findAll() {\n\t\treturn employeeDAO.findAll();\n\t}\n\n\t@Override\n\t@Transactional\n\tpublic Employee findById(int theId) {\n\t\treturn employeeDAO.findById(theId);\n\t}\n\n\t@Override\n\t@Transactional\n\tpublic void save(Employee theEmployee) {\n\t\temployeeDAO.save(theEmployee);\n\t}\n\n\t@Override\n\t@Transactional\n\tpublic void deleteById(int theId) {\n\t\temployeeDAO.deleteById(theId);\n\t}\n}\n\n\n\nThis class implements the following interface:\n\n\npackage com.springboot.cruddemo.service;\n\nimport java.util.List;\n\nimport com.springboot.cruddemo.entity.Employee;\n\npublic interface EmployeeService {\n\n\tpublic List<Employee> findAll();\n\t\n\tpublic Employee findById(int theId);\n\t\n\tpublic void save(Employee theEmployee);\n\t\n\tpublic void deleteById(int theId);\n\t\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/index.html",
    "title": "Overview",
    "body": "\n\nBack\n\n\nOverview\n\n\n\n\nSpring Boot is a framework that:\n\n\n\n\nMake it easier to get started with Spring development\n\n\nMinimize the amount of manual configuration\n\n\n\nPerform auto-configuration based on props files and JAR classpath\n\n\n\nHelp to resolve dependency conflicts (Maven or Gradle)\n\n\nProvide an embedded HTTP server so you can get started quickly\n\n\n\n\nTo create a new project you just have to go to Spring Initiliazr, where you simply select your dependencies and lets you create a maven/gradle project and import it into an IDE.\n\n\n\nSo now our app is a jar file, and it includes the source code and also the embedded http server, so can be ran from the command line, from your IDE, etc. However if you want to export your code as a war file, you can also do that by exporting only your source code, without the embedded server.\n\n\n\nWith the jar file you can run your application by executing:\n\n\n$ java -jar app.jar\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/SpringBoot/Spring Boot Starters.html",
    "title": "Spring Boot Starters",
    "body": "\n\nBack\n\n\nSpring Boot Starters\n\n\n\n\nSpring Boot Staters offer a curated list of dependencies that are grouped together and tested by the Spring Development Team. \n\n\n\nSo now, if your application depends on the Web and Security module and also uses Thymeleaf and JPA, you add the following dependencies:\n\n\n\n...\n\t<dependencies>\n\n    <!-- WEB -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-web</artifactId>\n\t\t</dependency>\n    \n    <!-- SECURITY -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-security</artifactId>\n\t\t</dependency>\n    \n    <!-- JPA -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-data-jpa</artifactId>\n\t\t</dependency>\n    \n    <!-- Thymeleaf -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-starter-thymeleaf</artifactId>\n\t\t</dependency>\n    \n\t\t<!-- ADD SUPPORT FOR AUTOMATIC RELOADING -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-devtools</artifactId>\n\t\t</dependency>\n\t\t\t\t\n\t</dependencies>\n...\n\n\nSpring Boot Starter Parent\n\n\nThis is a special starter that provides defaults:\n\n\n\n\nDefault compiler level\n\n\nUTF-8 source encoding\n\n\n\n\nYou include it in your pom.xml file as follows: \n\n\n...\n\t<parent>\n\t\t<groupId>org.springframework.boot</groupId>\n\t\t<artifactId>spring-boot-starter-parent</artifactId>\n\t\t<version>2.1.2.RELEASE</version>\n\t\t<relativePath/> <!-- lookup parent from repository -->\n\t</parent>\n\n\t<dependencies>\n\t...\n\t</dependencies>\n...\n\n\n\nIf you want to override a default, you use properties:\n\n\n...\n\t<parent>\n\t\t<groupId>org.springframework.boot</groupId>\n\t\t<artifactId>spring-boot-starter-parent</artifactId>\n\t\t<version>2.1.2.RELEASE</version>\n\t\t<relativePath/> <!-- lookup parent from repository -->\n\t</parent>\n\t\n\t<!-- Override default java version -->\n\t<properties>\n\t\t<java.version>1.8</java.version>\n\t</properties>\n\n\t<dependencies>\n\t...\n\t</dependencies>\n...\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/Pointcut Declarations.html",
    "title": "Pointcut Declarations",
    "body": "\n\nBack\n\n\nPointcut Declarations\n\n\n\n\nHow can we reuse a pointcut expression? We need to:\n\n\n\n\nCreate a pointcut Declaration\n\n\nApply the pointcut declaration to the advices we want\n\n\n\n\nCreate Pointcut Declaration\n\n\nWe define the pointcut declaration with the Pointcut annotation and we bind it to an arbitrary method.\n\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.annotation.Pointcut;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\npublic class MyDemoLoggingAspect {\n\n\t@Pointcut(\"execution(* com.aopdemo.dao.*.*(..))\")\n\tprivate void forDaoPackage() {}\n}\n\n\nReuse Pointcut Declaration\n\n\nTo reuse this declaration we simply call the method that is bound to the pointcut declaration:\n\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.annotation.Pointcut;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\npublic class MyDemoLoggingAspect {\n\n\t@Pointcut(\"execution(* com.aopdemo.dao.*.*(..))\")\n\tprivate void forDaoPackage() {}\n\t\n  // Reuse declaration\n\t@Before(\"forDaoPackage()\")\n\tpublic void beforeAddAccountAdvice() {\t\t\n\t\tSystem.out.println(\"\\n=====>>> Executing @Before advice on method\");\t\t\n\t}\n\t\n  // Reuse declaration\n\t@Before(\"forDaoPackage()\")\n\tpublic void performApiAnalytics() {\n\t\tSystem.out.println(\"\\n=====>>> Performing API analytics\");\t\t\n\t}\n\t\n}\n\n\nCombine Pointcut Declarations\n\n\nHow can we apply multiple pointcut expressions to a single advice? Well we can combine pointcut expressions using logic operators:\n\n\n\n\nAND (&&)\n\n\nOR (||)\n\n\nNOT (!)\n\n\n\n\nFor example: \n\n\n@Before(\"expressionOne() && expressionTwo()\")\n\n\n@Before(\"expressionOne() || expressionTwo()\")\n\n\n@Before(\"expressionOne() && !expressionTwo()\")\n\n\n\nImagine we want to execute an advice for every method in the package except for getters and setters, then we do:\n\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.annotation.Pointcut;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\npublic class MyDemoLoggingAspect {\n\n\t@Pointcut(\"execution(* com.aopdemo.dao.*.*(..))\")\n\tprivate void forDaoPackage() {}\n\t\n\t// create pointcut for getter methods\n\t@Pointcut(\"execution(* com.aopdemo.dao.*.get*(..))\")\n\tprivate void getter() {}\n\t\n\t// create pointcut for setter methods\n\t@Pointcut(\"execution(* com.aopdemo.dao.*.set*(..))\")\n\tprivate void setter() {}\n\t\n\t// create pointcut: include package ... exclude getter/setter\n\t@Pointcut(\"forDaoPackage() && !(getter() || setter())\")\n\tprivate void forDaoPackageNoGetterSetter() {}\n\t\n\t@Before(\"forDaoPackageNoGetterSetter()\")\n\tpublic void beforeAddAccountAdvice() {\t\t\n\t\tSystem.out.println(\"\\n=====>>> Executing @Before advice on method\");\t\t\n\t}\n\t\n\t@Before(\"forDaoPackageNoGetterSetter()\")\n\tpublic void performApiAnalytics() {\n\t\tSystem.out.println(\"\\n=====>>> Performing API analytics\");\t\t\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/Control Aspect Order.html",
    "title": "Control Aspect Order",
    "body": "\n\nBack\n\n\nControl Aspect Order\n\n\n\n\nHow do we control the order of advices being applied when they all match the pointcut expressions?\n\n\n\nTo control order we should: \n\n\n\n\nRefactor: place advices in separate Aspects\n\n\nControl order on Aspects using the @Order annotation\n\n\n\nRefactor and Order\n\n\nWe are going to create three aspects separate from each other as follows:\n\n\n\n\n\n\n\nSo with the ordering the aspect flow looks something like this:\n\n\n\n\n\n\nLog to Cloud Aspect\n\npackage com.luv2code.aopdemo.aspect;\n\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\n// Set order\n@Order(1)\npublic class MyCloudLogAsyncAspect {\n\n\t@Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\")\n\tpublic void logToCloudAsync() {\n\t\tSystem.out.println(\"\\n=====>>> Logging to Cloud in async fashion\");\t\t\n\t}\n\n}\n\n\nLogging Aspect\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\n// Set the order\n@Order(2)\npublic class MyDemoLoggingAspect {\n\t\n\t@Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\")\n\tpublic void beforeAddAccountAdvice() {\t\t\n\t\tSystem.out.println(\"\\n=====>>> Executing @Before advice on method\");\t\t\n\t}\n\t\n}\n\n\nAnalytics Aspect\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\n// Set the order\n@Order(3)\npublic class MyApiAnalyticsAspect {\n\n\t@Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\")\n\tpublic void performApiAnalytics() {\n\t\tSystem.out.println(\"\\n=====>>> Performing API analytics\");\t\t\n\t}\n\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/Pointcut Expressions.html",
    "title": "Pointcut Expressions",
    "body": "\n\nBack\n\n\nPointcut Expressions\n\n\n\n\nA pointcut expression is a predicate expression that tells spring when to apply a given advice. Spring AOP uses AspectJ's pointcut expression language.\n\n\n\nExecution Pointcut\n\n\nThe expression pattern is the following:\n\n\nexecution(modifiers-pattern? return-type-pattern declaring-type-pattern? method-name-pattern(param-pattern) throws-pattern?)\n\n\n\n\nmodifiers-pattern?: Spring AOP only supports public or *\n\n\nreturn-type-pattern: void, boolean, string, List<Costumer>, etc\n\n\ndeclaring-type-pattern?: the class name\n\n\nmethod-name-pattern(param-pattern): method name to match, and parameters type to match\n\n\nthrows-pattern?: exception types to match\n\n\n\n\nIf the parameter is optional it is followed by an ?. You can also add wildcards inside the patterns. \n\n\nMatch Methods\n\n\nSome examples are:\n\n\n\n\nMatch concrete method inside a class:\n\n\n\n@Before(\"execution(public void com.aopdemo.dao.AccountDAO.addAccount())\")\n\n\n\n\nMatch a method inside any class:\n\n\n\n@Before(\"execution(public void addAccount())\")\n\n\n\n\nMatch any method that starts with add:\n\n\n\n@Before(\"execution(public void add*())\")\n\n \n\n\nMatch all methods inside a given package:\n\n\n\n@Before(\"execution(* com.aopdemo.dao.*.*(..))\")\n\n\n\n\nThe first * denotes the return type, it can be anything\n\n\nThe second * denotes the class name, it can be anything inside the package\n\n\nThe third * denotes the method name, it can be anything\n\n\nLastly, .. denotes the param-type, there can be 0 or more parameters\n\n\n\nMatch Parameters\n\n\nThere are the following parameter pattern wildcards:\n\n\n\n\n(): matches a method with no arguments\n\n\n(*): matches a method with one argument of any type\n\n\n(..): matches a method with 0 or more arguments of any type\n\n\n\n\nFor example:\n\n\n\n\nMatch addAccount methods with no arguments:\n\n\n\n@Before(\"execution(* addAccount())\")\n\n\n\n\nMatch addAcount methods with one Account parameter:\n\n\n\n@Before(\"execution(* addAccount(com.aopdemo.Account))\")\n\n \n\n\nMatch addAcount methods with any number of parameters:\n\n\n\n@Before(\"execution(* addAccount(*))\")\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/After Advice.html",
    "title": "After Advice",
    "body": "\n\nBack\n\n\nAfter Advice\n\n\n\n\nThis advice runs always when the method is completed (like a finally clause inside a try catch).\n\n\n\nFor example if we want to always run the advice afterFinallyFindAccountsAdvice when the method findAccounts inside AccountDAO finishes:\n\n\npackage com.aopdemo.aspect;\n\nimport java.util.List;\n\nimport org.aspectj.lang.JoinPoint;\nimport org.aspectj.lang.annotation.After;\nimport org.aspectj.lang.annotation.AfterReturning;\nimport org.aspectj.lang.annotation.AfterThrowing;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.reflect.MethodSignature;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\nimport com.aopdemo.Account;\n\n@Aspect\n@Component\n@Order(2)\npublic class MyDemoLoggingAspect {\n\n\t@After(\"execution(* com.aopdemo.dao.AccountDAO.findAccounts(..))\")\n\tpublic void afterFinallyFindAccountsAdvice(JoinPoint theJoinPoint) {\n\t\t\n\t\t// print out which method we are advising on\n\t\tString method = theJoinPoint.getSignature().toShortString();\n\t\tSystem.out.println(\"\\n=====>>> Executing @After (finally) on method: \" \n\t\t\t\t\t\t\t+ method);\n\t\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/Before Advice.html",
    "title": "Before Advice",
    "body": "\n\nBack\n\n\nBefore Advice\n\n\n\n\nWe use the tag @Before to execute some code before we call the target object function:\n\n\n\n\n\n\nAdd Dependencies\n\n\n\nWe have to download the AspectJ jar file, because Spring AOP depends on some on their framework's classes \n\n\n \nCreate Target Object\n\n\nWe create a DAO object:\n\n\npackage com.aopdemo.dao;\n\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class AccountDAO {\n\tpublic void addAccount() {\n\t\tSystem.out.println(\n\t\t\tgetClass() \n\t\t\t+ \": DOING MY DB WORK: ADDING AN ACCOUNT\"\n\t\t);\n\t}\n}\n\n\nSpring Configuration\n\n\nWe now have to enable AOP proxying in our app configuration:\n\n\npackage com.aopdemo;\n\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.EnableAspectJAutoProxy;\n\n@Configuration\n// Enable proxying to add before advice\n@EnableAspectJAutoProxy\n@ComponentScan(\"com.aopdemo\")\npublic class DemoConfig {\n\n}\n\n\nCreate Aspect with @Before\n\n\nNow it is time to create an aspect with @Before advice:\n\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\npublic class MyDemoLoggingAspect {\n\n\t// this is where we add all of our related advices for logging\n\t// Here we specify we want to run this code before calling the \n\t// object method public void addAccount\n\t@Before(\"execution(public void addAccount())\")\n\tpublic void beforeAddAccountAdvice() {\n\t\tSystem.out.println(\"\\n=====>>> Executing @Before advice on addAccount()\");\n\t}\n}\n\n\nMain App\n\n\nWe now create a demo app:\n\n\npackage com.aopdemo;\n\nimport org.springframework.context.annotation.AnnotationConfigApplicationContext;\n\nimport com.aopdemo.dao.AccountDAO;\n\npublic class MainDemoApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// read spring config java class\n\t\tAnnotationConfigApplicationContext context =\n\t\t\t\tnew AnnotationConfigApplicationContext(DemoConfig.class);\n\t\t\n\t\t// get the bean from spring container\n\t\tAccountDAO theAccountDAO = context.getBean(\"accountDAO\", AccountDAO.class);\n\t\t\n\t\t// call the business method\n\t\ttheAccountDAO.addAccount();\n\n\t\t// do it again!\n\t\tSystem.out.println(\"\\nlet's call it again!\\n\");\n\t\t\n\t\t// call the business method again\n\t\ttheAccountDAO.addAccount();\n\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/Overview.html",
    "title": "Overview",
    "body": "\n\nBack\n\n\nOverview\n\n\n\n\nAspect-Oriented Programming is a programming technique based on the concept of an Aspect (that is something that encapsulated cross-cutting logic/functionality, which means logic that affect the project transversally like logging or security).\n\n\n\nWhat AOP does behind the scenes is call methods from the classes/aspects (like a logging class) whenever a method is called (this depends on the configuration):\n\n\n\n\n\n\nAdvantages\n\n\n\nReusable modules\n\n\nResolve code tangling\n\n\nResolve code scatter\n\n\nApplied selectively based on configuration\n\n\n\nDisadvantages\n\n\n\nToo many aspects and app flow is hard to follow \n\n\nMinor performance cost for aspect execution\n\n\n\nTerminology\n\n\n\nAspect: module of code for a cross-cutting concern (logging, security...)\n\n\nAdvice: what action is takes and when it should be applied\n\n\nJoint Point: when to apply code during program execution\n\n\nPointcut: a predicate expression for where advice should be applied\n\n\n\nAdvice Types\n\n\n\nBefore advice: run before the method\n\n\nAfter finally advice: run after the method (like finally clause in try catch)\n\n\nAfter returning advice: run after the method (success execution)\n\n\nAfter throwing advice: run after the method (if exception if thrown)\n\n\nAround advice: run before and after the method\n\n\n\n\nWeaving\n\n\nIt refers to the connection being made between aspects and target objects to create an advised object. There are different types:\n\n\n\n\nCompile-time\n\n\nLoad-time\n\n\nRun-time\n\n\n\n\nNote that the slowest is the run-time weaving\n\n\nBest Practices\n\n\n\nKeep the code inside the advices small\n\n\nKeep the code fast\n\n\nDo not perform any expensive/slow operations\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/AfterThrowing Advice.html",
    "title": "AfterThrowing Advice",
    "body": "\n\nBack\n\n\nAfterThrowing Advice\n\n\n\n\nThis advice is run whenever the target object throws and execption. For example:\n\n\n\npackage com.aopdemo.aspect;\n\nimport java.util.List;\n\nimport org.aspectj.lang.JoinPoint;\nimport org.aspectj.lang.annotation.AfterReturning;\nimport org.aspectj.lang.annotation.AfterThrowing;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.reflect.MethodSignature;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\nimport com.luv2code.aopdemo.Account;\n\n@Aspect\n@Component\n@Order(2)\npublic class MyDemoLoggingAspect {\n\t\n\t@AfterThrowing(\n\t\t\tpointcut=\"execution(* com.aopdemo.dao.AccountDAO.findAccounts(..))\",\n\t\t\t// Define the name of the parameter that holds the exception object\n\t\t\tthrowing=\"theExc\")\n\tpublic void afterThrowingFindAccountsAdvice(\n\t\t\t\t\tJoinPoint theJoinPoint, Throwable theExc) {\n\t\t\n\t\t// print out which method we are advising on\n\t\tString method = theJoinPoint.getSignature().toShortString();\n\t\tSystem.out.println(\"\\n=====>>> Executing @AfterThrowing on method: \" + method);\n\t\t\n\t\t// log the exception\n\t\tSystem.out.println(\"\\n=====>>> The exception is: \" + theExc);\n\t\n\t}\n}\n\n\n\nIn this code sample we have the advice afterThrowingFindAccountsAdvice that is run whenever the method findAccounts inside AccountDAO throws an exception. We also make use of the throwing attribute that lets us map the exception object to a parameter inside our advice.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/Around Advice.html",
    "title": "Around Advice",
    "body": "\n\nBack\n\n\nAround Advice\n\n\n\n\nThis type of advice is always called before and after the target object.\n\n\n\nWhen using the @Around advice we have access to a reference of a proceeding join point. Which is a handle to the target method, and will let us execute the taget method.\n\n\n\nSo for example if we want to measure the performance of the getFortuneMethod:\n\n\npackage com.aopdemo.aspect;\n\nimport java.util.List;\n\nimport org.aspectj.lang.JoinPoint;\nimport org.aspectj.lang.ProceedingJoinPoint;\nimport org.aspectj.lang.annotation.After;\nimport org.aspectj.lang.annotation.AfterReturning;\nimport org.aspectj.lang.annotation.AfterThrowing;\nimport org.aspectj.lang.annotation.Around;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.reflect.MethodSignature;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\nimport com.aopdemo.Account;\n\n@Aspect\n@Component\n@Order(2)\npublic class MyDemoLoggingAspect {\n\t\n\t@Around(\"execution(* com.aopdemo.service.*.getFortune(..))\")\t\n\tpublic Object aroundGetFortune(\n\t\t\tProceedingJoinPoint theProceedingJoinPoint) throws Throwable {\n\t\t\n\t\t// print out method we are advising on\n\t\tString method = theProceedingJoinPoint.getSignature().toShortString();\n\t\tSystem.out.println(\"\\n=====>>> Executing @Around on method: \" + method);\n\t\t\n\t\t// get begin timestamp\n\t\tlong begin = System.currentTimeMillis();\n\t\t\n\t\t// now, let's execute the method\n\t\tObject result = theProceedingJoinPoint.proceed();\n\t\t\n\t\t// get end timestamp\n\t\tlong end = System.currentTimeMillis();\n\t\t\n\t\t// compute duration and display it\n\t\tlong duration = end - begin;\n\t\tSystem.out.println(\"\\n=====> Duration: \" + duration / 1000.0 + \" seconds\");\n\t\t\n\t\treturn result;\n\t}\n}\n\n\n\nThe advice aroundGetFortune is called before the getFortune is called, then it proceeds to call from inside the advice and we measure how long does the method take to run.\n\n\nException Handling\n\n\nInside an advice, to handle exceptions you can:\n\n\n\n\nHandle the exception inside the advice\n\n\n\n\t@Around(\"execution(* com.aopdemo.service.*.getFortune(..))\")\t\n\tpublic Object aroundGetFortune(\n\t\t\tProceedingJoinPoint theProceedingJoinPoint) throws Throwable {\n\t\t\n\t\t// print out method we are advising on\n\t\tString method = theProceedingJoinPoint.getSignature().toShortString();\n\t\tSystem.out.println(\"\\n=====>>> Executing @Around on method: \" + method);\n\t\t\n\t\t// get begin timestamp\n\t\tlong begin = System.currentTimeMillis();\n\t\t\n\t\ttry {\n\t\t\tresult = theProceedingJoinPoint.proceed();\n\t\t} catch (Exception e) {\n\t\t\t// log the exception\n\t\t\tmyLogger.warning(e.getMessage());\n\t\t\t\n\t\t\t// give users a custom messagee\n\t\t\tresult = \"Major accident! But no worries, \"\n\t\t\t\t\t+ \"your private AOP helicopter is on the way!\";\n\t\t}\n\t\t\n\t\t// get end timestamp\n\t\tlong end = System.currentTimeMillis();\n\t\t\n\t\t// compute duration and display it\n\t\tlong duration = end - begin;\n\t\tSystem.out.println(\"\\n=====> Duration: \" + duration / 1000.0 + \" seconds\");\n\t\t\n\t\treturn result;\n\t}\n\n\n\n\nSimply rethrow the exception\n\n\n\n\t@Around(\"execution(* com.aopdemo.service.*.getFortune(..))\")\t\n\tpublic Object aroundGetFortune(\n\t\t\tProceedingJoinPoint theProceedingJoinPoint) throws Throwable {\n\t\t\n\t\t// print out method we are advising on\n\t\tString method = theProceedingJoinPoint.getSignature().toShortString();\n\t\tSystem.out.println(\"\\n=====>>> Executing @Around on method: \" + method);\n\t\t\n\t\t// get begin timestamp\n\t\tlong begin = System.currentTimeMillis();\n\t\t\n\t\ttry {\n\t\t\tresult = theProceedingJoinPoint.proceed();\n\t\t} catch (Exception e) {\n\t\t\t// log the exception\n\t\t\tmyLogger.warning(e.getMessage());\n\n\t\t\t// rethrow exception\n\t\t\tthrow e;\n\t\t}\n\t\t\n\t\t// get end timestamp\n\t\tlong end = System.currentTimeMillis();\n\t\t\n\t\t// compute duration and display it\n\t\tlong duration = end - begin;\n\t\tSystem.out.println(\"\\n=====> Duration: \" + duration / 1000.0 + \" seconds\");\n\t\t\n\t\treturn result;\n\t}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/JoinPoints.html",
    "title": "JoinPoints",
    "body": "\n\nBack\n\n\nJoinPoints\n\n\n\n\nWhen we are in an aspect, how can we access method parameters?\n\n\nDisplay Method Signature\n\n\nTo display the method signature we do the following:\n\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.JoinPoint;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.reflect.MethodSignature;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\nimport com.aopdemo.Account;\n\n@Aspect\n@Component\n@Order(2)\npublic class MyDemoLoggingAspect {\n\t\n\t@Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\")\n\tpublic void beforeAddAccountAdvice(JoinPoint theJoinPoint) {\n\t\t\n\t\tSystem.out.println(\"\\n=====>>> Executing @Before advice on method\");\t\n\t\t\n\t\t// display the method signature\n\t\tMethodSignature methodSig = (MethodSignature) theJoinPoint.getSignature();\n\t\t\n\t\tSystem.out.println(\"Method: \" + methodSig);\n\t}\n}\n\n\nDisplay Method Arguments\n\n\nAlso, to display the method arguments:\n\n\npackage com.aopdemo.aspect;\n\nimport org.aspectj.lang.JoinPoint;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.reflect.MethodSignature;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\nimport com.aopdemo.Account;\n\n@Aspect\n@Component\n@Order(2)\npublic class MyDemoLoggingAspect {\n\t\n\t@Before(\"com.aopdemo.aspect.LuvAopExpressions.forDaoPackageNoGetterSetter()\")\n\tpublic void beforeAddAccountAdvice(JoinPoint theJoinPoint) {\n\t\t\n\t\tSystem.out.println(\"\\n=====>>> Executing @Before advice on method\");\t\n    \n\t\t// display method arguments\n\t\t// get args\n\t\tObject[] args = theJoinPoint.getArgs();\n\t\t\n\t\t// loop through args\n\t\tfor (Object tempArg : args) {\n\t\t\tSystem.out.println(tempArg);\n\t\t\t\n\t\t\tif (tempArg instanceof Account) {\n\t\t\t\t\n\t\t\t\t// downcast and print Account specific stuff\n\t\t\t\tAccount theAccount = (Account) tempArg;\n\t\t\t\t\n\t\t\t\tSystem.out.println(\"account name: \" + theAccount.getName());\n\t\t\t\tSystem.out.println(\"account level: \" + theAccount.getLevel());\t\t\t\t\t\t\t\t\n\n\t\t\t}\n\t\t}\t\t\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/AOP/AfterReturning Advice.html",
    "title": "AfterReturning Advice",
    "body": "\n\nBack\n\n\nAfterReturning Advice\n\n\n\n\nThis advice is run after the method is done executing, and it executed successfully.\n\n\n\nThe flow of this advice is the following:\n\n\n\n\n\n\n\nSo for example, if you want to have an advice run everytime we call the findAccounts method inside a concrete class, and we also want to print out the result we obtained we do the following:\n\n\npackage com.aopdemo.aspect;\n\nimport java.util.List;\n\nimport org.aspectj.lang.JoinPoint;\nimport org.aspectj.lang.annotation.AfterReturning;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.reflect.MethodSignature;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\nimport com.aopdemo.Account;\n\n@Aspect\n@Component\n@Order(2)\npublic class MyDemoLoggingAspect {\n\t\t\n\t// add a new advice for @AfterReturning on the findAccounts method\n\t@AfterReturning(\n\t\t\tpointcut=\"execution(* com.aopdemo.dao.AccountDAO.findAccounts(..))\",\n      // This is the parameter name of the list of accounts returned by findAccounts\n\t\t\treturning=\"result\")\n\tpublic void afterReturningFindAccountsAdvice(\n\t\t\t\t\tJoinPoint theJoinPoint, List<Account> result) {\n\t\t\n\t\t// print out which method we are advising on \n\t\tString method = theJoinPoint.getSignature().toShortString();\n\t\tSystem.out.println(\"\\n=====>>> Executing @AfterReturning on method: \" + method);\n\t\t\t\t\n\t\t// print out the results of the method call\n\t\tSystem.out.println(\"\\n=====>>> result is: \" + result);\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Spring Rest/POJOs as JSON.html",
    "title": "POJOs as JSON",
    "body": "\n\nBack\n\n\nPOJOs as JSON\n\n\n\n\nTo test converting POJOs to JSON we are going to create a service that allows us to retrieve a list of students:\n\n\n\n\n\n\nCreate POJO\n\n\nWe are going to create the Student entity:\n\n\npackage com.springdemo.entity;\n\npublic class Student {\n\n\tprivate String firstName;\n\tprivate String lastName;\n\t\n\tpublic Student() {\n\t\t\n\t}\n\n\tpublic Student(String firstName, String lastName) {\n\t\tthis.firstName = firstName;\n\t\tthis.lastName = lastName;\n\t}\n\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n\t\n}\n\n\nCreate Service\n\n\nWe now code the logic that handles the controller.\n\n\npackage com.springdemo.rest;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport javax.annotation.PostConstruct;\n\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport com.luv2code.springdemo.entity.Student;\n\n@RestController\n@RequestMapping(\"/api\")\npublic class StudentRestController {\n\n\tprivate List<Student> theStudents;\n\t\n\t\n\t// define @PostConstruct to load the student data ... only once!\n\t@PostConstruct\n\tpublic void loadData() {\n\t\n\t\ttheStudents = new ArrayList<>();\n\t\t\n\t\ttheStudents.add(new Student(\"Poornima\", \"Patel\"));\n\t\ttheStudents.add(new Student(\"Mario\", \"Rossi\"));\n\t\ttheStudents.add(new Student(\"Mary\", \"Smith\"));\t\t\n\t}\n\t\n\t\n\t\n\t// define endpoint for \"/students\" - return list of students\n\t@GetMapping(\"/students\")\n\tpublic List<Student> getStudents() {\n\t\t\t\n\t\treturn theStudents;\n\t}\n\t\n\t// define endpoint for \"/students/{studentId}\" - return student at index\n\t@GetMapping(\"/students/{studentId}\")\n\tpublic Student getStudent(@PathVariable int studentId) {\n\t\t\n\t\t// just index into the list ... keep it simple for now\n\t\treturn theStudents.get(studentId);\n\t\t\n\t}\n}\n\n\n\nNote that the endpoint \"/students/{studentId}\" has a path variable studentId\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Spring Rest/JSON Data Binding.html",
    "title": "Java JSON Data Binding",
    "body": "\n\nBack\n\n\nJava JSON Data Binding\n\n\n\n\nData binding is the process of converting JSON data to a Java POJO (the conversion goes both ways)\n\n\n\n\n\n\n\nData binding is the same as Serialization/Deserialization and Marshalling/Unmarshalling.\n\n\n\nSpring uses the Jackson Project behind the scenes which handles data binding between JSON and Java POJOs. For conversion we use Object Mapper\n\n\n\nBy default Jackson will call appropiate getter and setter methods to populate a POJO from a JSON or to create a JSON object from a POJO.\n\n\n\n\nTo convert from JSON to Java, Jackson calls the setter methods\n\n\nTo convert from Java to JSON, Jackson calls the getter methods\n\n\n\nSet Up\n\n\nAdd Jackson Project as a dependency in the maven file:\n\n\n\t<dependencies>\n\n\t\t<!-- TODO: Add your dependency here -->\n\n\t\t<dependency>\n\t\t\t<groupId>com.fasterxml.jackson.core</groupId>\n\t\t\t<artifactId>jackson-databind</artifactId>\n\t\t\t<version>2.10.0.pr1</version>\n\t\t</dependency>\t\n\t\t\t\n\t</dependencies>\n\n\nCreate POJO Class\n\n\nWe now create the class we are going to convert to JSON (Serialize):\n\n\npackage com.jackson.json.demo;\n\npublic class Student {\n\n\tprivate int id;\n\tprivate String firstName;\n\tprivate String lastName;\n\tprivate boolean active;\n\t\n\tpublic Student() {\n\t\t\n\t}\n\t\n\tpublic int getId() {\n\t\treturn id;\n\t}\n\t\n\tpublic void setId(int id) {\n\t\tthis.id = id;\n\t}\n\t\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\t\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\t\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\t\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n\t\n\tpublic boolean isActive() {\n\t\treturn active;\n\t}\n\t\n\tpublic void setActive(boolean active) {\n\t\tthis.active = active;\n\t}\n\t\n}\n\n\nMain App\n\n\nNow, to test it we are going to create a Student object by reading from a JSON object:\n\n\npackage com.jackson.json.demo;\nimport java.io.File;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class Driver {\n\n\tpublic static void main(String[] args) {\n\t\t\n\t\ttry {\n\t\t\t// create object mapper\n\t\t\tObjectMapper mapper = new ObjectMapper();\n\t\t\t\n\t\t\t// read JSON  file and map/convert to Java POJO: \n\t\t\t// data/sample-lite.json\n\t\t\t\n\t\t\tStudent theStudent = mapper.readValue(\n\t\t\t\t\t\tnew File(\"data/sample-lite.json\"), Student.class);\n\t\t}\n\t\tcatch (Exception exc) {\n\t\t\texc.printStackTrace();\n\t\t}\n\t}\n}\n\n\nNested Objects\n\n\nBut, how can we read nested properties inside a json file, like the following:\n\n\n{\n\t\"id\": 14,\n\t\"firstName\": \"Mario\",\n\t\"lastName\": \"Rossi\",\n\t\"active\": true,\n\t\"address\": {\n\t\t\"street\": \"100 Main St\",\n\t\t\"city\": \"Philadelphia\",\n\t\t\"state\": \"Pennsylvania\",\n\t\t\"zip\": \"19103\",\n\t\t\"country\": \"USA\"\n\t},\n\t\"languages\" : [\"Java\", \"C#\", \"Python\", \"Javascript\"]\n}\n\n\n\nAs you can see the address property has properties inside it. What we are going to do is create a new attribute address inside the Student object, which will be a POJO object in itself.\n\n\n\npackage com.jackson.json.demo;\n\npublic class Student {\n\n\tprivate int id;\n\tprivate String firstName;\n\tprivate String lastName;\n\tprivate boolean active;\n\t\n\tprivate Address address;\n\t\n\tprivate String[] languages;\n\t\n\tpublic Student() {\n\t\t\n\t}\n\t\n\tpublic int getId() {\n\t\treturn id;\n\t}\n\t\n\tpublic void setId(int id) {\n\t\tthis.id = id;\n\t}\n\t\n\tpublic String getFirstName() {\n\t\treturn firstName;\n\t}\n\t\n\tpublic void setFirstName(String firstName) {\n\t\tthis.firstName = firstName;\n\t}\n\t\n\tpublic String getLastName() {\n\t\treturn lastName;\n\t}\n\t\n\tpublic void setLastName(String lastName) {\n\t\tthis.lastName = lastName;\n\t}\n\t\n\tpublic boolean isActive() {\n\t\treturn active;\n\t}\n\t\n\tpublic void setActive(boolean active) {\n\t\tthis.active = active;\n\t}\n\n\tpublic Address getAddress() {\n\t\treturn address;\n\t}\n\n\tpublic void setAddress(Address address) {\n\t\tthis.address = address;\n\t}\n\n\tpublic String[] getLanguages() {\n\t\treturn languages;\n\t}\n\n\tpublic void setLanguages(String[] languages) {\n\t\tthis.languages = languages;\n\t}\n\t\n}\n\n\n\nWe also need to create the Address class:\n\n\npackage com.jackson.json.demo;\n\npublic class Address {\n\n\tprivate String street;\n\tprivate String city;\n\tprivate String state;\n\tprivate String zip;\n\tprivate String country;\n\t\n\tpublic Address() {\n\t\t\n\t}\n\n\tpublic String getStreet() {\n\t\treturn street;\n\t}\n\n\tpublic void setStreet(String street) {\n\t\tthis.street = street;\n\t}\n\n\tpublic String getCity() {\n\t\treturn city;\n\t}\n\n\tpublic void setCity(String city) {\n\t\tthis.city = city;\n\t}\n\n\tpublic String getState() {\n\t\treturn state;\n\t}\n\n\tpublic void setState(String state) {\n\t\tthis.state = state;\n\t}\n\n\tpublic String getZip() {\n\t\treturn zip;\n\t}\n\n\tpublic void setZip(String zip) {\n\t\tthis.zip = zip;\n\t}\n\n\tpublic String getCountry() {\n\t\treturn country;\n\t}\n\n\tpublic void setCountry(String country) {\n\t\tthis.country = country;\n\t}\n}\n\n\nIgnore Unknwon Properties\n\n\nTo ignore properties from the JSON file that cannot be mapped to an attribute in the POJO we use the annotation:\n\n\n\npackage com.jackson.json.demo;\n\n@JsonIgnoreProperties(ignoreUnkown=true)\npublic class Student {\n\n\tprivate int id;\n\tprivate String firstName;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Spring Rest/Exception Handling.html",
    "title": "Exception Handling",
    "body": "\n\nBack\n\n\nException Handling\n\n\n\n\nIn this section we are going to show how to create an error page to display when there is an error on a request.\n\n\nCreate Error Response Class\n\npackage com.springdemo.rest;\n\npublic class StudentErrorResponse {\n\n\tprivate int status;\n\tprivate String message;\n\tprivate long timeStamp;\n\n\tpublic StudentErrorResponse() {\n\t\t\n\t}\n\t\n\tpublic StudentErrorResponse(int status, String message, long timeStamp) {\n\t\tthis.status = status;\n\t\tthis.message = message;\n\t\tthis.timeStamp = timeStamp;\n\t}\n\n\tpublic int getStatus() {\n\t\treturn status;\n\t}\n\n\tpublic void setStatus(int status) {\n\t\tthis.status = status;\n\t}\n\n\tpublic String getMessage() {\n\t\treturn message;\n\t}\n\n\tpublic void setMessage(String message) {\n\t\tthis.message = message;\n\t}\n\n\tpublic long getTimeStamp() {\n\t\treturn timeStamp;\n\t}\n\n\tpublic void setTimeStamp(long timeStamp) {\n\t\tthis.timeStamp = timeStamp;\n\t}\n\t\n\t\n}\n\n\nCreate Exception Class\n\npackage com.springdemo.rest;\n\npublic class StudentNotFoundException extends RuntimeException {\n\n\tpublic StudentNotFoundException(String message, Throwable cause) {\n\t\tsuper(message, cause);\n\t}\n\n\tpublic StudentNotFoundException(String message) {\n\t\tsuper(message);\n\t}\n\n\tpublic StudentNotFoundException(Throwable cause) {\n\t\tsuper(cause);\n\t}\n\t\n}\n\n\nRest Service with Exception\n\n\nWhat we need to know is:\n\n\n\n\nDefine an exception handler method with @ExceptionHandler annotation\n\n\nThe exception handler will return a Response Entity\n\n\nResponse Entity is a wrapper for the HTTP response object\n\n\nResposneEntity provides a fine-grained control to specify:\n\n\n\nHTTP status code\n\n\nHTTP headers\n\n\nResponse body\n\n\n\n\npackage com.springdemo.rest;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport javax.annotation.PostConstruct;\n\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.ExceptionHandler;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport com.springdemo.entity.Student;\n\n@RestController\n@RequestMapping(\"/api\")\npublic class StudentRestController {\n\n\tprivate List<Student> theStudents;\n  \n\t// define @PostConstruct to load the student data ... only once!\n\t@PostConstruct\n\tpublic void loadData() {\n\t\n\t\ttheStudents = new ArrayList<>();\n\t\t\n\t\ttheStudents.add(new Student(\"Poornima\", \"Patel\"));\n\t\ttheStudents.add(new Student(\"Mario\", \"Rossi\"));\n\t\ttheStudents.add(new Student(\"Mary\", \"Smith\"));\t\t\n\t}\n\t\n\t\n\t\n\t// define endpoint for \"/students\" - return list of students\n\t@GetMapping(\"/students\")\n\tpublic List<Student> getStudents() {\n\t\t\t\n\t\treturn theStudents;\n\t}\n\t\n\t// define endpoint for \"/students/{studentId}\" - return student at index\n\t@GetMapping(\"/students/{studentId}\")\n\tpublic Student getStudent(@PathVariable int studentId) {\n\t\t\n\t\t// just index into the list ... keep it simple for now\n\t\t// check the studentId against list size\n\t\tif ( (studentId >= theStudents.size()) || (studentId < 0) ) {\t\t\t\n\t\t\tthrow new StudentNotFoundException(\"Student id not found - \" + studentId);\n\t\t}\n\t\t\n\t\treturn theStudents.get(studentId);\n\t\t\n\t}\n\n  // Tag it as an exception handling method\n\t@ExceptionHandler\n  //                    Type of response body                 Exception type to handle\n\tpublic ResponseEntity<StudentErrorResponse> handleException(StudentNotFoundException exc) {\n\t\t\n\t\tStudentErrorResponse error = new StudentErrorResponse();\n\t\t\n    // json error object \n\t\terror.setStatus(HttpStatus.NOT_FOUND.value());\n\t\terror.setMessage(exc.getMessage());\n\t\terror.setTimeStamp(System.currentTimeMillis());\n\t  \n    // return response with the error object and the status code\n\t\treturn new ResponseEntity<>(error, HttpStatus.NOT_FOUND);\n\t }\n\n  // Another exception handler\n\t@ExceptionHandler\n  // Catch any exception thrown\n\tpublic ResponseEntity<StudentErrorResponse> handleException(Exception exc) {\n\t\t\n\t\tStudentErrorResponse error = new StudentErrorResponse();\n\t\t\n\t\terror.setStatus(HttpStatus.BAD_REQUEST.value());\n\t\terror.setMessage(exc.getMessage());\n\t\terror.setTimeStamp(System.currentTimeMillis());\n\t\t\n\t\treturn new ResponseEntity<>(error, HttpStatus.BAD_REQUEST);\n\t}\t\n}\n\n\nGlobal Exception Handler\n\n\nInstead of having the exception handling methods in every controller, we defined them globally. For that we use ControllerAdvice that acts as a filter between the requests and the controller. It:\n\n\n\n\nPre-processes requests to controllers\n\n\nPost-processes responses to handle exceptions\n\n\n\n\nSo, we create a class with the @ControllerAdvice annotation:\n\n\npackage com.springdemo.rest;\n\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.ControllerAdvice;\nimport org.springframework.web.bind.annotation.ExceptionHandler;\n\n@ControllerAdvice\npublic class StudentRestExceptionHandler {\n\n\t// add exception handling code here\n\t// Add an exception handler using @ExceptionHandler\n\t@ExceptionHandler\n\tpublic ResponseEntity<StudentErrorResponse> handleException(StudentNotFoundException exc) {\n\t\t\n\t\t// create a StudentErrorResponse\n\t\tStudentErrorResponse error = new StudentErrorResponse();\n\t\t\n\t\terror.setStatus(HttpStatus.NOT_FOUND.value());\n\t\terror.setMessage(exc.getMessage());\n\t\terror.setTimeStamp(System.currentTimeMillis());\n\t\t\n\t\t// return ResponseEntity\n\t\treturn new ResponseEntity<>(error, HttpStatus.NOT_FOUND);\n\t}\n\t\n\t// add another exception handler ... to catch any exception (catch all)\n\t@ExceptionHandler\n\tpublic ResponseEntity<StudentErrorResponse> handleException(Exception exc) {\n\t\t\n\t\t// create a StudentErrorResponse\n\t\tStudentErrorResponse error = new StudentErrorResponse();\n\t\terror.setStatus(HttpStatus.BAD_REQUEST.value());\n\t\terror.setMessage(exc.getMessage());\n\t\terror.setTimeStamp(System.currentTimeMillis());\n\t\t\n\t\t// return ResponseEntity\t\t\n\t\treturn new ResponseEntity<>(error, HttpStatus.BAD_REQUEST);\n\t}\n\t\n}\n\n\n\nAnd now we modify the controller to make use of this paradigm:\n\n\npackage com.springdemo.rest;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport javax.annotation.PostConstruct;\n\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.ExceptionHandler;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport com.springdemo.entity.Student;\n\n@RestController\n@RequestMapping(\"/api\")\npublic class StudentRestController {\n\n\tprivate List<Student> theStudents;\n\t\n\t// define @PostConstruct to load the student data ... only once!\n\t@PostConstruct\n\tpublic void loadData() {\n\t\n\t\ttheStudents = new ArrayList<>();\n\t\t\n\t\ttheStudents.add(new Student(\"Poornima\", \"Patel\"));\n\t\ttheStudents.add(new Student(\"Mario\", \"Rossi\"));\n\t\ttheStudents.add(new Student(\"Mary\", \"Smith\"));\t\t\n\t}\n  \n\t// define endpoint for \"/students\" - return list of students\n\t@GetMapping(\"/students\")\n\tpublic List<Student> getStudents() {\n\t\t\t\n\t\treturn theStudents;\n\t}\n\t\n\t// define endpoint for \"/students/{studentId}\" - return student at index\n\t@GetMapping(\"/students/{studentId}\")\n\tpublic Student getStudent(@PathVariable int studentId) {\n\t\t\n\t\t// just index into the list ... keep it simple for now\n\t\t// check the studentId against list size\n\t\tif ( (studentId >= theStudents.size()) || (studentId < 0) ) {\n\t\t\tthrow new StudentNotFoundException(\"Student id not found - \" + studentId);\n\t\t}\n\t\t\t\n\t\treturn theStudents.get(studentId);\n\t}\t\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Spring Rest/Spring Rest Controller.html",
    "title": "Spring Rest Controller",
    "body": "\n\nBack\n\n\nSpring Rest Controller\n\n\n\n\nSpring Web MVC provides support for Spring REST. For that we use a new annotation called RestController which is an extension of Controller and handles REST requests and responses. \n\n\n\nSpring REST will also automatically convert Java POJOs to JSON as long as the Jackson project is on the classpath or pom.xml.\n\n\nHello World\n\n\nTo exemplify how to set up a REST Controller in Spring we will create an application that upong request sends back a Hello World! message:\n\n\n\n\n\n\nConfiguration\n\n\nFirst of all, make sure you have the Jackson project, MVC and REST and also Servlet libraries as a maven dependency or as a library in your classpath.\n\n\n\t<dependencies>\n\n\t\t<!-- Add Spring MVC and REST support -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework</groupId>\n\t\t\t<artifactId>spring-webmvc</artifactId>\n\t\t\t<version>5.0.5.RELEASE</version>\n\t\t</dependency>\n\t\t\n\t\t<!-- Add Jackson for JSON converters -->\n\t\t<dependency>\n\t\t\t<groupId>com.fasterxml.jackson.core</groupId>\n\t\t\t<artifactId>jackson-databind</artifactId>\n\t\t\t<version>2.9.9.2</version>\n\t\t</dependency>\n\n\t\t<!-- Add Servlet support for \n\t\t\t Spring's AbstractAnnotationConfigDispatcherServletInitializer -->\n\t\t<dependency>\n\t\t\t<groupId>javax.servlet</groupId>\n\t\t\t<artifactId>javax.servlet-api</artifactId>\n\t\t\t<version>3.1.0</version>\n\t\t</dependency>\n\n\t\t<!-- Add support for JSP ... get rid of Eclipse error -->\t\t\t\t \n\t\t<dependency>\n\t\t\t<groupId>javax.servlet.jsp</groupId>\n\t\t\t<artifactId>javax.servlet.jsp-api</artifactId>\n\t\t\t<version>2.3.1</version>\n\t\t</dependency>\n\t\t\t\t \n\t</dependencies>\n\n\nGeneral\n\n\nWe create a configuration class as follows:\n\n\npackage com.springdemo.config;\n\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.servlet.config.annotation.EnableWebMvc;\nimport org.springframework.web.servlet.config.annotation.WebMvcConfigurer;\n\n// Mark it as a configuration class\n@Configuration\n@EnableWebMvc\n// Enable component scanning in our source code\n@ComponentScan(\"com.springdemo\")\npublic class DemoAppConfig implements WebMvcConfigurer {\n\n}\n\n\nServlet Initializer\n\n\nWe have to specify the configuration of our servlet, for this we extend AbstractAnnotationConfigDispatcherServletInitializer:\n\n\npackage com.springdemo.config;\n\nimport org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;\n\npublic class MySpringMvcDispatcherServletInitializer extends AbstractAnnotationConfigDispatcherServletInitializer {\n\n\t@Override\n\tprotected Class<?>[] getRootConfigClasses() {\n\t\t// TODO Auto-generated method stub\n\t\treturn null;\n\t}\n\n\t@Override\n\tprotected Class<?>[] getServletConfigClasses() {\n    // Specify our config class\n\t\treturn new Class[] { DemoAppConfig.class };\n\t}\n\n\t@Override\n\tprotected String[] getServletMappings() {\n\t\treturn new String[] { \"/\" };\n\t}\n\n}\n\n\nController\n\n\nFor this we need to create our server with the controller that handles this request:\n\n\npackage com.springdemo.rest;\n\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\n@RequestMapping(\"/test\")\npublic class DemoRestController {\n\n\t// add code for the \"/hello\" endpoint\n\t\n\t@GetMapping(\"/hello\")\n\tpublic String sayHello() {\n\t\treturn \"Hello World!\";\n\t}\n\t\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/index.html",
    "title": "Spring",
    "body": "\n\nBack\n\n\nSpring\n\n\n\n\n\nIntroduction\n\n\nCore Spring Framework\n\n\nSpring MVC\n\n\nHibernate\n\n\nSpring REST\n\n\nSpring Boot\n\n\nThymeleaf\n\n\nMaven\n\n\nSpring Security\n\n\nAspect Oriented Programming\n\n\n\n\n\nIntro\n\n\nSpring Docs\n\n\nGetting Ready\n\n\n\nSpring Framework\n\n\nSet Up\n\n\n\n\n\nCore Spring Framework\n\nSpring With XML Configuration\n\n\n\nInversion of Control\n\n\nDependency Injection\n\n\nBean Scopes and Life cycle\n\n\n\nSpring With Java Annotations\n\n\n\nJava Annotations\n\n\n\nSpring With Only Java\n\n\n\nSpring Configuration with Java Code\n\n\n\n\n\nSpring MVC\n\n\n\nOverview\n\n\nConfiguration\n\n\nController\n\n\nView\n\n\nRead HTML Form Data\n\n\nModel\n\n\nAdd CSS and JS\n\n\nRequest Params and Request Mappings\n\n\nForm Tags\n\n\nForm Validation\n\n\n\n\n\nHibernate\n\n\n\nOverview\n\n\n\nConfiguration\n\n\n\nAnnotations\n\n\n\nUsage\n\n\n\nSessions\n\n\nDatabase Operations\n\n\n\nAdvanced Annotations\n\n\n\nConcepts\n\n\nOneToOne\n\n\nOneToMany\n\n\nEager vs Lazy Loading\n\n\nManyToMany\n\n\n\n\n\nSpring REST\n\n\n\nJSON Data Binding\n\n\nSpring Rest Controller\n\n\nPOJOs as JSON\n\n\nException Handling\n\n\n\n\n\nSpring Boot\n\n\n\nOverview\n\n\nController\n\n\nSpring Boot Project Structure\n\n\nSpring Boot Starters\n\n\nSpring Boot DevTools\n\n\nSpring Boot Actuator\n\n\nApplication Properties\n\n\nJPA\n\n\nSpring Data JPA\n\n\nSpring Data REST\n\n\n\n\n\nThymeleaf\n\n\n\nOverview\n\n\nTables\n\n\n\n\n\nMaven\n\n\n\nOverview\n\n\nPOM File Structure\n\n\nMaven Archetypes\n\n\nAdditional Repositories\n\n\nPrivate Repositories\n\n\n\n\n\nSpring Security\n\n\n\nOverview\n\n\nJava Configuration\n\n\nBasic Security\n\n\nCustom Login Form\n\n\nLog Out\n\n\nCross Site Request Forgery\n\n\nDisplay User and Roles\n\n\nAuthorization\n\n\nJDBC Database Authentication\n\n\n\nAspect Oriented Programming (AOP)\n\n\n\nOverview\n\n\nBefore Advice\n\n\nPointcut Expressions\n\n\nPointcut Declarations\n\n\nControl Aspect Order\n\n\nJoinPoints\n\n\nAfterReturning Advice\n\n\nAfterThrowing Advice\n\n\nAfter Advice\n\n\nAround Advice\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/IoC/Inversion of Control.html",
    "title": "Inversion of Control",
    "body": "\n\nBack\n\n\nInversion of Control\n\n\n\n\nThe Spring container (generally known as ApplicationContext) has two main functions:\n\n\n\n\nCreate and manage objects (Inversion of control)\n\n\nInject object's dependencies (Dependency Injection)\n\n\n\n\n\n\n\nSo Inversion Control is externalizing the construction and management of objects which will be handled by and object factory. This is illustrated in the following image:\n\n\n\n\n\n\n\n\nMyApp has the main method\n\n\nMyApp asks Spring to retrieve the appropiate object based on a configuration file or an annotation, instead of having to code it manually like:\n\n\n\npackage com.springdemo;\n\npublic class MyApp {\n\n\tpublic static void main(String[] args) {\n\n\t\tCoach theCoach = new TrackCoach();\n\t\t\n\t\t// call methods on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t}\n\n}\n\n\n\nWhere we have defined an interface Coach that is implemented by both TrackCoach and BaseballCoach\n\n\npackage com.springdemo;\n\npublic interface Coach {\n\n\tpublic String getDailyWorkout();\n\t\n}\n\n\npackage com.springdemo;\n\npublic class TrackCoach implements Coach {\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Run a hard 5k\";\n\t}\n\n}\n\n\n\n\n\nTo avoid this approach we create a Spring container. To configure a Spring container we can use:\n\n\n\n\nXML configuration file (legacy)\n\n\nJava Annotations\n\n\nJava Source Code\n\n\n\n\n\n\nHowever what is a Spring Bean?\n\n\n\nA \"Spring Bean\" is simply a Java object.\n\n\n\nWhen Java objects are created by the Spring Container, then Spring refers to them as \"Spring Beans\". Spring Beans are created from normal Java classes just like Java objects. \n\n\n\nWhy do we specify the Coach interface in getBean()? \n\n\n\nWhen we pass the interface to the method, behind the scenes Spring will cast the object for you.\n\n\ncontext.getBean(\"myCoach\", Coach.class)\n\n\n\nHowever, there are some slight differences than normal casting.\n\n\n\nBehaves the same as getBean(String), but provides a measure of type safety by throwing a BeanNotOfRequiredTypeException if the bean is not of the required type. \n\n\n\nThis means that ClassCastException can't be thrown on casting the result correctly, as can happen with getBean(String).\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Dependency Injection/Setter Injection.html",
    "title": "Setter Injection",
    "body": "\n\nBack\n\n\nSetter Injection\n\n\n\n\nInject dependencies by calling setter methods on your class\n\n\nCreate Dependency Object\n\n\nRefer to Create Dependency Object\n\n\nDefine dependency\n\n\nWe include a setter method that takes the dependency as an argument like:\n\n\npackage com.springdemo;\n\npublic class CricketCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\t\n\t\n\t// create a no-arg constructor\n\tpublic CricketCoach() {\n\t\tSystem.out.println(\"CricketCoach: inside no-arg constructor\");\n\t}\n\t\n\t// our setter method\n\tpublic void setFortuneService(FortuneService fortuneService) {\n\t\tSystem.out.println(\"CricketCoach: inside setter method - setFortuneService\");\n\t\tthis.fortuneService = fortuneService;\n\t}\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice fast bowling for 15 minutes\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n\n}\n\n\nConfiguration File\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\">\n    \n    <!-- Define your beans here -->\n    <!-- define the dependency -->\n    <bean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\">\n    </bean>\n    \n    <bean id=\"myCoach\"\n    \tclass=\"com.springdemo.TrackCoach\">\t\n    \t<!-- set up constructor injection -->\n    \t<constructor-arg ref=\"myFortuneService\" />\n    </bean>\n\n    <bean id=\"myCricketCoach\" class=\"com.springdemo.CricketCoach\"> \n      <!-- set up setter injection -->\n      <!-- ref: references the id of the bean we define previously -->\n      <!-- name: name of the setter method set<name>, where the first \n      letter of the name is capitalized -->\n      <property name=\"fortuneService\" ref=\"myFortuneService\" />\n    </bean>\n    \n</beans>\n\n\n\n\n\nBehind the scenes, Spring framework does:\n\n\npackage com.springdemo;\n\npublic class MyApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// Create object\n\t\t// From the bean with id = myFortuneService in the config file\n\t\tHappyFortuneService myFortuneService = new HappyFortuneService();\n\t\t\n\t\t// From the bean with id = myCricketCoach in the config file\n\t\tCricketCoach myCricketCoach = new CricketCoach(fortuneService);\n\t\t// Add dependency via setter\n\t\tmyCricketCoach.setFortuneService(myFortuneService);\n\t}\n\n}\n\n\nMain Method\n\n\nNow, on the main method of our Spring App, we create the object by reading the config file, and Spring automatically injects the dependency via the setter method:\n\n\npackage com.springdemo;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class SetterDemoApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// load the spring configuration file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// retrieve bean from spring container\n\t\tCricketCoach theCoach = context.getBean(\"myCricketCoach\", CricketCoach.class);\n\t\t\n\t\t// call methods on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t\t\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Dependency Injection/Dependency Injection.html",
    "title": "Dependency Injection",
    "body": "\n\nBack\n\n\nDependency Injection\n\n\n\n\nThe dependencies of the objects are managed by the Spring container object factory:\n\n\n\n\n\n\n\nSo instead of having to build the object and all of its dependencies, the spring factory will do this work for you.\n\n\nInjection Types\n\n\nThere are several injection types in Spring. The more common are:\n\n\n\n\nConstructor Injection\n\n\nSetter Injection\n\n\nInjecting Literal Values\n\n\nInject Values From a Properties File\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Dependency Injection/Inject Values From a Properties File.html",
    "title": "Inject Values from the Properties Files",
    "body": "\n\nBack\n\n\nInject Values from the Properties Files\n\n\n\nCreate the properties file\n\n\nLet's define our properties inside a properties file sport.properties:\n\n\nfoo.email=myeasycoach@email.com\nfoo.team=Royal Challengers Bangalore\n\n\n\nLoad the properties file\n\n\nNow we load the properties file using the context tag inside our config file:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\">\n    \n  <!-- load the properties file: sport.properties -->\n  <context:property-placeholder location=\"classpath:sport.properties\"/>\n    \n  <!-- Define your beans here -->\n  <!-- define the dependency -->\n  <bean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\">\n  </bean>\n  \n  <bean id=\"myCoach\"\n  \tclass=\"com.springdemo.TrackCoach\">\t\n  \t<!-- set up constructor injection -->\n  \t<constructor-arg ref=\"myFortuneService\" />\n  </bean>\n  \n  <bean id=\"myCricketCoach\" class=\"com.springdemo.CricketCoach\"> \n    <!-- set up setter injection -->\n    <!-- ref: references the id of the bean we define previously -->\n    <!-- name: name of the setter method set<name>, where the first \n    letter of the name is capitalized -->\n    <property name=\"fortuneService\" ref=\"myFortuneService\" />\n    <!-- inject literal values, where name is the name of the attribute in the bean\n    and value is the value to set the value to -->\n    <!-- Note that we are now referencing the values from the properties file -->\n    <property name=\"emailAddress\" value=\"${foo.email})\" />\n    <property name=\"team\" value=\"${foo.team}\" />\n  </bean>\n    \n</beans>\n\n\nMain Method\n\n\nIn the main method, we create our object as usual, and if we invoke the getter methods, we retrieve the values passed in the property file:\n\n\npackage com.springdemo;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class SetterDemoApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// load the spring configuration file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// retrieve bean from spring container\n\t\tCricketCoach theCoach = context.getBean(\"myCricketCoach\", CricketCoach.class);\n\t\t\n\t\t// retrieve attribute values from property file\n\t\tSystem.out.println(theCoach.getTeam());\n\t\tSystem.out.println(theCoach.getEmailAddress());\n\t\t\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Dependency Injection/Constructor Injection.html",
    "title": "Constructor Injection",
    "body": "\n\nBack\n\n\nConstructor Injection\n\n\n\n\nNow we will show an example where the BaseballCoach has FortuneService as a dependency. So, first we create the dependency interface as follows:\n\n\nCreate Dependency Object\n\npackage com.springdemo;\n\npublic interface FortuneService {\n\n\tpublic String getFortune();\n\t\n}\n\n\n\nNext we create the dependency class than implements the interface:\n\n\n\npackage com.springdemo;\n\npublic class HappyFortuneService implements FortuneService {\n\n\t@Override\n\tpublic String getFortune() {\n\t\treturn \"Today is your lucky day!\";\n\t}\n\n}\n\n\nEstablish Dependency\n\n\nLet's also update the Coach Interface to add a method getDailyFortune (note that all classes that implement this interface have to implement this new method):\n\n\npackage com.springdemo;\n\npublic interface Coach {\n\n\tpublic String getDailyWorkout();\n\t\n\tpublic String getDailyFortune();\n\n}\n\n\n\n\nNow create a constructor for the dependency in the class that has the dependency\n\n\npackage com.springdemo;\n\npublic class BaseballCoach implements Coach {\n\n\t// define a private field for the dependency\n\tprivate FortuneService fortuneService;\n\t\n\t// define a constructor for dependency injection\n\tpublic BaseballCoach(FortuneService theFortuneService) {\n\t\tfortuneService = theFortuneService;\n\t}\n\t\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Spend 30 minutes on batting practice\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\t\t\n\t\t// use my fortuneService to get a fortune\t\t\n\t\treturn fortuneService.getFortune();\n\t}\n}\n\n\nConfiguration File\n\n\nFinally define the dependency in the configuration file:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\">\n    <!-- Define your beans here -->\n    <!-- define the dependency -->\n    <bean id=\"myFortuneService\"\n      class=\"com.springdemo.HappyFortuneService\">\n    </bean>\n    <!-- Bean with the dependency -->\n    <bean id=\"myCoach\"\n      class=\"com.springdemo.TrackCoach\">\t\n      <!-- Set up constructor injection, note ref=id of bean -->\n      <constructor-arg ref=\"myFortuneService\" />\n    </bean>\n</beans>\n\n\n\n\n\nBehind the scenes, Spring framework does:\n\n\npackage com.springdemo;\n\npublic class MyApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// Create object\n\t\t// From the bean with id = myFortuneService in the config file\n\t\tHappyFortuneService myFortuneService = new HappyFortuneService();\n\t\t\n\t\t// Add dependency via constructor\n\t\t// From the bean with id = myCoach in the config file\n\t\tTrackCoach myCoach = new TrackCoach(fortuneService);\n\t}\n\n}\n\n\nMain Method\n\n\nWe do not need to make any modifications to the app, when we create the Coach bean using Spring, the framework deals with the dependency injection:\n\n\npackage com.luv2code.springdemo;\n\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class HelloSpringApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// load the spring configuration file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\t\t\n\t\t// retrieve bean from spring container (with the dependency)\n\t\tCoach theCoach = context.getBean(\"myCoach\", Coach.class);\n\t\t\n\t\t// call methods on the bean\n\t\tSystem.out.println(theCoach.getDailyWorkout());\n\t\t\n\t\t// let's call our new method for fortunes\n\t\tSystem.out.println(theCoach.getDailyFortune());\n\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Dependency Injection/Injecting Literal Values.html",
    "title": "Injecting Literal Values",
    "body": "\n\nBack\n\n\nInjecting Literal Values\n\n\n\n\nTo inject concrete attributes into our beans:\n\n\nDefine the Attributes\n\n\nFirst we define the attributes emailAddress and team in the object. Also we create the set and get methods for both of them:\n\n\npackage com.luv2code.springdemo;\n\npublic class CricketCoach implements Coach {\n\n\tprivate FortuneService fortuneService;\n\t\n\t// add new fields for emailAddress and team\n\tprivate String emailAddress;\n\tprivate String team;\n\t\n\t\t\n\tpublic CricketCoach() {\n\t\tSystem.out.println(\"CricketCoach: inside no-arg constructor\");\n\t}\n\t\n  /* SETTERS AND GETTERS */\n\tpublic String getEmailAddress() {\n\t\treturn emailAddress;\n\t}\n\n\tpublic void setEmailAddress(String emailAddress) {\n\t\tSystem.out.println(\"CricketCoach: inside setter method - setEmailAddress\");\n\t\tthis.emailAddress = emailAddress;\n\t}\n\n\tpublic String getTeam() {\n\t\treturn team;\n\t}\n\n\tpublic void setTeam(String team) {\n\t\tSystem.out.println(\"CricketCoach: inside setter method - setTeam\");\n\t\tthis.team = team;\n\t}\n\n  /* Setter Injection */\n\tpublic void setFortuneService(FortuneService fortuneService) {\n\t\tSystem.out.println(\"CricketCoach: inside setter method - setFortuneService\");\n\t\tthis.fortuneService = fortuneService;\n\t}\n\n\t@Override\n\tpublic String getDailyWorkout() {\n\t\treturn \"Practice fast bowling for 15 minutes\";\n\t}\n\n\t@Override\n\tpublic String getDailyFortune() {\n\t\treturn fortuneService.getFortune();\n\t}\n\n}\n\n\nConfiguration File\n\n\nNow we define the properties in the configuration file:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context.xsd\">\n    \n\t<!-- Define your beans here -->\n\t<!-- define the dependency -->\n\t<bean id=\"myFortuneService\" class=\"com.springdemo.HappyFortuneService\">\n\t</bean>\n\t\n\t<bean id=\"myCoach\"\n\t\tclass=\"com.springdemo.TrackCoach\">\t\n\t\t<!-- set up constructor injection -->\n\t\t<constructor-arg ref=\"myFortuneService\" />\n\t</bean>\n\t\n\t<bean id=\"myCricketCoach\" class=\"com.springdemo.CricketCoach\"> \n\t  <!-- set up setter injection -->\n\t  <!-- ref: references the id of the bean we define previously -->\n\t  <!-- name: name of the setter method set<name>, where the first \n\t  letter of the name is capitalized -->\n\t  <property name=\"fortuneService\" ref=\"myFortuneService\" />\n\t\t<!-- inject literal values, where name is the name of the attribute in the bean\n\t\tand value is the value to set the value to -->\n\t  <property name=\"emailAddress\" value=\"email@email.com\" />\n\t  <property name=\"team\" value=\"Best Team\" />\n\t</bean>\n    \n</beans>\n\n\nMain Method\n\n\nNow in the main method of our app we can call the getters and setters for these new attributes:\n\n\npackage com.springdemo;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class SetterDemoApp {\n\n\tpublic static void main(String[] args) {\n\n\t\t// load the spring configuration file\n\t\tClassPathXmlApplicationContext context = \n\t\t\t\tnew ClassPathXmlApplicationContext(\"applicationContext.xml\");\n\t\t\n\t\t// retrieve bean from spring container\n\t\tCricketCoach theCoach = context.getBean(\"myCricketCoach\", CricketCoach.class);\n\t\t\n\t\t// retrieve attribute values\n\t\tSystem.out.println(theCoach.getTeam());\n\t\tSystem.out.println(theCoach.getEmailAddress());\n\t\t\t\t\t\t\n\t\t// close the context\n\t\tcontext.close();\n\t}\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Set Up.html",
    "title": "Set Up",
    "body": "\n\nBack\n\n\nSet Up\n\n\n\n\nRequirements:\n\n\n\n\nJDK\n\n\nJava Application Server (i.e. Tomcat)\n\n\nJava Integrated Development Environment (IDE)\n\n\nSpring 5 JAR files (download manually or use Maven)\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/Annotations.html",
    "title": "Configure Hibernate with Annotations",
    "body": "\n\nBack\n\n\nConfigure Hibernate with Annotations\n\n\n\nAdd Hibernate Configuration File\n\n\nWe create the following hibernate.cfg.xml file:\n\n\n<!DOCTYPE hibernate-configuration PUBLIC\n        \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\"\n        \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\">\n\n<hibernate-configuration>\n\n    <!-- A session factory allows us to get sessions objects to connect to the database -->\n    <session-factory>\n\n        <!-- JDBC Database connection settings -->\n        <property name=\"connection.driver_class\">com.mysql.cj.jdbc.Driver</property>\n        <property name=\"connection.url\">jdbc:mysql://localhost:3306/hb_student_tracker?useSSL=false&amp;serverTimezone=UTC</property>\n        <property name=\"connection.username\">hbstudent</property>\n        <property name=\"connection.password\">hbstudent</property>\n\n        <!-- JDBC connection pool settings ... using built-in test pool -->\n        <property name=\"connection.pool_size\">1</property>\n\n        <!-- Select our SQL dialect -->\n        <property name=\"dialect\">org.hibernate.dialect.MySQLDialect</property>\n\n        <!-- Echo the SQL to stdout -->\n        <property name=\"show_sql\">true</property>\n\n        <!-- Set the current session context -->\n        <property name=\"current_session_context_class\">thread</property>\n \n    </session-factory>\n\n</hibernate-configuration>\n\n\nAnnotate Java Class\n\n\nHibernate deals with the concept of Entity, which is basically a Java Class with its attributes, setters and getters, that is mapped to a database table with the help of annotations.\n\n\n\nNote that there are two ways of configuring the mapping:\n\n\n\n\nXML Config file (legacy)\n\n\nJava Annotations (modern, preferred)\n\n\n\n\nWith Java Annotations we have to follow these steps:\n\n\n\n\nMap the class to a database table\n// Let spring know this is an entity we want to map to a database table\n@Entity\n// Provides the actual name of the table (observe in this case it is optional \n// because the name of the class = the name of the database table)\n@Table(name=\"student\")\npublic class Student {\n...\n}\n\n\n\nMap the fields to database columns\npublic class Student {\n  // Primary key\n  @Id\n  // How to generate primary key\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  // Column name (also not needed if the name in the database and the name here are the same)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"first_name\")\n  private String firstName;\n  \n  @Column(name=\"last_name\")\n  private String lastName;\n  \n  @Column(name=\"email\")\n  private String email;\n  \n  ...\n  \n}\n\n\n\n\n\nSome other ID Generation Strategies are:\n\n\n\n\nAUTO: pick the appropiate strategy for the given database\n\n\nIDENTITY: assign primary keys using database identidy column\n\n\nSEQUENCE: assign primary keys using a database sequence\n\n\nTABLE: assign primary keys using an uderlying database table to ensure uniqueness\n\n\nYou can also create your custom generator\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/ManyToMany.html",
    "title": "Many To Many Relationship",
    "body": "\n\nBack\n\n\nMany To Many Relationship\n\n\n\n\nHere we demonstrate how to implement a many to many relationship between two entities. For this we need a join table:\n\n\n\n\n\n\n\nWell, first of all you have to define the two database tables corresponding to these two entities. And then we define a intermediate table to act as the join table called course_student.\n\n\nEntities\n\n\nWe now code the two entities:\n\n\npackage com.hibernate.demo.entity;\n// annotate the class as an entity and map to db table\n@Entity\n@Table(name=\"course\")\npublic class Course {\n  // define the fields\n  // annotate the fields with db column names\n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"title\")\n  private String title;\n  \n  // Set up one to many relationship\n  @ManyToOne(cascade= \n              // On delete course, do not delete instructor\n              {CascadeType.PERSIST, \n              CascadeType.MERGE,\n              CascadeType.DETACH, \n              CascadeType.REFRESH})\n  @JoinColumn(name=\"instructor_id\")\n  private Instructor instructor;\n  \n  // Set up unidirectional one to many relationship\n  @OneToMany(fetch=FetchType.LAZY, cascade=CascadeType.ALL)\n\t@JoinColumn(name=\"course_id\")\n\tprivate List<Review> reviews;\n  \n  // Set up many to many relationship with lazy loading\n  // so only Courses are retrieved, and the students associated\n  // are obtained only if needed\n\t@ManyToMany(fetch=FetchType.LAZY,\n\t\t\tcascade= {CascadeType.PERSIST, CascadeType.MERGE,\n\t\t\t CascadeType.DETACH, CascadeType.REFRESH})\n  // Specifying the join table, and the corresponding \n  // foreign keys\n  @JoinTable(\n    // table name\n    name=\"course_student\",\n    // this entity's pk\n    joinColumns=@JoinColumn(name=\"course_id\"),\n    // related entity's pk\n    inverseJoinColumns=@JoinColumn(name=\"student_id\")\n  )\n  private List<Student> students;\n  \n  public Course() {\n  }\t\t\n  \n  ...\n  // Setters and getters\n}\n\n\n\nAnd now the Student:\n\n\npackage com.hibernate.demo.entity;\n@Entity\n@Table(name=\"student\")\npublic class Student {\n  \n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"first_name\")\n  private String firstName;\n  \n  @Column(name=\"last_name\")\n  private String lastName;\n  \n  @Column(name=\"email\")\n  private String email;\n  \n  // Set up many to many relationship with lazy loading\n  // so only Students are retrieved, and the courses associated\n  // are obtained only if needed\n  @ManyToMany(fetch=FetchType.LAZY,\n  \t\tcascade= {CascadeType.PERSIST, CascadeType.MERGE,\n  \t\t CascadeType.DETACH, CascadeType.REFRESH})\n  // Specifying the join table, and the corresponding \n  // foreign keys\n  @JoinTable(\n      // table name\n  \t\tname=\"course_student\",\n      // this entity's pk\n  \t\tjoinColumns=@JoinColumn(name=\"student_id\"),\n      // related entity's pk\n  \t\tinverseJoinColumns=@JoinColumn(name=\"course_id\")\n  \t\t)\t\n  private List<Course> courses;\n\n  // constructor, getters, setters\n  ....\n\n\nMain App\n\n\nTo test our code, we are going to get a Course and add it to a Student:\n\n\npackage com.hibernate.demo;\npublic class CreateDemo {\n  public static void main(String[] args) {\n  \n    // create session factory\n    // ...\n    \n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t    \n      // start a transaction\n      session.beginTransaction();\n      \n      // get the student mary from database\n      int studentId = 2;\n      Student tempStudent = session.get(Student.class, studentId);\n      \n      // create more courses \n      Course tempCourse1 = new Course(\"Rubik's Cube - How to Speed Cube\");\n      Course tempCourse2 = new Course(\"Atari 2600 - Game Development\");\n      \t\t\t\n      // add student to courses\n      tempCourse1.addStudent(tempStudent);\n      tempCourse2.addStudent(tempStudent);\n      \t\t\t\n      // save the courses\n      session.save(tempCourse1);\n      session.save(tempCourse2);\n      \n      // commit transaction\n      session.getTransaction().commit();\n    }\n    finally {\n      session.close();\n    \tfactory.close();\n    }\n  }\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/Concepts.html",
    "title": "Database Concepts",
    "body": "\n\nBack\n\n\nDatabase Concepts\n\n\n\n\n\nCascade: perform an operations on related entities\n\n\n\nOn save: if we save an object, if it is related to another object, we need to also save that other object\n\n\nOn delete: if we delete an object that is related to another object, we might need to delete that other object (depends on the use case)\n\n\n\nFetch types: when we fetch data, should we retrieve everything?\n\n\n\nEager: will retrieve everything\n\n\nLazy: will retrieve on request\n\n\n\n\n\n\nCascade Types\n\n\n\nPERSIST: if entity is persisted/saved, the related entity will also be persisted\n\n\nREMOVE: if entity is removed/deleted, the related entity will also be deleted\n\n\nREFRESH: if entity is refreshed, the related entity will also be refreshed\n\n\nDETACH: if entity is detached (not associated with session), the related entity will also be detached\n\n\nMERGE: if entity is merged, the related entity will also be merged\n\n\nALL: all of the above cascade types\n\n\n\n\nBy default, no operations are cascaded.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/Sessions.html",
    "title": "Sessions",
    "body": "\n\nBack\n\n\nSessions\n\n\n\n\nThere are two key components when it comes to session handling:\n\n\n\n\nSessionFactory: reads the hibernate configuration file, creates sessions objects, and is created only once in the application and reused over and over again\n\n\nSession: is a wrapper around a JDBC connection, which is the main object used to save/retrieve objects. This object is created multiple times.\n\n\n\n\nSo to create a SessionFactory and then create Session from it:\n\n\npublic class Demo {\n  public static void main(String[] args) {\n  \n    // create session factory\n    SessionFactory factory = new Configuration()\n                              // configuration file in src/ (if it is not specified, hibernate will look for a file named hibernate.cfg.xml)\n                              .configure(\"hibernate.cfg.xml\")\n                              // Class that was annotated to be mapped\n                              .addAnnotatedClass(Student.class)\n                              // You can add multiple classes\n                              .addAnnotatedClass(...)\n                              // Create the factory\n                              .buildSessionFactory();\n    \n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t\t\n      // Use session object to perform CRUD operations\t\n    }\n    finally {\n      // Delete session factory\n      factory.close();\n    }\n  }\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/OneToOne.html",
    "title": "One To One Relationship",
    "body": "\n\nBack\n\n\nOne To One Relationship\n\n\n\n\n\nUnidirectional\n\n\nBidirectional\n\n\n\n\n\nUnidirectional\n\n\nHere we demonstrate how to implement a unidirectional one to one relationship between two entities:\n\n\n\n\n\n\n\nWell, first of all you have to define the two database tables corresponding to these two entities.\n\n\nEntities\n\n\nWe now code the two entities:\n\n\npackage com.hibernate.demo.entity;\n/* annotate the class as an entity and map to db table */\n@Entity\n@Table(name=\"instructor\")\npublic class Instructor {\n  // define the fields and annotate the fields \n  // with db column names\n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"first_name\")\n  private String firstName;\n  \n  @Column(name=\"last_name\")\n  private String lastName;\n  \n  @Column(name=\"email\")\n  private String email;\n  \n  // Set up mapping to InstructorDetail entity\n  // Note the cascade type\n  @OneToOne(cascade=CascadeType.ALL)\n  // Define the foreign key\n  @JoinColumn(name=\"instructor_detail_id\")\n  private InstructorDetail instructorDetail;\n  \n  public Instructor() {\n  \t\n  }\n  ...\n  // Setters and getters \n}\n\n\n\nNote the specification of the Cascade Type. And now the InstructorDetail:\n\n\npackage com.hibernate.demo.entity;\n// annotate the class as an entity and map to db table\n@Entity\n@Table(name=\"instructor_detail\")\npublic class InstructorDetail {\n\t// define the fields\n\t// annotate the fields with db column names\n\t\n\t@Id\n\t@GeneratedValue(strategy=GenerationType.IDENTITY)\n\t@Column(name=\"id\")\n\tprivate int id;\n\t\n\t@Column(name=\"youtube_channel\")\n\tprivate String youtubeChannel;\n\t\n\t@Column(name=\"hobby\")\n\tprivate String hobby;\n\t\n\tpublic InstructorDetail() {\n  }\t\t\n  \n  ...\n  // Setters and getters\n}\n\n\n\nMain App\n\n\nTo test our code, we are going to create an Instructor object and an InstructorDetail object and save them. The test main app is the following:\n\n\npackage com.hibernate.demo;\npublic class CreateDemo {\n  public static void main(String[] args) {\n  \n    // create session factory\n    // ...\n    \n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t\t\n    \n      // create the objects\n      Instructor tempInstructor = \n      \t\tnew Instructor(\"Madhu\", \"Patel\", \"madhu@mail.com\");\n      \n      InstructorDetail tempInstructorDetail =\n      \t\tnew InstructorDetail(\n      \t\t\t\t\"http://www.youtube.com\",\n      \t\t\t\t\"Guitar\");\t\t\n      \n      // associate the objects\n      tempInstructor.setInstructorDetail(tempInstructorDetail);\n      \n      // start a transaction\n      session.beginTransaction();\n      \n      // save the instructor\n      //\n      // Note: this will ALSO save the details object\n      // because of CascadeType.ALL\n      //\n      session.save(tempInstructor);\t\t\t\t\t\n      \n      // commit transaction\n      session.getTransaction().commit();\n    }\n    finally {\n    \tfactory.close();\n    }\n  }\n}\n\n\nBidirectional\n\n\nNow we will define the following Bidirectional One To One relationship:\n\n\n\n\n\n\n\nLet's now see how to code a bidirectional relationship:\n\n\nEntities\n\npackage com.hibernate.demo.entity;\n\n/* annotate the class as an entity and map to db table */\n@Entity\n@Table(name=\"instructor\")\npublic class Instructor {\n  // define the fields and annotate the fields \n  // with db column names\n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"first_name\")\n  private String firstName;\n  \n  @Column(name=\"last_name\")\n  private String lastName;\n  \n  @Column(name=\"email\")\n  private String email;\n  \n  // Set up mapping to InstructorDetail entity\n  // Note the cascade type\n  @OneToOne(cascade=CascadeType.ALL)\n  // Define the foreign key\n  @JoinColumn(name=\"instructor_detail_id\")\n  private InstructorDetail instructorDetail;\n  \n  public Instructor() {\n  \t\n  }\n  ...\n  // Setters and getters \n\n\n\nAnd now the InstructorDetail:\n\n\npackage com.hibernate.demo.entity;\n// annotate the class as an entity and map to db table\n@Entity\n@Table(name=\"instructor_detail\")\npublic class InstructorDetail {\n  // define the fields\n  // annotate the fields with db column names\n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"youtube_channel\")\n  private String youtubeChannel;\n  \n  @Column(name=\"hobby\")\n  private String hobby;\n\t\n  // add @OneToOne annotation\n  // mappedBy refers to the instructorDetail property\n  // in the Instructor class\n  // This uses the information from the Instructor class in @JoinColumn\n  // to define the mapping\n  @OneToOne(mappedBy=\"instructorDetail\", \n            // Different cascade types\n            cascade={\n            CascadeType.DETACH, \n            CascadeType.MERGE, \n            CascadeType.PERSIST,\n            CascadeType.REFRESH})\n  private Instructor instructor;\n  \n  public InstructorDetail() {\n  }\t\t\n  \n  ...\n  // Setters and getters\n}\n\n\n\nMain App\n\n\nIn our test main app we are going to search for an InstructorDetail object, and we are going to retrieve the related Instructor object:\n\n\npackage com.hibernate.demo;\npublic class GetInstructorDetailDemo {\n\tpublic static void main(String[] args) {\n    session = factory.getCurrentSession();\n    try {\n      // start a transaction\n      session.beginTransaction();\n      \n      // get the instructor detail object\n      int theId = 2999;\n      InstructorDetail tempInstructorDetail = \n      \t\tsession.get(InstructorDetail.class, theId);\n      \t\t\t\n      // print  the associated instructor\n      System.out.println(\"the associated instructor: \" + \n      \t\t\t\t\ttempInstructorDetail.getInstructor());\n      \n      // commit transaction\n      session.getTransaction().commit();\n    } catch(Exception exc){\n      exc.printStackTrace();\n    } finally {\n      // Finish session\n\t\t\tsession.close();\n\t\t  // Remove factory\t\n\t\t\tfactory.close();\n    }\n  }\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/Database Operations.html",
    "title": "Database Operations",
    "body": "\n\nBack\n\n\nDatabase Operations\n\n\n\nSave Java Object\n\n\nTo save a Java Object:\n\n\npublic ... {\n  try {\t\t\t\n  \t// create a student object\n  \tStudent tempStudent = new Student(\"Paul\", \"Doe\", \"paul@luv2code.com\");\n  \t\n  \t// start a transaction\n  \tsession.beginTransaction();\n  \t\n  \t// save the student object\n  \tsession.save(tempStudent);\n  \t\n  \t// commit transaction\n  \tsession.getTransaction().commit();\n  }\n  finally {\n  \tfactory.close();\n  }\n}\n\n\nRead Java Object\n\npublic ... {\n  try {\t\t\t\n    // From the student created and saved previously\n    // find out the student's id: primary key\n    \n    // now get a new session and start transaction\n    session = factory.getCurrentSession();\n    session.beginTransaction();\n    \n    // retrieve student based on the id: primary key\n    System.out.println(\"\\nGetting student with id: \" + tempStudent.getId());\n    \n    // Get from the DB by the primary key of the student\n    Student myStudent = session.get(Student.class, tempStudent.getId());\n    \n    // commit the transaction\n    session.getTransaction().commit();\n  }\n  finally {\n  \tfactory.close();\n  }\n}\n\n\nQuery Java Object\n\n\nHibernate has a query language for retrieving objects: HQL which is similar to SQL. \n\n\npublic class QueryStudentDemo {\n  public static void main(String[] args) {\n\n    // create session factory\n    ...\n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t\t\n    \n      // start a transaction\n      session.beginTransaction();\n      \n      // Note we use the Java object name for the table name\n      // and the name of the attribute in the class for the name\n      // of the column (firstName istd of first_name)\n      // query students: lastName='Doe' OR firstName='Daffy'\n      theStudents = session.createQuery(\"from Student s where\"\n                    + \" s.lastName='Doe' OR s.firstName='Daffy'\").getResultList();\n      \n      // query students where email LIKE '%gmail.com'\n      theStudents = session.createQuery(\"from Student s where\"\n      \t\t+ \" s.email LIKE '%gmail.com'\").getResultList();\n      \n      // commit transaction\n      session.getTransaction().commit();\n    }\n    finally {\n    \tfactory.close();\n    }\n  }\n\n\nUpdate Java Objects\n\npublic class UpdateStudentDemo {\n  public static void main(String[] args) {\n\n    // create session factory\n    ...\n    \n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t\t\t\t\t\t\t\n      // Update one student\n      int studentId = 1;\n      \n      // now get a new session and start transaction\n      session = factory.getCurrentSession();\n      session.beginTransaction();\n      \n      Student myStudent = session.get(Student.class, studentId);\n      \n      // Update name of student\n      myStudent.setFirstName(\"Scooby\");\n      \n      // commit the transaction\n      session.getTransaction().commit();\n      \n      // Update several students\n      \n      session = factory.getCurrentSession();\n      session.beginTransaction();\n      \n      // update email for all students\n      System.out.println(\"Update email for all students\");\n      \n      session.createQuery(\"update Student set email='foo@gmail.com'\")\n      \t.executeUpdate();\n      \t\t\t\n      // commit the transaction\n      session.getTransaction().commit();\n    }\n    finally {\n    \tfactory.close();\n    }\n  }\n}\n\n\nDelete Java Objects\n\npublic class DeleteStudentDemo {\n  public static void main(String[] args) {\n\n    // create session factory\n    ...\n    \n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t\t\t\t\t\t\t\n      int studentId = 1;\n\t\t\t\n      // now get a new session and start transaction\n      session = factory.getCurrentSession();\n      session.beginTransaction();\n      \n      // retrieve student based on the id: primary key\n      Student myStudent = session.get(Student.class, studentId);\n      \n      // delete the student\n      session.delete(myStudent);\n      \n      // delete student id=2\n      session.createQuery(\"delete from Student where id=2\").executeUpdate();\n      \n      // commit the transaction\n      session.getTransaction().commit();\n    }\n    finally {\n    \tfactory.close();\n    }\n  }\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/index.html",
    "title": "index",
    "body": "\n\nBack\n\n\nHibernate\n\n\n\n\nIs a framework for persisting/saving Java objects in a database\n\n\n\n\nHandles all of the low-level SQL\n\n\nMinimizes the amount JDBC code to develop\n\n\nProvides the Object-to-Relational Mapping (ORM):\n\n\n\nThe developer defines a mapping between a Java class and a database table\n\n\n\n\n\n\n\n\n\nHibernate uses JDBC for all database communications:\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/Eager vs Lazy Loading.html",
    "title": "Eager vs Lazy Loading",
    "body": "\n\nBack\n\n\nEager vs Lazy Loading\n\n\n\n\n\nEager: fetches all data all at once (with dependencies of the entity)\n\n\nLazy: fetches required data only\n\n\n\n\nLazy loading is usually preferred, that is only load data when absolutely needed. \n\n\n\nThe flow of Lazy Loading is:\n\n\n\n\nLoad the main entity first\n\n\nLoad dependent entities on demand\n\n\n\n\n\n\n\n\nNote than when using Lazy Loading you need an open Hibernate session, else if you close the session and try to retrieve the data Hibernate will throw an exception.\n\n\nDefault Fetch Types\n\n\n\n\nMapping\n\n\nDefaul Fetch Type\n\n\n\n\n@OneToOne\n\n\nFetchType.EAGER\n\n\n\n\n@OneToMany\n\n\nFetchType.LAZY\n\n\n\n\n@ManyToOne\n\n\nFetchType.EAGER\n\n\n\n\n@ManyToMany\n\n\nFetchType.LAZY\n\n\n\n\nSpecify Fetch Type on Entity\n\n\nWe can specify the fetching type on the Entity as follows:\n\n\n@Entity\n@Table(name=\"instructor\")\npublic class Instructor {\n\n\t@Id\n\t@GeneratedValue(strategy=GenerationType.IDENTITY)\n\t@Column(name=\"id\")\n\tprivate int id;\n\t\n\t@OneToOne(cascade=CascadeType.ALL)\n\t@JoinColumn(name=\"instructor_detail_id\")\n\tprivate InstructorDetail instructorDetail;\n\t\n  // Specify fetch type (only load the courses on demand, their retrieval\n  // is delayed)\n\t@OneToMany(fetch=FetchType.LAZY,\n\t\t\t   mappedBy=\"instructor\",\n\t\t\t   cascade= {CascadeType.PERSIST, CascadeType.MERGE,\n\t\t\t\t\t\t CascadeType.DETACH, CascadeType.REFRESH})\n\tprivate List<Course> courses;\n  \n  ...\n\n\nAvoid Closed Session Exception\n\n\nTo avoid the error we use the JOIN FETCH (we do override lazy loading with eager loading) of HQL:\n\n\npublic class FetchJoinDemo {\n  public static void main(String[] args) {\n  \n    // create session factory\n    SessionFactory factory = \n    ...\n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t\t\n      // start a transaction\n      session.beginTransaction();\n      \n      // Hibernate query with HQL to avoid exception of lazy loading when closing session\n      // get the instructor from db\n      int theId = 1;\n      Query<Instructor> query = \n      \t\tsession.createQuery(\"select i from Instructor i \"\n      \t\t\t\t\t\t+ \"JOIN FETCH i.courses \"\n      \t\t\t\t\t\t+ \"where i.id=:theInstructorId\", \n      \t\t\t\tInstructor.class);\n      \n      // set parameter on query\n      query.setParameter(\"theInstructorId\", theId);\n      \n      // execute query and get instructor\n      Instructor tempInstructor = query.getSingleResult();\n      \n      System.out.println(\"luv2code: Instructor: \" + tempInstructor);\t\n      \n      // commit transaction\n      session.getTransaction().commit();\n      \n      // close the session\n      session.close();\n      \n      System.out.println(\"\\nluv2code: The session is now closed!\\n\");\n      \n      // get courses for the instructor\n      System.out.println(\"luv2code: Courses: \" + tempInstructor.getCourses());\n      \n      System.out.println(\"luv2code: Done!\");\n    }\n    finally {\n      // add clean up code\n      session.close();\n      \n      factory.close();\n    }\n  }\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Hibernate/OneToMany.html",
    "title": "One To Many Relationship",
    "body": "\n\nBack\n\n\nOne To Many Relationship\n\n\n\n\n\nUnidirectional\n\n\nBidirectional\n\n\n\n\n\nUnidirectional\n\n\nHere we demonstrate how to implement a unidirectional one to many relationship between two entities:\n\n\n\n\n\n\n\nWell, first of all you have to define the two database tables corresponding to these two entities.\n\n\nEntities\n\n\nWe now code the two entities:\n\n\npackage com.hibernate.demo.entity;\n// annotate the class as an entity and map to db table\n@Entity\n@Table(name=\"course\")\npublic class Course {\n  // define the fields\n  // annotate the fields with db column names\n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"title\")\n  private String title;\n  \n  // Set up one to many relationship\n  @ManyToOne(cascade= \n              // On delete course, do not delete instructor\n              {CascadeType.PERSIST, \n              CascadeType.MERGE,\n              CascadeType.DETACH, \n              CascadeType.REFRESH})\n  @JoinColumn(name=\"instructor_id\")\n  private Instructor instructor;\n  \n  // Set up unidirectional one to many relationship\n  @OneToMany(fetch=FetchType.LAZY, cascade=CascadeType.ALL)\n\t@JoinColumn(name=\"course_id\")\n\tprivate List<Review> reviews;\n  \n  public Course() {\n  }\t\t\n  \n  ...\n  // Setters and getters\n}\n\n\n\nAnd now the Review:\n\n\npackage com.hibernate.demo.entity;\n@Entity\n@Table(name=\"review\")\npublic class Review {\n\n\t@Id\n\t@GeneratedValue(strategy=GenerationType.IDENTITY)\n\t@Column(name=\"id\")\n\tprivate int id;\n\t\n\t@Column(name=\"comment\")\n\tprivate String comment;\n\t\n\tpublic Review() {\n\t\t\n\t}\n\n\n\nNote that there is no reference in the Review to the Course.\n\n\nMain App\n\n\nTo test our code, we are going to get a Course and the list of Review objects associated. The test main app is the following:\n\n\npackage com.hibernate.demo;\npublic class CreateDemo {\n  public static void main(String[] args) {\n  \n    // create session factory\n    // ...\n    \n    // create session\n    Session session = factory.getCurrentSession();\n    \n    try {\t\t    \n      // start a transaction\n      session.beginTransaction();\n      \n      // get the course\n      int theId = 10;\n      Course tempCourse = session.get(Course.class, theId);\n      \n      // Get reviews\n      tempCourse.getReviews();\n      \n      // commit transaction\n      session.getTransaction().commit();\n    }\n    finally {\n      session.close();\n    \tfactory.close();\n    }\n  }\n}\n\n\nBidirectional\n\n\nNow we will define the following relationship:\n\n\n\n\n\n\n\nLet's now see how to code a bidirectional relationship:\n\n\nEntities\n\npackage com.hibernate.demo.entity;\n\n/* annotate the class as an entity and map to db table */\n@Entity\n@Table(name=\"instructor\")\npublic class Instructor {\n  // define the fields and annotate the fields \n  // with db column names\n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"first_name\")\n  private String firstName;\n  \n  @Column(name=\"last_name\")\n  private String lastName;\n  \n  @Column(name=\"email\")\n  private String email;\n  \n  // Set up mapping to InstructorDetail entity\n  // Note the cascade type\n  @OneToOne(cascade=CascadeType.ALL)\n  // Define the foreign key\n  @JoinColumn(name=\"instructor_detail_id\")\n  private InstructorDetail instructorDetail;\n  \n  // Bidirectional relationship with courses\n  // the mapping information is in the instructor\n  // property in the Course class\n  @OneToMany(mappedBy=\"instructor\",\n              // On delete instructor, do not delete courses\n              cascade= \n              {CascadeType.PERSIST, \n              CascadeType.MERGE,\n              CascadeType.DETACH, \n              CascadeType.REFRESH})\n  private List<Course> courses;\n  \n  public Instructor() {\n  \t\n  }\n  ...\n  // Setters and getters \n}\n\n\n\nAnd now the Course class:\n\n\npackage com.hibernate.demo.entity;\n// annotate the class as an entity and map to db table\n@Entity\n@Table(name=\"course\")\npublic class Course {\n  // define the fields\n  // annotate the fields with db column names\n  @Id\n  @GeneratedValue(strategy=GenerationType.IDENTITY)\n  @Column(name=\"id\")\n  private int id;\n  \n  @Column(name=\"title\")\n  private String title;\n  \n  // Set up one to many relationship\n  @ManyToOne(cascade= \n              // On delete course, do not delete instructor\n              {CascadeType.PERSIST, \n              CascadeType.MERGE,\n              CascadeType.DETACH, \n              CascadeType.REFRESH})\n  @JoinColumn(name=\"instructor_id\")\n  private Instructor instructor;\n  \n  public Course() {\n  }\t\t\n  \n  ...\n  // Setters and getters\n}\n\n\n\nMain App\n\n\nIn our test main app we are going to search for an InstructorDetail object, and we are going to retrieve the related Instructor object:\n\n\npackage com.hibernate.demo;\npublic class GetInstructorDetailDemo {\n  public static void main(String[] args) {\n    session = factory.getCurrentSession();\n    try {\n      // start a transaction\n      session.beginTransaction();\n      // get the instructor from db\n      int theId = 1;\n      Instructor tempInstructor = session.get(Instructor.class, theId);\t\t\n      \n      // create some courses\n      Course tempCourse1 = new Course(\"Air Guitar - The Ultimate Guide\");\n      Course tempCourse2 = new Course(\"The Pinball Masterclass\");\n      \n      // add courses to instructor\n      tempInstructor.add(tempCourse1);\n      tempInstructor.add(tempCourse2);\n      \n      // save the courses\n      session.save(tempCourse1);\n      session.save(tempCourse2);\n      \n      // commit transaction\n      session.getTransaction().commit();\n      \n    } catch(Exception exc){\n      exc.printStackTrace();\n    } finally {\n      // Finish session\n      session.close();\n      // Remove factory\t\n      factory.close();\n    }\n  }\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Spring/Spring Framework.html",
    "title": "Spring Framework",
    "body": "\n\nBack\n\n\nSpring Framework\n\n\n\n\nComponents:\n\n\n\n\nCore Container \n\n\n\nBeans (define entities)\n\n\nCore (management of beans)\n\n\nSpEL: Spring Expression Language (annotations)\n\n\nContext (store entities)\n\n\n\nAOP (Aspect Oriented Programming): allows you to create application wide services like messaging, logging, security, etc. and add this functionality to your objects in a declarative fashion.\n\n\nData Access Layer: establishes the connection with the database \n\n\n\nJDBC Helper classes\n\n\nORM: provides hook to Hibernate\n\n\nTransactions\n\n\nOXM\n\n\nJMS (Java Message Service) for async messages\n\n\n\nWeb Layer: all web related classes, holds all of the Spring MVC framework\n\n\n\nServlet\n\n\nWebSocket\n\n\nWeb\n\n\nPortlet\n\n\n\nTest Layer: supports TDD:\n\n\n\nUnit\n\n\nIntegration\n\n\nMock\n\n\n\n\nSpring Projects\n\n\nSpring modules built on top of the core Spring Framework:\n\n\n\n\nSpring Boot\n\n\nSpring Cloud\n\n\nSpring Batch\n\n\netc\n\n\n\n\nSpring Projects\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Start in indexjs.html",
    "title": "Start in index.js",
    "body": "\n\nBack\n\n\nStart in index.js\n\n\n\n\nKeep in mind, index.js is the entry point:\n\n\n\nFirst of all refer to File Structure, and then basically remove everything from index.js, and replace it for:\n\n\n\nimport React from 'react';\nimport ReactDom from 'react-dom';\n\n// CSS\nimport './index.css';\n\n\n\n\n\n\nWe use the ReactDom module to make use of the React DOM API, which let's us render components, etc.\n\n\n\n\nNext we call ReactDom.render() to output our HTML:\n\n\n\nimport React from 'react';\nimport ReactDom from 'react-dom';\n\n// CSS\nimport './index.css';\n\nfunction Component() {\n  return (\n    <h4> HI! </h4>\n  );\n}\n\nReactDom.render(\n  <Component/>,\n  document.getElementbyId(\"root\")\n)\n\n\n\n\n\nNote \n\n\n\n\nThe function must start with a capital letter\n\n\nThe tag that encloses the component must be closed, so either: <Component/> or <Component></ Component>\n\n\nWe use document.getElementbyId(\"root\"), this tells React where to place the component inside the HTML\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/PropTypes.html",
    "title": "PropTypes",
    "body": "\n\nBack\n\n\nPropTypes\n\n\n\n\nPropTypes allows us to validate our props.\n\n\nimport React from 'react'\nimport Product from './Product'\nimport { useFetch } from './useFetch'\n\nconst url = 'https://course-api.com/react-prop-types-example'\n\nconst Index = () => {\n  const { products } = useFetch(url)\n  return (\n    <div>\n      <h2>products</h2>\n      <section className='products'>\n        {products.map((product) => {\n          // Pass the props \n          return <Product key={product.id} {...product} />\n        })}\n      </section>\n    </div>\n  )\n}\n\nexport default Index\n\n\n\nIn this Product component we show how to use propTypes to parametrize the props, and how to use conditional render to avoid getting an error when some of the props are missing.\n\n\nimport React from 'react';\nimport PropTypes from 'prop-types';\nimport defaultImage from './assets/default-image.jpeg';\n\nconst Product = ({ image, name, price }) => {\n  const url = image && image.url;\n  return (\n    <article className='product'>\n      {/*Use conditional rendering in case the data does not exist */}\n      <img src={url || defaultImage} alt={name || 'default name'} />\n      <h4>{name}</h4>\n      <p>${price || 3.99}</p>\n    </article>\n  );\n};\n\n// Define the propTypes for the object\nProduct.propTypes = {\n  image: PropTypes.object.isRequired,\n  name: PropTypes.string.isRequired,\n  price: PropTypes.number.isRequired,\n};\n\nexport default Product;\n\n\nDefault Props\n\n\nIn this other Product component, we show how to use defaultProps instead of conditional rendering.\n\n\nimport React from 'react';\nimport PropTypes from 'prop-types';\nimport defaultImage from './assets/default-image.jpeg';\n\nconst Product = ({ image, name, price }) => {\n  return (\n    <article className='product'>\n      {/*Use conditional rendering in case the data does not exist */}\n      <img src={image.url} alt={name} />\n      <h4>{name}</h4>\n      <p>${price}</p>\n    </article>\n  );\n};\n\n// Define the propTypes for the object\nProduct.propTypes = {\n  image: PropTypes.object.isRequired,\n  name: PropTypes.string.isRequired,\n  price: PropTypes.number.isRequired,\n};\n\nProduct.defaultProps = {\n  name: 'default name',\n  price: 3.99,\n  image: defaultImage,\n};\n\nexport default Product;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/File Structure.html",
    "title": "File Structure",
    "body": "\n\nBack\n\n\nFile Structure\n\n\n\n\n\nnode_modules: folder that contains all of the dependencies\n\n\npackage.json: is the manifest file for the project\n\n\n\nscripts   \n\n\n\nstart: runs the development server\n\n\nbuild: creates a production version for the project inside a folder called build, where the optimized files resulting of the build are stored.\n\n\n\n\n\n\nThe rest of the files created by create-react-app are mostly useless:\n\n\n\n\nApp.js\n\n\nApp.css\n\n\nApp.test.js\n\n\nlogo.svg\n\n\nserviceWorker.js\n\n\nsetupTests.js\n\n\n\n\nAlso all of the contents of index.js can be removed.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Reducer.html",
    "title": "Reducers and Actions",
    "body": "\n\nBack\n\n\nReducers and Actions\n\n\n\n\nLet's now see an example of a reducer, more concretely the reducer of the user slice we defined previously:\n\n\n// Use create slice to define the slice\nimport { createSlice } from \"@reduxjs/toolkit\";\n\n// Define initial state\nconst initialStateValue = { name: \"\", age: 0, email: \"\" };\n\nexport const userSlice = createSlice({\n  // Name of slice\n  name: \"user\",\n  // Initial state of reducer\n  initialState: { value: initialStateValue },\n  // Possible reducers\n  reducers: {\n    login: (state, action) => {\n      state.value = action.payload;\n    },\n\n    logout: (state) => {\n      state.value = initialStateValue;\n    },\n  },\n});\n\n// De-structure actions\nexport const { login, logout } = userSlice.actions;\n\n// Export reducer\nexport default userSlice.reducer;\n\n\n\nWe now \n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Props.html",
    "title": "Props",
    "body": "\n\nBack\n\n\nProps\n\n\n\n\nIn React to define parameters in our components, we do as follows:\n\n\n\nimport React from 'react'\n\n// This are the props\nconst Book = (props) => {\n return (\n  <article className='book'>\n   <img src={props.img} alt='' />\n   <h1>{props.title}</h1>\n   <h4>{props.author}</h4>\n  </article>\n );\n};\n\nexport default Book\n\n\n\nAnother way (more readable), is to spread the object:\n\n\nimport React from 'react'\n\n// This are the props\nconst Book = ({ title, author }) => {\n return (\n  <article className='book'>\n   <h1>{title}</h1>\n   <h4>{author}</h4>\n  </article>\n );\n};\n\nexport default Book\n\n\n\nNow, to pass these props we do:\n\n\nimport React from 'react';\nimport ReactDom from 'react-dom';\n\n// CSS\nimport './index.css';\n\nimport Book from './Book'\n\nReactDom.render(\n  <Book title='Book title' author='Book author'/>, \n  document.getElementById('root')\n);\n\n\nSpread operator\n\n\nLet's define an object singleBook that contains all of the book's properties and pass it to the Book component:\n\n\nimport React from 'react';\nimport ReactDom from 'react-dom';\n\n// CSS\nimport './index.css';\n\nimport Book from './Book'\n\nconst singleBook = {\n  title: 'Book title',\n  author: 'Book author'\n}\n\nReactDom.render(\n  // Use the spread operator\n  <Book {...singleBook}/>, \n  document.getElementById('root')\n);\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/useRef.html",
    "title": "useRef",
    "body": "\n\nBack\n\n\nuseRef\n\n\n\n\nuseRef returns a mutable ref object whose .current property is initialized to the passed argument. Some properties:\n\n\n\n\nPreserves the value of the object\n\n\nDoes not trigger re-render\n\n\nAssigned to DOM nodes/elements\n\n\n\nimport React, { useEffect, useRef } from 'react';\n\nconst UseRefBasics = () => {\n  // Create the container\n  const refContainer = useRef(null);\n\n  const handleSubmit = (e) => {\n    e.preventDefault();\n    // Print the value inside the input\n    console.log(refContainer.current.value);\n  };\n  \n  useEffect(() => {\n    // Focus on the input element whenever we render the application\n    refContainer.current.focus();\n  });\n\n  return (\n    <>\n      <form className='form' onSubmit={handleSubmit}>\n        <div>\n          {/*The refContainer points to the input element*/}\n          <input type='text' ref={refContainer} />\n        </div>\n        <button type='submit'>submit</button>\n      </form>\n    </>\n  );\n};\n\nexport default UseRefBasics;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/useState.html",
    "title": "useState",
    "body": "\n\nBack\n\n\nuseState\n\n\n\nError\n\n\nIn the next piece of code we show how, if we change the value of a variable in React, it does not change in our web app because it is not re-rendered:\n\n\nimport React from 'react';\n\nconst ErrorExample = () => {\n  let title = 'random title';\n\n  const handleClick = () => {\n    title = 'hello people';\n    console.log(title);\n  };\n  return (\n    <React.Fragment>\n      <h2>{title}</h2>\n      <button type='button' onClick={handleClick}>\n        change title\n      </button>\n    </React.Fragment>\n  );\n};\n\nexport default ErrorExample;\n\n\n\nThat is why we will need to use the hook useState, so we change handle state changes.\n\n\nimport React, { useState } from 'react';\n\nconst UseStateBasics = () => {\n  const [text, setText] = useState('random title');\n  const handleClick = () => {\n    if (text === 'random title') {\n      setText('hello world');\n    } else {\n      setText('random title');\n    }\n  };\n\n  return (\n    <React.Fragment>\n      <h1>{text}</h1>\n      <button type='button' onClick={handleClick}>\n        change title\n      </button>\n    </React.Fragment>\n  );\n};\n\nexport default UseStateBasics;\n\n\n\nWhen we invoke useState we have to pass as an argument the initial value of the state variable. useState is a function that returns an array:\n\n\n\n\nThe first element: the state variable\n\n\nThe second element: the handler that controls the value of the state value\n\n\n\n\nWhen using useState with objects, whenever you update one property of the object, you have to pass the object to the handler (with the spread operator), and then override the property you want to update:\n\n\nimport React, { useState } from 'react';\n\nconst UseStateObject = () => {\n  // Object\n  const [person, setPerson] = useState({\n    name: 'peter',\n    age: 24,\n    message: 'random message',\n  });\n\n  const changeMessage = () => {\n    // Pass the person object with the spread operator \n    // and override the message property\n    setPerson({ ...person, message: 'hello world' });\n  };\n\n  return (\n    <>\n      <h3>{person.name}</h3>\n      <h3>{person.age}</h3>\n      <h4>{person.message}</h4>\n      <button className='btn' onClick={changeMessage}>\n        change message\n      </button>\n    </>\n  );\n};\n\nexport default UseStateObject;\n\n\nAsynchronous functions\n\n\nIf we want to update a value asynchronally, and fetch the value of the state variable when the change happens, and not when the function is defined, then:\n\n\nimport React, { useState } from 'react';\n\nconst UseStateCounter = () => {\n  const [value, setValue] = useState(0);\n\n  const reset = () => {\n    setValue(0);\n  };\n\n  const complexIncrease = () => {\n    setTimeout(() => {\n      // value is the value of the state variable when the timeout is defined\n      // if you call it multiple times consecutively you get the same value, because they all get value = 0\n      // setValue(value + 1);\n      // prevState is the value of the state variable when the timeout finished\n      // if you call it multiple times consecutively you get different values, because value has already been updated\n      // by another setTimeout.\n      // if you call it multiple times\n      setValue((prevState) => {\n        return prevState + 1;\n      });\n    }, 2000);\n  };\n\n  return (\n    <>\n      <section style={{ margin: '4rem 0' }}>\n        <h2>more complex counter</h2>\n        <h1>{value}</h1>\n        <button className='btn' onClick={complexIncrease}>\n          increase later\n        </button>\n      </section>\n    </>\n  );\n};\n\nexport default UseStateCounter;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/npm.html",
    "title": "npm",
    "body": "\n\nBack\n\n\nnpm\n\n\n\n\nIt is the Node Package Manager:\n\n\n\nCreate package.json (manifest) file, with the list of dependencies\n\n$ npm init\n\n\n\nInstall package locally and add it to package.json, under the keyword \"dependencies\"\n\n$ npm install <package name>\n\n\n\nInstall package globally (requires sudo)\n\n$ npm install -g <package name>\n\n\n\nInstall package only for development\n\n$ npm install <package name> --save-dev\n\n\n\nThe packages installed with be saved under the file node_modules\n\n\n\nTo install all the dependencies listed in package.json, just run:\n\n\n$ npm install\n\n\n\nWhere the package.json is.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/useEffect.html",
    "title": "useEffect",
    "body": "\n\nBack\n\n\nuseEffect\n\n\n\n\nThis hook is used for any work needed to be made outside of the component: fetch data, changing the document title, signing up for a subscription, setting up an event listener.\n\n\n\n\nRuns after every re-render\n\n\nCleanup function\n\n\nSecond parameter\n\n\n\nimport React, { useState, useEffect } from 'react';\n\nconst UseEffectBasics = () => {\n\n  // Callback called whenever the component is rendered\n  useEffect(() => {\n    document.title = `New Messages(${value})`;\n  });\n  \n  return (\n    <>\n      <h1>{value}</h1>\n      <button className='btn'}>\n        click me\n      </button>\n    </>\n  );\n};\n\nexport default UseEffectBasics;\n\n\n\nDependencies\n\n\nThe useEffect definition allows you to pass an array of dependencies:\n\n\n\n\nIf it is specified as []: useEffect will only be triggered in the first render\n\n\nIf it is an array of state variables: it will be triggered every time the state variable is updated.\n\n\n\nimport React, { useState, useEffect } from 'react';\n\nconst UseEffectBasics = () => {\n\n  const [value, setValue] = useState(0);\n  // Only trigger on first render\n  // useEffect(() => {\n  //   document.title = `New Messages(${value})`;\n  // }, []);\n  // Call whenever value is updated\n  useEffect(() => {\n    document.title = `New Messages(${value})`;\n  }, [value]);\n  \n  return (\n    <>\n      <h1>{value}</h1>\n      <button className='btn'}>\n        click me\n      </button>\n    </>\n  );\n};\n\nexport default UseEffectBasics;\n\n\nClean up Function\n\n\nuseEffect lets us define a function that is invoked once we exit the function:\n\n\nimport React, { useState, useEffect } from 'react';\n\nconst UseEffectCleanup = () => {\n  const [size, setSize] = useState(window.innerWidth);\n\n  const checkSize = () => {\n    setSize(window.innerWidth);\n  };\n\n  useEffect(() => {\n    console.log('useEffect');\n    window.addEventListener('resize', checkSize);\n    // Clean up function\n    return () => {\n      console.log('cleanup');\n      window.removeEventListener('resize', checkSize);\n    };\n  }, []);\n  console.log('render');\n  return (\n    <>\n      <h1>window</h1>\n      <h2>{size} PX</h2>\n    </>\n  );\n};\n\nexport default UseEffectCleanup;\n\n\nFetch Data\n\n\nUp next we will show how to get data using useEffect.\n\n\n\nNote, if we do not specify the restriction of only triggering on the first render:\n\n\n\nuseEffect calls getUsers\n\n\ngetUsers updates the state, and so the component re-renders\n\n\nBecause there is a re-render, useEffect is called again\n\n\n\nThus, we end in an infinite loop\n\n\nimport React, { useState, useEffect } from 'react';\n\nconst url = 'https://api.github.com/users';\n\nconst UseEffectFetchData = () => {\n  const [users, setUsers] = useState([]);\n\n  const getUsers = async () => {\n    const response = await fetch(url);\n    const users = await response.json();\n    setUsers(users);\n  };\n\n  useEffect(() => {\n    getUsers();\n    // Specify [] so we only run useEffect on the first render.\n  }, []);\n  return (\n    <>\n      <h3>github users</h3>\n      <ul className='users'>\n        {users.map((user) => {\n          const { id, login, avatar_url, html_url } = user;\n          return (\n            <li key={id}>\n              <img src={avatar_url} alt={login} />\n              <div>\n                <h4>{login}</h4>\n                <a href={html_url}>profile</a>\n              </div>\n            </li>\n          );\n        })}\n      </ul>\n    </>\n  );\n};\n\nexport default UseEffectFetchData;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Performance Optimization.html",
    "title": "Performance Optimization",
    "body": "\n\nBack\n\n\nPerformance Optimization\n\n\n\n\nEven though React is fast by default (you do not need to use it), we can use different optimization techniques (mind, they do add their own cost):\n\n\nReact.memo\n\n\nReact.memo stores a component, and only re-renders if the props of the component change (it memoizes the component). In the next example, that means that we only re-render BigList if products change, thus, we do not re-render any SingleProduct component unless products change.\n\n\nimport React, { useState, useCallback, useMemo } from 'react'\n\n// Custom hook\nimport { useFetch } from 'useFetch'\n\nconst url = 'https://course-api.com/javascript-store-products'\n\nconst Index = () => {\n  const { products } = useFetch(url)\n  const [count, setCount] = useState(0)\n\n  return (\n    <>\n      <h1>Count : {count}</h1>\n      <button className='btn' onClick={() => setCount(count + 1)}>\n        click me\n      </button>\n      <BigList products={products} />\n    </>\n  )\n}\n\n\n// Each time a prop or the state changes, the component re-renders, so all\n// the elements of the list are processed again.\n// However if we use React.memo we only re-render the component if products change \n\nconst BigList = React.memo(({ products }) => {\n\n  return (\n    <section className='products'>\n      {products.map((product) => {\n        return (\n          <SingleProduct\n            key={product.id}\n            {...product}\n          ></SingleProduct>\n        )\n      })}\n    </section>\n  )\n})\n\nconst SingleProduct = ({ fields }) => {\n  let { name, price } = fields\n  price = price / 100\n  const image = fields.image[0].url\n\n  return (\n    <article className='product'>\n      <img src={image} alt={name} />\n      <h4>{name}</h4>\n      <p>${price}</p>\n    </article>\n  )\n}\n\nexport default Index\n\n\nuseCallback\n\n\nWhat happens if we pass a function to BigList, well if the state changes (whichever variable of the state) then the function is created again, and so the function is different. Which means the props of BigList list changes, and causes React.memo to re-render the entire component. That is why we use useCallback.\n\n\n\nuseCallback allows us to define when to create a function, by specifying the dependencies like we did with useEffect:\n\n\n\n\nIf the dependency is []: then only create in the first render\n\n\nIf there are variables in the []: create whenever those variables change\n\n\nIf there is nothing: create always.\n\n\n\n\nRefer to Customs Hooks for an use case of useCallback inside the custom hook useFetch.\n\n\nimport React, { useState, useCallback, useMemo } from 'react'\n\n// Custom hook\nimport { useFetch } from 'useFetch'\n\nconst url = 'https://course-api.com/javascript-store-products'\n\nconst Index = () => {\n  const { products } = useFetch(url);\n  const [count, setCount] = useState(0);\n  const [cart, setCart] = useState(0);\n  \n  // We only create this function when we update the cart value\n  // That is we memoize the function\n  const addToCart = useCallback(() => {\n    setCart(cart + 1)\n  }, [cart])\n\n  return (\n    <>\n      <h1>Count : {count}</h1>\n      <button className='btn' onClick={() => setCount(count + 1)}>\n        click me\n      </button>\n      <BigList products={products} addToCart={addToCart}/>\n    </>\n  )\n}\n\n\n// Each time a prop or the state changes, the component re-renders. Because now \n// addToCart is define with useCallback, the re-render is not triggered\n\nconst BigList = React.memo(({ products, addToCart }) => {\n\n  return (\n    <section className='products'>\n      {products.map((product) => {\n        return (\n          <SingleProduct\n            key={product.id}\n            {...product}\n            addToCart={addToCart}\n          ></SingleProduct>\n        )\n      })}\n    </section>\n  )\n})\n\nconst SingleProduct = ({ fields, addToCart }) => {\n  let { name, price } = fields\n  price = price / 100\n  const image = fields.image[0].url\n\n  return (\n    <article className='product'>\n      <img src={image} alt={name} />\n      <h4>{name}</h4>\n      <p>${price}</p>\n      <button onClick={addToCart}>add to cart</button>\n    </article>\n  )\n}\n\nexport default Index;\n\n\nuseMemo\n\n\nNote that this hook deals with values (which is the traditional functionality of the idea of memoizing), whilst React.memo look for changes in the props. \n\n\n\nIn the next example we create a function that returns a value, and we memoize the function, so it only computes the value whenever the products change (the argument of the function), else it returns the value stored before:\n\n\nimport React, { useState, useCallback, useMemo } from 'react'\n\n// Custom hook\nimport { useFetch } from 'useFetch'\n\nconst url = 'https://course-api.com/javascript-store-products'\n\n// Define the function we are going to memoize\nconst calculateMostExpensive = (data) => {\n  return (\n    data.reduce((total, item) => {\n      const price = item.fields.price\n      if (price >= total) {\n        total = price\n      }\n      return total\n    }, 0) / 100\n  )\n}\n\nconst Index = () => {\n  const { products } = useFetch(url);\n  const [count, setCount] = useState(0);\n  const [cart, setCart] = useState(0);\n  \n  const addToCart = useCallback(() => {\n    setCart(cart + 1)\n  }, [cart])\n  \n  // Memoize the function with useMemo\n  const mostExpensive = useMemo(() => calculateMostExpensive(products), [\n    products,\n  ])\n\n  return (\n    <>\n      <h1>Count : {count}</h1>\n      <button className='btn' onClick={() => setCount(count + 1)}>\n        click me\n      </button>\n      <!-- Show most expensive product -->\n      <h1>Most Expensive : ${mostExpensive}</h1>\n      <BigList products={products} addToCart={addToCart}/>\n    </>\n  )\n}\n\nconst BigList = React.memo(({ products, addToCart }) => {\n\n  return (\n    <section className='products'>\n      {products.map((product) => {\n        return (\n          <SingleProduct\n            key={product.id}\n            {...product}\n            addToCart={addToCart}\n          ></SingleProduct>\n        )\n      })}\n    </section>\n  )\n})\n\nconst SingleProduct = ({ fields, addToCart }) => {\n  let { name, price } = fields\n  price = price / 100\n  const image = fields.image[0].url\n\n  return (\n    <article className='product'>\n      <img src={image} alt={name} />\n      <h4>{name}</h4>\n      <p>${price}</p>\n      <button onClick={addToCart}>add to cart</button>\n    </article>\n  )\n}\n\nexport default Index;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Context API.html",
    "title": "Context API",
    "body": "\n\nBack\n\n\nContext API\n\n\n\n\nContext API and useContext allows us to resolve the issue of the prop drilling. The context has two components:\n\n\n\n\nThe provider: works as a distributer\n\n\nThe consumer\n\n\n\n\nWe use them as follows:\n\n\nimport React, { useState, useContext } from 'react';\nimport { data } from '../../../data';\n\n// Create context object\nconst PersonContext = React.createContext();\n\nconst ContextAPI = () => {\n  // State saved in the context\n  const [people, setPeople] = useState(data);\n  // Event handler saved in the context\n  const removePerson = (id) => {\n    setPeople((people) => {\n      return people.filter((person) => person.id !== id);\n    });\n  };\n  \n  return (\n    {/*Wrap the components in the context provider, so all the nested components\n      have access to the variables defined in the context object*/}\n    <PersonContext.Provider value={{ removePerson, people }}>\n      <h3>Context API / useContext</h3>\n      <List />\n    </PersonContext.Provider>\n  );\n};\n\nconst List = () => {\n  // Obtain data from the context with the useContext hook\n  const mainData = useContext(PersonContext);\n  return (\n    <>\n      {mainData.people.map((person) => {\n        return <SinglePerson key={person.id} {...person} />;\n      })}\n    </>\n  );\n};\n\nconst SinglePerson = ({ id, name }) => {\n  // Obtain data from the context with the useContext hook\n  const { removePerson } = useContext(PersonContext);\n  return (\n    <div className='item'>\n      <h4>{name}</h4>\n      <button onClick={() => removePerson(id)}>remove</button>\n    </div>\n  );\n};\n\nexport default ContextAPI;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Dispatch.html",
    "title": "Dispatch",
    "body": "\n\nBack\n\n\nDispatch\n\n\n\n\nIn order to dispatch actions in our reducers we do as follows:\n\n\nimport React from \"react\";\n// Get dispatch hook\nimport { useDispatch } from \"react-redux\";\n// Get actions\nimport { login, logout } from \"../features/user\";\n\nfunction Login() {\n  // Initialize dispatch hook\n  const dispatch = useDispatch();\n\n  return (\n    <div>\n      <button\n        onClick={() => {\n          // Dispatch login action\n          dispatch(login({ name: \"Pedro\", age: 20, email: \"pedro@gmail.com\" }));\n        }}\n      >\n        Login\n      </button>\n\n      <button\n        onClick={() => {\n          // Dispatch logout action\n          dispatch(logout());\n        }}\n      >\n        LOGOUT\n      </button>\n    </div>\n  );\n}\n\nexport default Login;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Children in Props.html",
    "title": "Children in Props",
    "body": "\n\nBack\n\n\nChildren in Props\n\n\n\n\nYou can nest content inside your component. If we have the following:\n\n\nimport React from 'react';\nimport ReactDom from 'react-dom';\n\n// CSS\nimport './index.css';\n\nimport Book from './Book'\n\nconst singleBook = {\n  title: 'Book title',\n  author: 'Book author'\n}\n\nReactDom.render(\n  <Book {...singleBook}>\n    <p> I am nested!</p>\n  </Book>, \n  document.getElementById('root')\n);\n\n\n\nYou can access the nested object from your component:\n\n\nimport React from 'react'\n\n// De-structure the children prop\nconst Book = ({ title, author, children }) => {\n return (\n  <article className='book'>\n   <h1>{title}</h1>\n   <h4>{author}</h4>\n   {children}\n  </article>\n );\n};\n\nexport default Book\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Conditional Rendering.html",
    "title": "Conditional Rendering",
    "body": "\n\nBack\n\n\nConditional Rendering\n\n\n\n\nIn the following example we show how we can have React display different elements conditionally:\n\n\nimport React, { useState, useEffect } from 'react';\nconst url = 'https://api.github.com/users/QuincyLarson';\nconst MultipleReturns = () => {\n  const [isLoading, setIsLoading] = useState(true);\n  const [isError, setIsError] = useState(false);\n  const [user, setUser] = useState('default user');\n\n  // Fetch data\n  useEffect(() => {\n    fetch(url)\n      .then((resp) => {\n        if (resp.status >= 200 && resp.status <= 299) {\n          return resp.json();\n        } else {\n          // Update the control state variables\n          setIsLoading(false);\n          setIsError(true);\n          throw new Error(resp.statusText);\n        }\n      })\n      .then((user) => {\n        const { login } = user;\n        setUser(login);\n        // Update the control state variables\n        setIsLoading(false);\n      })\n      .catch((error) => console.log(error));\n  }, []);\n  \n  // Different display depending on the state of the get\n  if (isLoading) {\n    return (\n      <div>\n        <h1>Loading...</h1>\n      </div>\n    );\n  }\n  if (isError) {\n    return (\n      <div>\n        <h1>Error....</h1>\n      </div>\n    );\n  }\n  return (\n    <div>\n      <h1>{user}</h1>\n    </div>\n  );\n};\n\nexport default MultipleReturns;\n\n\n\nShort Circuit Evlauation\n\n\nNow, let's see an example of Short Circuit Evaluation in action:\n\n\nimport React, { useState } from 'react';\n\nconst ShortCircuit = () => {\n  const [text, setText] = useState('');\n  const [isError, setIsError] = useState(false);\n  // If text is falsy, then return 'hello world'\n  // else return text\n  // const firstValue = text || 'hello world';\n  // If text is true, then return 'hello world'\n  // else return text\n  // const secondValue = text && 'hello world';\n\n  return (\n    <>\n      {/*If text is false, return h1 with 'john doe value'*/}\n      <h1>{text || 'john doe'}</h1>\n      {/*If text is true, return h1 with 'john doe value'*/}\n      {text && <h1>'john doe'</h1>}\n    </>\n  );\n};\n\nexport default ShortCircuit;\n\n\nTernary operators\n\n\nWe can also use ternary operators to render conditionally in React.\n\n\nimport React, { useState } from 'react';\n\nconst ShortCircuit = () => {\n  const [isError, setIsError] = useState(false);\n  \n  return (\n    <>\n      <button className='btn' onClick={() => setIsError(!isError)}>\n        toggle error\n      </button>\n      {/*Check the value of isError, if is error is true, return the first value after the ?\n        else return the second value*/}\n      {isError ? (\n        <p>there is an error...</p>\n      ) : (\n        <div>\n          <h2>there is no error</h2>\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default ShortCircuit;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/CSS in JSX.html",
    "title": "CSS in JSX",
    "body": "\n\nBack\n\n\nCSS in JSX\n\n\n\n\nWe can define the style inside JSX, for that we use the prop style. The first curly braces takes us back to javascript, and the second are to specify the creation of an object.\n\n\n\nAlso note that we do not write font-size but we use the React convention of writing fontSize\n\n\nconst Author = () => (\n  <h4 style={{fontSize: '1px'}}>\n    Test\n  </h4>\n);\n\n\n\nThis level has higher preference (overrides) than the CSS imported from a CSS file.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Event Basics.html",
    "title": "Event Basics",
    "body": "\n\nBack\n\n\nEvent Basics\n\n\n\n\n\nList of all possible events\n\n\n\n\nTo define an event we have to specify:\n\n\n\n\nattribute: like onClick, onMouseHover, etc.\n\n\neventHandler: the function to apply. This can be specified as a reference or as an in-line function.\n\n\n\n\nNext, we present an example:\n\n\nimport React from 'react'\n\nconst Book = ({ title, author }) => {\n\n  const clickHandler = () => {alert('Hello!!')}\n  \n  return (\n   <article className='book'>\n    <!-- Here we have the eventHandler as an in-line function -->\n    <h1 onClick={() => alert('Hello!!')}>{title}</h1>\n    <h4>{author}</h4>\n    <!-- Here we have the eventHandler as a reference -->\n    <button type=\"button\" onClick={clickHandler}>This is a button</button>\n   </article>\n  );\n};\n\nexport default Book\n\n\n\nTo pass an argument to the eventHandler we have to use a lambda function, else when we load the application will invoke the function clickHandler(author)\n\n\nimport React from 'react'\n\nconst Book = ({ title, author }) => {\n\n  const clickHandler = (author) => {alert(author)}\n  \n  return (\n   <article className='book'>\n    <h1 onClick={() => alert('Hello!!')}>{title}</h1>\n    <h4>{author}</h4>\n    <!-- Wrap function with an in-line function -->\n    <button type=\"button\" onClick={() => clickHandler(author)}>This is a button</button>\n   </article>\n  );\n};\n\nexport default Book\n\n\n\n\nWe can also access the event object from within the function, like:\n\n\nimport React from 'react'\n\nconst Book = ({ title, author }) => {\n\n  // You can always access the event object from an eventHandler\n  const clickHandler = (author, e) => {console.log(e)}\n  \n  return (\n   <article className='book'>\n    <h1 onClick={() => alert('Hello!!')}>{title}</h1>\n    <h4>{author}</h4>\n    <button type=\"button\" onClick={() => clickHandler(author)}>This is a button</button>\n   </article>\n  );\n};\n\nexport default Book\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/create-react-app.html",
    "title": "create-react-app",
    "body": "\n\nBack\n\n\ncreate-react-app\n\n\n\n\nYou do not need create-react-app to create a React app, but it makes it way easier:\n\n\n\nnpx create-react-app <app-name>\ncd <app-name>\nnpm start\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Prop Drilling.html",
    "title": "Prop Drilling",
    "body": "\n\nBack\n\n\nProp Drilling\n\n\n\n\nProp Drilling refers to the scenario where we have to pass props to anidated components recursively. Next up, we show and example\n\n\nimport React, { useState } from 'react';\n\n// Data\nimport { data } from '../../../data';\n\n// Outer component\nconst PropDrilling = () => {\n  // State passed as a prop\n  const [people, setPeople] = useState(data);\n \n  // Event handler passed as a prop\n  const removePerson = (id) => {\n    setPeople((people) => {\n      return people.filter((person) => person.id !== id);\n    });\n  };\n  return (\n    <section>\n      <h3>prop drilling</h3>\n      {/* Pass props to the list elements */}\n      <List people={people} removePerson={removePerson} />\n    </section>\n  );\n};\n\n// Middle component\nconst List = ({ people, removePerson }) => {\n  return (\n    <>\n      {people.map((person) => {\n        {/* Pass props to the SinglePerson elements */}\n        return (\n          <SinglePerson\n            key={person.id}\n            {...person}\n            removePerson={removePerson}\n          />\n        );\n      })}\n    </>\n  );\n};\n\n// Inner component\nconst SinglePerson = ({ id, name, removePerson }) => {\n  return (\n    <div className='item'>\n      <h4>{name}</h4>\n      <button onClick={() => removePerson(id)}>remove</button>\n    </div>\n  );\n};\n\nexport default PropDrilling;\n\n\n\nIn these cases we can use the Context API\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/List of components.html",
    "title": "List of Components",
    "body": "\n\nBack\n\n\nList of Components\n\n\n\n\nReact has one restriction for list of objects, and that is: they have to have a key. So, for example:\n\n\nimport React from 'react';\nimport ReactDom from 'react-dom';\n\n// CSS\nimport './index.css';\n\nimport Book from './Book'\n\n// Data to create book object\nconst books = [\n  {\n    id: '1',\n    title: 'Book title',\n    author: 'Book author'\n  },\n  {\n    id: '2',\n    title: 'Book title',\n    author: 'Book author'\n  },\n]\n\nconst bookList = books.map((book) => {\n  // De-structure book object\n  return <Book key={book.id} {...book} />;\n})\n\nReactDom.render(\n  <div>\n    bookList \n  </div>,\n  document.getElementById('root')\n);\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Properties Hooks.html",
    "title": "Properties of Hooks",
    "body": "\n\nBack\n\n\nProperties of Hooks\n\n\n\n\nAll the hooks have the following properties:\n\n\n\n\nThey start with the word use\n\n\nThe component where they are created must be named in uppercase\n\n\nThey  cannot be invoked inside a function/component body.\n\n\nYou cannot call hooks conditionally\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/React Router.html",
    "title": "React Router",
    "body": "\n\nBack\n\n\nReact Router\n\n\n\n\nIn React routing behaves differently than in traditional HTML applications:\n\n\n\n\nIt does not fetch the HTML page from the server, it is done in the client side.\n\n\nThere is no re-rendering even though we change the url.\n\n\n\n\nHere we have an example:\n\n\nimport React from 'react';\n// react router\nimport { BrowserRouter as Router, Route, Switch } from 'react-router-dom';\n// pages\nimport Home from './Home';\nimport About from './About';\nimport People from './People';\nimport Error from './Error';\nimport Person from './Person';\n// Navbar\nimport Navbar from './Navbar';\nconst ReactRouterSetup = () => {\n  return (\n    <Router>\n      <Navbar />\n      <!-- With the switch component only the first one that matches is displayed -->\n      <Switch>\n        <!-- Match the path exactly, else this will be rendered always along the \n            other components  -->\n        <Route exact path='/'>\n          <!-- Component to display -->\n          <Home />\n        </Route>\n        <!-- Match the path -->\n        <Route path='/about'>\n          <About />\n        </Route>\n        <!-- Match the path -->\n        <Route path='/people'>\n          <People />\n        </Route>\n        <!-- Match the path and pass id as a parameter -->\n        <!-- Specify children property because it will be a list of components -->\n        <Route path='/person/:id' children={<Person />}></Route>\n        <!-- Match any path (this is only displayed when the other paths do not \n             match if we use the switch component)-->\n        <Route path='*'>\n          <Error />\n        </Route>\n      </Switch>\n    </Router>\n  );\n};\n\nexport default ReactRouterSetup;\n\n\nLinks\n\n\nHow do we navigate through our application, well by using Links. So, for example, in the Navbar:\n\n\nimport React from 'react';\n\nimport { Link } from 'react-router-dom';\n\nconst Navbar = () => {\n  return (\n    <nav>\n      <ul>\n        <li>\n          <!-- Specify the path -->\n          <Link to='/'>Home</Link>\n        </li>\n        <li>\n          <!-- Specify the path -->\n          <Link to='/about'>About</Link>\n        </li>\n        <li>\n          <!-- Specify the path -->\n          <Link to='/people'>People</Link>\n        </li>\n      </ul>\n    </nav>\n  );\n};\n\nexport default Navbar;\n\n\n\nTo pass a parameter to the link we can do the following:\n\n\nimport React, { useState } from 'react';\n\nimport { data } from '../../../data';\n\nimport { Link } from 'react-router-dom';\n\nconst People = () => {\n  // List of people\n  const [people, setPeople] = useState(data);\n  return (\n    <div>\n      <h1>People Page</h1>\n      {people.map((person) => {\n        return (\n          <div key={person.id} className='item'>\n            <h4>{person.name}</h4>\n            <!-- Specify the path and pass the id of the current person as a parameter -->\n            <Link to={`/person/${person.id}`}>Learn More</Link>\n          </div>\n        );\n      })}\n    </div>\n  );\n};\n\nexport default People;\n\n\n\nNow in the Person component, we can fetch the parameter:\n\n\nimport React, { useState, useEffect } from 'react';\n\nimport { data } from '../../../data';\n\nimport { Link, useParams } from 'react-router-dom';\n\nconst Person = () => {\n  // State\n  const [name, setName] = useState('default name');\n  \n  // useParams hook to fetch the parameter\n  // the name of the parameter (id), is specified in the \"Route\" component\n  // in our case the path to person was: /person/:id\n  const { id } = useParams();\n\n  useEffect(() => {\n    const newPerson = data.find((person) => person.id === parseInt(id));\n    setName(newPerson.name);\n  }, []);\n  \n  return (\n    <div>\n      <h1>{name}</h1>\n      <!-- Go to the previous page of the list of people -->\n      <Link to='/people' className='btn'>\n        Back To People\n      </Link>\n    </div>\n  );\n};\n\nexport default Person;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Index.html",
    "title": "Index file",
    "body": "\n\nBack\n\n\nIndex file\n\n\n\n\nIn the following piece of code we create our store object, where we are going to save the state of our application. As you may note, in this store there are three slices defined. That is because we differentiate three different states (slices). So our store is defined as:\n\n\n{\n  user: {...}\n  theme: {...}\n}\n\n\n\nimport { configureStore } from \"@reduxjs/toolkit\";\n// Different slices\nimport userSlice from \"./features/userSlice.js\";\nimport themeSlice from \"./features/themeSlice.js\";\n\n// Create store\nconst store = configureStore({\n  reducer: {\n    // In each case obtain the reducer\n    user: userSlice.reducer,\n    theme: themeSlice.reducer,\n  },\n});\nexport default store;\n\n\n\nNow, we have to wrap our application with our store:\n\n\nimport React from \"react\";\nimport ReactDOM from \"react-dom\";\n\nimport App from \"./App\";\n\n// Import our store as a provider\nimport { Provider } from \"react-redux\";\nimport store from \"./store\";\n\nReactDOM.render(\n  <React.StrictMode>\n    <Provider store={store}>\n      <App />\n    </Provider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n);\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/index.html",
    "title": "React",
    "body": "\n\nBack\n\n\nReact\n\n\n\nBasic React\n\n\nnpm\n\n\ncreate-react-app\n\n\nBabel\n\n\nFile Structure\n\n\nStart in indexjs\n\n\nJSX Rules\n\n\nCSS in JSX\n\n\nProps\n\n\nChildren in Props\n\n\nList of components\n\n\nEvent Basics\n\n\n\nAdvanced React\n\n\n\nProperties Hooks\n\n\nuseState\n\n\nuseEffect\n\n\nConditional Rendering\n\n\nControlled Inputs\n\n\nuseRef\n\n\nuseReducer\n\n\nProp Drilling\n\n\nContext API\n\n\nCustom Hooks\n\n\nPropTypes\n\n\nReact Router\n\n\nPerformance Optimization\n\n\n\nRedux\n\n\n\nBasics\n\n\nIndex\n\n\nReducers and Actions\n\n\nGet State\n\n\nDispatch\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/JSX Rules.html",
    "title": "JSX Rules",
    "body": "\n\nBack\n\n\nJSX Rules\n\n\n\n\n\nAlways return something\n\n\nAlways return a single element or div, section, article or React.Fragment (does not create a div) enclosing the element\n\n\nUse camelCase for HTML attribute\n\n\nUse className instead of class\n\n\nClose every element\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/useReducer.html",
    "title": "useReducer",
    "body": "\n\nBack\n\n\nuseReducer\n\n\n\n\nAn alternative to useState. Accepts a reducer of type (state, action) => newState, and returns the current state paired with a dispatch method.\n\n\n\nuseReducer is usually preferable to useState when you have complex state logic that involves multiple sub-values or when the next state depends on the previous one. useReducer also lets you optimize performance for components that trigger deep updates because you can pass dispatch down instead of callbacks.\n\n\n\nFor example:\n\n\nimport React, { useState, useReducer } from 'react';\n\n// Components\nimport Modal from './Modal';\n\n// Data\nimport { data } from '../../../data';\n\n// Reducer dispatch function\nimport { reducer } from './reducer';\n\n// Initial state for the reducer\nconst defaultState = {\n  people: [],\n  isModalOpen: false,\n  modalContent: '',\n};\n\nconst Index = () => {\n  // Define state variables\n  const [name, setName] = useState('');\n  // Define reducer: (dispatch fuction, initial state)\n  const [state, dispatch] = useReducer(reducer, defaultState);\n  \n  const handleSubmit = (e) => {\n    // Avoid the re-rendering caused by the submit event\n    e.preventDefault();\n    if (name) {\n      const newItem = { id: new Date().getTime().toString(), name };\n      // Call reducer to update state\n      dispatch({ type: 'ADD_ITEM', payload: newItem });\n      setName('');\n    } else {\n      // Call reducer to update state\n      dispatch({ type: 'NO_VALUE' });\n    }\n  };\n  \n  const closeModal = () => {\n    // Call reducer to update state\n    dispatch({ type: 'CLOSE_MODAL' });\n  };\n  \n  return (\n    <>\n      {/*Render Modal component conditionally */}\n      {state.isModalOpen && (\n        <Modal closeModal={closeModal} modalContent={state.modalContent} />\n      )}\n      {/* Form to add a new person to the reducer state variable */}\n      <form onSubmit={handleSubmit} className='form'>\n        <div>\n          <input\n            type='text'\n            value={name}\n            onChange={(e) => setName(e.target.value)}\n          />\n        </div>\n        <button type='submit'>add </button>\n      </form>\n      {/* Show the people stored in the reducer state variable */}\n      {state.people.map((person) => {\n        return (\n          <div key={person.id} className='item'>\n            <h4>{person.name}</h4>\n            <button\n              onClick={() =>\n                // Call reducer to update state\n                dispatch({ type: 'REMOVE_ITEM', payload: person.id })\n              }\n            >\n              remove\n            </button>\n          </div>\n        );\n      })}\n    </>\n  );\n};\n\nexport default Index;\n\n\n\nNow, let's see the reducer function:\n\n\n/* Reducer function */\nexport const reducer = (state, action) => {\n  // Define logic for each type of action\n  if (action.type === 'ADD_ITEM') {\n    // Add new person (action.payload) to existing people array (state.people)\n    const newPeople = [...state.people, action.payload];\n    return {\n      // Always copy the value from the previous state\n      ...state,\n      // Update the people array\n      people: newPeople,\n      isModalOpen: true,\n      modalContent: 'item added',\n    };\n  }\n  if (action.type === 'NO_VALUE') {\n    // Always copy the value from the previous state\n    return { ...state, isModalOpen: true, modalContent: 'please enter value' };\n  }\n  if (action.type === 'CLOSE_MODAL') {\n    return { ...state, isModalOpen: false };\n  }\n  if (action.type === 'REMOVE_ITEM') {\n    // Filter people array, by removing the person\n    const newPeople = state.people.filter(\n      (person) => person.id !== action.payload\n    );\n    // Copy the previous state (...state) and update the people the array (newPeople)\n    return { ...state, people: newPeople };\n  }\n  throw new Error('no matching action type');\n};\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Controlled Inputs.html",
    "title": "Controlled Inputs",
    "body": "\n\nBack\n\n\nControlled Inputs\n\n\n\n\nLet's see how to handle inputs in a form using React:\n\n\nimport React, { useState } from 'react';\n\nconst ControlledInputs = () => {\n  const [firstName, setFirstName] = useState('');\n  const [people, setPeople] = useState([]);\n\n  const handleSubmit = (e) => {\n    // Avoid the default behaviour in submit which re-renders the page\n    e.preventDefault();\n    // Our own logic for the submit action\n    if (firstName) {\n      // Create new person object\n      const person = { id: new Date().getTime().toString(), firstName };\n      // Update our state (remember you need to spred the people state variable we have before, else the you would \n      // override the people state variable and it would be assigned to only the person object)\n      setPeople((people) => {\n        return [...people, person];\n      });\n      // Set to empty, so the value of the input is the empty string\n      setFirstName('');\n    } else {\n      // No values to create new person\n      console.log('empty values');\n    }\n  };\n  return (\n    <>\n      <article>\n        {/*Event handler for the submit event*/}\n        <form onSubmit={handleSubmit}>\n          <div >\n            <label htmlFor='firstName'>Name : </label>\n            <input\n              type='text'\n              id='firstName'\n              name='firstName'\n              {/*Set the value of the input, it updates every time we change the input*/}\n              value={firstName}\n              {/*Event handler for the change event: use a lambda function to pass the event e and get the value in the input*/}\n              onChange={(e) => setFirstName(e.target.value)}\n            />\n          </div>\n          <button type='submit'>add person</button>\n        </form>\n        {/*Show each person in the people array */}\n        {people.map((person, index) => {\n          const { id, firstName } = person;\n          return (\n            <div className='item' key={id}>\n              <h4>{firstName}</h4>\n            </div>\n          );\n        })}\n      </article>\n    </>\n  );\n};\n\nexport default ControlledInputs;\n\n\n\nMultiple inputs\n\n\nHow can we define an event handler for the OnChange event that is generic, instead of defining one for each input? To showcase this scenario, we will use the same code as before, but with two new inputs. All of the inputs have the same OnChange event handler.\n\n\nimport React, { useState } from 'react';\n\nconst ControlledInputs = () => {\n  // Create a new state variable person, that holds the properties of the person we are currently creating\n  const [person, setPerson] = useState({ firstName: '', email: '', age: '' });\n  // Array of people we have already created\n  const [people, setPeople] = useState([]);\n  \n  // Generic event handler\n  const handleChange = (e) => {\n    // Obtain the name of the input/state variable\n    const name = e.target.name;\n    // Obtain the new value for the input\n    const value = e.target.value;\n    // Update the value of the property for the current person\n    setPerson({ ...person, [name]: value });\n  };\n  \n  const handleSubmit = (e) => {\n    e.preventDefault();\n    if (person.firstName && person.email && person.age) {\n      const newPerson = { ...person, id: new Date().getTime().toString() };\n      setPeople([...people, newPerson]);\n      setPerson({ firstName: '', email: '', age: '' });\n    }\n  };\n  return (\n    <>\n      <article className='form'>\n        <form>\n          <div className='form-control'>\n            <label htmlFor='firstName'>Name : </label>\n            <input\n              type='text'\n              id='firstName'\n              name='firstName'\n              // Access the firstName of the person object\n              value={person.firstName}\n              // Generic event handler\n              onChange={handleChange}\n            />\n          </div>\n          <div className='form-control'>\n            <label htmlFor='email'>Email : </label>\n            <input\n              type='email'\n              id='email'\n              name='email'\n              // Access the email of the person object\n              value={person.email}\n              // Generic event handler\n              onChange={handleChange}\n            />\n          </div>\n          <div className='form-control'>\n            <label htmlFor='age'>Age : </label>\n            <input\n              type='number'\n              id='age'\n              name='age'\n              // Access the age of the person object\n              value={person.age}\n              // Generic event handler\n              onChange={handleChange}\n            />\n          </div>\n          <button type='submit' className='btn' onClick={handleSubmit}>\n            add person\n          </button>\n        </form>\n      </article>\n      <article>\n        {people.map((person) => {\n          const { id, firstName, email, age } = person;\n          return (\n            <div key={id} className='item'>\n              <h4>{firstName}</h4>\n              <p>{email}</p>\n              <p>{age}</p>\n            </div>\n          );\n        })}\n      </article>\n    </>\n  );\n};\n\nexport default ControlledInputs;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Babel.html",
    "title": "Babel",
    "body": "\n\nBack\n\n\nBabel\n\n\n\n\nBabel is a Javascript compiler that converts ES7, ES6 to E5 so it can run smoothly in older browsers. This way we can use new features of ES7 and ES6 while maintaining compatibility.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Get State.html",
    "title": "Get State",
    "body": "\n\nBack\n\n\nGet State\n\n\n\n\nIn order to access the state saved in our state, we do the following:\n\n\nimport React from \"react\";\nimport { useSelector } from \"react-redux\";\n\nfunction Profile() {\n  // Use the useSelector hook\n  const user = useSelector((state) => state.user.value);\n\n  return (\n    <div style={{ color: themeColor }}>\n      <h1> Profile Page</h1>\n      <!--Obtain the user state-->\n      <p> Name: {user.name} </p>\n      <p> Age: {user.age}</p>\n      <p> Email: {user.email}</p>\n    </div>\n  );\n}\n\nexport default Profile;\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Basics.html",
    "title": "Basics",
    "body": "\n\nBack\n\n\nBasics\n\n\n\n\nRedux is a complex state management tool, with a single store (javascrip object) as a CDS (Central Data Storage). Components\n\n\n\n\nStore: object that holds the state\n\n\nReducers: events handler that manages the state and returns the new updated state. The reducers get the arguments and return the state modified.\n\n\nActions: describe the event handler by the reducer and has two properties:\n\n\n\nType: is the identifier of the action\n\n\nPayload: holds the data\n\n\n\nDispatch: is used to send actions to update the data\n\n\n\n\nSo Redux is composed by:\n\n\n\n\n\n\n\nHandle an action\n\n\nThe process of handling an action is the following: \n\n\n\n\nWe create an action object and dispatch it:\n\n\n \n\n\n\n\n\n\nThe store forwards the action to the reducer:\n\n\n\n\n\n\n\n\n\nThe reducer updates the state and returns it\n\n\n \n\n\n\n\n\n\nThe store notifies the UI components of the change of the state\n\n\n\nInstall Redux\n\n$ npm install redux react-redux\n\n\nFirst steps\n\n\n\nInside src create a store folder\n\n\nInside the store folder create an index.js that holds all of the React states in this file\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/React/Custom Hooks.html",
    "title": "Custom Hooks",
    "body": "\n\nBack\n\n\nCustom Hooks\n\n\n\n\nCustoms hooks allow us to avoid duplicating code that uses hooks and essentially in different places of your code. For example, the fetching function is very common, so we create a useFetch hook.\n\n\n\nWhen you define a custom hook, that is, if you define a function outside a component that uses hooks, you will have to name it use<FunctionName>, else you will get an error.\n\n\nimport React, { useState, useEffect } from 'react'\n\n// Import custom hook\nimport { useFetch } from './2-useFetch'\n\nconst url = 'https://course-api.com/javascript-store-products'\n\nconst Example = () => {\n  // Values returned by useFetch\n  const { loading, products } = useFetch(url)\n  return (\n    <div>\n      <h2>{loading ? 'loading...' : 'data'}</h2>\n    </div>\n  )\n}\n\nexport default Example\n\n\nimport { useState, useEffect, useCallback } from 'react';\n\nexport const useFetch = (url) => {\n  // State within the hook\n  const [loading, setLoading] = useState(true);\n  const [products, setProducts] = useState([]);\n  \n  // Functionality of the hook\n  const getProducts = useCallback(async () => {\n    const response = await fetch(url);\n    const products = await response.json();\n    setProducts(products);\n    setLoading(false);\n  }, [url]);\n\n  // Run whenever the url or the getProducts function changes\n  useEffect(() => {\n    getProducts();\n  }, [url, getProducts]);\n  \n  // Values returned by the custom hook\n  return { loading, products };\n};\n\n\n\nNote we are using the hook useCallback (refer to Performance Optimization), we do this because we are specifying getProducts as a dependency for useEffect. However getProducts is created every time the state changes. \n\n\n\nSo when we call useEffect, we change the state, and therefore create the function getProducts, which triggers useEffect, thus the state changes, and we create getProducts, and so on and so forth.\n\n\n\nTo avoid this, we use useCallback, which will create the function whenever any of the dependencies in the list change. So this means, now getProducts is only created when the url changes. This allows us to avoid the infinite loop we ran into before.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/MongoDB/index.html",
    "title": "MongoDB",
    "body": "\n\nBack\n\n\nMongoDB\n\n\n\nMongoDB Commands\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/MongoDB/commands.html",
    "title": "MongoDB Commands",
    "body": "\n\nBack\n\n\nMongoDB Commands\n\n\nTo log into MongoDB with the created user and database:\n\n\n\n$ mongo -u <your username> -p <your password> \\\\\n                --authenticationDatabase <your database name>\n\n\n\n\nOr \n\n\n\n$ mongo -u <your username> \\\\ \n        --authenticationDatabase <your database name>\n\n\n\n\nTo connect to the database use the following URI:\n\n\n\nmongodb://YourUsername:YourPasswordHere@127.0.0.1:27017/your-database-name\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/route_params.html",
    "title": "Route Params",
    "body": "\n\nBack\n\n\nRoute Params\n\n\n\n\nIf, for example, we have a list of products, and we want to get a certain product by its id, we use route params. They can have any name, and are specified by :param. This is then stored in the request object.\n\n\n\napp.get('/api/products/:productID', (req, res) => {\n\t\n  // De-structure param\n  const { productID } = req.params\n\n  // Filter products by id\n  const singleProduct = products.find(\n    (product) => product.id === Number(productID)\n  )\n\t\n  // If it does not exist \n  if (!singleProduct) {\n    return res.status(404).send('Product Does Not Exist')\n  }\n\n  return res.json(singleProduct)\n})\n\n\n\n\nNote that the route params are always strings, in our case we had to convert it to a Number. We can also have more that one route parameter like so:\n\n\n\napp.get('/api/products/:productID/reviews/:reviewID', (req, res) => {\n  res.send('hello world')\n})\n\n\n\n\nWhere we define productID and reviewID as route parameters, and can, therefore, filter by them.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/jwt.html",
    "title": "JSON Web Tokens",
    "body": "\n\nBack\n\n\nJSON Web Tokens\n\n\n\nInstallation\n\n\n$ npm install jsonwebtoken\n\n\n\nExample of Usage\n\n\nWe first create our Express application and so, we import express and jsonwebtoken. And then we start the server.\n\n\n\nconst express = require(\"express\");\nconst jwt = require(\"jsonwebtoken\");\n\nconst app = express();\n\napp.listen(3000, () => {\n    console.log(\"nodejs app running...\");\n});\n\n\n\n\nNow, we define two new endpoints: /api and /api/login.\n\n\n\napp.get(\"/api\", (req , res) => {\n    res.json({\n        mensaje: \"Nodejs and JWT\"\n    });\n});\n\napp.post(\"/api/login\", (req , res) => {\n    const user = {\n        id: 1,\n        nombre : \"Henry\",\n        email: \"henry@email.com\"\n    }\n\n    jwt.sign({user}, 'secretkey', {expiresIn: '32s'}, (err, token) => {\n        res.json({\n            token\n        });\n    });\n\n});\n\n\n\n\nWhere we use the sign method to create a new token.\n\n\n\nSo, if we want to define an endpoint that requires authentication we do:\n\n\n\n// Middleware\nfunction verifyToken(req, res, next){\n     const bearerHeader =  req.headers['authorization'];\n\n     if(typeof bearerHeader !== 'undefined'){\n          const bearerToken = bearerHeader.split(\" \")[1];\n          req.token  = bearerToken;\n          next();\n     }else{\n         res.sendStatus(403);\n     }\n}\n\napp.post(\"/api/posts\", verifyToken, (req , res) => {\n\n    jwt.verify(req.token, 'secretkey', (error, authData) => {\n        if(error){\n            res.sendStatus(403);\n        }else{\n            res.json({\n                    mensaje: \"Post fue creado\",\n                    authData\n                });\n        }\n    });\n});\n\n\n\n\nWhere verifyToken is a middleware function that gets the token from the header, and then we use the verify method to check if the token is valid.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/routes.html",
    "title": "Routes",
    "body": "\n\nBack\n\n\nRoutes\n\n\n\nSet Up\n\n\nIn order to set up the routes for our project, we first create a folder called routes that will contain all the javascript files that control routing functionality. In this example we create two files within routes, people.js and auth.js. \n\n\n\nOnce we have created them, we include them as middleware to the specific endpoints (/api/people for people.js and /login for auth.js), as follows:\n\n\n\nconst express = require('express')\nconst app = express()\n\nconst people = require('./routes/people')\nconst auth = require('./routes/auth')\n\napp.use('/api/people', people)\napp.use('/login', auth)\n\napp.listen(5000, () => {\n  console.log('Server is listening on port 5000....')\n})\n\n\n\nRouter\n\n\nLet's focus now on people.js than controls the routing of /api/people. For that we import the controller of this endpoint and we specify the functions to execute for the different HTTP methods and for the different routes.\n\n\n\n\n/: This is the default endpoint /api/people there we specify that the logic for a get request is contained in the getPeople function.\n\n\n/:d: This endpoint allows for specifying an id as a parameter.\n\n\n\n\nconst express = require('express')\nconst router = express.Router()\n\nconst {\n  getPeople,\n  createPerson,\n  createPersonPostman,\n  updatePerson,\n  deletePerson,\n} = require('../controllers/people')\n\nrouter.route('/').get(getPeople).post(createPerson)\nrouter.route('/:id').put(updatePerson).delete(deletePerson)\n\nmodule.exports = router\n\n\n\nController\n\n\nThe people controller contains:\n\n\n\nlet { people } = require('../data')\n\nconst getPeople = (req, res) => {\n  res.status(200).json({ success: true, data: people })\n}\n\nconst createPerson = (req, res) => {\n  const { name } = req.body\n  if (!name) {\n    return res\n      .status(400)\n      .json({ success: false, msg: 'please provide name value' })\n  }\n  res.status(201).send({ success: true, person: name })\n}\n\nconst createPersonPostman = (req, res) => {\n  const { name } = req.body\n  if (!name) {\n    return res\n      .status(400)\n      .json({ success: false, msg: 'please provide name value' })\n  }\n  res.status(201).send({ success: true, data: [...people, name] })\n}\n\nconst updatePerson = (req, res) => {\n  const { id } = req.params\n  const { name } = req.body\n\n  const person = people.find((person) => person.id === Number(id))\n\n  if (!person) {\n    return res\n      .status(404)\n      .json({ success: false, msg: `no person with id ${id}` })\n  }\n  const newPeople = people.map((person) => {\n    if (person.id === Number(id)) {\n      person.name = name\n    }\n    return person\n  })\n  res.status(200).json({ success: true, data: newPeople })\n}\n\nconst deletePerson = (req, res) => {\n  const person = people.find((person) => person.id === Number(req.params.id))\n  if (!person) {\n    return res\n      .status(404)\n      .json({ success: false, msg: `no person with id ${req.params.id}` })\n  }\n  const newPeople = people.filter(\n    (person) => person.id !== Number(req.params.id)\n  )\n  return res.status(200).json({ success: true, data: newPeople })\n}\n\nmodule.exports = {\n  getPeople,\n  createPerson,\n  createPersonPostman,\n  updatePerson,\n  deletePerson,\n}\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/mock_mongo.html",
    "title": "Mocking MongoDB",
    "body": "\n\nBack\n\n\nMocking MongoDB\n\n\n\n\nWe will now use the node library MongoMemoryServer in order to mock our MongoDB database using Node.js inside a Docker container.\n\n\nMongoMemoryServer\n\n\nAs we have mentioned we need MongoMemoryServer, so we install it as a development depencendy. For that we head to our node app's root folder and we execute:\n\n\n$ npm install mongodb-memory-server-core --save-dev\n\n\nDocker\n\n\nSo, now we create our Dockerfile, which holds our app source code, and where we install mongodb:\n\n\n\nFROM alpine:latest\nMAINTAINER albamr09\n\n# Install dependencies\nRUN apk add --no-cache nodejs npm\n\n# Install mongodb\nRUN echo 'http://dl-cdn.alpinelinux.org/alpine/v3.6/main' >> /etc/apk/repositories\nRUN echo 'http://dl-cdn.alpinelinux.org/alpine/v3.6/community' >> /etc/apk/repositories\nRUN apk update\nRUN apk add mongodb\nRUN apk add mongodb-tools\nRUN mkdir -p /data/db/\nRUN chmod -R 777 /data/db\n\n\n# Add common user\nRUN adduser -D user\n#RUN useradd --create-home --shell /bin/bash user\n\n# Create app directory\nWORKDIR /home/user/src/\n# Change permissions\nRUN chown -R user:user /home/user/src/\nRUN chmod -R 755 /home/user/src/\n\nUSER user\n\n# Copy with user as owner\nCOPY --chown=user:user ./package*.json ./\n\n# Install app dependencies\nRUN npm install\n\n# Copy and override src folder\nCOPY . .\n\n\n\n\nNote that this version of MongoDB is 3.4.4, mainly because we are using the alpine image. This version may not coincide with our MongoDB Docker image, and is not desirable. So make sure (or force) that you are installing the save versions.\n\n\nMongoMemoryServer Configuration\n\n\nAlso, we only need to install it for those images that are not supported by MongoDB. Furthermore, if instead of the package mongo-memory-server-core we install mongo-memory-server, the latter will include a post-install hook that will install MongoDB if it is not already installed on the system.\n\n\n\nIn case of manually installing MongoDB we have to let know MongoMemoryServer where the binary lays. So, within our package.json file we add:\n\n\n\n    \"config\": {\n        \"mongodbMemoryServer\": {\n        \"systemBinary\": \"/usr/bin/mongod\",\n        \"version\": \"3.4.4\"\n    }\n    \n\n\nExample of Usage\n\n\nWe, now, exemplify how to mock our database in our tests: \n\n\n\nconst { MongoMemoryServer } = require('mongodb-memory-server-core');\nconst mongoose = require('mongoose');\n\nconst UserModel = require('../../models/user');\n\nconst userData = { 'name': 'test', 'email': 'test@test.com', 'password': 'test1234', 'username': 'testname' };\n\ndescribe('User Model Tests', ()=> {\n    let mongoServer;\n\n    beforeAll(async () => {\n      mongoServer = await MongoMemoryServer.create();\n      await mongoose.connect(mongoServer.getUri(), {\n        useNewUrlParser: true,\n        useUnifiedTopology: true,\n      }).catch(error => console.log(error));\n    });\n\n\n    afterAll(async () => {\n        await mongoServer.stop();\n        await mongoose.connection.close();\n    });\n\n    afterEach(() => {\n        mongoose.connection.collections['users'].drop( function() {});\n    });\n\n    it('Create a new user', async ()=> {\n        const user = new UserModel(userData);\n        const savedUser = await user.save();\n\n        expect(savedUser._id).toBeDefined();\n        expect(savedUser.name).toBe(userData.name);\n        expect(savedUser.email).toBe(userData.email);\n        expect(savedUser.password).toBe(userData.password);\n        expect(savedUser.username).toBe(userData.username);\n    })\n\n    it('Create a user with invalid fields', async ()=> {\n        var invalidUserData = {...userData};\n        delete invalidUserData.email;\n        const user = new UserModel(invalidUserData);\n\n        let error;\n\n        try{\n            const savedUser = await user.save();\n            error = savedUser;\n        }catch(err){\n            error = err;\n        }\n\n        expect(error).toBeInstanceOf(mongoose.Error.ValidationError);\n        expect(error.errors.email).toBeDefined();\n    })\n\n    it('Create user that already exists', async ()=>{\n        await new UserModel(userData).save();\n\n        let error;\n\n        try{\n            const repeatedUser = new UserModel(userData);\n            await repeatedUser.save();\n        }catch(err){\n            error = err;\n        }\n\n        expect(error).toBeDefined();\n        expect(error.code).toBe(11000);\n    })\n\n    it('Create user with undefined fields', async ()=>{\n        var newUserData = {...userData};\n        delete newUserData.name;\n        const user = new UserModel(newUserData);\n        await user.save();\n\n        expect(user._id).toBeDefined();\n        expect(user.name).toBeUndefined();\n    })\n\n}\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/http.html",
    "title": "HTTP",
    "body": "\n\nBack\n\n\nHTTP\n\n\n\nHTTP Messages\n\n\n\nRequest Message: what the user sends\n\n\nResponse Message: what the server sends\n\n\n\n\n\n\n\n\nThe messages have the following parts:\n\n\n\nInfo about the request: Request URL, Request Method (GET is the default method), Status Code, etc.\n\n\nHeaders: meta information about the request/response, (e.g. \"Content type: application/json\" tells the browser that the body is json)\n\n\nBody: which is the request payload, or the content of the response.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/globals.html",
    "title": "Globals",
    "body": "\n\nBack\n\n\nGlobals\n\n\n\n\nSome global variables available\n\n\n\n\n__dirname: path of current directory\n\n\n__filename\n\n\nrequire: function to use modules\n\n\nmodule: info about current module\n\n\nprocess: info about the environment where the program is bein executed\n\n\n\n\nNote that in Node there is no window object like in Javascript.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/npm.html",
    "title": "NPM",
    "body": "\n\nBack\n\n\nNPM\n\n\n\n\nThe Node Package Manager allows us to:\n\n\n\nReuse our own code in other projects\n\n\nUse code written by other developers and \n\n\nShare our own solutions. \n\n\n\n\nThis tool is installed along node. Npm calls the reusable code a package (also modules or dependencies), that is basically a folder that contains some js code. Note that there is no quality control applied to the packages that are published, so it is the developer's responsibility to check whether the package is secure or not.\n\n\nInstalling packages\n\n\nYou can install a package locally within your project as a local dependency:\n\n\n\n$ nmp i <packageName>\n\n\n\n\nOr you can install the package globally, so it can be accessed from any project:\n\n\n\n$ npm install -g <packageName>\n\n\n\n\nIf you want to specify a version for the package:\n\n\n\n$ npm install <packageName>@1.0.0\n\n\n\nPackage.json\n\n\nThis file stores important information about the project and the packages, it can be conceived as a manifest file. There are two ways to create it:\n\n\n\n\nManually: create package.json in the root folder of the project and define the properties of the project/packages.\n\n\nUsing npm following the guide (add -y to skip the questions of the guide):\n\n\n\t\n\t\n$ npm init \n\t\n\n\n\nWhen the project is initialized, the package.json file is as follows:\n\n\n\n{\n  \"name\": \"08_project\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n\n\n\n\nWhere all those properties are set up during the guide of npm init or set as default with the flag -y.\n\n\n\nAfter installing a dependency\n\n\n\n$ npm i lodash\n\n\n\n\nThe following property is added:\n\n\n\n  \"dependencies\": {\n    \"lodash\": \"^4.17.21\"\n  }\n\n\n\n\nAnd npm creates the folder node_modules, if it does not already exist, which stores the dependencies code. Also, in case of wanting to install dependencies needed only during the development process:\n\n\n\n$ npm i <package> -D\n$ npm i <package> --save-dev\n\n\n\n\nAnd so, the property devDependencies is created in pakage.json.\n\n\nScripts\n\n\nThe object scripts, which is a property of package.json, can contain the definition of different actions, for example:\n\n\n\n\"scripts\": {\n  \"start\": \"node app.js\"\n}\n\n\n\n\nSo when running npm start our app.js will be executed. For some commands you will need to specify run and the command name as follows:\n\n\n\n$ npm run dev\n\n\n\nNodemon\n\n\nThis is a package that lets you hot reload your project without having to execute your app constantly. For that, after installing nodemon as a local or global dependency, we specify on package.json:\n\n\n\n\"scripts\": {\n  \"dev\": \"nodemon app.js\"\n}\n\n\n\n\nIf we want to run it:\n\n\n\n$ npm run dev\n\n\n\nPackage-lock.json\n\n\nThis file stores the dependencies version of the packages installed as dependencies, as to avoid installing newer version that can be the cause of bugs. Because within the package.json only our project's dependencies' versions are specified.\n\n\nUninstalling packages\n\n\nIn order to uninstall the package we have a command, that follows the syntax:\n\n\n\n$ npm uninstall <package>\n\n\n\n\nWe can also remove it from the dependencies object within package.json. So when you remove package-lock.json and the node_modules folder if you run\n\n\n\n$ npm install\n\n\n\n\nThe package that was removed will not be installed.\n\n\n\nGit\n\n\nWhen using git or other version control tool, it is desirable to create a .gitignore and to specify to avoid the node_modules folder, since its size can get big very easily.\n\n\n\nSo, by just pushing the source code, including package.json, if we want to install all of the project's dependencies' again, on the root folder we run:\n\n\n\n$ npm install\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/http_basics.html",
    "title": "HTTP Basics",
    "body": "\n\nBack\n\n\nHTTP Basics\n\n\n\n\nWhen answering to a request, node requires a method to signal to the server that all of the response headers and body have been sent, and so the server can consider the message complete. That method is res.end()\n\n\n\nconst http = require('http')\n\nconst server = http.createServer((req, res) => {\n  res.end('Home page') \n})\n\nserver.listen(5000)\n\n\n\n\nWe create a server with http.createServer. This method takes a callback as an argument, which is called every time a user hits the server.\n\n\n\nNext we specify the port on which the server will be listening for requests. The value of this port is somewhat irrelevant in the development environment.\n\n\nHeaders\n\n\nIf we want to provide the metadata about the response we have to provide headers:\n\n\n\nconst http = require('http')\n\nconst server = http.createServer((req, res) => {\n  res.writeHead(200, { 'content-type': 'text/html' })\n  res.write('<h1>home page</h1>')\n  res.end()\n})\n\nserver.listen(5000)\n\n\n\n\nWith writeHead we specify the headers, in our case we specify the status code (200: OK) and the content type of the response (text/html). The later are called MIME-types or media types. \n\n\n\nThen we specify the body of the response with write and finally we finalize the message with end.\n\n\nRequest Object\n\n\nThe request object that is an argument of the createServer method has several attributes:\n\n\n\n\nreq.method: Allows you to obtain the method of the user's request, i.e. GET, POST, PUT, etc.\n\n\nreq.url: Contains the url of the user's request.\n\n\n\nHTML File\n\n\nAs we have seen the method write allows us to define the content of the body as HTML. However we do not need to write the HTML code inside the method we can also pass a file as input and the method will serve it's content to the response.\n\n\n\nconst http = require('http')\nconst { readFileSync } = require('fs')\n\nconst homePage = readFileSync('./index.html')\n\nconst server = http.createServer((req, res) => {\n  res.writeHead(200, { 'content-type': 'text/html' })\n  res.write(homePage)\n  res.end()\n})\n\nserver.listen(5000)\n\n\n\n\nObserve that we user readFileSync, we do so because, for one this is an example, and also the file is only read once when the server is created, not every time the user hits the server.\n\n\nExternal resources\n\n\nWhen adding external resources to a given HTML file we also need to handle the request to those resources in our server.\n\n\n\nconst http = require('http')\nconst { readFileSync } = require('fs')\n\nconst homePage = readFileSync('./index.html')\nconst homeStyles = readFileSync('./styles.css')\nconst homeImage = readFileSync('./logo.svg')\n\nconst server = http.createServer((req, res) => {\n  // home page\n  if (url === '/') {\n    res.writeHead(200, { 'content-type': 'text/html' })\n    res.write(homePage)\n    res.end()\n  }\n\t// styles\n  else if (url === '/styles.css') {\n    res.writeHead(200, { 'content-type': 'text/css' })\n    res.write(homeStyles)\n    res.end()\n  }\n\t// image/logo\n  else if (url === '/logo.svg') {\n    res.writeHead(200, { 'content-type': 'image/svg+xml' })\n    res.write(homeImage)\n    res.end()\n  }\n})\n\n\n\nNote that the content types differ every time, with css we use text/css, with images we use image/svg+xml.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/events_info.html",
    "title": "Events",
    "body": "\n\nBack\n\n\nEvents\n\n\n\n\nIn Node.js it the event-driven approach to programming is very commonly used. Meaning the flow of our program is in part controlled by events.\n\n\nEvent Emitter\n\n\nAll objects which emit events are instances of EventEmitter, which is accessible from the events module:\n\n\n\nconst EventEmitter = require('events')\n\nconst customEmitter = new EventEmitter()\n\ncustomEmitter.on('response', () => {\n  console.log('some other logic here')\n})\n\ncustomEmitter.emit('response')\n\n\n\n\nHere we can see that we create an EventEmitter object and we listen for the response event with customEmitter.on(). The latter function takes the name of the event as its first argument and the callback as its second. In order to emit a concrete event we use customEmitter.emit(), which takes the event name as its argument.\n\n\nMore Listeners\n\n\nWe can have more than one listener:\n\n\n\nconst EventEmitter = require('events')\n\nconst customEmitter = new EventEmitter()\n\ncustomEmitter.on('response', (name, id) => {\n  console.log(`data recieved user ${name} with id:${id}`)\n})\n\ncustomEmitter.on('response', () => {\n  console.log('some other logic here')\n})\n\ncustomEmitter.emit('response', 'john', 34)\n\n\n\n\nWhere the second listener define a callback that takes name and id as arguments. So when emitting the event we can pass those arguments to the emit function.\n\n\n\nTake into account that the functions' order matter, if you emit and event before you listen for it, the event will never be registered.\n\n\nHTTP Events\n\n\nBecause http.Server extends net.Server which then extends EventEmitter, we can use the methods discussed above. So we can listen for the event request to handle requests from the browser.\n\n\n\nconst http = require('http')\n\n// Using Event Emitter API\nconst server = http.createServer()\n// emits request event\n// subcribe to it / listen for it / respond to it\nserver.on('request', (req, res) => {\n  res.end('Welcome')\n})\n\nserver.listen(5000)\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/modules.html",
    "title": "Modules",
    "body": "\n\nBack\n\n\nModules\n\n\n\n\nEncapsulated code, as to only share what we want. Node uses CommonJS so every file is treated as a module by default.\n\n\n\nIn any .js file we have the global object module:\n\n\n\nconsole.log(module)\n\n\n\n\nModule {\n   id: '.',\n   path: '/home/alba/Desktop/NodeJs',\n   exports: {},\n   filename: '/home/alba/Desktop/NodeJs/02_constants.js',\n   loaded: false,\n   children: [],\n   paths: [\n     '/home/alba/Desktop/NodeJs/node_modules',\n     '/home/alba/Desktop/node_modules',\n     '/home/alba/node_modules',\n     '/home/node_modules',\n     '/node_modules'\n   ]\n }\n \n\n\nExporting\n\n\nSo we can treat the attribute exports as an object and pass it whatever values we would like to show to other app that import our module:\n\n\n\nmodule.exports = { value1: 'value1', value2: 'value2'  }\n\n\n\n\nWhere value1 is the key of the attribute and 'value1' is its value, e.g.:\n\n\n\nconst name = 'John'\nconst surname = 'Tuckey'\n\nmodule.exports = { Name: name, Surname: surname }\n\n\n\n\nAlso, if we only export one object it is sufficient to type:\n\n\n\nconst name = 'John'\n\nmodule.exports = name \n\n\n\n\nAnother way to export is to define explicitly the name of the attributes to export:\n\n\n\nmodule.exports.items = ['item1', 'item2']\n\nconst person = {\n    name: 'bob'\n}\nmodule.exports.singlePerson = person\n\n\n\n\nImporting\n\n\nNow, a module can be imported with the keyword require as follows:\n\n\n\nconst externalModule = require('./module')\nconsole.log(externalModule)\n\n{ Name: 'John', Surname: 'Tukey' }\n\n\n\n\nAnother type of syntax could be unrolling the attributes of the export object:\n\n\n\nconst { Name, Surname } = require('./module')\n\n\n\n\nBuilt-in Modules\n\n\nSome built-in modules are:\n\n\n\n\nOS\n\n\nPATH\n\n\nFS (Filesystem)\n\n\nHTTP\n\n\n\n\nEven though there are several more built-in modules. \n\n\nOS\n\n\nTo import the OS built-in module we do:\n\n\n\nconst os = require('os')\n\n\n\n\nAnd we call it by:\n\n\n\nconsole.log(`The system uptime is ${os.uptime()} seconds`)\n\n\n\nFS\n\n\nWe can also interact with the file system via the FS module. There are two ways to do so:\n\n\n\n\nAsynchronously, which is non-blocking\n\n\nSynchronously, that is blocking\n\n\n\nSynchronous\n\n\nTo exemply both setups, we first de-structure the read and write synchronous methods from the FS module, and then we read and write files.\n\n\n\nconst { readFileSync, writeFileSync } = require('fs')\n\n// Read file with a given path and the corresponding encoding\nconst first = readFileSync('./file.txt', 'utf8')\nconst second = readFileSync('./file2.txt', 'utf8')\n\n// Write to a file given a path, the content is overwritten\nwriteFileSync('./writeFile', 'This content will be written')\n\n// Write to a file given a path, the content is appended\nwriteFileSync('./writeFile', 'This content will be written', {flag: 'a'})\n\n\n\nAsynchronous\n\n\nNow, in order to access the file system asynchronously, we need a callback, and so we do:\n\n\n\nconst { readFileSync, writeFileSync } = require('fs')\n\nreadFile('./file', 'utf8', (error, result) => {\n  if(error){\n    console.log(error)\n    return\n  }\n  else{\n    console.log(result)\n    const first = result\n    // Here we can add another read call\n  }\n})\n\nwriteFile('./file', 'This is the content', (error, result) => {\n  if(error){\n    console.log(error)\n    return\n  }else{\n    console.log(result)\n  }\n})\n\n\n\n\nWhere we specify a callback function with the ES6 syntax. Its first parameter is the error parameter and the second is the result of the operation.\n\n\n\nThe problem with synchronous calls is that they can be very time consuming and they halt the execution, which can be critical when working on time sensitive tasks or when several user call upon these type of functions at a time.\n\n\nHTTP\n\n\nTo show the bare basics, we will set up a server:\n\n\n\nconst http = require('http')\n\nconst server = http.createServer((request, response) => {\n  response.write('This is the index!')\n  response.end()\n})\n\n// Define the port\nserver.listen(5000)\n\n\n\n\nThat can be accessed on localhost:5000. Next, we can code something a little more complex, where the content handed as a response depends on the request:\n\n\n\nconst http = require('http')\n\nconst server = http.createServer((request, response) => {\n  if(request.url === '/'){\n    response.end('This is the index')\n  }else if(request.url === '/about'){\n    response.end('This is the about')\n  }else{\n    response.end('404')\n  }\n})\n\n// Define the port\nserver.listen(5000)\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/async_patterns.html",
    "title": "Asynchronous Patterns",
    "body": "\n\nBack\n\n\nAsynchronous Patterns\n\n\n\nBlocking Code\n\n\nImagine we have the following piece of code:\n\n\n\nconst http = require('http')\n\nconst server = http.createServer((req, res) => {\n  if (req.url === '/') {\n    res.end('Home Page')\n  }\n  if (req.url === '/about') {\n    // blocking code\n    for (let i = 0; i < 1000; i++) {\n      for (let j = 0; j < 1000; j++) {\n        console.log(`${i} ${j}`)\n      }\n    }\n    res.end('About Page')\n  }\n  res.end('Error Page')\n})\n\nserver.listen(5000, () => {\n  console.log('Server listening on port : 5000....')\n})\n\n\n\n\nBecause inside the second conditional we have a nested for loop which is computationally expensive, when a user accesses the about page, the server is blocked, and so it prevents other users from loading any other page. That is essentially because JavaScript is single threaded, so by running the nested conditional, the thread is occupied for a period of time, during which the server will not be able to answer to any other request until it is freed.\n\n\nPromises\n\n\nA Promise is an object that represents the eventual completion (or failure) of an asynchronous operation and its resulting value. So, we can wrap the asynchronous readFile function with a Promise:\n\n\n\nconst { readFile, writeFile } = require('fs')\n\nconst getText = (path) => {\n  return new Promise((resolve, reject) => {\n    readFile(path, 'utf8', (err, data) => {\n      if (err) {\n        reject(err)\n      } else {\n        resolve(data)\n      }\n    })\n  })\n}\n\n\n\n\nThe result of a Promise can be accessed as follows:\n\n\n\ngetText('./content/first.txt')\n  .then((result) => console.log(result))\n  .catch((err) => console.log(err))\n\n\n\n\nAnd then, we can define an asynchronous function start that will wait for the execution of getText:\n\n\n\nconst start = async () => {\n  try {\n    const first = await getText('./content/first.txt')\n    const second = await getText('./content/second.txt')\n    console.log(first, second)\n  } catch (error) {\n    console.log(error)\n  }\n}\n\n\n\n\nWhere you can see that we surround the call with a try-catch statement, which allows us to have more control over the execution flow\n\n\nNode's Native Promises\n\n\nWe can use the utils module in order to wrap functions with the Promise object:\n\n\n\nconst { readFile, writeFile } = require('fs')\nconst util = require('util')\nconst readFilePromise = util.promisify(readFile)\nconst writeFilePromise = util.promisify(writeFile)\n\nconst start = async () => {\n  try {\n    const first = await readFilePromise('./content/first.txt', 'utf8')\n    const second = await readFilePromise('./content/second.txt', 'utf8')\n\t\tawait writeFilePromise(\n      './content/result-mind-grenade.txt',\n      `THIS IS AWESOME : ${first} ${second}`,\n      { flag: 'a' }\n    )\n    console.log(first, second)\n  } catch (error) {\n    console.log(error)\n  }\n}\n\n\n\n\nBut, we can also avoid importing the utils module, by adding .promises when importing the asynchronous functions:\n\n\n\nconst { readFile, writeFile } = require('fs').promises\n\nconst start = async () => {\n  try {\n    const first = await readFile('./content/first.txt', 'utf8')\n    const second = await readFile('./content/second.txt', 'utf8')\n    await writeFile(\n      './content/result-mind-grenade.txt',\n      `THIS IS AWESOME : ${first} ${second}`,\n      { flag: 'a' }\n    )\n    console.log(first, second)\n  } catch (error) {\n    console.log(error)\n  }\n}\n\nstart()\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/intro.html",
    "title": "NodeJS",
    "body": "\n\nBack\n\n\nNodeJS\n\n\n\n\nNodeJS in an environment to run Javascript outside of the browser that was build on top of Chrome's V8 JS Engine.\n\n\n\nIt allows for easy development of full stack apps, since both the frontend and the backend are build in the same language, Javascript.\n\n\nDifferences between to the browser and NodeJS\n\n\n\n\nBrowser\n\n\nNodeJS\n\n\n\n\nDOM\n\n\nNo Dom\n\n\n\n\nWindow\n\n\nNo Window\n\n\n\n\nInteractive Apps\n\n\nServer Side Apps\n\n\n\n\nNo Filesystem\n\n\nFilesystem\n\n\n\n\nFragmentation\n\n\nVersions\n\n\n\n\nES6 Modules\n\n\nCommonJS\n\n\n\n\nHow to get Node to evaluate our code\n\n\n\nREPL (Read, Eval, Print Loop)\n\n\n\n\n$ node\nWelcome to Node.js v16.9.1.\nType \".help\" for more information.\n>\n\n\n\n\n\nCLI executable\n\n\n \n\n$ node 00_app.js\nlarge number\nhey it is my first node app\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/query_strings.html",
    "title": "Query Strings",
    "body": "\n\nBack\n\n\nQuery Strings\n\n\n\n\nWe can use the query attribute from the request object in order to further filter our data. So whenever the user types localhost:5000/whateverendpoint?name=john, the request object passed as an argument of the callback defined for whateverendpoint will have the object {name: 'john'} stored in request.query.\n\n\n\napp.get('/whateverendpoint', (req, res) => {\n  console.log(req.query)\n})\n\n\n\n\nNow we code the way to filter by the keywords search and limit:\n\n\n\napp.get('/api/v1/query', (req, res) => {\n\t\n\t// De-structure keys\n  const { search, limit } = req.query\n  // Get a copy of the products\n  let sortedProducts = [...products]\n\n  // If search was specified\n  if (search) {\n\t  // Return only the products whose name start with \n    sortedProducts = sortedProducts.filter((product) => {\n      return product.name.startsWith(search)\n    })\n  }\n  // If limit was specified\n  if (limit) {\n    // Return as many products as the limit specified\n    sortedProducts = sortedProducts.slice(0, Number(limit))\n  }\n  // If no product matched the search\n  if (sortedProducts.length < 1) {\n    return res.status(200).json({ sucess: true, data: [] })\n  }\n\t\n  // Return the products filtered\n  res.status(200).json(sortedProducts)\n})\n\n\n\n\nSo now, if we go to localhost:5000/api/v1/query?search=a&limit=2 the server will return a JSON object that contains at most 2 products whose name start with an \"a\".\n\n\n\nObserve, that in order to avoid error for sending more than one response (note that we have two res.json() in our function), we must add the return keyword after sending each response, then the method exits.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/express.html",
    "title": "Express",
    "body": "\n\nBack\n\n\nExpress\n\n\n\n\nExpress is a minimal and flexible Node.js web app framework that allows us to develop and design web sites and APIs much faster. To install:\n\n\n\n$ npm install express --save\n\n\n\n\nThey suggest including the flag --save because in earlier versions of Express if it was not specified the package would not be saved as a dependency on package.json.\n\n\nInitializing Express App\n\n\nIn order to do so we import the express module, and the we create the instance, more or less like we did with our HTTP servers:\n\n\n\nconst express = require('express')\nconst app = express()\n\n\n\nApp Methods\n\n\nThe app instance we just created has several methods, we now list the most common:\n\n\n\n\napp.get: HTTP method to read data.\n\n\n\n\napp.get('/', (req, res) => {\n  res.status(200).send('Home Page')\n})\n\n\n\n\n\napp.post: HTTP method to insert data.\n\n\napp.put: HTTP method to update data.\n\n\napp.delete: HTTP method to delete data.\n\n\napp.all: Usually used to respond when we cannot locate a resource on the server.\n\n\n\n\napp.all('*', (req, res) => {\n  res.status(404).send('<h1>resource not found</h1>')\n})\n\n\n\n\n\napp.use: It is responsible for the middleware.\n\n\napp.listen: This method listens for any requests made to the server.\n\n\n\n\napp.listen(5000, () => {\n  console.log('server is listening on port 5000...')\n})\n\n\n\nSend HTML files\n\n\nTo send HTML files as a response instead of plain text we have to use the sendFile method:\n\n\n\nconst express = require('express')\nconst path = require('path')\n\nconst app = express()\n\napp.get('/', (req, res) => {\n  res.sendFile(path.resolve(__dirname, './index.html'))\n})\n\napp.listen(5000, () => {\n  console.log('server is listening on port 5000...')\n})\n\n\n\n\nNow, we have to import the external resources needed by the HTML file:\n\n\n\nconst express = require('express')\nconst path = require('path')\n\nconst app = express()\n\napp.use(express.static('./public'))\n\napp.get('/', (req, res) => {\n  res.sendFile(path.resolve(__dirname, './index.html'))\n})\n\napp.listen(5000, () => {\n  console.log('server is listening on port 5000...')\n})\n\n\n\n\nSo we invoke app.use as to tell the server that there are static resources stored in the public folder. \n\n\n\nHowever, because in this case index.html is also a static file we can remove the sendFile method if we store index.html inside the public folder:\n\n\n\nconst express = require('express')\nconst path = require('path')\n\nconst app = express()\n\napp.use(express.static('./public'))\n\napp.listen(5000, () => {\n  console.log('server is listening on port 5000...')\n})\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/json.html",
    "title": "JSON",
    "body": "\n\nBack\n\n\nJSON\n\n\n\n\nThe method res.json() allows us to return a array of objects as the body of the HTTP response:\n\n\n\nconst express = require('express')\nconst app = express()\n\napp.get('/', (req, res) => {\n  res.json([{name: 'john'}, {name: 'susan'}])\n})\n\napp.listen(5000, () => {\n  console.log('Server is listening on port 5000....')\n})\n\n\n\n\nWe can also pass a JSON file to res.json():\n\n\n\nconst express = require('express')\nconst app = express()\nconst { products } = require('./data')\n\napp.get('/', (req, res) => {\n  res.json(products)\n})\n\napp.listen(5000, () => {\n  console.log('Server is listening on port 5000....')\n})\n\n\n\n\nWhere data.js contains:\n\n\n\nconst products = [\n  {\n    id: 1,\n    name: 'albany sofa',\n    image:\n      'product-3.jpg',\n    price: 39.95,\n    desc: `I'm baby direct trade farm-to-table hell of`,\n  }]\n\nmodule.exports = products\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/http_methods.html",
    "title": "HTTP Methods",
    "body": "\n\nBack\n\n\nHTTP Methods\n\n\n\n\nIn this section we will show a few examples of the different HTTP methods in Express, take into account that we are not using a database.\n\n\nGET\n\n\napp.get('/api/people', (res, req) => {\n  res.status(200).json({ success: true, data: people })\n})\n\n\n\nPOST\n \n\nObserve that we use a middleware provided by Express that lets us parse incoming requests with urlencoded payload, and another middleware function to parse json.\n\n\n\napp.use(express.urlencoded({ extended: false }))\napp.use(express.json())\n\napp.post('/api/people', (res, req) => {\n  const { name } = req.body\n  if(!name){\n        return res\n          .status(400)\n          .json({ success: false, msg: 'Please provide a name'})   \n  }\n    \n  // Send array of people adding the new person (this is not permanent)\n  res.status(201).json({ \n                    success: true, \n                    data: [...data, { name, id: data.length + 1}] \n                    })\n})\n\n\n\nPUT\n\n\napp.put('/api/people/:id', (res, req) => {\n    // De-structure params\n    const { id } = req.params\n    const { name } = req.body\n    \n    const person = people.find((person) => person.id === Number(id))\n    \n    // The person does not exist\n    if(!person){\n        return res\n          .status(400)\n          .json({ success: false, msg: `no person with id: ${id}`})   \n    }\n    // Update the person data\n    const newPeople = people.map((person) => {\n        if(person.id === Number(id)){\n            person.name = name\n        }\n        return person\n    })\n    res.status(200).json({ success: true, data: newPeople })\n})\n\n\n\nDELETE\n\n\napp.delete('/api/people/:id', (res, req) => {\n    // De-structure params\n    const { id } = req.params\n    const { name } = req.body\n    \n    const person = people.find((person) => person.id === Number(id))\n    \n    // The person does not exist\n    if(!person){\n        return res\n          .status(400)\n          .json({ success: false, msg: `no person with id: ${id}`})   \n    }\n    // Filter the person data\n    const newPeople = people.filter((person) => person.id !== id)\n    res.status(200).json({ success: true, data: newPeople })\n})\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/index.html",
    "title": "Node.js",
    "body": "\n\nBack\n\n\nNode.js\n\n\n\nNode.js\n\n\n\nIntro \n\n\nGlobals\n\n\nModules\n\n\nNPM\n\n\nEvent Loop\n\n\nAsynchronus Patterns\n\n\nEvents\n\n\nStreams\n\n\nHTTP\n\n\n\nExpress\n\n\n\nHTTP Basics\n\n\nExpress\n\n\nAPI vs SSR\n\n\nJSON\n\n\nRoute Params\n\n\nQuery Strings\n\n\nMiddleware\n\n\nHTTP Methods\n\n\nRoutes\n\n\nView Engines\n\n\nMongoDB\n\n\nMock MongoDB\n\n\nEnvironment Variables\n\n\nJSON Web Tokens\n\n\n\n\n\n\nProjects\n\n\nBooks Directory\n\n\nBasic Users System\n\n\nReal-time Chat Application\n\n\nCollaborative Drawing App\n\n\nEmail Sender\n\n\nVideo Streaming Platform\n\n\nWeb Scraper \n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/api_ssr.html",
    "title": "API vs SSR",
    "body": "\n\nBack\n\n\nAPI vs SSR\n\n\n\n\n\nIn Express when we talk about APIs we are talking about HTTP interfaces to interact our data. \n\n\n\nThe main differences between APIs and Server Side Rendering (SSR) are:\n\n\n\n\n\n \n\n\nAPI\n\n\nSSR\n\n\n\n\nContent type\n\n\nJSON\n\n\nTemplate\n\n\n\n\nWhat is sent\n\n\nSend data\n\n\nSend template\n\n\n\n\nMethod\n\n\nres.json()\n\n\nres.render()\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/middleware.html",
    "title": "Middleware",
    "body": "\n\nBack\n\n\nMiddleware\n\n\n\n\nWhen we are talking about Middleware we are typically talking about any type of code and function between getting a certain request and sending the corresponding respond. \n\n\n\nExpress allows us to pass middleware as an argument to the app methods. Note that middleware runs from top to bottom in our server, so order does matter when specifying middleware.\n\n\n\nconst express = require('express')\nconst app = express()\n\nconst logger = (req, res, next) => {\n  const method = req.method\n  const url = req.url\n  const time = new Date().getFullYear()\n  console.log(method, url, time)\n  next()\n}\n\napp.get('/', logger, (req, res) => {\n  res.send('Home')\n})\n\napp.get('/about', logger, (req, res) => {\n  res.send('About')\n})\n\napp.listen(5000, () => {\n  console.log('Server is listening on port 5000....')\n})\n\n\n\n\nHere we have defined a logger function that tells us some information about the request made. This function is passed as an argument to the app.get() method, and then Express passes req, res and next as arguments for the middleware.\n\n\n\nThe next argument is a function that is needed in order to pass the flow to the next middleware and it always has to be invoked, unless the current middleware sends a response and so finishes the message. In any other case, if the next method is not invoked then the browser will be stuck loading because the program flow was halted by not calling the next middleware.\n\n\n\nThe middleware functions that we can use can be ones we code ourselves, express functions or third party software.\n\n\nApply Middleware with app.use\n\n\nIn order to apply a certain middleware to all the routes we first save the logger on a separate file named logger.js, then we import it into our main app, and we specify its usage as a middleware by app.use.\n\n\n\nconst express = require('express')\nconst logger = require('./logger')\nconst app = express()\n\napp.use(logger)\n\n\n\n\nWith this our logger will be executed every time the user accesses our server. We can also specify an argument like so:\n\n\n\nconst express = require('express')\nconst logger = require('./logger')\nconst app = express()\n\napp.use('/api/', logger)\n\n\n\n\nThis tells Express to only use the middleware for the /api route and all its subdomains (i.e. /api/*).\n\n\nApply Multiple Middleware\n\n\nWe now define a new middleware function, that goes by the name of authorize.js, we import it into our app.js and we add it as middleware by using an array.\n\n\n\nconst express = require('express')\nconst logger = require('./logger')\nconst authorize = require('./authorize')\nconst app = express()\n\napp.use([logger,authorize])\n\n\n\n\nNote that the order matters, meaning the first middleware executed is logger, in this instance, and then the control flow is passed to authorize.\n\n\n\nWe can also define more than one middleware function on one concrete end-point:\n\n\n\napp.get('/api', [logger, authorize], (req, res) => {\n  res.send('API Home Page')\n})\n\n\n\n\nAs we can see, we have specified two middleware functions, namely logger and authorize by using an array.\n\n\nExample\n\n\nconst authorize = (req, res, next) => {\n  // De-structure user object\n  const { user } = req.query\n  if(user == 'alice'){\n    req.user = { name: 'alice', id: 3 }\n    // Yield control flow\n    next()\n\t}\n  else{\n    res.status(401).send('Unauthorized')\n  }\n}\n\n\n\n\nAs you can see the authorize middleware function creates a new object within the request object, which can be accessed from the next middleware, or from the server.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/mongodb.html",
    "title": "MongoDB",
    "body": "\n\nBack\n\n\nMongoDB\n\n\n\nIntro\n\n\nIt is a NoSQL which is structured in collections, where each collection would be used to store a particular type of data in the form of documents:\n\n\n\n\n\nBlog Collection\n\n\n\n\nBlog document\n\n\n\n\nBlog document\n\n\n\n\nBlog document\n\n\n\n\n\nHere each document represent a single item of data, for example, each Blog document represents one blog. The data is contained inside the documents in a very similar fashion to JSON objects, so the documents consist of key-value pairs like so:\n\n\n{\n\"id\": ObjectId(12345),\n\"title\": \"Opening party\",\n\"snippet\": \"All about...\",\n\"body\": \"Lorem ipsum\"\n}\n\n\nSet Up\n\n\nWe can either install MongoDB locally or we can use a cloud database which is already hosted for us. For the latter we will use MongoDB Atlas. \n\n\n\nThere we create a cluster and inside this new cluster we create a new collection called Blog.\n\n\n\nThen we create a user accessing the Security -> Database Access section.\n\n\n\nOnce we have our user created, we specify a way to connect to the database, by heading to Clusters -> Connect your application. We then copy the Connection String that we will use as the database URI. Observe that this URI needs you to input your password.\n\n\nMongoose\n\n\nNow we need to actually connect to the database, we could use the MongoDB API package and use the MongoDB API, however we will use Mongoose that makes it easier to interact with the database.  \n\n\n\nMongoose is a ODM (Object Document Mapping) library, which means that it maps the standard MongoDB API providing a much easier way to connect to and interact with the database.\n\n\n\nIt does this by allowing us to create simple data models which have query methods to create, get, delete and update database documents. \n\n\n\nFor that we first have to create a Schema for the document which define the structure of a type of data or document. For example:\n\n\n\nBlog Schema:\n    - title(string), required\n    - snippet(string), required\n    - body(string), required\n\n\n\n\nNext, what we do is to create a Model based on that Schema, the Model is what actually allows us to communicate with a particular database collection. Each Model has static methods get, save, delete, etc, that allow us to manage the data.\n\n\nInstalling\n\n\n$ npm install mongoose\n\n\n\nConnect to MongoDB\n\n\nSo, now, we import the Mongoose package and we use our database URI to connect to it, remember to change password and cluster_name to the values you specified for your database.\n\n\n\nconst express = require('express');\nconst morgan = require('morgan');\nconst mongoose = require('mongoose');\n\n// express app\nconst app = express();\n\n// connect to mongodb & listen for requests\nconst dbURI = \"mongodb+srv://user:<password>@test.mongodb.net/<cluster_name>\n\nmongoose.connect(dbURI, { useNewUrlParser: true, useUnifiedTopology: true })\n  .then(result => app.listen(3000))\n  .catch(err => console.log(err));\n\n\n\n\nThe connect method is an asynchronous function, so it will execute a callback function when it finished connecting, or an error if the connection failed. In our case, we proceed to start our server when the database is ready.\n\n\nCreate Models & Schemas\n\n\nOnce we have successfully connected to our database, we will create our Blog Schema. For that, we first create a folder called models and inside it we create blog.js that will contain the following code:\n\n\n\nconst mongoose = require('mongoose');\nconst Schema = mongoose.Schema;\n\nconst blogSchema = new Schema({\n  title: {\n    type: String,\n    required: true,\n  },\n  snippet: {\n    type: String,\n    required: true,\n  },\n  body: {\n    type: String,\n    required: true\n  },\n}, { timestamps: true });\n\nconst Blog = mongoose.model('Blog', blogSchema);\nmodule.exports = Blog;\n\n\n\n\nAs you can see, we first import mongoose and the Schema object that we use to define the Blog Schema.\n\n\n\nIn order to create a new Blog Schema we create a new Schema object and we specify the different properties and restrictions. We also set and object of options, where we specify that we want MongoDB to save the timestamps of updates, creations, etc.\n\n\n\nNext we created a model that is based in the Schema we just created with the function model and we pass it the Model name (this name is then pluralized, as to then look up the collection that matches it) and the Schema instance.\n\n\nGetting/Saving Data\n\n\nIn order to work we data, we must import the Model we just created.\n\n\n\nconst express = require('express');\nconst morgan = require('morgan');\nconst mongoose = require('mongoose');\nconst Blog = require('./models/blog');\n\n// express app\nconst app = express();\n\n// connect to mongodb & listen for requests\nconst dbURI = \"mongodb+srv://user:<password>@test.mongodb.net/<cluster_name>\n\nmongoose.connect(dbURI, { useNewUrlParser: true, useUnifiedTopology: true })\n  .then(result => app.listen(3000))\n  .catch(err => console.log(err));\n\napp.get('/blogs', (req, res) => {\n  Blog.find()\n    .then(result => {\n      res.send(result);\n    })\n    .catch(err => {\n      console.log(err);\n    });\n});\n\napp.get('/blogs/:id', (req, res) => {\n  const id = req.params.id;\n  Blog.findById(id)\n    .then(result => {\n      res.send(result);\n    })\n    .catch(err => {\n      console.log(err);\n    });\n});\n\n\n\n\nHere we use the find and findById methods to interact with our database.\n\n\n\nIn order to create or delete new Blogs:\n\n\n\napp.post('/blogs', (req, res) => {\n  const blog = new Blog(req.body);\n\n  blog.save()\n    .then(result => {\n      res.redirect('/blogs');\n    })\n    .catch(err => {\n      console.log(err);\n    });\n});\n\napp.delete('/blogs/:id', (req, res) => {\n  const id = req.params.id;\n  \n  Blog.findByIdAndDelete(id)\n    .then(result => {\n      res.json({ redirect: '/blogs' });\n    })\n    .catch(err => {\n      console.log(err);\n    });\n});\n\n\n\n\nIn the POST method we create a new Blog object using the objects from the request body, and then we save it in our database. On the other hand, in order to delete a Blog we pass the id as a parameter, we search for it on the database and we delete it.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/env.html",
    "title": "Environment Variables",
    "body": "\n\nBack\n\n\nEnvironment Variables\n\n\n\nInstalling\n\n\nIn order to pass environment variables, like MongoDB credentials, to our app we can use a third party package called cross-env:\n\n\n\n$ npm install --save-dev cross-env\n\n\n\n\nAnd then we can pass environment variables as arguments to our node application like so:\n\n\n\nnpx cross-env NODE_ENV=development node app.js\n\n\n\n\nAnd the environment variables can be accessed from our app as follows:\n\n\n\nconsole.log(process.env.NODE_ENV)\n\n\n\n\nCommand\n\n\nTo make it easier we can modify our package.json scripts to pass these variables for us:\n\n\n\n{\n  \"name\": \"project\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"app.js\",\n  \"scripts\": {\n    \"dev\": \"npx cross-env NODE_ENV=development node app\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n\n\n\n\nAnd we start the application with:\n\n\n\n$ npm dev\n\n\n\nFile\n\n\nAnother way to do it is using a .env file:\n\n\n\nNODE_ENV=development\nPORT=3000\nHOST=localhost\n\n\n\n\nTo pass those variables to Node.js we use the eval command:\n\n\n\n$ eval $(cat .env) node app\n\n\n\n\nAnd we can also include it to package.json.\n\n\n\n{\n  \"name\": \"project\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"app.js\",\n  \"scripts\": {\n    \"dev\": \"eval $(cat .env) node app\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n\n\n\ndotenv\n\n\nIn case of not wanting to use commands that are exclusive to our operative system, we can use the package dotenv\n\n\n\n$ npm install --save-dev dotenv\n\n\n\n\nAnd in our app we do:\n\n\n\nrequire('dotenv').config()\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/streams.html",
    "title": "Streams",
    "body": "\n\nBack\n\n\nStreams\n\n\n\n\nStreams are used to read or write sequentially. There are different types:\n\n\n\n\nWriteable\n\n\nReadable\n\n\nDuplex: for both writing and reading.\n\n\nTransform: to modify data while writing or reading.\n\n\n\n\nThey are used in order to read files which are too big to store on variables, as it would pose an error.\n\n\n\nconst { createReadStream } = require('fs')\n\nconst stream = createReadStream('./content/big.txt')\n\nstream.on('data', (result) => {\n  console.log(result)\n})\n\n\n\n\nWhen logging result when listening on the data event we get the amount of data that is being read, as streams read data chunk by chunk, whose default value is 64kb. In order to modify this value we specify, on the options object, the property highWaterMark:\n\n\n\nconst { createReadStream } = require('fs')\n\nconst stream = createReadStream('./content/big.txt', { highWaterMark: 90000 })\n\nstream.on('data', (result) => {\n  console.log(result)\n})\n\nstream.on('error', (err) => console.log(err))\n\n\n\n\nSo, now we are reading 90kb chunks of data. In order to read the data, we specify the encoding of the file:\n\n\n\nconst { createReadStream } = require('fs')\n\nconst stream = createReadStream('./content/big.txt', { encoding: 'utf8' })\n\nstream.on('data', (result) => {\n  console.log(result)\n})\n\n\n\n\nIn order to listen for errors:\n\n\n\nconst { createReadStream } = require('fs')\n\nconst stream = createReadStream('./content/big.txt')\n\nstream.on('error', (err) => console.log(err))\n\n\n\nStreams on the Web\n\n\nWhen reading and writing files on servers, it is highly advisable to use chunks instead of the hole file, like so:\n\n\n\nvar http = require('http')\nvar fs = require('fs')\n\nhttp\n  .createServer(function (req, res) {\n    const text = fs.readFileSync('./content/big.txt', 'utf8')\n    res.end(text)\n  })\n  .listen(5000)\n\n\n\n\nInstead of this approach, we use streams, both for reading and for writing:\n\n\n\nvar http = require('http')\nvar fs = require('fs')\n\nhttp\n  .createServer(function (req, res) {\n    const fileStream = fs.createReadStream('./content/big.txt', 'utf8')\n    fileStream.on('open', () => {\n      fileStream.pipe(res)\n    })\n    fileStream.on('error', (err) => {\n      res.end(err)\n    })\n  })\n  .listen(5000)\n\n\n\n\nHere, we see that we use the on method to listen for the open event. And then, we use pipe to write on the stream.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/NodeJS/event_loop.html",
    "title": "Event Loop",
    "body": "\n\nBack\n\n\nEvent Loop\n\n\n\n\nIt is what allows Node.js to perform non-blocking I/O operations, despite the fact that JavaScript is single-threaded- by offloading operations to the system kernel whenever possible.\n\n\n\nThe Event Loop follows the next steps:\n\n\n\n\nAn asynchronous request is made by a user\n\n\nThe Event Loop registers the callback of the request\n\n\nWhen the request is completed and we are ready to execute the callback the Event Loop stores the callback at the end of the execution line, meaning, once the immediate tasks are done (i.e. synchronous code) the callback is executed\n\n\n\n\nFor example, we have the following code:\n\n\n\nconst { readFile, writeFile } = require('fs')\n\nconsole.log('started a first task')\nreadFile('./content/first.txt', 'utf8', (err, result) => {\n  if (err) {\n    console.log(err)\n    return\n  }\n  console.log(result)\n  console.log('completed first task')\n})\nconsole.log('starting next task')\n\n\n\n\nWhich outputs:\n\n\n\nstarted first task\nstarting next task\nHello this is first text file\nCompleted first task\n\n\n\n\nSo we can see that the synchronous code is run first, and then the callback of the asynchronous function readFile is called upon finishing reading the file. In the next example:\n\n\n\n// started operating system process\nconsole.log('first')\nsetTimeout(() => {\n  console.log('second')\n}, 0)\nconsole.log('third')\n// completed and exited operating system process\n\n\n\n\nWhich outputs:\n\n\n\nfirst\nthird\nsecond\n\n\n\n\nSo even though the timeout is initialized to 0, because it is an asynchronous function it is offloaded and so it is put to the end of the execution line, and then it is executed after the synchronous code. It is important to note that the listen function of the http module is also asynchronous.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/updating.html",
    "title": "Mutations",
    "body": "\n\nBack\n\n\nMutations\n\n\n\n\nIn order to update, delete or add new data using GraphQL we use Mutations.\n\n\nTypeDef\n\n\nWe create the type definition for the Mutation object (which is reserved in GraphQL to modify/add data, much like the Query object). In it, we define all the modifying functions we want, along with the data that must be provided to execute the modification, and also the type of object that is returned.\n\n\n\ntype Mutation {\n      addAnimal(\n        name: String!\n        description: [String!]!\n        parameter: String!\n        category: String!\n      ): Animal\n      removeAnimal(id: ID!): Boolean!\n  }\n\n\n\n\nWith this we have defined the addAnimal method, which creates and animal by specifying the name, description, URL parameter and the category. This function will return an Animal object. \n\n\n\nWe have also defined the removeAnimal method, that only takes an id as a parameter and returns a Boolean. \n\n\nResolvers\n\n\nWe now define the logic behind both of these methods, so we create a Mutation.js file as follows:\n\n\n\nconst { v4 } = require(\"uuid\")\n\nconst Mutation = {\n    addAnimal: (parent, { name, description, parameter, category }, { animals }) => {\n        let newAnimal = {\n            id: v4(),\n            name,\n            description,\n            parameter,\n            category,\n        }\n\n        // Only because this is an object: here we would create in the database\n        animals.push(newAnimal)\n        \n        return newAnimal\n    },\n\n    removeAnimal: (parent, { id }, { animals }) => {\n        // Here we would delete in the database\n        let index = animals.findIndex((animal) => {\n            return animal.id === id\n        });\n\n        animals.splice(index, 1);\n\n        return true\n    }\n}\n\nmodule.exports = Mutation\n\n\n\n\nNote that we de-structure the parameters from the args object for readability sake.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/qtr.html",
    "title": "Queries TypeDefs and Resolvers",
    "body": "\n\nBack\n\n\nQueries TypeDefs and Resolvers\n\n\n\n\n\nTypeDefs: define how the data should look.\n\n\nResolvers: resolve what the actual data is going to be. Here we could introduce some logic, like calling the database or applying validation.\n\n\nQuery: defines how we can query our data\n\ntype Query{\n  books: [Book]\n}\n\n\n\n\n\nSo the book resolver would return an array of books.\n\n\nData Specification\n\n\n\nArrays: to define an array on TypeDefs or Queries you use [].\n\n\n\n\ntype Book {\n  author: [String]\n}\n\n\n\n\n\nNon nullable field: to specify that an attribute cannot be null you use !.\n\n\n\n\ntype Book {\n  author: String!\n  author: [String]! // the array must not be null\n  author: [String!]! // the elements of the array and the array must not be null\n}\n\n\n\nQueries\n\n\n\nParameters: on the query object you add an argument between brackets (the ! specifies the argument must be provided).\n\n\n\n\ntype Animal {\n  id: ID!\n  name: String!\n  description: [String!]!\n}\n\ntype Query {\n  animals: [Animal!]!\n  animal(id: String!): Animal\n}\n\n\n\n\nOn the resolver we use the arg parameter to retrieve the parameter passed:\n\n\n\nconst resolvers = {\n  Query: {\n    animals: () => animals,\n    animal: (parent, args, ctx) => {\n      let animal = animals.find((animal) => {\n        retunr animal.id === args.id\n      })\n      return animal\n    }\n  }\n}\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/client.html",
    "title": "Client",
    "body": "\n\nBack\n\n\nClient\n\n\n\n\nAs well as with the server there are several clients for GraphQL within different languages and frameworks, visit the official page to check them out. \n\n\n\nWe are going to use Apollo Client so for that we need to install apollo and graphql on the client side of our application:\n\n\n\n$ npm install @apollo/client graphql\n\n\n\n\nIn our case we are going to connect our client to React (Reference). So, first we import the necessary modules.\n\n\n\nimport React from 'react';\nimport { render } from 'react-dom';\nimport {\n  ApolloClient,\n  InMemoryCache,\n  ApolloProvider,\n  useQuery,\n  gql\n} from \"@apollo/client\";\n\nconst client = new ApolloClient({\n  uri: 'http://localhost:4000',\n  cache: new InMemoryCache()\n});\n\nfunction App() {\n  return (\n    <div>\n      <h2>My first Apollo app 🚀</h2>\n    </div>\n  );\n}\n\nrender(\n  <ApolloProvider client={client}>    <App />  </ApolloProvider>,  document.getElementById('root'),\n);\n\n\n\n\nWe tell apollo that our GraphQL server is listening for request on our localhost on the port 4000.\n\n\n\nWhere apollo allows us to cache our queries, with the InMemoryCache module. That way we do not need to make the same request twice, because the data is cached in memory.\n\n\n\nAnd then, we wrap our app with the ApolloProvider, so all of our components have access to our client. Note that we pass our client as a prop.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/intro.html",
    "title": "Intro",
    "body": "\n\nBack\n\n\nIntro\n\n\n\n\nGraphQL is a query language used to communicate to our API and query for data.\n\n\nDifference with APIs\n\n\nWhenever we use REST APIs and we hit specific endpoints, more often than not, we are going to retrieve some data that we have no use for. This is what is called overfetching.\n\n\n\nFor example when you access https://my-rest-api/animals you get an object with a list of animal objects, and you may not need all of the information of every animal.\n\n\n\nGraphQL solves this problem by:\n\n\n\n\nOnly having one endpoint.\n\n\nFrom this endpoint we use the graph query language to select whatever data that we want.\n\n\n\n\nFor example, to retrieve the same information stated above:\n\n\n\nquery{\n  animals{\n    title\n    ratings\n    img\n    price\n  }\n}\n\n\n\n\nWhich gets only the specified attributes for each animal.\n\n\n\nGraphQL also solves underfetching, which is the situation where you cannot get enough data with a call to only one endpoint, forcing you to call a second endpoint. \n\n\n\nFor example, if you want information about the animals and the categories you have to access https://my-rest-api/animals, and https://my-rest-api/categories, however with GraphQL:\n\n\n\nquery{\n  animals{\n    title\n    ratings\n    img\n    price\n  }\n  categories{\n    id\n    title\n    img\n  }\n}\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/relationships.html",
    "title": "Relationships",
    "body": "\n\nBack\n\n\nRelationships\n\n\n\nOne To Many\n\n\nWe are now going to illustrate the situation where an animal belongs to only one category whilst a category contains several animals:\n\n\n\ntype Animal {\n  id: ID!\n  category: Category!\n  name: String!\n  parameter: String!\n}\n\ntype Category {\n  id: ID!\n  name: String!\n  animals: [Animal!]!\n  parameter: String!\n}\n\n\n\n\nWhere we have stored in our database the id of the category as a foreign key of the Animal entity.\n\n\n\nIn order to query for animals from a category we create a new resolver: \n\n\n\nconst resolvers = {\n  Query: {\n    animals: () => animals,\n    animal: (parent, args, ctx) => {\n      let animal = animals.find((animal) => {\n        return animal.paramenter === args.id\n      })\n      return animal\n    }\n  }\n  Category: {\n    animals: (parent, args, ctx) => {\n      return animals.filter((animal) >= {\n        return animal.category == parent.id\n      }) \n    }\n  }\n}\n\n\n\n\n\nSo if we query for:\n\n\n\n\n{\n  category(parameter: \"mammal\"){\n    category \n    animals {\n      name\n    }\n  }\n}\n\n\n\n\nWe get all the names of the animals that are mammals.\n\n\n\nThe parent object symbolizes the object resulting from category(parameter: \"mammal\"), this object will be a Category object and will have an id, that we will use in our resolver to filter the animals.\n\n\n\nObserve that the animals have a attribute called category, which is *not* the same as the type definition we have made for our Animal object, this attribute is defined on the database.\n\n\n\nNote that we have created a Category resolver that acts as the query resolver but for queries within the category object.\n\n\n\nWe, now, do the same for the animals, meaning we want to get the Category object that we specified in the Animal object, for that we create a new resolver:\n\n\n\n\nAnimal: {\n  category: (parent, args, ctx) => {\n    return categories.find((category) => {\n      return category.id === parent.category\n    })\n  }\n}\n\n\n\n\nSo what we do is go through all of the categories until we find the one that has the same id.\n\n\n\n{\n  animal(parameter: \"cat\"){\n    name \n    category {\n      name\n    }\n}\n\n\n\n\nAnd with this query we retrieve the name and the category name of a cat.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/fetch.html",
    "title": "Fetch Data",
    "body": "\n\nBack\n\n\nFetch Data\n\n\n\n\nYou can start requesting data with useQuery. useQuery is a React hook that shares GraphQL data with your UI. So for example to fetch the image and the title of the cards:\n\n\n\nimport { useQuery, gql } from '@apollo/client'\n\nconst FETCH_DATA = gql`\n  {\n    mainCards {\n      image\n      title\n    }\n  }\n`\n\nfunction MainHero(){\n\n  const mainData = useQuery(FETCH_DATA)\n\n  return(<div></div>)\n\n}\n\n\n\n\nWhere mainCards is one of our resolvers, and we specify that we want to select the image and the title.\n\n\n\nSo now, we can de-structure the different attributes offered by the ApolloProvider, namely loading, error and data. And therefore control the flow of our application by using them.\n\n\n\nimport { useQuery, gql } from '@apollo/client'\n\nconst FETCH_DATA = gql`\n  {\n    mainCards {\n      image\n      title\n    }\n  }\n`\n\nfunction MainHero(){\n\n  const { loading, error, data } = useQuery(FETCH_DATA)\n\n  return(<div></div>)\n\n}\n\n\n\nVariables\n\n\nIn order to make a query by passing parameters we do:\n\n\n\nconst ANIMAL_QUERY = gql`\n  query($slug: String!){\n    animal(slug: $slug){\n      title\n      image\n      stock\n      description\n      price\n    }\n  }\n`\n\n\n\n\nWhere $string is the variable we want to pass in, and we specify its type and the fact that it is required with String!.\n\n\n\nNow to make the query we do:\n\n\n\nfunction AnimalPage() {\n  \n  const { slug } = useParameters()\n  \n  const { loading, data, error } = useQuery(\n    variables: {\n      slug: 'cat'\n    }\n  )\n}\n\n\n\n\nWith variables we pass in all of the parameters needed in the query.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/terminology.html",
    "title": "Terminology",
    "body": "\n\nBack\n\n\nTerminology\n\n\n\nSchema\n\n\nIt defines the data associated with an Entity:\n\n\n\ntype Person {\n  id: ID!\n  name: String!\n  email: String!\n  age: Int!\n  phone: String\n  gender: Boolean!\n}\n\n\n\n\nThat is to say, it defines the type definitions of the data that conforms a given Entity.\n\n\nResolver\n\n\nThe data that we get back is dependent on the resolvers. They are functions that return data that follow a certain schema, it does not need to follow the schema, but then when querying it, it may throw and error.\n\n\n\npeople(parent, args, ctx, info){\n  return[\n    {\n      id: \"1\",\n      name: \"Laith\",\n      email: \"email@email.com\",\n      age: 23,\n      phone: \"623198135\",\n      gender: true\n    }\n  ]\n}\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/index.html",
    "title": "GraphQL",
    "body": "\n\nBack\n\n\nGraphQL\n\n\n\nBackend\n\n\n\nIntro\n\n\nTerminoligy\n\n\nGraphQL Server\n\n\nQueries, TypeDefs and Resolvers\n\n\nRelationships \n\n\nFile Structure\n\n\nMutations\n\n\n\nFrontend\n\n\n\nGraphQL Client\n\n\nFetch Data\n\n\nMutations\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/mutations_client.html",
    "title": "Mutations",
    "body": "\n\nBack\n\n\nMutations\n\n\n\n\nIn order to execute a mutation from the client side we create a mutation request:\n\n\n\nconst ADD_ANIMAL_MUTATION = gql`\n  mutation(\n      $name: String!,\n      $description: [String!]\n      $parameter: String!,\n      $category: String!\n    ) {\n    addAnimal(\n      name: $name,\n      description: $description,\n      parameter: $parameter,\n      category: $category\n    )\n  }\n`\n\n\n\n\nAnd now we use the useMutation hook to obtain the function that will be called in order to update our animal:\n\n\n\nimport { useMutation, gql } from '@apollo/client'\n\nfunction Animal(){\n\n  const [addAnimal] = useMutation(ADD_ANIMAL_MUTATION)\n\n  return(\n    <div>\n      <button onClick={() => \n        addAnimal({\n          variables: {\n            name: 'cat',\n            description: ['This is a description'],\n            parameter: 'cat',\n            category: 'mammal'\n          } \n        }\n      )}/> \n    </div>\n  )\n}\n\n\n\n\nWith this we get the function addAnimal with the useMutation hook and we use it in our button, so when it is clicked we add a cat to our animal collection.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/file_structure.html",
    "title": "File Structure",
    "body": "\n\nBack\n\n\nFile Structure\n\n\nWhat is best practice is to separate the type definitions and the resolvers:\n\n\n\n\nTypeDefs: stored in schema.js for example.\n\n\nResolvers: stored in a folder called resolvers, and then for each Resolver we create a file, for example for the Query resolver:\n\n\n\n\nconst Category = {\n    animals: (parent, args, { animals }) => {\n        return animals.filter(animal => {\n            return animal.category === parent.id\n        })\n    }\n}\n\nmodule.exports = Category\n\n\n\n\nThen we create an index.js inside the resolvers folder where we can import and export all of our Resolvers together:\n\n\n\n\nconst Query = require('./query')\nconst Category = require('./category')\nconst Animal = require('./animal')\n\nmodule.exports = {\n  Query,\n  Category,\n  Animal\n}\n\n\n\n\nAnd we put everything together in our index.js inside the root folder:\n\n\n\n\nconst { ApolloServer } = require('apollo-server');\nconst { mainCards, animals, categories } = require('./db')\nconst typeDefs = require('./schema')\nconst { Query, Category, Animal } = require('./resolvers/index')\n\n  const server = new ApolloServer({ \n    typeDefs, \n    resolvers: {\n      Query,\n      Animal,\n      Category\n    },\n    context: {\n      mainCards,\n      animals,\n      categories\n    }\n  });\n\n  // The `listen` method launches a web server.\n  server.listen().then(({ url }) => {\n    console.log(`🚀  Server ready at ${url}`);\n  });\n\n\n\n\nWe now use the context object in order to make our \"database\" available to all of the resolvers through ctx. (Note that we de-structure the object to the get animal object).\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/GraphQL/server.html",
    "title": "GraphQL Server",
    "body": "\n\nBack\n\n\nGraphQL Server\n\n\n\n\nGraphQL supports several languages, and has several servers that do mainly the same. Consult the official page for the one that suits your needs.\n\n\n\nWe are going to use apollo-server to demonstrate how to use GraphQL in a node.js application:\n\n\n\nSo, first, we install the apollo-server along with graphql dependency with npm:\n\n\n\n$ npm install apollo-server graphql\n\n\n\n\nNow we use graphql to define our type definitions:\n\n\n\nconst { ApolloServer, gql } = require('apollo-server');\n\nconst typeDefs = gql`\n\n  type Book {\n    title: String\n    author: String\n  }\n  \n  type Query {\n    books: [Book]\n  }\n  \n\n\n\nAnd we also create our resolvers:\n\n\n\nconst resolvers = {\n  Query: {\n    books: () => books,\n  }\n}\n\n\n\n\nWhere books is an already defined array of books.\n\n\n\nFinally we create the actual server:\n\n\n\nconst server = new ApolloServer({typeDefs, resolvers});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀  Server ready at ${url}`);\n});\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Django/django_notes.html",
    "title": "<code>Django</code> Notes",
    "body": "\n\nBack\n\n\nDjango Notes\n\n\nIn this section we lay out some concepts about the Django Framework.\n\n\nApps\n\nModels\n\n\nThe models can be thought of as objects, in the sense of OOP, that have certain attributes. This objects are then mapped by Django to the database of choice.\nTo define new models, or modify existing model (e.g. the user model) you need to modify the models.py file in the root folder of every app that is created. Alternatively, you can centralize all of your models on the core app.\n\n\n\nAn example of a simple model is the following Tag model:\n\n\n\nclass Tag(models.Model):\n    \"\"\"Tag to be used for a book\"\"\"\n    # Define the attributes of the table\n    name = models.CharField(max_length=255)\n    # Define the relation between the tag and the user\n    user = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n    )\n\n    # Define the string representation of the Tag\n    def __str__(self):\n        return self.name\n\n\n\n\nOnce the model is define, it needs to be registered on the admin.py file:\n\n\n\nadmin.site.register(models.Tag)\n\n\n\n\nSpecifically when modifying existing models, you will need to extend the classes defined by Django (e.g. AbstractBaseUser, UserAdmin). For example:\n\n\n\nclass User(AbstractBaseUser, PermissionsMixin):\n    \"\"\"Custom user model that suppors using email instead of username\"\"\"\n    email = models.EmailField(max_length=255, unique=True)\n    name = models.CharField(max_length=255)\n    is_active = models.BooleanField(default=True)\n    is_staff = models.BooleanField(default=False)\n\n    objects = UserManager()\n\n\n\n\nWhich has to be registered as follows:\n\n\n\nadmin.site.register(models.User, UserAdmin)\n\n\n\n\nWhere UserAdmin is a class define in the admin.py file, that defines the custom User model:\n\n\n\nclass UserAdmin(BaseUserAdmin):\n    ordering = ['id']\n    list_display = ['email', 'name']\n    # User edit page fields\n    fieldsets = (\n        (None, {'fields': ('email', 'password')}),\n        (_('Personal Info'), {'fields': ('name',)}),\n        (\n            _('Permissions'),\n            {'fields': ('is_active', 'is_staff', 'is_superuser')}\n        ),\n        (_('Important Dates'), {'fields': ('last_login',)})\n    )\n    # User create page fields\n    add_fieldsets = (\n        (None, {\n            'classes': ('wide',),\n            'fields': ('email', 'password', 'password2')\n        }),\n\n\n\nAdmin\n\n\nThis is the feature that allows you to manage your models, let it be create them, modify them or delete them.\nThe functionality of the admin model is defined within the admin.py file on the root folder of every app that is created.\n\n\n\nIn order to create a superuser execute the following command:\n\n\n\n$ python manage.py createsuperuser\n\n\n\n\nOn Docker:\n\n\n\n$ docker-compose run app sh -c \"python manage.py createsuperuser\"\n\n\n\n\nThen, you will be prompted to enter an email and a password. Once you have filled said fields, you can start the server with\n\n\n\n$ docker-compose up\n\n\n\n\nAnd enter to the admin page located on 127.0.0.1:8000/admin, where you can log in with your credentials.\n\n\n\nURLs\n\n\nDjango allows us to define relative URLs on a very modular way. First off, we have the core file when it comes to URL definition: app/app/urls.py. Here we may have something like this:\n\n\n\nfrom django.contrib import admin\nfrom django.urls import path, include\n\nurlpatterns = [\n    path('admin/', admin.site.urls),\n    path('api/user/', include('user.urls')),\n]\n\n\n\n\nThis example shows that the urlpatterns variable is a list that holds all of the urls defined in our project. The modularization comes from the way the URLs defined on the user’s app are specified. First we specify the endpoint for these URLs (namely api/user/), and then we pull all the relative URLs from the user’s app, defined on the file app/user/urls.py. Which are then concatenated with api/user/.\n\n\n\nThe URLs defined on the user app are as follows:\n\n\n\napp_name = 'user'\n\nurlpatterns = [\n    path('create/', views.CreateUserView.as_view(), name='create'),\n]\n\n\n\n\nThis the can be used like this:\n\n\n\n# Create user api endpoint dinamically\nCREATE_USER_URL = reverse('user:create')\n\n\n\nSerializers\n\n\nThis files are defined to specify how to serialize (map to the database) the JSON objects received, in our case, from HTTP requests. For that we create, for each model, a class that extends serializers.ModelSerializer. In this class we define an inner class called Meta that tells the framework which fields does the object have and so allows the mapping to take place. You can also add extra arguments to this inner class, for example to restrict or exercise a stronger control on the fields.\n\n\n\nNext on, we have a simple example of our User Model serializer:\n\n\n\nfrom django.contrib.auth import get_user_model\n\nfrom rest_framework import serializers\n\n\nclass UserSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for the users object\"\"\"\n\n    class Meta:\n        \"\"\"Info about how to serialize the user model\"\"\"\n        model = get_user_model()\n        fields = ('email', 'password', 'name')\n        # Extra requirements for the user model\n        extra_kwargs = {'password': {'write_only': True, 'min_length': 5}}\n\n    def create(self, validated_data):\n        \"\"\"Create a new user with encrypted password and return it\"\"\"\n        # validation_data: JSON data passed in the HTTP POST\n        return get_user_model().objects.create_user(**validated_data)\n\n\n\n\nWe can also serialize an object that is not related to a model per se, for example:\n\n\n\nclass AuthTokenSerializer(serializers.Serializer):\n    \"\"\"Serializer for the user authentication object\"\"\"\n    email = serializers.CharField()\n    password = serializers.CharField(\n        style={'input_type': 'password'},\n        trim_whitespace=False\n    )\n\n\n\nViews\n\n\nThis is, on simple terms, a Python function that takes a Web request and returns a Web response. In our case, we will mostly use views for our API, so we use pre-make view that allows us to easily make an API that creates, updates, etc an object on the database using the serializer that we specify, for example, the API for creating a user is as follows:\n\n\n\nclass CreateUserView(generics.CreateAPIView):\n    \"\"\"Create a new user in the system\"\"\"\n    serializer_class = UserSerializer\n\n\n\n\nIn case of wanting to update an object we extend generics.RetrieveUpdateAPIView instead of generics.CreateAPIView. Because this view is private, we need to indicate an authentication mechanism and the level of permissions the user has, in our case the authentication is made via token and the permissions are that the user needs to be logged in.\n\n\n\nclass ManageUserView(generics.RetrieveUpdateAPIView):\n    \"\"\"Manage the authenticated user\"\"\"\n    serializer_class = UserSerializer\n    # Authentication mechanism by which the authentication happens\n    authentication_classes = (authentication.TokenAuthentication,)\n    permission_classes = (permissions.IsAuthenticated,)\n\n    def get_object(self):\n        \"\"\"Retrieve and return authentication user\"\"\"\n        return self.request.user\n\n\n\nActions\n\n\n\nStart the server\n\n\n\n\nObserve that this is executed on the docker-compose configuration file\n\n\n\n$ python manage.py runserver 0.0.0.0:8000\n\n\n\n\n\nSync Django settings (app/app/settings.py)\n\n\n\n\n$ python manage.py migrate\n\n\n\n\nOn docker:\n\n\n\n$ docker-compose run app sh -c \"python manage.py migrate\"\n\n\n\n\n\nSync changes made on models\n\n\n\n\n$ docker-compose run app sh -c \"python manage.py migrate\"\n\n\n\n\nOn docker: \n\n\n\n\n$ docker-compose run app sh -c \"python manage.py makemigrations\"\n\n\n\n\nYou can also specify the name off the app that contains the model\n\n\n\n$ python manage.py makemigrations app_name\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Django/index.html",
    "title": "<code>Django</code>",
    "body": "\n\n\nBack\n\n\nDjango\n\n\n\n\n\nDjango Notes\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/orchestration.html",
    "title": "Container Orchestration",
    "body": "\n\nBack\n\n\nContainer Orchestration\n\n\n\n\nWhen in production, it is often needed that several instances of containers are run (because of a heavy load on the application for example). So in these cases you need to monitor the instances as well as the host itself in case any of them crash.\n\n\n\nFor that we use container orchestration that offers a set of tools and scripts that allow us to manage the hosts and containers. \n\n\n\nThe typical approach is to create several instances of containers in different hosts, so if one fails the application can still offer the service. For example:\n\n\n\n$ docker service create --replicas=100 nodejs\n\n\n\n\nSome solutions let us automatically scale the number of containers depending on the demand. Others can help in automatically adding new hosts to support the user load.\n\n\n\nThey also provide complex networking between the containers as well as load balancing user requests across different hosts or sharing storage between the hosts, configuration management or security.\n\n  \n\nThere are several solutions:\n\n\n\n\nDocker Swarm from Docker\n\n\nKubernetes from Google\n\n\nMESOS from Apache.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/setup.html",
    "title": "Set Up",
    "body": "\n\nBack\n\n\nSet Up\n\n\n\n\nIn this first step, we will present how to install the necessary tools to use Docker and Docker Compose in Arch Linux.\n\n\nInstall Docker\n\n\nIn the current section we will lay out the steps to carry out in order to get docker up and running on an Arch Linux machine.\n\n\nDocker Engine\n\n\nBefore installing anything we will update the system as follows\n\n\n\n$ sudo pacman -Syu\n\n\n\n\nWhen it is done updating we will proceed rebooting the system, and then we enable the loop module:\n\n\n\n$ sudo tee /etc/modules-load.d/loop.conf <<< \"loop\"\n$ sudo modprobe loop\n\n\n\nInstall using static binaries\n\n\nFor reference go to the official documentation on Docker's website.\n\n\n\n\nFirstly we will download the static binary archive on https://download.docker.com/linux/static/stable/.\n\n\nOnce the file is downloaded extract it executing the following command, and substituting our docker-20.10.8 for your package's version.\n\n\n\n\n$ tar xzvf docker-20.10.8.tgz\n\n\n\n\n\nCopy the binaries to your executable path (/usr/bin or /bin). This is optional.\n\n\n\n\n$ sudo cp docker/* /usr/bin/\n\n\n\n\n\nStart docker's daemon:\n\n\n\n\n$ sudo dockerd \n\n\n\n\n\nFinally run to check that the installation was correct (it will download an example image that outputs a message informing the user that the installation was successful, among other things).\n\n\n\n\n$ sudo docker run hello-world\n\n\n\nOfficial Repo\n\n\nThis other approach will allows to have a docker service so we do not have to always run sudo dockerd & to start docker's daemon.\n\n\n\n\nWe install Docker using pacman:\n\n\n\n\n\n$ sudo pacman -S docker\n\n\n\n\n\nAfterwards, we enable the docker service executing:\n\n\n\n\n$ sudo systemctl start docker.service\n$ sudo systemctl enable docker.service\n\n\n\n\n\nFinally run to check that the installation was correct (it will download an example image that outputs a message informing the user that the installation was successful, among other things).\n\n\n\n\n$ sudo docker run hello-world\n\n\n\nConfigure Docker\n\nRunning as normal user\n\n\nIn order to use Docker as a normal user we need to add said user to the docker group.\n\n\n\n\nAdd the Docker group\n\n\n\n\n$ sudo groupadd docker\n\n\n\n\n\nAdd your user to the Docker group\n\n\n\n\n$ sudo usermod -aG docker $USER\n\n\n\n\n\nLog out, log in and verify that it runs properly\n\n\n\n\n$ docker run hello-world\n\n\n\nInstall Docker Compose\n\n\n\nDownload the current stable release of Docker Compose. Mind you, this command downloads the 1.29.2 version, check the official page for new releases.\n\n\n\n\n$ sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n\n\n\n\n\nMake the binary executable\n\n\n\n\n$ sudo chmod +x /usr/local/bin/docker-compose\n\n\n\n\n\nTest the installation\n\n\n\n\n$ docker-compose --version\ndocker-compose version 1.29.2, build 5becea4c\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/kubernetes.html",
    "title": "Kubernetes",
    "body": "\n\nBack\n\n\nKubernetes\n\n\nSome of its functionalities are:\n\n\n\n\nRunning several instances of a service.\n\n\nScaling up or down the number of instances.\n\n\nRolling updates.\n\n\nRolling back from updates.\n\n\nSupports many different network and storage renderers.\n\n\nProvides autoscaling.\n\n\nHelps you test new features of your application by only upgrading a percentage of the instances, which allows for doing AB testing.\n\n\n\n\nArchitecture\n\n\nA kubernetes cluster consists of several nodes, the worker nodes are where containers will be launched, so even if one node fails the application is still available.\n\n\n\nKubernetes clusters are managed by the master, which is a node that watches over worker nodes and is responsible of the orchestration of containers in the worker nodes.\n\n\nComponents\n\n\nWhen you install Kubernetes in your system you are actually installing:\n\n\n\n\nAPI Server: acts as the front-end for Kubernetes, so all of the programs talk to this server to interact with the kubernetes server.\n\n\netcd: it is the distributed reliable key value store to store all data to manage the cluster.\n\n\nScheduler: responsible for distributing work.\n\n\nController: responsible for noticing/responding to nodes/containers going down.\n\n\nContainer Runtime: underline software used to run containers (e.g. Docker).\n\n\nkubelet: is the agent that runs in each node in the cluster, and is responsible of making sure the containers are running on the nodes as expected.\n\n\n\n\nOne of the command line utilities used by Kubernetes is kubectl, that is the Kubernetes CLI and is used to deploy and manage applications on a kubernetes cluster.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/engine.html",
    "title": "Docker Engine",
    "body": "\n\nBack\n\n\nDocker Engine\n\n\n\n\nWhen you install Docker on your Linux system you are installing:\n\n\n\n\nDocker daemon: this is the background process that manages docker objects (i.e. images, containers, volumes and networks).\n\n\nREST API: it is the interface programs can access to provide instructions to the daemon.\n\n\nDocker CLI: command line interface to manage our docker objects. This uses the REST API to interact with the docker daemon.\n\n\n\n\nNote that the Docker CLI can be run from a remote machine, that is to say the REST API and the Docker daemon are running on a different machine. So, in order to interact with the API we use the -H flag, indicating the IP where the API and the daemon reside with the 2375 port.\n\n\n\n$ docker -H=10.123.2.1:2375 <docker-command>\n$ docker -H=10.123.2.1:2375 run nginx\n\n\n\nContainerization\n\n\nAs we have seen all of our containers run on top of the same operative system, so it is a given that the processes will be handled by the same kernel. This means that the processes of our containers are run along with the rest of processes in the host machine, in other words the PIDs of all the processes must be different. \n\n\n\nWhat Docker does to isolate these processes is the container is using namespaces and maps the process id to another process id within the container, and that is visible only on this container.\n\n\ncgroups\n\n\nBecause all docker containers share the hosts resources it could be possible that a container takes up all of the machine's resources. So, to restrict the amount of resources used by a container Docker uses cgroups. You can specify the amount of CPU or RAM that the container is allowed to have:\n\n\n\n$ docker run --cpus=.5 ubuntu\n$ docker run --memory=100m ubuntu\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/intro.html",
    "title": "Intro",
    "body": "\n\nBack\n\n\nIntro\n\n\n\nWhat are containers\n\n\nThey are completely isolated environments, they have their own processes, network interfaces, etc. However they share the same os kernel.\n\n\n\nDocker uses LXC containers, which are very low lever, so Docker provides a high level tool that allows us to manage our containers easily.\n\n\nSharing the Kernel\n\n\nAs we have said, Docker uses the system's kernel, so it is capable of running any distributions whose underlying kernel is Linux (e.g. Docker running on Ubuntu can run a container based on Debian, Fedora, etc.)\n\n\nContainers vs Virtual Machines\n\n\n\nContainers:\n\n\n\n\n\n\nApplication 1\n\n\nApplication 2\n\n\n\n\nLibs/Dependencies 1\n\n\nLibs/Dependencies 2\n\n\n\n\nContainer 1\n\n\nContainer 2\n\n\n\n\nDocker\n\n\n \n\n\n\n\nOS\n\n\n \n\n\n\n\nHardware\n\n\n \n\n\n\n\n\n\nVirtual Machines:\n\n\n\n\n\n\nApplication 1\n\n\nApplication 2\n\n\n\n\nLibs/Dependencies 1\n\n\nLibs/Dependencies 2\n\n\n\n\nOS 1\n\n\nOS 2\n\n\n\n\nVirtual Machine 1\n\n\nVirtual Machine 2\n\n\n\n\nHypervisor\n\n\n \n\n\n\n\nHardware\n\n\n \n\n\n\n\n\nThe main differences are the use of Hypervisors in Virtual Machines and how on these, each instance has its own OS. Which results in needing more hardware resources. Also Virtual Machines have total isolation, as they use their own OS, which does not happen with containers, because these do share the same kernel.\n\n\n\nHowever the key is combining both technologies, so each virtual machine runs several applications hosted in different containers.\n\n\nContainer vs Image\n\n\nAn image can be thought as a package or a template that is used to create one or more containers. That is to say, containers are running instances of images that are isolated and have their own environment.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/registry.html",
    "title": "Docker Registry",
    "body": "\n\nBack\n\n\nDocker Registry\n\n\n\nPublic Registry\n\n\nIn the following example you are pulling the nginx image, which in reality is stored as nginx/nginx where the first nginx corresponds to the user name, and the second to the image name.\n\n\n\nimage: nginx\n\n\n\n\nThis is a public image so it is stored in a public registry, usually in docker.io which is the default registry. So a more verbose configuration file would be:\n\n\n\n\nimage: docker.io/nginx/nginx\n\n\n\nPrivate Registry\n\n\nWhen you have applications that should no be made available to the public private registries are used.\n\n\n\nTo pull or use an image from a private registry:\n\n\n\n\nRegister into the private registry:\n\n\n\n\n$ docker login private-registry.io\n\n\n\n\n\nRun the image indicating the registry:\n\n\n\n\n$ docker run private-registry.io/apps/internal-app\n\n\n\nDeploy Private Registry\n\n\nA private registry is in itself a docker image, so first you have to have your registry image running:\n\n\n\n\n$ docker run -p 5000:5000 --name registry registry:2\n\n\n\n\nSo now you have your registry running on port 5000. The next step is to assign a tag to your image as follows:\n\n\n\n$ docker image tag my-image localhost:5000/my-image\n\n\n\n\nWhere my-image is the name of the image and localhost:5000/my-image is the tag assigned.\n\n\n\nFinally you push your image to your registry\n\n\n\n$ docker push localhost:5000/my-image\n\n\n\n\nNow you can pull your image:\n\n\n\n$ docker pull localhost:5000/my-image\n$ docker pull 192.168.56.100:5000/my-image\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/cmd_vs_entrypoint.html",
    "title": "<code>CMD</code> vs <code>ENTRYPOINT</code>",
    "body": "\n\nBack\n\n\nCMD vs ENTRYPOINT\n\nCMD\n\n\nA command allows us to append to the command executed when the container start of the base image. For example, Ubuntu's CMD is bash, so if we append sleep 5 our container will sleep for 5 seconds when started and then exit.\n\n\n\nFROM Ubuntu\n\nCMD sleep 5\n\n\n\n\nThe command can also be specified as CMD [\"sleep\", \"5\"].\n\n\nENTRYPOINT\n\n\nThis other instruction also adds to the base image starting command, but this lets us add arguments from the command line, for example, if we define the following Dockerfile:\n\n\n\nFROM Ubuntu\n\nENTRYPOINT [\"sleep\"]\n\n\n\n\nWe build the image\n\n\n\n$ docker build Dockerfile -t ubuntu-sleeper\n\n\n\n\nAnd then we running with 10 as and argument:\n\n\n\n$ docker run ubuntu-sleeper 10\n\n\n\n\nOur container will sleep for 10 seconds and then exit.\n\n\n\nTo define a default value for sleep, when no argument is passed from the command line, we use both ENTRYPOINT and CMD\n\n\n\nFROM Ubuntu\n\nENTRYPOINT [\"sleep\"]\n\nCMD [\"5\"]\n\n\n\n\nTo override the ENTRYPOINT command specified in the Dockerfile we use the flag --entrypoint:\n\n\n\n$ docker run --entrypoint sleep2.0 ubuntu-sleeper 10\n\n\n\nDifference\n\n\nWhen using CMD when running:\n\n\n\n$ docker run ubuntu-sleeper sleep 10\n\n\n\n\nThe argument sleep 10 replaces entirely the starting command. However with ENTRYPOINT if we run:\n\n\n\n$ docker run ubuntu-sleeper 10\n\n\n\n\nThe argument 10 is passed and appended to the ENTRYPOINT command.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/containers.html",
    "title": "Container",
    "body": "\n\nBack\n\n\nContainer\n\n\n\nRUN\n\nBasics\n\n\n\nRun a container from an image, the attached way, (i.e. it is not run on the background).\n\n\n\n\n$ docker run nginx \n\n\n\n\nIf the image is not present on the host it will be downloaded from Docker Hub. \n\n\n\nWhen it is downloaded it runs and exits right away, because there is not application running in the container.\n\n\n\nTo run the container in the detach mode, so it run on the background:\n\n\n\n$ docker run -d nginx\n\n\n\n\nTo bring the container to the foreground:\n\n\n\n$ docker attach ( container_id | container_name )\n\n\n\n\n\n\n\nRun a container with a specific tag:\n\n\n\n\n$ docker run redis:4.0\n\n\n\n\nThis way we run the redis image where redis's version is 4.0. \n\n\n\n\n\n\nRun a container listening to the standard input (because by default Docker does not listen for input):\n\n\n\n\n$ docker run -i <image_name>\n\n\n\n\nThis way we are running our container in interactive mode.\n\n\n\nIn order to attach a terminal:\n\n\n\n$ docker run -it <image_name>\n\n\n\n\n\nPort Mapping\n\n\nEach container is assigned a port (e.g. 5000) and an internal IP by default (e.g. 127.17.0.2) but this IP is only accessible from the host. So to access it from outside, we would use our host's IP (e.g. 192.168.1.5), however we still need to map our container's port to a free port in our host.\n\n\n\nSo to map, for example, the port 5000 of our Docker container to the port 80 of our host:\n\n\n\n\n$ docker run -p 80:5000 <image_name>\n\n\n\n\nAnd now, we can access the service running in our Docker container by heading to 192.168.1.5:80. This way all traffic in this specific URL will be routed to the port 5000 in our Docker container.\n\n\nVolume Mapping\n\n\nOur container has its own file system, so the changes made to data stored in it are only made in the container.\n\n\n\nIf you want certain data to persist (because when removing the Docker container the files stored within are also removed) you use the flag -v to map a certain file/folder in the container to a certain file/folder in our host:\n\n\n\n$ docker run -v /opt/datadir:/var/lib/mysql mysql\n\n\n\n\nIn this particular example we store the data we saved in our MySQL database in a directory in our container (/var/lib/mysql), and we map this directory to a directory in our host (/opt/datadir) This way Docker mounts implicitly the folder in our host to the folder in the container.\n\n\nLinking\n\n\nIf we have a web application that connects to a redis instance, we need to tell the web app's container which redis instance to wait for (because there may be multiple). So, first we start the redis container:\n\n\n\n$ docker run -d --name=redis redis\n\n\n\n\nAnd now we start our web app's container and we link it with the redis container:\n\n\n\n\n$ docker run -d --name=vote -p 5000:80 --link redis:redis voting-app\n\n\n\n\nThe redis before the colon is the name of our redis container, and the redis after the name is the name used in the web app container.\n\n\n\nThis option is soon to be deprecated because new concepts are technologies are being introduced.\n\n\nInformation of a Container\n\n\nIn order to get more detailed information about a certain container:\n\n\n\n$ docker inspect ( container_name | container_id )\n\n\n\nLogs\n\n\nTo see the logs of a container (usually printed to the stdout):\n\n\n\n$ docker log ( container_name | container_id )\n\n\n\nLIST\n\n\n\nLists all running containers and some information about it.\n\n\n\n\n$ docker ps\n\n\n\n\nTo see all containers, even if they are not currently running:\n\n\n\n$ docker ps -a\n\n\n\nSTOP\n\n\n\nStop running a container who matches the id or the name provided:\n\n\n\n\ndocker stop ( container_id | container_name )\n\n\n\nREMOVE\n\n\n\nRemoves a container permanently\n\n\n\n\ndocker rm ( container_id | container_name )\n\n\n\nExecute commands\n\n\n\nTo execute a command after creating a new container:\n\n\n\n\n$ docker run ubuntu sleep 5\n\n\n\n\nThis commands starts the container and run the command sleep 5 and then exits.\n\n\n\n\nTo execute a command in a currently running container:\n\n\n\n\n$ docker exec ( container_id | container_name ) cat /etc/hosts\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/storage.html",
    "title": "Storage",
    "body": "\n\nBack\n\n\nStorage\n\n\n\n\nThe data pertaining Docker is stored within the folder /var/lib/docker/. This includes containers, images, volumes created, etc.\n\n\nLayers\n\n\nBecause of Docker's layered architecture when creating very similar images that share a lot of instructions, it uses the cached layers and is, therefore more efficient by not building each image from scratch.\n\n\n\nFor example, when you update your application's source code, only the instructions after the COPY instruction, this one included, from your Dockerfile is run.\n\n\nImage and Container Layers\n\n\nThe layers created from each instruction on the Dockerfile constitute the image layers and are all read-only files.\n\n\n\nWhen you run your image a new layer is created, denoted by Container Layer which is a writable file which is a writable file. However, when the container is destroyed, this layer is removed. This is the reason why we use volumes for permanent storage.\n\n\n\nThis is needed because all the containers use the same image, so the changes made in the image by the different containers should not affect the image.\n\n\nCopy-on-write\n\n\nAlso, the changes made on files stored in the image are not made on the original file. The file is copied to the Container Layer and the changes are made onto this copy. \n\n\nVolumes\n\n\nAs we have said, we need volumes to store permanent data. So, first we create the volume:\n\n\n\n$ docker volume <volume_name>\n\n\n\n\nWhich is stored in /var/lib/docker/volumes\n\n\nVolume mounting\n\n\nOnce we have created the volume, we specify that we want to mount this volume within our container:\n\n\n\n$ docker run -v <volume_name>:/var/lib/mysql mysql\n\n\n\n\nIf you run this same command, without creating the volume first, Docker will automatically create the volume for you.\n\n\nBind mounting\n\n\nIf you want to mount another directory that is not inside /var/lib/docker/volumes, then you have to specify the whole directory's (may be an absolute or relative path).\n\n\n\n$ docker run -v /data/mysql:/var/lib/mysql mysql\n\n\n\nMount\n\n\nThis is the new way to mount:\n\n\n\n$ docker run --mount type=bind,source=/data/mysql,target=/var/lib/mysql\n\n\n\n\nWhich is preferred as it is more verbose.\n\n\nStorage Administration\n\n\nThe responsible for all of these operations that happen under the hood are the storage drivers, which are chosen depending on the hosts' OS:\n\n\n\n\nAUFS\n\n\nZFS\n\n\nBTRFS\n\n\nDevice Mapper\n\n\nOverlay\n\n\nOverlay2\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/compose_networks.html",
    "title": "Docker Compose Networks",
    "body": "\n\nBack\n\n\nDocker Compose Networks\n\n\n\n\nLet's start with an example application, which is made up of five services:\n\n\n\n\nvoting-app: a front-end application for the user to vote.\n\n\nredis: and in-memory database to store the vote.\n\n\nworker: application in the back-end that processes the vote and stores it in the database.\n\n\ndb: database in which the vote is stored.\n\n\nresult-app: front-end application that shows the voting results. \n\n\n\n\nIn this architecture we have two networks:\n\n\n\n\nfront-end: voting-app and result-app\n\n\nback-end: all the services.\n\n\n\n\nTherefore it is desirable to define two networks in our docker-compose and attach the networks to the services:\n\n\n\nversion: 2\nservices:\n  redis:\n    image: redis\n    networks:\n      - back-end\n  db:\n    image: postgres\n    networks:\n      - front-end\n  vote:\n    image: voting-app\n    networks:\n      - front-end\n      - back-end\n  result:\n    image: result\n    networks:\n      - front-end\n      - back-end\n  worker:\n    image: worker\n    networks:\n      - front-end\n      - back-end\n\nnetworks:\n  - front-end:\n  - back-end:\n\n\n\n\nAs you can see we define two networks: front-end and back-end (note that we have omitted the configuration of the networks) and then for each service we specify the network to which the service has access (also, observe that the configuration of the services has been trimmed down for readability purposes). \n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/swarm.html",
    "title": "Docker Swarm",
    "body": "\n\nBack\n\n\nDocker Swarm\n\n\n\n\nYou can combine multiple docker machines together into a single cluster and Docker Swarm will take care of managing your services.\n\n\n\n\nYou need to have different hosts with docker installed on them.\n\n\nYou must designate one to be the manager, so the rest are the workers.\n\n\nRun the docker swarm init command on the manager and that will initialize the manager.\n\n\nOn the workers run docker swarm join <token> where <token> is specified in the output of docker swarm init.\n\n\n\n\nNow you can deploy your services in your cluster, and will be run on the nodes (i.e. workers).\n\n\nDocker Service\n\n\nDocker Services are one or more instances of application or services that run along the nodes in the Swarm cluster.\n\n\n\n$ docker services create --replicas=3 <image-name>\n\n\n\n\nThis creates three instances of my image and runs them in the nodes of the cluster. \n\n\n\nThis command must be run on the manager node, not on the worker nodes.\n\n\n\nIt is similar to the docker run command in terms of the options to pass (networks, ports, interactive mode, etc.)\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/environmentvar.html",
    "title": "Environment Variables",
    "body": "\n\nBack\n\n\nEnvironment Variables\n\n\n\n\nIn order to pass an environment variables to our container we run:\n\n\n\n$ docker run -e ENV_VAR=value <image_name>\n\n\n\n\nThis way we set up and environment variable within the container.\n\n\n\nIf you inspect a running container, you will be able to see the environment variables defined, inside the \"Env\" object:\n\n\n\n$ docker inspect <image_name>\n\n{\n  .\n  .\n  \"Config\": {\n            \"Hostname\": \"51049352a8ee\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"ExposedPorts\": {\n                \"3456/tcp\": {},\n                \"80/tcp\": {}\n            },\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"NGINX_VERSION=1.19.10\",\n                \"NJS_VERSION=0.5.3\",\n                \"PKG_RELEASE=1\"\n            ],\n            \"Cmd\": [\n                \"nginx\",\n                \"-g\",\n                \"daemon off;\"\n            ]\n  .\n  .\n  .\n}\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/images_commands.html",
    "title": "Image",
    "body": "\n\nBack\n\n\nImage\n\n\n\nLIST\n\n\n\nLists downloaded images:\n\n\n\n\n$ docker images\n\n\n\n\nOr alternatively:\n\n\n\n$ docker image ls\n\n\n\nREMOVE\n\n\n\nRemove an image\n\n\n\n\n$ docker rmi nginx\n\n\n\n\nYou must stop and remove all the containers that are instances of the image before removing said image.\n\n\nDOWNLOAD\n\n\n\nTo only download an image and not also run a container:\n\n\n\n\n$ docker pull nginx\n\n\n\nCreate your own image\n\n\nFirst create a Dockerfile specifying all of the steps required to set up your application:\n\n\n\nFROM ubuntu\n\nRUN apt-get update\nRUN apt-get install python\n\nRUN pip install flask\nRUN pip install flask-mysql\n\nCOPY . /opt/source-code\n\nENTRYPOINT FLASK_APP=/opt/source-code/app.py flask run\n\n\n\n\nThen build your image, to store locally:\n\n\n\n$ docker build Dockerfile -t mycustomapp\n\n\n\n\nHere we specify our Dockerfile as input for building the image and the tag of the image with the flag -t.\n\n\n\nTo make it available on the DockerHub:\n\n\n\n$ docker push mycustomapp\n\n\n\n\nDockerfile\n\n\nThis is configuration file that follows a certain syntax and tells Docker how to build the image. The syntax is the following:\n\n\n\n\nINSTRUCTION ARGUMENT\n\n\n\n\nIn the previous example we have:\n\n\n\n\nFROM: defines the base image, which can be an OS or another image (every image have to be based off another image).\n\n\nRUN: run a particular command on the base image.\n\n\nCOPY: copies files from the host system onto the Docker image.\n\n\nENTRYPOINT: specifies the command that will be run when the container is started.\n\n\n\nLayered architecture\n\n\nDocker follows a layered architecture so each INSTRUCTION represents a different layer, which contains only the changes from the layer before, and may serve as a snapshot from which to start the build from a particular layer.\n\n\n\nAlso, Docker caches the layers, so if there is an error, the build would start from the last layer that did not produce a failure. Also, if you were to add additional steps, Docker would not start the build from scratch.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/index.html",
    "title": "index",
    "body": "\n\nBack\n\n\nDocker\n\n\n\n\n\nIntro\n\n\nSet Up\n\n\nContainer\n\n\nImage\n\n\nEnvironment Variables\n\n\nCMD vs ENTRYPOINT\n\n\nNetworking\n\n\nStorage\n\n\nDocker Compose\n\n\nDocker Compose Networks\n\n\nDocker Registry\n\n\nDocker Engine\n\n\nDocker on Windows and Mac\n\n\nContainer Orchestration\n\n\nDocker Swarm\n\n\nKubernetes \n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/nerworking.html",
    "title": "Networking",
    "body": "\n\nBack\n\n\nNetworking\n\n\n\n\nWhen you install Docker it creates three networks automatically:\n\n\n\n\nBridge: default network the container get attached to.\n\n$ docker run ubuntu\n\n\n\n\n\n\n\nnone: \n\n$ docker run ubuntu --network=none\n\n\n\n\nhost\n\n$ docker run ubuntu --network=host\n\n\n\n\n\n\n\n\n\nBridge\n\n\nThis is a private internal network created by Docker on the host. All containers can access each other using their internal IP (usually subnets of 172.17.0.3). \n\n\n\nTo access from outside you have to map a port of the container to a port of the host.\n\n\n\n\n\n\nhost\n\n\nAnother way to configure the network is to associate the container to the host's network, removing all kind of network isolation between the Docker host and the Docker container.\n\n\n\nThis way when you run a server on port 5000 it would automatically accessible from the host on the port 5000 without needing to map it to a host's port. \n\n\n\nThis prevents you from using the same ports for different applications.\n\n\nnone\n\n\nThe containers are not attached to any network and are, therefore, isolated from any other containers so they do not have any access to the external network or other containers.\n\n\nUser defined networks\n\n\nBecause with the default internal network, the containers can access each other, it is sometimes desirable to create new internal networks:\n\n\n\n$ docker network create --drive bridge --subnet 172.18.0.0/16 <network_name>\n\n\n\n\nTo list the created networks:\n\n\n\n$ docker network ls\n\n\n\nInspect network\n\n\nIn order to see the network configuration use inspect and head to the Networks section:\n\n\n\n$ docker inspect ( container_name | container_id )\n\n\n\n\n.\n.\n.\n          \"MacAddress\": \"aa:bb:cc:dd:ee:ff\",\n            \"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"NetworkID\": \"24af0d...\",\n                    \"EndpointID\": \"3449a29...\",\n                    \"Gateway\": \"172.17.0.1\",\n                    \"IPAddress\": \"172.17.0.3\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"02:42:ac:11:00:03\",\n                    \"DriverOpts\": null\n                }\n            }\n.\n.\n.\n\n\n\n\nEmbedded DNS\n\n\nWhen containers in the same subnet may want to access each other, for that you could hard code the internal IP assigned to the containers. However this is not advisable, as this IP may change when the container is started in another occasion in the future. \n\n\n\nBecause of that all containers in a Docker host can resolve each other using their names. This is possible has a built-in DNS server for this purpose that runs at 172.0.0.11.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/compose.html",
    "title": "Docker Compose",
    "body": "\n\nBack\n\n\nDocker Compose\n\n\n\n\nIt is used to set up a complex application running multiple services.\n\n\n\nDocker commands map to Docker Compose as follows:\n\n\n\n\n\n\n\nTo start the application we run:\n\n\n\n$ docker-compose up\n\n\n\nBuild\n\n\nIf we would like to tell Docker Compose to build a Docker build instead of pulling an image we use the build keyword inside a service instead of the image keyword. And we specify the location of the directory which contains the application code and a Dockerfile.\n\n\n\nvote:\n  build: ./vote\n  ports:\n    - 5000:80\n  links:\n    - redis\n\n\n\nVersions\n\n\nDifferent Docker Compose versions have different formats and functionality.\n\n\nVersion 2\n\n\nFrom version 2 on, you must specify the Docker Compose version by adding to the top of the file:\n\n\n\nversion: 2\n\n\n\n\nAlso, all of the different containers should be listed under a sevices section. \n\n\n\nAnd now, links are no longer needed as Docker creates a virtual network and attaches all of the services to this network with the name of the service.\n\n\n\nFinally, a depends_on keyword is introduced to force a order of startup.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/WebDev/Docker/windows_mac.html",
    "title": "Docker on Windows and Mac",
    "body": "\n\nBack\n\n\nDocker on Windows and Mac\n\n\nOn these systems we have two options:\n\n\n\n\nDocker Toolbox (usually for older PC's): installs Docker along with VirtualBox to create a Linux system on which Docker is run.\n\n\nHypervirtualization: installs Docker and uses Hyper-V (comes with Windows Server or Professional edition) or Hyperkit on Mac. This allows Docker to create a Linux machine under the hood and run Docker in it.\n\n\n\nWindows Containers\n\n\nThe options just discussed will only work for Linux applications and containers. In 2016 Microsoft announced support for Windows containers, there are two types:\n\n\n\n\nWindows Server Container: the containers share the kernel, as regular Linux containers do.\n\n\nHyper-V isolation: each container is run within a highly optimized virtual machine, so complete kernel isolation between the containers and the underline host is guaranteed.\n\n\n\nBase Images\n\n\nWhere in Linux we had the debian, ubuntu or alpine base images in windows we have two options:\n\n\n\n\nWindows Server Core\n\n\nNano Server: this is a headless deploy of the Windows Server, that is, the lightweight option.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/Other/VimWiki/index.html",
    "title": "Vim Wiki",
    "body": "\n\nBack\n\n\nVim Wiki\n\n\n\nKey Bindings\n\n\n\nConvert current file to html: ,wh\n\n\nSee html file in browser: ,whh\n\n\n\n\nMore info on VimWiki\n\n\nLaTeX\n\n\n\nInline\n\n\n\n\\(a = 1\\)\n\n\n\n\nEquation\n\\begin{align}\nA\n\\end{align}\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Data Cleaning is a Must.html",
    "title": "Data Cleaning is a Must",
    "body": "\n\nBack\n\n\nData Cleaning is a Must\n\n\n\n\n\nDirty data: data that is incomplete, incorrect or irrelevant to the problem\n\n\nClean data: data that is complete, correct and relevant to the problem\n\n\n\n\nTypes of dirty data:\n\n\n\n\nDuplicate data: data record that shows up more than once\n\n\nOutdated data: data that is old which should be replaced with newer and more accurate information\n\n\nIncomplete data: data that is missing important fields\n\n\nIncorrect/Inaccurate data: data that is complete but inaccurate\n\n\nInconsistent data: data that uses different formats to represent the same thing\n\n\n\n\n\n\n\nData validation: tool for checking the accuracy and quality of data before adding or importing it.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Cleaning Data in Spreadsheets.html",
    "title": "Cleaning Data in Spreadsheets",
    "body": "\n\nBack\n\n\nCleaning Data in Spreadsheets\n\n\n\n\n\nData Mapping: process of matching fields from one data source to another.\n\n\n\n\n\n\nData Cleaning exercise:\n\n\n\nBoba Tea Shop Data Cleaning\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Data Integrity and Analytics Objectives.html",
    "title": "Data Integrity and Analytics Objectives",
    "body": "\n\nBack\n\n\nData Integrity and Analytics Objectives\n\n\n\n\nData Integrity: accuracy, completeness, consistency and trustworthiness of data throughout its life cycle.\n\n\n\nData can be compromised through:\n\n\n\n\nData replication: process of storing data in multiple locations (data can be out of sync)\n\n\nData transfer: process of copying data from one place to another (data can be incomplete because the copying process was interrupted)\n\n\nData manipulation: process of changing data\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Begin Cleaning Data.html",
    "title": "Begin Cleaning Data",
    "body": "\n\nBack\n\n\nBegin Cleaning Data\n\n\nWhat and how to clean\n\n\n\n\nData merging: process of combining two or more datasets into a single dataset\n\n\nData compatibility: describes how well two or more datasets are able to work together\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Manually Cleaning Data.html",
    "title": "Manually Cleaning Data",
    "body": "\n\nBack\n\n\nManually Cleaning Data\n\n\n\n\n\nVerification: process to confirm that the data-cleaning was well-executed and the resulting data is accurate and reliable.\n\n\nChangelog: file containing a chronologically ordered list of modifications made to a project\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/index.html",
    "title": "Process Data from Dirty to Clean",
    "body": "\n\nBack\n\n\nProcess Data from Dirty to Clean\n\n\n\nFirst Week\n\n\n> 10/04/2022 - 10/04/2022\n\n\n\n\nFocusing on Integrity\n\n\nData Integrity and Analytics Objectives\n\n\nOvercoming the Challenges of Insufficient Data\n\n\nTesting your Data\n\n\nConsider the Margin of Error\n\n\nWeekly Challenge\n\n\n\nSecond Week\n\n\n> 10/04/2022 - 10/04/2022\n\n\n\n\nData Cleaning is a Must\n\n\nBegin Cleaning Data\n\n\nCleaning Data in Spreadsheets\n\n\nWeekly Challenge\n\n\n\nThird Week\n\n\n> 10/04/2022 - 11/04/2022\n\n\n\n\nUsing SQL to Clean Data\n\n\nLearn Basic SQL Queries\n\n\nTransforming Data\n\n\nWeekly Challenge\n\n\n\nFourth Week\n\n\n> 11/04/2022 - 11/04/2022\n\n\n\n\nManually Cleaning Data\n\n\nDocumenting Results and the Cleaning Process\n\n\nWeekly Challenge\n\n\n\nFifth Week\n\n\n> 11/04/2022 - 11/04/2022\n\n\n\n\nThe Data Analyst Hiring Process\n\n\nUnderstand the Elements of a Data Analyst Resume\n\n\nHighlighting Experiences on Resumes\n\n\nExploring Areas of Interest\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Overcoming the Challenges of Insufficient Data.html",
    "title": "Overcoming the Challenges of Insufficient Data",
    "body": "\n\nBack\n\n\nOvercoming the Challenges of Insufficient Data\n\n\n\n\nTypes of insufficient data:\n\n\n\n\nData from only one source\n\n\nData that keeps updating\n\n\nOutdated data\n\n\nGeographically-limited data\n\n\n\n\nCommon data errors:\n\n\n\n\n\n\n\n\n\n\nRandom sampling: way of selecting a sample from a population so that every possible type of the sample has an equal chance of being chosen\n\n\nMargin of error: Since a sample is used to represent a population, the sample’s results are expected to differ from what the result would have been if you had surveyed the entire population. This difference is called the margin of error.\n\n\nConfidence level: How confident you are in the survey results. For example, a 95% confidence level means that if you were to run the same survey 100 times, you would get similar results 95 of those 100 times.\n\n\nConfidence interval: The range of possible values that the population’s result would be at the confidence level of the study.\n\n\nStatistical significance: The determination of whether your result could be due to random chance or not. The greater the significance, the less due to chance.\n\n\n\n\n\nDetermine the sample size\n\n\n\nDon’t use a sample size less than 30. It has been statistically proven that 30 is the smallest sample size where an average result of a sample starts to represent the average result of a population. \n\n\nThe confidence level most commonly used is 95%, but 90% can work in some cases.\n\n\nFor a higher confidence level, use a larger sample size\n\n\nTo decrease the margin of error, use a larger sample size\n\n\nFor greater statistical significance, use a larger sample size\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Testing your Data.html",
    "title": "Testing your Data",
    "body": "\n\nBack\n\n\nTesting your Data\n\n\n\n\n\nStatistical Power: probability of getting meaningful results from a test (value between 0 and 1, 0.6 means there is 60% chance as statistically significant result)\n\n\nHypothesis testing: way to see if a survey or experiment has meaningful results\n\n\nStatistically significant: it means the results of the test are real and not an error caused by random chance\n\n\n\n\nSample size calculators\n\n\n\n\nSample size calculator by surveymonkey.com\n\n\nSample size calculator by raosoft.com\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/04. Process/Using SQL to Clean Data.html",
    "title": "Using <code>SQL</code> to Clean Data",
    "body": "\n\nBack\n\n\nUsing SQL to Clean Data\n\n\n\n\nDifferences between Spreadsheets and SQL:\n\n\n\n\nSpreadsheets \n\n\n\nGenerated with a program\n\n\nAccess to the data you input\n\n\nStored locally\n\n\nSmall datasets\n\n\nWorking independently\n\n\nBuilt-it features\n\n\n\nSQL \n\n\n\nA language used to interact with database programs\n\n\nCan pull information from different sources in the database\n\n\nStored across a database\n\n\nLarger datasets\n\n\nTracks changes across teams\n\n\nUseful across multiple programs \n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/05. Analyze/Data Analysis Basics.html",
    "title": "Data Analysis Basics",
    "body": "\n\nBack\n\n\nData Analysis Basics\n\n\n\n\nThe four phases of analysis:\n\n\n\n\nOrganize data\n\n\nFormat and adjust data\n\n\nGet input from others\n\n\nTransform data\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/05. Analyze/Use JOINs to Aggregate Data in SQL.html",
    "title": "Use JOINs to Aggregate Data in SQL",
    "body": "\n\nBack\n\n\nUse JOINs to Aggregate Data in SQL\n\n\n\n\nThere are four general ways in which to conduct JOINs in SQL queries: INNER, LEFT, RIGHT, and FULL OUTER. \n\n\n\n\n\n\nINNER JOIN or JOIN\n\n\nINNER JOIN returns records if the data lives in both tables.\n\n\nLEFT JOIN\n\n\nLEFT JOIN returns all the records from the left table and only the matching records from the right table. The nulls are in the right table, because it returns all of the values in the left table with the joined values (if they exist) in the right table. It might be the case that there is no value in the right table linked to a record in the left, so it is null.\n\n\nRIGHT JOIN\n\n\nRIGHT JOIN returns all records from the right table and the corresponding records from the left table. The nulls are in the left table, same as above.\n\n\nFULL OUTER JOIN\n\n\nFULL OUTER JOIN returns all records from the specified tables. So there are null values in both of the table.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/05. Analyze/The Data Validation Process.html",
    "title": "The Data Validation Process",
    "body": "\n\nBack\n\n\nThe Data Validation Process\n\n\n\n\nSix types of data validation:\n\n\n\n\nData type: Check that the data matches the data type defined for a field\n\n\nData range: Check that the data falls within an acceptable range of values defined for the field.\n\n\nData constraints: Check that the data meets certain conditions or criteria for a field.\n\n\nData consistency: Check that the data makes sense in the context of other related data.\n\n\nData structure: Check that the data follows or conforms to a set structure.\n\n\nCode validation: Check that the application code systematically performs any of the previously mentioned validations during user data input.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/05. Analyze/index.html",
    "title": "Analyze Data to Answer Questions",
    "body": "\n\nBack\n\n\nAnalyze Data to Answer Questions\n\n\n\nFirst Week\n\n\n> 11/04/2022 - 11/04/2022\n\n\n\n\nLet's get organized\n\n\nData Analysis Basics\n\n\nOrganize Data for Analysis\n\n\nSort Data in Spreadsheets\n\n\nSort Data using SQL\n\n\nWeekly Challenge\n\n\n\nSecond Week\n\n\n> 11/04/2022 - 11/04/2022\n\n\n\n\nConvert and Format Data\n\n\nCombine Multiple Datasets\n\n\nGet Support during Analysis\n\n\nWeekly Challenge\n\n\n\nThird Week\n\n\n> 11/04/2022 - 11/04/2022\n\n\n\n\nVLOOKUP for Data Aggregation\n\n\nUse JOINs to Aggregate Data in SQL\n\n\nWork with Subqueries\n\n\nWeekly Challenge\n\n\n\nFourth Week\n\n\n> 11/04/2022 - 11/04/2022\n\n\n\n\nGet Started with Data Calculations\n\n\nPivot Pivot Pivot\n\n\nLearn More SQL Calculations\n\n\nThe Data Validation Process\n\n\nUsing SQL with Temporary Tables\n\n\nWeekly Challenge\n\n\nCourse Challenge\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/05. Analyze/Convert and Format Data.html",
    "title": "Convert and Format Data",
    "body": "\n\nBack\n\n\nConvert and Format Data\n\n\n\n\nPractice CONCAT function\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/05. Analyze/VLOOKUP for Data Aggregation.html",
    "title": "VLOOKUP for Data Aggregation",
    "body": "\n\nBack\n\n\nVLOOKUP for Data Aggregation\n\n\n\n\n\nData Aggregation: process of gathering data from multiple sources in order to combine it into a single summarized collection\n\n\n\n\n\nPractice VLOOKUP function\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/06. Visualize/index.html",
    "title": "Share Data Through the Art of Visualization",
    "body": "\n\nBack\n\n\nShare Data Through the Art of Visualization\n\n\n\nFirst Week\n\n\n> 11/04/2022 - 11/04/2022\n\n\n\n\nCommunicating your Data Insights\n\n\nUnderstand Data Visualization\n\n\nDesign Data Visualizations\n\n\nExplore Visualization Considerations\n\n\n\nSecond Week\n\n\n> 11/04/2022 - 12/04/2022\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/The importance of fair business decisions.html",
    "title": "The importance of fair business decisions",
    "body": "\n\nBack\n\n\nThe importance of fair business decisions\n\n\n\n\n\nIssue: topic or subject to investigate\n\n\nQuestion: designed to discover information\n\n\nProblem: obstacle or complication that needs to be worked out.\n\n\nBusiness task: question or problem data analysis answers for a business\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Understanding the data ecosystem.html",
    "title": "Understanding the data ecosystem",
    "body": "\n\nBack\n\n\nUnderstanding the data ecosystem\n\n\nData is a collection of facts\n\n\n\nData ecosystems are made up of elements that interact with one another in order to procude manage store organize analyze and share data.\n\n\n\nData analysis is the collection, transformation and organization of data in order to draw conclusions, make predictions, and drive informed decision-making\n\n\n\nData analytics is the science of data\n\n\n\nData-driven-decision-making is using facts to guide business strategy\n\n\n\nData science is a field of study that uses raw data to create new ways of modelling and understanding the unkown\n\n\n\nDataset is a collection of data that can be manipulated or analyzed as a unit\n\n\n\nSubject Matter Experts: people that are familiar with the bussiness problem\n\n\n\n\n\n“How do I define success for this project?” Ask yourserlf:\n\n\n\n\nWhat kind of results are needed?\n\n\n \n\n\nWho will be informed?\n\n\n \n\n\nAm I answering the question being asked?\n\n\n \n\n\nHow quickly does a decision need to be made?\n\n\n\n\n\nData Analysis Life Cycle\n\n\n\nAsk: Business Challenge/Objective/Question\n\n\nPrepare: Data generation, collection, storage, and data management\n\n\nProcess: Data cleaning/data integrity\n\n\nAnalyze: Data exploration, visualization, and analysis\n\n\nShare: Communicating and interpreting results \n\n\nAct: Putting your insights to work to solve the problem\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Thinking about analytical thinking.html",
    "title": "Thinking about Analytical Thinking",
    "body": "\n\nBack\n\n\nThinking about Analytical Thinking\n\n\n\n\nWhat is analytical thinking? Is identifying and defining a problem and then solving it by using data in an organized, step-by-step manner.\n\n\n\nThe five key aspects to analytical thinking are:\n\n\n\n\nVisualization: is the graphical representation of information (helps data analysts understand and explain information more effectively)\n\n\nStrategy: it helps data analysts see what they want to achieve with the data and how to get there. It allows them to stay focused and on track.\n\n\nProblem-orientation: is about keeping the problem as the priority throughout the entire project.\n\n\nCorrelation: is about being able to pick up and define relations in data.  (Correlation does not equal causation)\n\n\nBig-picture and detail-oriented thinking: is being able to see the big picture as well as the details of a problem\n\n\n\n\nQuestions frequently asked by data analysts\n\n\n\n\nWhat is the root cause of a problem?\n\n\nWhere are the gaps in our process?\n\n\nWhat did we no consider before?\n\n\n \n\nUse the rule of the five \"why's\" to reveal the root cause. This rule consists of asking five times why, once each time an answer is provided.\n\n\n\nTo identify gaps in a process the technique gap analysis is used. It is a method for examining and evaluating how a process works currently in order to get where you want to be in the future. The steps are:\n\n\n\n\nIdentify where you are now and where you want to be in the future\n\n\nDefine the gaps between the two stages\n\n\nDetermine how to bridge them\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/learning-log.html",
    "title": "Learning Log",
    "body": "\n\nBack\n\n\nLearning Log\n\n\n\nThink about data in daily life\n\n\n01/04/2022\n\n\nInstructions\n\n\nYou can use this document as a template for the learning log activity: Think about data in daily life.\n\n\n\nWe recommend that you save every learning log in one folder and include a date in the file name to help you stay organized. Important information like course number, title, and activity name are already included. After you finish your learning log entry, you can come back and reread your responses later to understand how your opinions on different topics may have changed throughout the courses.\n\n\nCreate a list of at least five questions\n\n\n\nWhat areas of a city have more pedestrians\n\n\nAt what point in their life do people consume less\n\n\nWhich places are more likely to return an amazon package\n\n\nWhich kind of films tend to get worse/better reviews on letterbox \n\n\nHow many women are in stem\n\n\nAt what time in the day do i feel more energized\n\n\nHow many words do i read every day\n\n\nHow does the number of books a read vary throughout the year\n\n\nWhat type of movie do people tend to enjoy\n\n\nHow many hours am i productive\n\n\n\nReflection\n\n\nWrite 2-3 sentences (40-60 words) in response to each of the questions below                                                                              \nWhat are some considerations or preferences you want to keep in mind when making a decision? \n\n\n\nFirst of all you have to look at the problem objectively, without any bias towards the probable solution, as to avoid jumping to less efficient solutions. Also you may want to summarize each solution/option to its core idea, so it will be easier to pick up the advantages and disadvantages \n\n\n\nWhat kind of information or data do you have access to that will influence your decision? \n\n\n\nI may have a journal where I introduce the number of books a read (as in I registry each book I have read as an entry)\n\n\n\nAre there any other things you might want to track associated with this decision? \n\n\n\nOther characteristics of the books, other than the time when they were finished may help analyze a trend: the time it took for me to read it, the subject of the book, the language of the book, etc.\n\n\n\n\nConsider how data analysts approach tasks\n\n\n01/04/2022\n\n\nInstructions\n\n\nYou can use this document as a template for the learning log activity: Consider how data analysts approach tasks.\n\n\n\nWe recommend that you save every learning log in one folder and include a date in the file name to help you stay organized. Important information like course number, title, and activity name are already included. After you finish your learning log entry, you can come back and reread your responses later to understand how your opinions on different topics may have changed throughout the courses.\n\n\nReview the 6 phases of data analysis\n\n\nConsider how the data analysts at Google used the data analysis process to break down their analysis project:\n\n\n\n\nThe analysts asked questions to define both the issue to be solved and what would equal a successful result.\n\n\nNext, they prepared by building a timeline and collecting data with employee surveys, which should be inclusive.\n\n\nThey processed the data by cleaning it to make sure it was complete, correct, relevant, and free of errors and outliers.\n\n\nThey analyzed the clean employee survey data. Then the analysts shared their findings and recommendations with team leaders. Afterward, leadership acted on the results and focused on improving key areas.\n\n\n\nReflection\n\n\nWrite 2-3 sentences in response to each of the questions below\n\n\n\nDid the details of the case study help to change the way you think about data analysis? Why or why not?? \n\n\n\nEven though I am familiar with the process and steps one has to follow to perform data analysis, I did not really think about the asking part of it, or the showing your results in a way everybody can understand. \n\n\n\nDid you find anything surprising about the way the data analysts approached their task? \n\n\n\nNot surprising, every step that was laid out seems to make sense. Also coming from a CS background all the workflow of asking questions to define the needs of the client is very similar.\n\n\n\nWhat else would you like to learn about data analysis? I would like to know how to extract/find trends in data, be able to turn a heap of information to something useful\n\n\n\n\nExplore data from your daily life\n\n\n02/04/2022\n\n\nInstructions\n\n\nCreate a list exploring an area of your daily life and include details, such as the date, time, cost, quantity, size, etc:\n\n\n\n\n28/03 - Slept 6 hours, moderately well rested \n\n\n29/03 - Slept 7 hours, slightly tired\n\n\n30/03 - Slept 5 hours, very tired\n\n\n31/03 - Slept 4.5 hours, very tired\n\n\n01/04 - Slept 7 hours, tired\n\n\n\nReflection\n\n\nAre there any trends you noticed in your behavior?\n\n\n\nWhenever something stressful comes up I get very little sleep. Also because I, one, finished a math book (so I searched a for a new resource to learn) and, two, got a new job (the resource I chose was this one) I suddenly was trying to do everything in a frenzy, and so stayed up until way later than usual. \n\n\n\nAre there factors that influence your decision-making?\n\n\n\nI am used to having 2 to 3 hours free before going to sleep, so if I do not manage to have enough time to have that amount of hours, I will just stay up until later, and kind of make the free time even longer because of the anxiety of knowing I should go to sleep.\n\n\n\nIs there anything you identified that might influence your future behavior?\n\n\n\nI will sleep better if I can manage better my time (not cram as many tasks a day) and reduce my anxiety whenever a slight change occurs in my life.\n\n\n\n\nReflect on your skills and expectations\n\n\n02/04/2022\n\n\nInstructions\n\n\nThe table has a row for each essential aspect of analytical skills: \n\n\n\n\nCuriosity: a desire to know more about something, asking the right questions\n\n\n\n\n\nUnderstanding context: understanding where information fits into the “big picture”\n\n\n\n\n\nHaving a technical mindset: breaking big things into smaller steps\n\n\n\n\n\nData design: thinking about how to organize data and information\n\n\n\n\n\nData strategy: thinking about the people, processes, and tools used in data analysis \n\n\n\n\nYou will put an X in the column that you think best describes your current level with each aspect. The three ratings are:\n\n\n\n\nStrength: This is an area you feel is one of your strengths\n\n\n\n\n\nDeveloping: You have some experience with this area, but there’s still significant room for growth\n\n\n\n\n\nEmerging: This is new to you, and will gain experience in this area from this course \n\n\n\n\nThen update the Comments/Plans/Goals column with a quick note to yourself about why you chose those ratings. \n\n\nComplete the Analytical Skills Table\n\n\n\n\nAnalytical skills\n\n\nStrength\n\n\nDeveloping\n\n\nEmerging\n\n\nComments/Plans/Goals\n\n\n\n\nCuriosity\n\n\n \n\n\n \n\n\nX\n\n\nI am usually not very curious, I more like to have the knowledge than explore the unknown\n\n\n\n\nContext\n\n\n \n\n\nX\n\n\n \n\n\nI am pretty good at spotting trends\n\n\n\n\nTechnical mindset\n\n\nX\n\n\n \n\n\n \n\n\nComing from a CS background I am very used to try to resolve different types of problems\n\n\n\n\nData Design\n\n\nX\n\n\n \n\n\n \n\n\nFor the same reason as above, I am familiar with having to chose a data structure/design that fits well your needs\n\n\n\n\nData Strategy\n\n\n \n\n\n \n\n\nX\n\n\nI am not used to having to deal with the people or timeline of a project\n\n\n\n\nReflection\n\n\nWhat do you notice about the ratings you gave yourself in each area? How did you rate yourself in the areas that appeal to you most?\n\n\n\nGenerally speaking I am most proficient at the one that I have been trained academically in, and are more technical. The ones that require soft skills, I am worse at.\n\n\n\nIf you are asked to rate your experience level in these areas again in a week, what do you think the ratings will be, and why do you think that?\n\n\n\nI think most of them will stay the same, but maybe I will become better in data strategy with the help of this course.\n\n\n\nHow do you plan on developing these skills from now on?\n\n\n\nWell curiosity wise, I think the best way for me to go forward is to start projects of my own to see all the caveats a data analysis project can entail.\n\n\n\nAnd when it comes to data strategy, my way of improving would be to understand better how to manage a project and also the different tools available to manage data.\n\n\n\nOrganize your data in a table\n\nIntroduction\n\n\nYou have been collecting data from the beginning of the course. Take a moment to consider the data you have gathered in your learning log. Now, determine how you could organize your data in a table. \n\n\nStructuring your data\n\n\n\n\nDate\n\n\nTime Asleep\n\n\nRest level\n\n\n\n\n28/03\n\n\n6h\n\n\nmoderately well rested\n\n\n\n\n29/03\n\n\n7h\n\n\nslightly tired\n\n\n\n\n30/03\n\n\n5h\n\n\nvery tired\n\n\n\n\n31/03\n\n\n4.5h\n\n\nvery tired\n\n\n\n\n01/04\n\n\n7h\n\n\ntired\n\n\n\n\nReflection\n\n\nIn a new learning log entry, follow the instructions in the template, and add a table to organize your data. Then, write 3-5 sentences (60-100 words) on opportunities in your personal life or current job to organize data into tables.\n\n\n\n\nI could gather data about how many hours a day I am productive at my job\n\n\nHow many time I spend logging my work, instead of working\n\n\n\nGenerating a chart from a spreadsheet\n\nIntroduction\n\n\nSo far, you have planned a project, identified the data you need, and collected the data. Earlier in this course, you completed a learning log where you recorded some data from your daily life, then took the practical step of organizing it. Now, you’re ready for the most satisfying step of the data analysis project: visualizing your data! \n\n\n\nFor this activity, you will move your data to a spreadsheet and bring it to life in a chart.\n\n\nChart\n\n\nSleep data\n\n\nReflect on the data analysis process\n\nReflect\n\n\n\nWhich part(s) of the data analysis process did you enjoy the most? What did you enjoy about it? \n\n\n\n\nI enjoyed both the process, analysis and share steps because I feel it was the more interactive (as asking questions to oneself is not that fun), and allowed me to use the different tools discussed during the course.\n\n\n\n\nWhat were some of the key ideas you learned in this course?\n\n\n\n\nThe importance of following through each step to obtain a thorough and clear insight on the data you are analyzing. And also, the need of taking into account what the stakeholder hopes for when analyzing the data.\n\n\n\n\nAre there concepts or portions of the content that you would like to learn more about? If so, what are they? Which upcoming course do you think would teach you the most about this area?\n\n\n\n\nI am so very excited about the visualization part of the data analysis. Because I have never dug deep enough into it, as I may have into the analysis or process step.\n\n\n\n\nNow that you've gained experience doing data analysis, how do you feel about becoming a data analyst? Have your feelings changed since you began this course? If so, how?\n\n\n\n\nWell, I am mostly doing this course for fun. But sure being a data analyst still sounds exciting enough\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Structured Query Language.html",
    "title": "Structured Query Language",
    "body": "\n\nBack\n\n\nStructured Query Language\n\n\n\n\n\nQuery: a request for data or information from a database.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Embrace your data analyst skills.html",
    "title": "Embrace your data analyst skills",
    "body": "\n\nBack\n\n\nEmbrace your data analyst skills\n\n\n\n\nThe five key data analyst skills are\n\n\n\n\nCuriosity\n\n\nUnderstanding context: is the condition in which something exists or happens, could be a structure or environment.\n\n\nHaving a technical mindset: is the ability to break things down into smaller steps or pieces and work with them in an orderly and logical way\n\n\nData design: is how to organize information (typically has to do with databases)\n\n\nData strategy: is the management of \n\n\n\nThe people: they know how to use the right data to find solutions on the problem you are working on \n\n\nThe processes: the path to the solution is clear and accessible\n\n\nThe tools: make sure the right technology is being used for the job.\n\n\n\nAnalytical skills: are the qualities and characteristics associated with solving problems using facts\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/The data analysis toolbox.html",
    "title": "The data analysis toolbox",
    "body": "\n\nBack\n\n\nThe data analysis toolbox\n\n\n\n\nTools data analysts use:\n\n\n\n\nSpreadsheets\n\n\nQuery languages for databases: computer programming language that allows you to retrieve and manipulate data from a database (Structured Query Language or SQL)\n\n\nVisualization tools\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Follow the data life cycle.html",
    "title": "Follow the data life cycle",
    "body": "\n\nBack\n\n\nFollow the data life cycle\n\n\n\n\nThe life cycle of data is \n\n\n\n\nPlan: during planning a business decides:\n\n\n\nWhat data is needed\n\n\nHow to manage the data throughout its life cycle\n\n\nWho is responsible for the data\n\n\nWhat is the desired outcome\n\n\n\nCapture: this is when data is collected from different sources and brought into the company.\n\n\nManage: refers to how we store the data, the tools we use to keep it secure, and the actions taken to make sure it is maintained properly.\n\n\nAnalyze: use the data to solve problems, make good decisions, and reach the company's goals.\n\n\nArchive: means storing data in a place where it is still available, but it may not be used again.\n\n\nDestroy: Remove data from storage and delete any shared copies of the data.\n\n\n\n\n\nA database is a collection of data stored in a computer system.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Transforming Data into insights.html",
    "title": "Transforming Data into insights",
    "body": "\n\nBack\n\n\nTransforming Data into insights\n\n\n\n\nThe six steps of the data analysis process that you have been learning in this program are: ask, prepare, process, analyze, share, and act. \n\n\n\n\nAsk: ask effective questions to define the project and what is the desired result\n\n\nPrepare: build a timeline, decide how to gather data, how and when to communicate with your client\n\n\nProcess: clean the data, make sure it is complete, correct, relevant free of errors and outliers\n\n\nAnalyze: analyze the gathered data to search for solutions, findings, etc.\n\n\nShare: know how to show and display your findings to your team leaders\n\n\nAct: decide how to best implement changes and take action\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Outlining the data analysis.html",
    "title": "Outlining the data analysis process",
    "body": "\n\nBack\n\n\nOutlining the data analysis process\n\n\n\n\n\nStakeholder: people who have invested time and resources into a project and are interested in the outcome\n\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/index.html",
    "title": "Foundations: Data, Data, Everywhere",
    "body": "\n\n\nBack\n\n\nFoundations: Data, Data, Everywhere\n\n\n\n\n\nLearning Log\n\n\n\n\n\nFirst Week\n\n\n> 28/03/2022 - 01/04/2022\n\n\n\n\nGet Started\n\n\nTransforming Data into insights\n\n\nUnderstanding the data ecosystem\n\n\nProgram expectations\n\n\nWeekly challenge 1\n\n\n\nSecond Week\n\n\n> 02/04/2022 - 03/04/2022\n\n\n\n\nEmbrace your data analyst skills\n\n\nThinking about analytical thinking\n\n\nThinking about outcomes\n\n\nWeekly challenge 2\n\n\n\nThird Week\n\n\n> 04/04/2022 - 05/04/2022\n\n\n\n\nFollow the data life cycle\n\n\nOutlining the data analysis\n\n\nThe data analysis toolbox\n\n\nWeekly challenge 3\n\n\n\nFourth Week\n\n\n> 06/04/2022 - 06/04/2022\n\n\n\n\nMastering spreadsheets basics\n\n\nStructured Query Language\n\n\nData visualization\n\n\nWeekly challenge 4\n\n\n\nFifth Week\n\n\n> 06/04/2022 - 07/04/2022\n\n\n\n\nData analyst job opportunities\n\n\nThe importance of fair business decisions\n\n\nOptional: Exploring your next job\n\n\nWeekly challenge 5\n\n\nCourse challenge\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Optional: Exploring your next job.html",
    "title": "Data analyst roles and job descriptions",
    "body": "\n\nBack\n\n\nData analyst roles and job descriptions\n\n\n\n\nData analysts, data scientists, and data specialists sound very similar but focus on different tasks.The table below illustrates some of the overlap and distinctions between them: \n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/01. Foundations/Mastering spreadsheets basics.html",
    "title": "Mastering spreadsheets basics",
    "body": "\n\nBack\n\n\nMastering spreadsheets basics\n\n\n\n\n\nAttribute: characteristic or quality of data used to label a column in a table.\n\n\nObservation: all the attributed for something contained in a row of a data table.\n\n\nFormula: set of instructions that performs a specific action using the data in a spreadsheet.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/index.html",
    "title": "Google Data Analyst Certificate",
    "body": "\n\nBack\n\n\nGoogle Data Analyst Certificate\n\n\n\n\n> 28/03/2022 - \n\n\n\n\n\nFoundations: Data, Data, Everywhere\n\n\nAsk Questions to Make Data-Driven Decisions\n\n\nPrepare Data for Exploration\n\n\nProcess Data from Dirty to Clean\n\n\nAnalyze Data to Answer Questions\n\n\nShare Data Through the Art of Visualization\n\n\nData Analysis with R Programming\n\n\nGoogle Data Analytics Capstone_ Complete a Case Study\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Working with databases.html",
    "title": "Working with Databases",
    "body": "\n\nBack\n\n\nWorking with Databases\n\n\n\n\nA relational database is a database that contains a series of tables that can be connected to show relationships.\nSome tables don't require a primary key. For example, a revenue table can have multiple foreign keys and not have a primary key.\nA primary key may also be constructed using multiple columns of a table. This type of primary key is called a composite key.\n\n\n\n\n\n\n\nIce Cream Dataset Analysis\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Data ethics and privacy.html",
    "title": "Data Ethics and Privacy",
    "body": "\n\nBack\n\n\nData Ethics and Privacy\n\n\n\n\n\nData Ethics: standards of right and wrong about how data is collected, shared and used\n\n\n\n\nAspects of data ethics:\n\n\n\n\nOwnership: individuals own the raw data they provide and they have control over the usage, processing and how it is shared.\n\n\nTransaction transparency: all data-processing activities and algorithms should be completely explainable and understood by the individual who provides their data.\n\n\nConsent: individual's right to know how and why their data will be used before agreeing to provide it.\n\n\nCurrency: individuals should be aware of financial transactions resulting from the use of their personal data.\n\n\nPrivacy: preserving a data subject's information and activity any time a data transaction occurs.\n\n\nOpenness: free access usage and sharing of data.\n\n\n\n\n\n\nPersonally identifiable information , or PII , is information that can be used by itself or with other data to track down a person's identity. \nData anonymization is the process of protecting people's private or sensitive data by eliminating that kind of information.\n\n\n\n\n\nOpen data standards:\n\n\n\n\nAvailability and access: the data is available as a whole\n\n\nReuse and redistribution: data is provided under terms that allow it to be reused and redistributed\n\n\nUniversal participation: everybody should be able to use the data\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Collecting Data.html",
    "title": "Collecting Data",
    "body": "\n\nBack\n\n\nCollecting Data\n\n\n\n\nThese are the key data collection considerations:\n\n\n\n\nHow the data will be collected\n\n\nDetermine the time frame\n\n\nExisting data?\n\n\n\nChoose the data sources\n\n\nDecide what data to use\n\n\n\nNew data?\n\n\n\nHow much data to collected\n\n\nSelect the right data type\n\n\n\n\n\n\n\n\n\n\n\nType of data collected:\n\n\n\n\nFirst-party data: collected by an individual using their own resources\n\n\nSecond-party data: collected by a group directly from its audience and then sold\n\n\nThird-part data: collected from outside sources who did not collect it directly\n\n\n\n\n\n\n\nPopulation: All possible data values in a certain dataset\n\n\nSample: part of a population that is representative of the population\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Explore data credibility.html",
    "title": "Explore Data Credibility",
    "body": "\n\nBack\n\n\nExplore Data Credibility\n\n\n\n\nGood data is ROCCC:\n\n\n\n\nReliable\n\n\nOriginal: Check the quality of the data with the original source\n\n\nComprehensive: contain all critical information needed to find a solution for a problem\n\n\nCurrent\n\n\nCited: should be cited by trusted sources\n\n\n\n\nBad data is data that does not satisfies one or more of the characteristics listed above.\n\n\n\nSome good sources for data are:\n\n\n\n\nVetted public datasets\n\n\nGovernmental agency data\n\n\nAcademic papers\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Sorting and filtering.html",
    "title": "Sorting and Filtering",
    "body": "\n\nBack\n\n\nSorting and Filtering\n\n\n\n\nLittle exercise of sorting and filtering:\n\n\n\nStudent Performance Data\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Working with large datasets in SQL.html",
    "title": "Working with Large Datasets in <code>SQL</code>",
    "body": "\n\nBack\n\n\nWorking with Large Datasets in SQL\n\n\n\n\nBig Query\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Understanding open data.html",
    "title": "Understand Open Data",
    "body": "\n\nBack\n\n\nUnderstand Open Data\n\n\n\n\nSites and resources for open data:\n\n\n\n\nU.S. government data site\n\n\nU.S. Census Bureau\n\n\nOpen Data Network\n\n\nGoogle Cloud Public Datasets\n\n\nDataset Search\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Effectively organize your data.html",
    "title": "Effectively organize your data",
    "body": "\n\nBack\n\n\nEffectively organize your data\n\n\n\n\nFile naming DO's:\n\n\n\n\nWork out your conventions early\n\n\nAlign file naming with your team\n\n\nMake sure file names are meaningful\n\n\nKeep file names short and simple\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/index.html",
    "title": "Prepare for Data Exploration",
    "body": "\n\nBack\n\n\nPrepare for Data Exploration\n\n\n\nFirst Week\n\n\n> 09/04/2022 - 09/04/2022\n\n\n\n\nData Exploration\n\n\nCollecting Data\n\n\nDifferentiate between data formats and structures\n\n\nExplore data types and values\n\n\nWeekly challenge\n\n\n\nSecond Week\n\n\n> 10/04/2022 - 10/04/2022\n\n\n\n\nUnbiased and objective data\n\n\nExplore data credibility\n\n\nData ethics and privacy\n\n\nUnderstanding open data\n\n\nWeekly challenge\n\n\n\nThird Week\n\n\n> 10/04/2022 - 10/04/2022\n\n\n\n\nWorking with databases\n\n\nManaging data with metadata\n\n\nAccessing different data sources\n\n\nSorting and filtering\n\n\nWorking with large datasets in SQL\n\n\nWeekly challenge\n\n\n\nFourth Week\n\n\n> 10/04/2022 - 10/04/2022\n\n\n\n\nEffectively organize your data\n\n\nSecuring data\n\n\nWeekly challenge\n\n\n\nFifth Week\n\n\n> 10/04/2022 - 10/04/2022\n\n\n\n\nCreate or enhance our online presence\n\n\nBuild a data analytics network \n\n\n\nSixth Week\n\n\n> 10/04/2022 - 10/04/2022\n\n\n\n\nCourse challenge\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Differentiate between data formats and structures.html",
    "title": "Differentiate between data formats and structures",
    "body": "\n\nBack\n\n\nDifferentiate between data formats and structures\n\n\n\n\nHere are some types of data:\n\n\n\n\nDiscrete data: is counted and has a limited number of values\n\n\nContinuous data: is measured and can have almost any numeric value\n\n\n\n-\n\n\n\nNominal data: type of qualitative data that is categorized without a set order\n\n\nOrdinal data: type of qualitative data that with a set order or scale\n\n\n\n-\n\n\n\nInternal data: data that lives within a company's own systems\n\n\nExternal data: data that lives and is generated outside of an organization\n\n\n\n-\n\n\n\nStructured data: data organized in a certain format such as rows and columns\n\n\nUnstructured data: data that is not organized in any easily identifiable manner\n\n\n\n\n\n\n\nData Model: model that is used for organizing data elements and how they relate to one another.\n\n\n\n\nTypes of data modelling:\n\n\n\n\nConceptual data modelling: gives a high level view of the data structure\n\n\nLogical data modelling: focuses on relationships, attributes and entities in the database.\n\n\nPhysical data modelling: shows how a database operates. (column names, table names, data types, etc)\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Securing data.html",
    "title": "Securing Data",
    "body": "\n\nBack\n\n\nSecuring Data\n\n\n\n\n\nData security: protecting data from unauthorized access or corruption by adopting safety measures\n\n\n\n\nSome security measures:\n\n\n\n\nEncryption: uses a unique algorithm to alter data and make it unusable by users and applications that don’t know the algorithm.\n\n\nTokenization: replaces the data elements you want to protect with randomly generated data referred to as a “token”.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Managing data with metadata.html",
    "title": "Managing Data with Metadata",
    "body": "\n\nBack\n\n\nManaging Data with Metadata\n\n\n\n\nMetadata: is data about data.\n\n\n\nTypes of metadata:\n\n\n\n\nDescriptive: describes a piece of data\n\n\nStructural: describes how a piece of data is organized.\n\n\nAdministrative: indicates the technical source of a digital asset.\n\n\n\n\n\n\n\nMetadata repository: database created to store metadata\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/03. Prepare/Unbiased and objective data.html",
    "title": "Unbiased and Objective Data",
    "body": "\n\nBack\n\n\nUnbiased and Objective Data\n\n\n\n\n\nBias: preference in favor or against a person or thing\n\n\nData Bias: type of error that systematically skews results in a certain direction\n\n\nUnbiased sampling: when a sample is representative of the population being measured\n\n\n\n\nTo avoid bias when sampling, make sure to take random samples and make visualizations comparing the population with your sample to check if the sample is representative.\n\n\n\nTypes of bias:\n\n\n\n\nSampling Bias: when a sample is not representative of the population as a whole\n\n\nObserver Bias (experimenter bias/research bias): tendency for different people to observe things differently\n\n\nInterpretation Bias: tendency to always interpret ambiguous situations in a positive or negative way\n\n\nConfirmation Bias: tendency to search for or interpret information in a way that confirms pre-existing beliefs\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Connecting the data dots.html",
    "title": "Connecting the Data Dots",
    "body": "\n\nBack\n\n\nConnecting the Data Dots\n\n\n\n\nThere are two types of data:\n\n\n\n\nSmall data: is specific, recorded in a short-time period and used to make day-to-day decisions. (analyze with spreadsheets)\n\n\nBig data: is large and less specific, recorded in a long-time period and used to make big decisions. (analyze with spreadsheets)\n\n\n\nThe three (or four) V words for big data\n\n\n\nVolume: amount of data.\n\n\nVariety: different kinds of data.\n\n\nVelocity: how fast can it be processed.\n\n\nVeracity: quality and reliability of data.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Take action with data.html",
    "title": "Take action with data",
    "body": "\n\nBack\n\n\nTake action with data\n\n\n\nAsk\n\n\n\nDefine the problem you're trying to solve \n\n\nMake sure you fully understand the stakeholder's expectations\n\n\nFocus on the actual problem and avoid any distractions\n\n\nCollaborate with stakeholders and keep an open line of communication\n\n\nTake a step back and see the whole situation in context\n\n\n\nPrepare\n\n\nYou will decide what data you need to collect in order to answer your questions and how to organize it.\n\n\n\n\nWhat metrics to measure\n\n\nLocate data in your database\n\n\nCreate security measures to protect that data\n\n\n\nProcess\n\n\nYou will need to clean up your data to get rid of any possible errors, inaccuracies, or inconsistencies.\n\n\n\n\nUsing spreadsheet functions to find incorrectly entered data \n\n\nUsing SQL functions to check for extra spaces\n\n\nRemoving repeated entries\n\n\nChecking as much as possible for bias in the data\n\n\n\nAnalyze\n\n\nNow you may need to think analytically about your data. You might sort and format your data to make it easier to: \n\n\n\n\nPerform calculations\n\n\nCombine data from multiple sources\n\n\nCreate tables with your results\n\n\n\nShare\n\n\nSummarize your results with clear and enticing visuals of your analysis using data via tools like graphs or dashboards.\n\n\nAct\n\n\nNow it’s time to act on your data. You will take everything you have learned from your data analysis and put it to use. This could mean providing your stakeholders with recommendations based on your findings so they can make data-driven decisions.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Functions in spreadsheets.html",
    "title": "Functions in spreadsheets",
    "body": "\n\nBack\n\n\nFunctions in spreadsheets\n\n\nIn this activity, you will import a dataset, build a custom data table, and use functions to analyze your data. For this activity, imagine you're a data analyst working for a recruiting agency. This recruiting agency helps all sorts of companies find skilled people to fill open data analytics jobs. The agency has collected data about job applications for opportunities posted on its website for the year 2019.\n\n\n\nJob Applications Spreadsheet\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Solve problems with data.html",
    "title": "Solve problems with data",
    "body": "\n\nBack\n\n\nSolve problems with data\n\n\n\n\nData analysts typically work with six problem types\n\n\n\n\nMaking predictions: using data to make an informed decision about how things might be in the future\n\n\nCategorizing things: assigning information to different groups or clusters based on common features\n\n\nSpotting something unusual: identifying data that is different from the norm\n\n\nIdentifying themes: Grouping categorized information into broader concepts\n\n\nDiscovering connections: finding similar challenges faced by different entities and combining data and insights to address them\n\n\nFinding patterns: using historical data to understand what happened in the past and is therefore likely to happen again\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Craft effective questions.html",
    "title": "Craft effective questions",
    "body": "\n\nBack\n\n\nCraft effective questions\n\n\n\n\nIneffective questions:\n\n\n\n\nLead question: it leads you to answer in a certain way.\n\n\nClose ended: it can be answer with yes or no.\n\n\nToo vague: is too broad an lacks content.\n\n\n\n\nEffective questions follow the SMART methodology:\n\n\n\n\nSpecific: simple and focuses on the problem.\n\n\nMeasurable: can be quantified and assessed.\n\n\nAction-oriented: encourage change.\n\n\nRelevant: have significance to the problem at hand.\n\n\nTime-bound: specify the time to be studied.\n\n\n\n\nAlso question must assure fairness, that is to make sure they do not reinforce bias.\n\n\nQuestion 1\n\n\nYou are three weeks into your new job as a junior data analyst. The company you work for has just collected data on their weekend sales. Your manager asks you to perform a “deep dive” into this data.\n\n\n\nBased on the SMART framework, which questions are most important to ask?\n\n\n\n\nWhat is the variation in number of sales between this week and the week before. \n\n\nWhat products are the ones that are most often purchased. \n\n\nWhat common characteristics do these products have in common. \n\n\nWhich kind of costumers purchase more and most often. At what time of the week are the sales higher.\n\n\n\n\nHow will these questions clarify the requirements and goals for the project?\n\n\n\n\nIt will allow us to detect if there was a change in the number of sales, and so to investigate as to why\n\n\nIt will guide to explore which products to explore\n\n\nIt will allows us to know better our costumers\n\n\n\n\nHow does asking detailed, specific questions benefit you when planning for a project? Can vague or unclear questions harm a project?\n\n\n\nIt can be used to lay out clearly what our objectives are, without leading to bias. Yes, then can introduce misunderstandings between the clients and the analysts.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Understand the power of data.html",
    "title": "Understand the power of data",
    "body": "\n\nBack\n\n\nUnderstand the power of data\n\n\n\n\n\nData-inspired decision making: explores different data sources to find out what they have in common\n\n\nData-driven decision making:\n\n\n\n\nNote that there is a difference between making a decision with incomplete data and making a decision with a small amount of data. You learned that making a decision with incomplete data is dangerous. But sometimes accurate data from a small test can help you make a good decision.\n\n\n\n\nQuantitative data: measures of numerical facts.\n\n\nQualitative data: subjective measures of qualities and characteristics.\n\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/learning-log.html",
    "title": "Learning Log",
    "body": "\n\nBack\n\n\nLearning Log\n\n\n\nConsider what data means to you\n\n\n07/04/2022\n\n\n\nWhat does data mean to you?\n\n\n\nNow, I usually picture data like a very big table full of attributes and entries.\n\n\n\nWhen you come across a problem and you aren’t sure of the answer or solution, what do you do?\n\n\n\nI tend to search in google for the answer of a problem\n\n\n\nHow do you identify new and interesting problems to begin with? Is there a process you use to identify problems you want to solve?\n\n\n\nGenerally, the problems come from me inserting myself into new technologies. This way I am more likely to come up with a new \"problem\" in the form of a project, for me to develop.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Working with spreadsheets.html",
    "title": "Working with spreadsheets",
    "body": "\n\nBack\n\n\nWorking with spreadsheets\n\n\n\n\nHere are the core spreadsheets tasks:\n\n\n\n\nOrganize your data\n\n\n\nPivot table\n\n\n\nSort and filter \n\n\n\n\nCalculate your data\n\n\n\nFormulas\n\n\nFunctions\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Follow the evidence.html",
    "title": "Follow the evidence",
    "body": "\n\nBack\n\n\nFollow the evidence\n\n\n\n\nLet's see two kinds of visual representation tools:\n\n\n\n\nReports: static collection of data given to stakeholders periodically.\n\n\nDashboards: monitors live incoming data.\n\n\n\n\n\nReports\n\nPros\n\n\n\nHigh level historical data\n\n\nEasy to design\n\n\nPre-cleaned sorted data\n\n\n\nCons\n\n\n\nContinual maintenance\n\n\nLess visually appealing\n\n\nStatic\n\n\n\n\n\nDashboards\n\nPros\n\n\n\nDynamic, automatic, interactive\n\n\nMore stakeholder access\n\n\nLow maintenance\n\n\n\nCons\n\n\n\nLabor-intensive design\n\n\nCan be confusing\n\n\nPotentially uncleaned data\n\n\n\n\n\n\n\n\nPivot table: data summarization tool used in data processing. They are used to summarize, sort, reorganize, group, count, total or average data stored in a database.\n\n\nMetric: quantifiable type of data than can be used for measurement.\n\n\n\n\nTypes of dashboards:\n\n\n\n\nStrategic: focuses on long term goals and strategies at the highest level of metrics \n\n\nOperational: short-term performance tracking and intermediate goals\n\n\nAnalytical: consists of the datasets and the mathematics used in these sets\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Problem-solving and effective questioning.html",
    "title": "Problem-solving and effective questioning",
    "body": "\n\nBack\n\n\nProblem-solving and effective questioning\n\n\n\n\n\nStructured thinking: process of: \n\n\n\nRecognizing the current problem\n\n\nOrganizing the available information\n\n\nRevealing gaps and opportunities\n\n\nIdentifying options\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/index.html",
    "title": "Ask Questions to Make Data-Driven Decisions",
    "body": "\n\nBack\n\n\nAsk Questions to Make Data-Driven Decisions\n\n\n\n\n\nLearning Log\n\n\n\n\n\nFirst Week\n\n\n> 07/04/2022 - 08/04/2022\n\n\n\n\nProblem-solving and effective questioning\n\n\nTake action with data\n\n\nSolve problems with data\n\n\nCraft effective questions\n\n\nWeekly challenge\n\n\n\nSecond Week\n\n\n> 08/04/2022 - 09/04/2022\n\n\n\n\nUnderstand the power of data\n\n\nFollow the evidence\n\n\nConnecting the data dots\n\n\nWeekly challenge\n\n\n\nThird Week\n\n\n> 09/04/2022 - 09/04/2022\n\n\n\n\nWorking with spreadsheets\n\n\nFormulas in spreadsheets\n\n\nFunctions in spreadsheets\n\n\nSave time with structured thinking\n\n\nWeekly challenge\n\n\n\nFourth Week\n\n\n> 09/04/2022 - 09/04/2022\n\n\n\n\nBalance team and stakeholder needs\n\n\nCommunication is key\n\n\nAmazing teamwork\n\n\nWeekly challenge\n\n\nCourse challenge\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/GoogleDataAnalyst/02. Ask/Save time with structured thinking.html",
    "title": "Save time with structured thinking",
    "body": "\n\nBack\n\n\nSave time with structured thinking\n\n\n\n\n\nProblem domain: specific area of analysis that encompasses every activity affecting or affected by the problem \n\n\nScope of work: outline of the work you are going to perform in a project\n\n\n\nDeliverables: what things are being created as a result of the project\n\n\nMilestones\n\n\nTimeline\n\n\nReports: how to give status updates to the stakeholders.\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Aprendizaje Online.html",
    "title": "Aprendizaje Online",
    "body": "\n\nBack\n\n\nAprendizaje Online\n\n\n\n\nEn estos tipos de problemas se generan datos de forma continua, tal que para cada nuevo dato:\n\n\n\n\nObtenemos \\((x, y)\\)\n\n\nActualizamos \\(\\theta\\) utilizando el nuevo ejemplo:\n\n\n\n\\(\\theta_j = \\theta_j - \\alpha (h_\\theta(x) - y)x_j\\)\n\n\n\n\nEjemplo\n\n\nAprender a buscar. Supongamos que lo queremos aprender es aquellos resultados que le interesen más al usuario. Si tenemos los siguientes datos:\n\n\n\n\n\\(X\\): características del producto\n\n\n\\(y\\): si el usuario hace click\n\n\n\n\nEntonces, lo que queremos aprender es \\(P(y= 1|x;\\theta)\\), tal que por ejemplo enseñemos los 10 productos cuya probabilidad es mayor.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/ExpectationMaximization/Expectation-Maximization Algorithms.html",
    "title": "Expectation Maximization",
    "body": "\n\nBack\n\n\nExpectation Maximization\n\n\n\n\n\nIntroduction\n\n\nGaussian Mixture Models\n\n\nEM Algorithm with GMM's\n\n\n\nE-Step\n\n\nM-Step\n\n\n\nOptimal Parameters of a GMM\n\n\n\nIterative Process\n\n\n\nRecap: Anomaly Detection\n\n\nGeneralized EM Algorithm\n\n\n\nJensen's Inequality\n\n\nMotivation\n\n\nE-Step\n\n\nM-Step\n\n\nPutting Everything Together\n\n\n\nDerive EM for GMM\n\n\n\nE-Step\n\n\nM-Step\n\n\n\n\n\n\nIntroduction\n\n\nThis technique is employed in Density Estimation problems and Anomaly Detection. \n\n\n\nSuch problems aim to represent data in a compact form using a statistical distribution, e.g., Gaussian, Beta, or Gamma. You can think of those problems as a clustering task but from a probabilistic point of view. This is what makes the EM algorithm a probabilistic generative model. \n\n\n\nThus, if we are given \\(n\\) samples, we model them with \\(P(x)\\), such that if \\(P(x) < \\epsilon\\), where \\(\\epsilon\\) is some threshold, then we detect an anomaly.\n\n\n\nHowever, you may expect that a single Gaussian with its mean and variance cannot map thousands of instances in a dataset into a set of \\(K\\) clusters accurately, so we may assume that there are \\(K\\) distributions that describe the data, hence we use Mixture Models.\n\n\n\nFor example, imagine you have the following dataset:\n\n\n\n\n\n\n\nIt looks like the data comes from two different Gaussian distributions:\n\n\n\n\n\n\n\nSo to model this data we use a Mixture of Gaussian Models. \n\n\n\nNote that if we knew by which distribution each sample was generated, we would simply use MLE, however we do not know this information, therefore we use the Expectation Maximization Algorithm and we introduce the latent variable \\(z\\) in place of the predicted output \\(y\\) we had in supervised learning algorithms.\n\n\n\n\n\nTo model the data, first of all, we suppose that there is a latent (hidden/unobserved) random variable \\(z\\), and \\(x^{(i)}, z^{(i)}\\) are distributed (by a joint distribution) like so \n\n\n\\begin{align}\nP(x^{(i)},z^{(i)}) = P(x^{(i)}|z^{(i)}) P(z^{(i)})\n\\end{align}\n\n\nWhere \\(z^{(i)} \\sim Multinomial(\\phi)\\), that is \\(z^{(i)}\\) is distributed according to a multinomial distribution. This distribution models for each \\(z^{(i)}\\) the probability of it being equal to \\(1, 2, ..., K\\), where \\(K\\) is the number of clusters. This will denote the probability of a point \\(x^{(i)}\\) being drawn from each of the distributions.\n\n\n\nAnd \\(P(x^{(i)}|z^{(i)}=j)\\) is the probability of \\(x^{(i)}\\) being generated by the cluster \\(j\\). Where \\(x^{(i)}|z^{(i)} = j\\) is drawn from a normal distribution \\(\\mathcal{N}(\\mu_j, \\Sigma_j)\\).\n\n\nGaussian Mixture Models\n\n\nTo build a density estimator model, we cannot rely on a simple distribution. Mixture models try to tackle this limitation by combining a set of distributions to create a convex space where we can search for the optimal parameters for such distributions using Maximum Likelihood Estimation (MLE).\n\n\n\nA Mixture Model is expressed by the following equations:\n\n\n\\begin{align}\np(x^{(i)}) = \\sum_{j=1}^K \\phi^{(i)}_j p_j(x^{(i)}) \\tag{1}\n\\end{align}\n\n\\begin{align}\n0 \\leq \\phi^{(i)}_j \\leq 1, \\sum_{j=1}^K \\phi^{(i)}_j = 1\n\\end{align}\n\n\nWhere \\(K\\) is the number of mixture components (clusters), \\(\\phi^{(i)}_j\\)'s are the mixture weights, and \\(p_j(x^{(i)})\\)'s are members of a family of distributions (Gaussian, Poisson, Bernoulli, etc). So for each example \\(x^{(i)}\\) and for each distribution \\(j\\), each weight \\(\\phi^{(i)}_j\\) is between 0 and 1, and the sum over \\(k\\) of the weights \\(\\phi_j^{(i)}\\) for every example \\(x^{(i)}\\) equals one.\n\n\n\nConsequently, a GMM is a Mixture Model where the \\(p_j(x^{(i)})\\) is a finite combination of Gaussian Distributions. Therefore, a GMM can be precisely defined by the following set of equations:\n\n\n\\begin{align}\np(x^{(i)};\\theta) = \\sum_{j=1}^K \\phi^{(i)}_j \\mathcal{N}(x^{(i)};\\mu_j,\\,\\Sigma_j)\n\\end{align}\n\n\\begin{align}\n0 \\leq \\phi^{(i)}_j \\leq 1, \\sum_{j=1}^K \\phi^{(i)}_j = 1\n\\end{align}\n\n\nWhere \\(\\theta\\) is the collection of all the parameters of the model (mixture weights, means, and covariance matrices):\n\n\n\\begin{align}\n\\theta = \\{\\phi_1, \\cdots, \\phi_K, \\mu_1, \\cdots, \\mu_K, \\Sigma_1, \\cdots, \\Sigma_K\\}\n\\end{align}\n\n\nFor example, the following plot shows what a GMM derived from 3 mixture components looks like:\n\n\n\n\n\n\n\nAs a consequence, for each data point, \\(x^{(i)}\\) (in red), we can compute the probability that it belongs to each component (\\(P(x^{(i)}|z^{(i)} = j)\\), where \\(j = 1, 2, 3\\))(make a “soft” assignment). This quantity is called “responsibility”.\n\n\nEM Algorithm with GMM's\n\n\nThe Expectation Maximization Algorithm is comprised of two steps:\n\n\n\n\nGuess the value of the responsibilities \\(w^{(i)}_j\\), that represent the \"amount\" of each \\(x^{(i)}\\) that was generated from the distribution \\(j\\) (or the probability that the \\(j\\)th distribution generated the point \\(x^{(i)}\\)).\n\n\nCompute the values of the parameters of the distributions: \\(\\theta = \\{\\phi, \\mu, \\Sigma\\}\\) according to the \\(MLE\\) (Maximum Likelihood Estimation) with respect to the parameters. Thus, we want to maximize \\(\\mathcal{L}(\\Phi, \\mu, \\Sigma)\\).\n\n\n\n\nE-Step\n\n\nIn this step, as we have said, we will compute the value of the responsibilities with the given parameters \\(\\phi, \\mu, \\Sigma\\). So for each example \\(i\\) and each component (distribution) \\(j\\), the amount of \\(x^{(i)}\\) that is generated by the component \\(j\\) is given by:\n\n\n\\begin{align}\nw^{(i)}_j = P(z^{(i)} = j | x^{(i)}; \\phi_j, \\mu_j, \\Sigma_j)\n\\end{align}\n\n\nBy Bayes' Rule, we can rewrite the equation as follows:\n\n\n\\begin{align}\nw^{(i)}_j = \\frac{P(x^{(i)}|z^{(i)} = j)P(z^{(i)} = j)}{\\sum_{l=1}^K \\left[P(x^{(i)}|z^{(i)} = l)P(z^{(i)} = l)\\right]}\n\\end{align}\n\n\nNote that the likelihood \\(P(x^{(i)}|z^{(i)} = j)\\) and each likelihood \\(P(x^{(i)}|z^{(i)} = l)\\) come from a Gaussian distribution, therefore:\n\n\n\\begin{align}\nP(x^{(i)}|z^{(i)} = j) = \\frac{1}{(2\\pi)^{\\frac{n}{2}}|\\Sigma_j|^{\\frac{1}{2}}} \\exp\\left(-\\frac{1}{2}(x^{(i)} - \\mu_j)^T \\Sigma_j^{-1} (x^{(i)} - \\mu_j)\\right) \\tag{2}\n\\end{align}\n\n\nTo simplify notation we will denote \\(P(x^{(i)}|z^{(i)} = j)\\) as \\(\\mathcal{N}(\\mu_j, \\Sigma_j)\\). On the other hand, the prior \\(P(z^{(i)} = j)\\) comes from a Multinomial distribution, hence:\n\n\n\\begin{align}\nP(z^{(i)} = j) = \\phi_j \\tag{3}\n\\end{align}\n\n\nCombining all the expressions:\n\n\n\\begin{align}\nw^{(i)}_j = \\frac{\\phi_j\\mathcal{N}(\\mu_j, \\Sigma_j)}{\\sum_{l=1}^K \\left[\\phi_l\\mathcal{N}(\\mu_l, \\Sigma_l)\\right]} \\tag{4}\n\\end{align}\n\n\nAll that is left to do is plug all of the values into each equation \\((2)\\) and \\((3)\\) (this values are known, given the equations are written in terms of the distributions' parameters) and compute each \\(w^{(i)}_j\\) given \\((4)\\).\n\n\nM-Step\n\n\nIn this step what we do is maximize the log likelihood of the distributions' parameters \\(\\theta\\), that is we maximize \\(\\mathcal{L}(\\phi, \\mu, \\sigma)\\). But first, let us see how do we maximize the parameters in GMM.\n\n\nOptimal Parameters of a GMM\n\n\nWe are going to show how to maximize the log likelihood of the parameters of a Gaussian Mixture Model. The goal of the GMM is to represent the distribution of the data as accurately as possible using a linear combination of Gaussian Distributions.\n\n\n\nGiven a dataset \\(X\\) of \\(m\\) data points, we assume they are i.i.d (independent and identically distributed), therefore the maximum likelihood estimator over \\(X\\) can be expressed as the product of the individual likelihoods. To simplify the equations, we are going to directly apply the logarithm to the MLE function:\n\n\n\\begin{align}\n\\log \\mathcal{L}(X|\\theta) = \\log p(X|\\theta) = \\log \\prod_{i=1}^m p(x^{(i)}|\\theta) = \\sum_{i=1}^m \\log p(x^{(i)}|\\theta)\n\\end{align}\n\n\nBy \\((1)\\) we know that \\(p(x^{(i)}|\\theta)\\) is a linear combination of Gaussian distributions, therefore:\n\n\n\\begin{align}\n\\log \\mathcal{L}(X|\\theta) = \\sum_{i=1}^n \\log \\sum_{j=1}^K \\phi_j^{(i)}\\mathcal{N}(x^{(i)}|\\mu_j, \\Sigma_j)\n\\end{align}\n\n\nThis equation is not tractable, so we won't get an analytical solution by just taking the its derivative with respect to \\(\\theta\\) and setting it to 0. The following set of equations outline how we would evaluate it:\n\n\n\\begin{align}\n\\frac{\\delta \\mathcal{L}}{\\delta \\mu_j} \\sum_{i=1}^m \\frac{\\delta \\log p(x^{(i)}|\\theta)}{\\delta \\mu_j} = 0^T\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta \\mathcal{L}}{\\delta \\Sigma_j} \\sum_{i=1}^m \\frac{\\delta \\log p(x^{(i)}|\\theta)}{\\delta \\Sigma_j} = 0\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta \\mathcal{L}}{\\delta \\phi_j} \\sum_{i=1}^m \\frac{\\delta \\log p(x^{(i)}|\\theta)}{\\delta \\phi_j} = 0\n\\end{align}\n\n\nObserve that the computation of each parameter from \\(\\theta (\\mu, \\Sigma, \\phi)\\) depends on the other parameters in a complex way. To solve those equations, we can use the strategy of optimizing some parameters while keeping the others fixed.\n\n\n\n\n\nGoing back to the Expectation Maximization Algorithm, there is a way of updating the individual parameters of a GMM given prior (initialized at random) parameters \\(\\mu, \\Sigma, \\phi\\). This approach works by updating some parameters while keeping the others fixed. So, by solving the derivatives presented above we derive the three following updating rules:\n\n\n\\begin{align}\n\\hat{\\mu}_j = \\frac{\\sum_{i=1}^m w^{(i)}_jx^{(i)}}{\\sum_{l=1}^m w^{(l)}_j}\n\\end{align}\n\n\\begin{align}\n\\hat{\\Sigma}_j = \\frac{\\sum_{i=1}^m w^{(i)}_j (x^{(i)} - \\hat{\\mu}_j)(x^{(i)} - \\hat{\\mu}_j)^T}{\\sum_{l=1}^m w^{(l)}_j}\n\\end{align}\n\n\\begin{align}\n\\hat{\\phi}_j = \\frac{1}{m} \\sum_{i=1}^m w^{(i)}_j\n\\end{align}\n\n\nTo simplify a bit the notation, if \\(N_j = \\sum_{l=1}^m w^{(i)}_l\\):\n\n\n\\begin{align}\n\\hat{\\mu}_j = \\frac{1}{N_j} \\sum_{i=1}^m w^{(i)}_jx^{(i)}\n\\end{align}\n\n\\begin{align}\n\\hat{\\Sigma}_j = \\frac{1}{N_j}\\sum_{i=1}^m w^{(i)}_j (x^{(i)} - \\hat{\\mu}_j)(x^{(i)} - \\hat{\\mu}_j)^T\n\\end{align}\n\n\\begin{align}\n\\hat{\\phi}_j = \\frac{N_j}{m}\n\\end{align}\n\n\nNote that the update of \\(\\mu, \\Sigma, \\phi\\), all depend on the responsibilities (\\(w^{(i)}_j\\)), which by its turn, depends on \\(\\mu, \\Sigma, \\phi\\). That’s why there's not a closed-form solution to equations.\n\n\n\nFurthermore these equations do not aim to precisely maximize over \\(\\theta\\) the actual log likelihood. Instead they maximize a proxy function of the log-likelihood over \\(\\theta\\), namely, the expected log-likelihood, which can be derived from the log-likelihood using Jensen's Inequality as follows:\n\n\n\\begin{align}\n\\hat{\\mathcal{L}}(X|\\theta) = \\sum_{i=1}^m\\sum_{j=1}^K w^{(i)}_j \\log \\left( \\frac{\\phi_j \\mathcal{N}(x^{(i)} | \\mu_j, \\Sigma_j)}{w^{(i)}_j} \\right) \\tag{5}\n\\end{align}\n\nIterative Process\n\n\nThe process consists of an iterative process that alternates between two steps. The first step is to compute the responsibilities (E step) of each mixture component for each data point using the current parameters (\\(\\mu, \\Sigma, \\phi\\)). The second step consists of updating the parameters (M step) in order to maximize the expected log-likelihood given by \\((5)\\)\n\n \n\nThe E and M steps are repeated until there is no significant progress in the proxy function of the log-likelihood computed after the M step.\n\n\n\n\nRecap: Anomaly Detection\n\n\nThus, when the parameters \\(\\theta\\) are optimized, we can compute \\(P(x) = \\sum_{j=1}^K P(x|z = j)\\) and if \\(P(x) < \\epsilon\\) you can flag \\(x\\) as an anomaly.\n\n\n\n\nGeneralized EM Algorithm\n\nJensen's Inequality\n\nConvex function\n\n\nWe are going to show what Jensen's Inequality is about. So:\n\n\n\n\nLet \\(f\\) be a convex function (e.g. \\(f''(x) > 0\\)) and\n\n\nLet \\(x\\) be a random variable, then\n\n\n\n\\begin{align}\nf(E[x]) \\leq E[f(x)]\n\\end{align}\n\n\nwhere \\(E\\) is the expected value.\n\n\n\nFurther, if \\(f''(x) > 0\\) (we say f is strictly convex, that is f is not a straight line), then:\n\n\n\\begin{align}\nE[f(x)] = f(E[x]) \\leftrightarrow \\text{ x is a constant, more formally } X = E[X] \\text{ with probability 1}\n\\end{align}\n\nConcave function\n\n\nWe are going to apply the same arguments with a concave function. Note that a concave function equals the negative of a convex function, thus:\n\n\n\n\nLet \\(f\\) be a concave function (e.g. \\(f''(x) < 0\\)) and\n\n\nLet \\(x\\) be a random variable, then\n\n\n\n\\begin{align}\nf(E[x]) \\geq E[f(x)]\n\\end{align}\n\n\nwhere \\(E\\) is the expected value.\n\n\n\nFurther, if \\(f''(x) < 0\\) (we say f is strictly concave), then:\n\n\n\\begin{align}\nE[f(x)] = f(E[x]) \\leftrightarrow \\text{ x is a constant, more formally } X = E[X] \\text{ with probability 1}\n\\end{align}\n\nSome Intuition\n\n\nGiven any convex function (the inverse also applies to concave functions), if we draw a chord between any two points, its middle point (that is the expected value of the function or \\(E[f(x)]\\)) is always above that the value of the expected value under the function (that is \\(f(E[x])\\)). Graphically:\n\n\n\n\n\n\nMotivation\n\n\nGiven a model for \\(P(x, z , \\theta)\\) where \\(\\theta\\) are the parameters of the model. We only observe \\(X = \\{x^{(1)}, \\cdots, x^{(m)}\\}\\).\n\n\n\nThe goal is to obtain by the Maximum Likelihood Estimation the value of \\(\\theta\\) that maximizes the log likelihood, defined as:\n\n\n\\begin{align}\n\\theta = \\underset{\\theta}{\\arg \\max{l(\\theta)} }  = \\sum_{i=1}^m \\log (P(x^{(i)}; \\theta))\n\\end{align}\n\n\nIf we marginalize \\(z^{(i)}\\):\n\n\n\\begin{align}\n\\theta = \\underset{\\theta}{\\arg \\max{l(\\theta)} } = \\sum_{i=1}^m \\log \\sum_{z^{(i)}} (P(x^{(i)}, z^{(i)}; \\theta))\n\\end{align}\n\nE-Step\n\n\nIn the E-Step we construct a lower bound from a given theta: so, let's say \\(l(\\theta)\\) is the log likelihood.\n\n\n\nOn the first iteration, the graph would be as follows:\n\n\n\n\n\n\n\nAnd on the second iteration:\n\n\n\n\n\n\n\nWe iterate until there are no significant changes in the lower bound, that is the algorithm converges to a local optimum (it should be noted the optimum is local not absolute, and it depends on the initialization of the distributions' parameters).\n\n\nM-Step\n\n\nNow, in the M-Step we maximize the log likelihood as follows:\n\n\n\\begin{align}\n\\underset{\\theta}{\\max{ }} \\sum_{i=1}^m \\log P(x^{(i)}; \\theta)\n\\end{align}\n\n\nBy marginalizing \\(z^{(i)}\\):\n\n\n\\begin{align}\n\\underset{\\theta}{\\max{ }} \\sum_{i=1}^m \\log \\sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \\theta)\n\\end{align}\n\n\nWe now introduce a probability distribution over \\(z^{(i)}\\) (thus \\(\\sum_{z^{(i)}}Q(z^{(i)}) = 1\\)), and we multiply by \\(\\frac{Q(z^{(i)})}{Q(z^{(i)})}\\):\n\n\n\\begin{align}\n\\underset{\\theta}{\\max{ }} \\sum_{i=1}^m \\log \\sum_{z^{(i)}} Q(z^{(i)}) \\frac{P(x^{(i)}, z^{(i)}; \\theta)}{Q(z^{(i)})}\n\\end{align}\n\n\nNow, by the definition of expected value (Given a sequence of real values \\(a_1, \\cdots, a_n\\) with probabilities \\(p_1, \\cdots, p_n\\), the expected value is defined as: \\(e = \\sum_{i=1}^n p_i a_i\\)), if \\(p_i = Q(z^{(i)})\\) and \\(a_i = \\frac{P(x^{(i)}, z^{(i)}; \\theta)}{Q(z^{(i)})}\\)\n\n\n\\begin{align}\n\\underset{\\theta}{\\max{ }} \\sum_{i=1}^m \\log E_{z^{(i)}\\sim Q} \\left[\\frac{P(x^{(i)}, z^{(i)}; \\theta)}{Q(z^{(i)})}\\right]\n\\end{align}\n\n\nIf we apply the concave version of Jensen's Inequality we obtain a lower bound of the form:\n\n\n\\begin{align}\n\\sum_{i=1}^m \\log E_{z^{(i)}\\sim Q} \\left[\\frac{P(x^{(i)}, z^{(i)}; \\theta)}{Q(z^{(i)})}\\right] \\geq \\sum_{i=1}^m E_{z^{(i)} \\sim Q} \\left[\\log \\frac{P(x^{(i)}, z^{(i)}; \\theta)}{Q(z^{(i)})}  \\right]\n\\end{align}\n\n\nIf \\(\\log (x) = f(x)\\), then this equation can be mapped to the inequality:\n\n\n\\begin{align}\nf(E[x]) \\geq E[f(x)]\n\\end{align}\n\n\nNote that \\(log\\) is a concave function. If we \"unpack\" the expected value:\n\n\n\\begin{align}\n\\sum_{i=1}^m E_{z^{(i)} \\sim Q} \\left[\\log \\frac{P(x^{(i)}, z^{(i)}; \\theta)}{Q(z^{(i)})}  \\right] = \\sum_{i=1}^m \\sum_{z^{(i)}} \\log Q(z^{(i)}) \\left[\\frac{P(x^{(i)}, z^{(i)}; \\theta)}{Q(z^{(i)})}\\right]\n\\end{align}\n\nMake Log Likelihood and Lower Bound Equal on Theta\n\n\nFor each \\(\\theta\\) on the E-Step you wan the value of \\(\\theta\\) under the lower bound function to be equal to \\(l(\\theta)\\), which is what guarantees that when you optimize the lower bound you optimize \\(l(\\theta)\\).\n\n\n\nSo, for a given iteration the current value of \\(\\theta\\), denoted by \\(\\hat{\\theta}\\), we want:\n\n\n\\begin{align}\n\\sum_{i=1}^m \\log E_{z^{(i)}\\sim Q} \\left[\\frac{P(x^{(i)}, z^{(i)}; \\hat{\\theta})}{Q(z^{(i)})}\\right] = \\sum_{i=1}^m E_{z^{(i)} \\sim Q} \\left[\\log \\frac{P(x^{(i)}, z^{(i)}; \\hat{\\theta})}{Q(z^{(i)})}  \\right]\n\\end{align}\n\n\nRemember, by the extension on Jensen's Inequality we know that \\(E[f(x)] = f(E[x])\\) if and only if \\(x\\) is a constant. In this case \n\n\n\\begin{align}\nx = \\frac{P(x^{(i)}, z^{(i)}; \\hat{\\theta})}{Q(z^{(i)})} = constant\n\\end{align}\n\n\nFor this to hold, we need \\(Q(z^{(i)})\\) to be directly proportional to \\(P(x^{(i)}, z^{(i)}; \\hat{\\theta})\\) (so when one is bigger the other is bigger and vice versa, so the ratio between the two remains constant). So:\n\n\n\\begin{align}\nQ(z^{(i)}) \\propto P(x^{(i)}, z^{(i)}; \\hat{\\theta})\n\\end{align}\n\n\nBecause \\(\\sum_{z^{(i)}}Q(z^{(i)}) = 1\\), a way to ensure this is to set each \\(Q^{(i)} = P(x^{(i)}, z^{(i)}; \\hat{\\theta})\\) and then normalize it to make sure the sum of \\(Q\\) over \\(z^{(i)}\\) equals one. Hence:\n\n\n\\begin{align}\nQ(z^{(i)}) = \\frac{P(x^{(i)}, z^{(i)}; \\hat{\\theta})}{\\sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \\hat{\\theta})}\n\\end{align}\n\n\nIt turns out you can further derive this equation to be:\n\n\n\\begin{align}\nQ(z^{(i)}) = P(z^{(i)}|x^{(i)}; \\hat{\\theta})\n\\end{align}\n\nPutting Everything Together\n\n\nSo, after everything we have seen, we can summarize the EM generalized algorithm as follows: If \\(\\theta\\) is the value of the parameters in the current iteration:\n\n\n\n\nE-Step: set \n\\begin{align}\nQ_i(z^{(i)}) = P(z^{(i)}|x^{(i)}; \\theta)\n\\end{align}\n\n\nM-Step: set \n\\begin{align}\n\\theta := \\underset{\\theta}{\\arg \\max} \\sum_{i=1}^m \\sum_{z^{(i)}} Q_i(z^{(i)}) \\log \\left[\\frac{P(x^{(i)}, z^{(i)};\\theta)}{Q_i(z^{(i)})}\\right]\n\\end{align}\n\n\n\nDerive EM for GMM from the Generalized Algorithm\n\n\nGiven a model described by:\n\n\n\n\n\\(P(x^{(i)}, z^{(i)}) = P(x^{(i)}|z^{(i)}) P(z^{(i)})\\)\n\n\nwhere \\(z^{(i)} \\sim Multinomial(\\phi)\\) (which means \\(P(z^{(i)} = j) = \\phi_j\\))\n\n\nand \\(x^{(i)} | z^{(i)} \\sim \\mathcal{N}(\\mu_j, \\Sigma_j)\\)\n\n\n\nE-Step\n\n\nOn the E-Step we compute:\n\n\n\n\\(Q_i(z^{(i)}) P(z^{(i)} = j | x^{(i)}; \\phi, \\mu, \\Sigma)\\)\n\n\n\nIf we look at E-Step from GMM's we can see that the expression above equals \\(w^{(i)}_j\\).\n\n\nM-Step\n\n\nNow on the M-Step what we do is maximize the lower bound we have constructed in the E-Step. For that we need to compute the value of the parameters \\(\\phi, \\mu, \\Sigma\\) that maximize this function, that is:\n\n\n\\begin{align}\n\\underset{\\phi, \\mu, \\Sigma}{\\max} \\sum_{i=1}^m \\sum_{z^{(i)}} Q_i(z^{(i)}) \\log \\left( \\frac{P(x^{(i)}, z^{(i)}; \\phi, \\mu, \\Sigma)}{Q_i(z^{(i)})} \\right) =\n\\end{align}\n\n\nAs we know \\(Q_i(z^{(i)}) = w^{(i)}_j\\) and \\(P(x^{(i)}, z^{(i)}) = P(x^{(i)}|z^{(i)}) P(z^{(i)})\\), thus:\n\n\n\\begin{align}\n= \\sum_{i=1}^m \\sum_{j}^K w^{(i)}_j \\log \\left( \\frac{P(x^{(i)}|z^{(i)} = j, \\mu_j, \\Sigma_j) P(z^{(i)} = j)}{w^{(i)}_j} \\right)\n\\end{align}\n\n\nWe also know that \\(P(z^{(i)} = j) = \\phi_j\\) and \\(x^{(i)} | z^{(i)} \\sim \\mathcal{N}(\\mu_j, \\Sigma_j)\\), therefore:\n\n\n\\begin{align}\n= \\sum_{i=1}^m \\sum_{j}^K w^{(i)}_j \\log \\left( \\frac{\\mathcal{N}(x^{(i)}; \\mu_j, \\Sigma_j) \\phi_j}{w^{(i)}_j} \\right)\n\\end{align}\n\n\nWhere:\n\n\n\\begin{align}\n\\mathcal{N}(x^{(i)}; \\mu_j, \\Sigma_j) = \\frac{1}{(2\\pi)^{1/2}|\\Sigma_j|^{1/2}} \\exp \\left( -\\frac{1}{2}(x^{(i)} - \\mu_j)^T \\Sigma_j^{-1}(x^{(i)} - \\mu_j)\\right)\n\\end{align}\n\n\n\n\nFrom now on we denote \\(\\sum_{i=1}^m \\sum_{j}^K w^{(i)}_j \\log \\left( \\frac{\\mathcal{N}(x^{(i)}; \\mu_j, \\Sigma_j) \\phi_j}{w^{(i)}_j} \\right)\\) as \\(\\mathcal{L}(\\phi, \\mu, \\Sigma)\\):\n\n\n\nTo maximize this formula over \\(\\phi, \\mu\\) and \\(\\Sigma\\) you have to compute the derivatie of the function with respect to each parameter, such that:\n\n\n\n\n\\(\\Delta_{\\mu_j} (\\mathcal{L}(\\phi, \\mu, \\Sigma)) = 0\\), then: \\(\\mu_j = \\sum_{i}^m \\frac{w^{(i)}_j x^{(i)}_j}{w^{(i)}_j}\\) (same as in M-Step in GMM's)\n\n\n\\(\\Delta_{\\Sigma_j} (\\mathcal{L}(\\phi, \\mu, \\Sigma)) = 0\\) and\n\n\n\\(\\Delta_{\\phi_j} (\\mathcal{L}(\\phi, \\mu, \\Sigma)) = 0\\)\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/SVM/Optimal Margin Classifier.html",
    "title": "Optimal Margin Classifier",
    "body": "\n\nBack\n\n\nOptimal Margin Classifier\n\n\n\n\nWe use this classifier to categorize datasets that are perfectly separable, that is to say, we use it over data that is linearly separable. This classifier will help us find the green line we saw in the geometric margin.\n\n\n\nWhat the optimal margin classifier does is choose the parameters \\(w, b\\) that maximize \\(\\gamma\\)\n\n\n\nOne way to solve this optimization problem is:\n\n\n\\begin{align}\n\\underset{\\gamma, w, b}{\\max} \\gamma\n\\end{align}\n\n\nsubject to\n\n\n\\begin{align}\n\\frac{y^{(i)}(w^Tx + b)}{||w||} \\geq \\gamma\n\\end{align}\n\n\nThis will cause the maximization of the geometric margin with respect to the training set. The restriction means that we want to maximize \\(\\gamma\\) while having every example have a geometric margin of at least \\(\\gamma\\).\n\n\n\n\n\nBecause this is a non-convex problem, we will transform it. Given \\(\\gamma = \\frac{\\hat{\\gamma}}{||w||}\\), then \\(\\gamma \\cdot ||w|| = \\hat{\\gamma}\\), and so if we multiply in the subject both sides by \\(||w||\\):\n\n\n\\begin{align}\n\\frac{y^{(i)}(w^Tx + b)}{||w||} \\cdot ||w|| \\geq \\gamma \\cdot ||w|| \\Leftrightarrow y^{(i)}(w^Tx + b) \\geq \\hat{\\gamma}\n\\end{align}\n\n\nand the optimization problem can be re-written as:\n\n\n\\begin{align}\n\\underset{\\hat{\\gamma}, w, b}{\\max} \\frac{\\hat{\\gamma}}{||w||}\n\\end{align}\n\n\nsubject to\n\n\n\\begin{align}\ny^{(i)}(w^Tx + b) \\geq \\hat{\\gamma}\n\\end{align}\n\n\nHowever, we are still stuck with a non-convex objective \\(\\frac{\\hat{\\gamma}}{||w||}\\). Because, as we've said previously scaling the functional margin (changing the magnitude of \\(w^Tx + b\\)) does not change the decision boundary itself, we will add an scaling constraint that the functional margin of \\(w, b\\) with respect to the training set must be 1: \\(\\hat{\\gamma} = 1\\) \n\n\n\nObserve, now, that maximizing \\(\\frac{\\hat{\\gamma}}{||w||} = \\frac{1}{||w||}\\) is like minimizing \\(||w||^2\\), we re-write the optimization problem as follows:\n\n\n\\begin{align}\n\\underset{w, b}{\\min} ||w||^2\n\\end{align}\n\n\nsubject to\n\n\n\\begin{align}\ny^{(i)}(w^Tx + b) \\geq 1\n\\end{align}\n\n\n\n\nWe will revise once more the optimization problem for the Optimal Margin Classifier. First, we have to suppose two facts:\n\n\n\n\nBy the representer theorem we can assume that \\(w\\) can be expressed as a linear combination of \\(x\\), that is:\n\n\n\n\\begin{align}\nw = \\sum_{i=1}^m \\alpha_i x^{(i)}\n\\end{align}\n\n\nLet's review this claim with logistic regression. We know that we apply stochastic gradient descent (we update \\(\\Theta\\) for every example, instead of summing all the examples) on \\(\\Theta\\) as follows:\n\n\n\\begin{align}\n\\Theta = \\Theta - \\alpha (h_\\Theta(x^{(i)}) - y^{(i)})x^{(i)}\n\\end{align}\n\n\nWhich means that in every interation we are updating \\(\\Theta\\) by adding or substracting a factor \\(\\alpha_i\\) multiplied by \\(x^{(i)}\\). Therefore we can show by mathematical induction that if we start with \\(\\theta_0 = c\\), where \\(c\\) is a constant and go on adding and substracting \\(Ax^{(i)}\\), where \\(A= \\alpha (h_\\Theta(x^{(i)}) - y^{(i)})\\), then \\(w\\) can be expressed as a linear combination of \\(x\\).\n\n\n\nYou can also derive the gradient descent expression in our optimization problem, and show that in this case \\(w\\) is also a linear combination of \\(x\\). We can rewrite \\(w\\) as follows:\n\n\n\\begin{align}\nw = \\sum_{i=1}^m \\alpha_i y^{(i)} x^{(i)}\n\\end{align}\n\n\n\nGiven any decision boundary, the vector \\(w\\) is always orthogonal to the decision boundary:\n\n\n\n\n\n\n\n\n\n\nNow, the optimization problem becomes (note \\(w^2 = w^Tw\\)):\n\n\n\\begin{align}\n\\underset{w, b}{min} \\frac{1}{2}||w||^2  = \\underset{w, b}{min} \\frac{1}{2} (\\sum_{i=1}^m \\alpha_i y^{(i)} x^{(i)})^T(\\sum_{j=1}^m \\alpha_j y^{(j)} x^{(j)}) = \n\\end{align}\n\n\\begin{align}\n\\underset{w, b}{min} \\frac{1}{2} \\sum_{i=1}^m\\sum_{j=1}^m \\alpha_i \\alpha_j y^{(i)}y^{(j)}(x^{(i)})^Tx^{(j)}\n\\end{align}\n\n\nWe now denote the inner product of \\((x^{(i)})^T x^{(j)}\\) as \\(\\langle x^{(i)}, x^{(j)} \\rangle\\), so:\n\n\n\\begin{align}\n\\underset{w, b}{min} \\frac{1}{2} \\sum_{i=1}^m\\sum_{j=1}^m \\alpha_i \\alpha_j y^{(i)}y^{(j)} \\langle x^{(i)}, x^{(j)} \\rangle\n\\end{align}\n\n\nAnd the restriction of the optimization becomes:\n\n\n\\begin{align}\ny^{(i)}(w^Tx^{(i)} + b) \\geq 1 \\rightarrow y^{(i)}((\\sum_{j=1}^m \\alpha_j y^{(j)}x^{(j)})^Tx^{(i)} + b) \\geq 1 \\rightarrow\n\\end{align}\n\n\\begin{align}\ny^{(i)}((\\sum_{j=1}^m \\alpha_j y^{(j)}(x^{(j)})^Tx^{(i)}) + b) \\geq 1 \\rightarrow y^{(i)}((\\sum_{j=1}^m \\alpha_j y^{(j)} \\langle x^{(j)}, x^{(i)} \\rangle) + b) \\geq 1\n\\end{align}\n\n\nApplying convex optimization theory you can simplify this optimization problem further to:\n\n\n\\begin{align}\n\\underset{\\alpha}{max} \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\sum_{i=1}^m\\sum_{j=1}^m y^{(i)}y^{(j)}\\alpha_i\\alpha_j\\langle x^{(i)}, x^{(j)}\\rangle\n\\end{align}\n\n\nsubject to\n\n\n\\begin{align}\n\\alpha_i \\geq 0\n\\end{align}\n\\begin{align}\n\\sum_{i=1} y^{(i)}\\alpha_i = 0, i=1, \\cdots,m\n\\end{align}\nTrain the Classifier\n\n\nTo train the SVM we have to solve the optimization problem for \\(\\alpha\\)\n\n\nClassify an example\n\n\nTo predict an example \\(x\\): \n\n\n\\begin{align}\nh_{w,b} = g(w^Tx + b) = g\\left(\\left(\\sum_{i=1}^m \\alpha_i y^{(i)}x^{(i)}\\right)^Tx + b\\right) = g\\left(\\left(\\sum_{i=1}^m \\alpha_i y^{(i)} \\langle x^{(i)}, x^{(j)} \\rangle\\right) + b\\right)\n\\end{align}\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/SVM/Geometric Margin.html",
    "title": "Geometric Margin",
    "body": "\n\nBack\n\n\nGeometric Margin\n\n\n\nIntuition\n\n\nFirst of all, let's assume we have a dataset that is linearly separable like:\n\n\n\n\n\n\n\nHere we have two examples of two decision boundaries that do classify correctly all of the samples. However the red one looks worse than the green one. \n\n\n\nThat is because for the red one there are some examples that are very close to the boundary compared to the rest. Whereas for the green one there is a bigger separation.\n\n\n\nSo, first we define a line by the equation \\(w^Tx + b = 0\\), therefore:\n\n\n\n\nevery example \\(x\\) that lies to the left of the line satisfies \\(w^Tx + b < 0\\) and\n\n\nevery example \\(x\\) that lies to the right of the line satisfies \\(w^Tx + b > 0\\)\n\n\n\n\nFurthermore the geometric margin with respect to a single example \\((x^{(i)}, y^{(i)})\\) is the euclidean distance between the point \\((x^{(i)}, y^{(i)})\\) and the line we have defined as \\(w^Tx + b = 0\\).\n\n\nEuclidean distance to the decision boundary\n\n\nThe decision boundary corresponding to (w, b) is shown, along with the vector w. Note that w is orthogonal (at 90º) to the separating hyperplane.\n\n\n\n\n\n\n\nConsider the point at \\(A\\), which represents the example \\(x^{(i)}\\) with \\(y^{(i)} = 1\\). Its distance to the decision boundary, denoted by \\(\\gamma^{(i)}\\), is given by the line segment \\(AB\\).\n\n\n\nHow do we find \\(\\gamma^{(i)}\\):\n\n\n\n\nWe know \\(\\frac{w}{||w||}\\) is a unit length vector pointing to the same direction as \\(w\\).\n\n\nAlso \\(A = x^{(i)}\\)\n\n\n\n\nWe also know that the vector between points \\(A\\) and \\(B\\) is defined like \\(A - B\\), in this scenario, \\(A - B = \\gamma^{(i)}\\frac{w}{||w||}\\), where \\(\\gamma^{(i)}\\) is the length of the vector and \\(\\frac{w}{||w||}\\) is the direction of the vector.\n\n\n\n\nThus if we solve for \\(B\\), \\(B = x^{(i)} - \\gamma^{(i)}\\frac{w}{||w||}\\)\n\n\nFurthermore, \\(B\\) lies on the decision boundary, therefore:\n\n\n\n\\begin{align}\nw^T(B) + b = 0 \\rightarrow w^T\\left(x^{(i)} - \\gamma^{(i)}\\frac{w}{||w||}\\right) + b = 0\n\\end{align}\n\n\nSolving for \\(y^{(i)}\\) yields:\n\n\n\\begin{align}\n\\gamma^{(i)} = \\frac{w^Tx^{(i)} + b}{||w||} = \\left(\\frac{w}{||w||}\\right)^Tx(i) + \\frac{b}{||w||}\n\\end{align}\n\n\nFormal definition\n\n\nThe geometric margin of the hyperplane \\((w, b)\\) with respect to \\((x^{(i)}, y^{(i)})\\) is defined as:\n\n\n\\begin{align}\n\\gamma^{(i)} = \\frac{w^T x^{(i)} + b}{||w||}\n\\end{align}\n\n\nThis is the definition for a positive example (\\(y^{(i)} = 1\\)), and measures the euclidean distance from the decision boundary to the example \\((x^{(i)}, y^{(i)})\\). \n\n\n\nIf we generalize, as to compute the geometric margin for both positive and negative examples:\n\n\n\\begin{align}\n\\gamma^{(i)} = \\frac{y^{(i)} (w^T x^{(i)} + b)}{||w||}\n\\end{align}\n\nEvaluation\n\n\nTo evaluate the geometric margin with respect to the training set we make use of the worst case notion:\n\n\n\\begin{align}\n\\gamma = \\underset{i}{\\min} \\gamma^{(i)} \n\\end{align}\n\n\nThat is, we evaluate how well we are doing in the worst example.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/SVM/SVM.html",
    "title": "SVM",
    "body": "\n\nBack\n\n\nSVM\n\n\n\n\n\nNotation\n\n\nFunctional Margin\n\n\nGeometric Margin\n\n\nFunctional and Geometric Margin\n\n\nOptimal Margin Classifier\n\n\nSVM\n\n\n\nKernels\n\n\n\nThe Kernel Trick\n\n\nApplying Kernels\n\n\nValidity of Kernels\n\n\n\nGenerality of the Kernel Trick\n\n\n\nL1-Norm Soft Margin SVM\n\n\n\nOutliers\n\n\nOptimization\n\n\n\nKernel Examples\n\n\n\n\n\n\nThe Support Vector Machine allows you to find potential non-linear decision boundaries:\n\n\n\n\n\n\n\nSVM provides an algorithm that:\n\n\n\n\nMaps a vector of features to a vector of features of a much higher dimension (manually picking the new features is difficult, that is why we automate it with these types of algorithms)\n\\begin{align}\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\end{bmatrix} \\rightarrow \n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_1^2 \\\\\nx_2^2 \\\\\nx_1\\cdot x_2 \\\\\n\\vdots\n\\end{bmatrix}\n\\end{align}\n\n\n\n\n\nApplies a linear classifier over the high dimensional features (Note: if you apply logistic regression to high dimensional vectors then it can learn non-linear decision boundaries)\n\n\n\nNotation\n\n\n\nLabels: \\(y^{(i)} \\in \\{-1, +1\\}\\)\n\n\nNow the hypothesis outputs a \\(1\\) or a \\(-1\\), which means:\n\n\n\n\\begin{align}\ng(z) = \n\\begin{cases}\n1, & \\text{ if } z \\geq 0 \\\\\n0, & \\text{ otherwise } \\\\\n\\end{cases}\n\\end{align}\n\n\nThat is, now instead of a smooth transition of probabilities from zero to one, we have a hard transition between \\(1\\) and \\(-1\\).\n\n\n\n\nWeights: now the weights \\(\\Theta \\in \\mathbb{R}^{(n+1)}\\), where \\(\\theta_0 = 1\\) are divided into: \\(w \\in \\mathbb{R}^{(n)}\\) and \\(b \\in \\mathbb{R}\\). Thus we drop the convention of assigning \\(x_0 = 1\\).\n\n\nAlso now the hypothesis function is defined as: \\(h_{w,b}(x) = g(w^Tx + b) = g((\\sum_{i=1}^n w_i x) + b)\\)\n\n\n\nFunctional Margin\n\n\nFunctional Margin\n\n\n\nGeometric Margin\n\n\nGeometric Margin\n\n\n\nRelationship between Functional Margin and Geometric Margin\n\n\nAs you may have picked up we can stablish an equality between both margins:\n\n\n\\begin{align}\n\\gamma^{(i)} = \\frac{\\hat{\\gamma}^{(i)}}{||w||}\n\\end{align}\n\nOptimal Margin Classifier\n\n\nOptimal Margin Classifier\n\n\nSVM\n\nKernels\n\nKernel Trick\n\n\nTo apply kernels first we will lay out the kernel trick:\n\n\n\n\nWrite the algorithm in terms of the inner products of the training examples \\(\\langle x^{(i)}, x^{(j)} \\rangle=(\\langle x, z \\rangle)\\) \n\n\nLet there be a mapping \\(x \\rightarrow \\phi(x)\\), where \\(\\phi(x)\\) is a high dimensional feature vector.\n\n\nFind a way to compute \\(K(x, z) = \\phi(x)^T\\phi(z)\\), even if \\(x, z\\) are very high dimensional features vectors (which would be very computationally expensive). Where \\(K(x, z)\\) is denoted as the kernel function\n\n\nReplace \\(\\langle x, z \\rangle\\) with \\(K(x, z)\\)\n\n\n\nApplying Kernels\n\n\n\nGiven \\(x, z \\in \\mathbb{R}^n\\), where:\n\n\n\n\\begin{align}\nx = \\begin{bmatrix}\nx_1 \\\\\n\\vdots \\\\ \nx_n \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nWe define the mapping \\(\\phi(x) \\in \\mathbb{R}^{n^2}\\) as follows:\n\n\n\\begin{align}\n\\phi(x) = \\begin{bmatrix}\nx_ix_i \\\\\n\\end{bmatrix}\n\\end{align}\n\n\n\\(\\forall i, j\\) with \\(1 \\leq i,j \\leq n\\)\n\n\n\nSo we have \n\n\n\\begin{align}\nK(x, z) = \\phi(x)^T \\phi(z) = \\sum_{i=1}^{n^2} \\phi(x)_i \\phi(z)_i = \\sum_{i=1}^n \\sum_{j=1}^n (x_ix_j) (z_iz_j)\n\\end{align}\n\n\nWhich would take \\(O(n^2)\\) time to compute. But, observe that:\n\n\n\\begin{align}\n(x^Tz)^2 = (x^Tz)^T(x^Tz) = \\sum_{i=1}^n\\sum_{j=1}^n (x_iz_i)(x_jz_j) = \\sum_{i=1}^n\\sum_{j=1}^n (x_ix_j)(z_iz_j)\n\\end{align}\n\n\nwhick takes \\(O(n)\\) time to compute.\n\n\n\nSo we conclude that the kernel can be defined as \\(K(x, z) = (x^Tz)^n\\)\n\n\n\n\n\n\nGiven \\(x, z \\in \\mathbb{R}^n\\)\n\n\n\n\\(K(x, z) = (x^Tz + c)^2\\)\n\n\nWhere the mapping function \\(\\phi\\) is defined as: given\n\n\n\n  \n\\begin{align}\nx = \\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nThen:\n\n\n\\begin{align}\n\\phi(x) = \\begin{bmatrix}\nx_1x_1 \\\\\nx_1x_2 \\\\\nx_2x_1 \\\\\nx_2x_2 \\\\\n\\sqrt{2c}x_1 \\\\\n\\sqrt{2c}x_2 \\\\\n\\end{bmatrix}\n\\end{align}\n\n\n\n\n\nGiven \\(x, z \\in \\mathbb{R}^n\\)\n\n\n\n\\(K(x, z) = (x^Tz+ c)^d\\)\n\n\nWhere \\(\\phi(x)\\) contains the \\(\\binom{n+d}{d}\\) combinations of monomials of degree d. (Note: a monomial of degree 3 could be \\(x_1x_2x_3\\) or \\(x_1x_2^2\\), etc)\n\n\n\n\nValidity of Kernels\n\n\nTo test is a Kernel is valid we use Mercer's Theorem that says:\n\n\n\nK is a valid kernel function (i.e. \\(\\exists \\phi\\) such that \\(K(x, z) = \\phi(x)^T\\phi(z)\\)) if and only if for any \\(d\\) points \\(\\{x^{(1)}, \\cdots , x^{(d)}\\}\\) the corresponding kernel matrix \\(K\\) is positive semi-definite, that is \\(K \\geq 0\\)\n\n  \n\nWe are going to prove the first part of this theorem:\n\n  \n\nGiven examples \\(\\{x^{(1)}, \\cdots , x^{(d)}\\}\\), let \\(K \\in \\mathbb{R}^{d\\times d}\\), be the kernel matrix, such that \n\n    \n\\begin{align}\nK_{ij} = K(x^{(i)}, x^{(j)})\n\\end{align}\n\n\nThen, if \\(K\\) is a valid kernel:\n\n\n\\begin{align}\nz^TKz = \\sum_{i=1}^d \\sum_{j=1}^d z_i^T K_{ij} z_j = \\sum_{i=1}^d \\sum_{j=1}^d z_i^T \\phi(x^{(i)})^T \\phi(x^{(j)}) z_j =\n\\end{align}\n\n\nWe expand \\(\\phi(x^{(i)})^T \\phi(x^{(j)})\\) as follows:\n\n\n\\begin{align}\n= \\sum_{i=1}^d \\sum_{j=1}^d z_i^T \\left[\\sum_{k=1}^d (\\phi(x^{(i)}))_k (\\phi(x^{(j)}))_k\\right] z_j =\n\\end{align}\n\n\nNow, if we rearrange the sums:\n\n\n\\begin{align}\n= \\sum_{k=1}^d \\left[\\sum_{i=1}^d z_i (\\phi(x^{(i)}))_k\\right]^2\n\\end{align}\n\n\nSo, because the power of two of any real number is a positive number, and the sum of positive numbers is positive we derive:\n\n\n\\begin{align}\n\\sum_{k=1}^d \\left[\\sum_{i=1}^d z_i (\\phi(x^{(i)}))_k\\right]^2 \\geq 0\n\\end{align}\n\n\nWhich means that \\(K \\geq 0\\), hence \\(K\\) is a positive, semi-definite matrix\n\n\nGenerality of the Kernel Trick\n\n\nThe kernel trick can be applied to more algorithms, not only in SVM. Because, if you have any algorithm written in terms of \\(\\langle x^{(i)}, x^{(j)} \\rangle\\), you can apply the kernel trick to it. \n\n\n\nSome of the algorithms that can be re-written like this are: \n\n\n\n\nLineal Regression\n\n\nLogistic Regression\n\n\nGDM\n\n\nPCA\n\n\netc.\n\n\n\nL1-Norm Soft Margin SVM\n\n\nIt may be the case where you map your data to a very high dimensional space, but it is still not linearly separable, or the decision boundary becomes too complex:\n\n\n\n\n\n\n\nIn order to avoid this we will use a modification of the basic algorithm called L1-Norm Soft Margin SVM. With this new algorithm the optimization problem becomes\n\n\n\\begin{align}\n\\underset{w,b,\\xi_i}{min} \\frac{1}{2}||w||^2 + C \\sum_{i=1}^m \\xi_i\n\\end{align}\n\n\nsubject to\n\n\n\\begin{align}\ny^{(i)}(w^Tx^{(i)} + b) \\geq 1 - \\xi_i\n\\end{align}\n\\begin{align}\n\\xi_i \\geq 0, i = 1, \\cdots, m\n\\end{align}\n\n\nNote that if \\(x^{(i)}\\) is classified correctly then \\(y^{(i)}(w^Tx^{(i)} + b) \\geq 0\\) and therefore satisfies  \\(y^{(i)}(w^Tx^{(i)} + b) \\geq 1 - \\xi_i\\), because \\(\\xi_i \\geq 0\\)\n\n\n\nBefore the modification, the restriction forced the functional margin to be at least 1, however after the modification, because \\(\\xi_i\\) is positive we relax the restriction.\n\n\n\nAlso, we do not want \\(\\xi_i\\) to be too big, that is why it is added to the optimization objective as a cost.\n\n\nGraphical representation\n\n\nWith the addition of \\(\\xi_i\\) we are allowing some examples to have a functional margin less than 1, by setting \\(\\xi_i \\geq 0\\). For example look at the example \\(x^{(i)}\\) which has \\(\\xi_i = 0.5\\)\n\n\n\n\n\n\nOutliers\n\n\nThis relaxation on the restriction upong the geometric margin also avoids the following problem. If you have a lot of data that is linearly separable, but you have one outlier the optimal margin classifier allows for the decision boundary to be drastically changed because its optimization is based on the word performing example (which would be the outlier in this case). Thus:\n\n\n\n\n\n\n\nHowever, the L1-Norm Soft Margin SVM allows for this example to be classified incorrectly of be close to the decision boundary without changing the boundary which makes it more robuts to outliers.\n\n\nOptimization\n\n\nPicking up the Optimal Margin Classifier optimization problem, after applying the insight derived from the representer theorem, we have that the only addition needed to implement this algorithm is:\n\n\n\\begin{align}\n\\underset{\\alpha}{max} \\sum_{i=1}^m \\alpha_i - \\frac{1}{2} \\sum_{i=1}^m\\sum_{j=1}^m y^{(i)}y^{(j)}\\alpha_i\\alpha_j\\langle x^{(i)}, x^{(j)}\\rangle\n\\end{align}\n\n\nsubject to\n\n\n\\begin{align}\n\\sum_{i=1} y^{(i)}\\alpha_i = 0\n\\end{align}\n\\begin{align}\n0 \\leq \\alpha_i \\leq C, i = 1, \\cdots , m\n\\end{align}\n\n\nThe parameter \\(C\\) is a parameter your choose and it determines the level of strictness you want your model to have about some examples being misclassified.\n\n\nKernel Examples\n\n\n\nThe Gaussian Kernel: \\(K(x, z) = \\exp\\left(\\frac{||x-z||^2}{2\\sigma}\\right)\\)\n\n\nLinear Kernel: \\(K(x, z) = \\phi(x)^T\\phi(z)\\), where \\(\\phi(x) = x\\)\n\n\nPolynomial Kernel: \\(K(x, z) = (x^Tz)^d\\)\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/SVM/Functional Margin.html",
    "title": "Functional Margin",
    "body": "\n\nBack\n\n\nFunctional Margin\n\n\n\nIntuition\n\n\nThe Functional Margin describes how accurately do we classify an example. For example, for binary classification, given an example x:\n\n\n\\begin{align}\nh_\\Theta(x) = g(\\Theta x) =\n\\begin{cases}\n\\text{ predict } 1 & \\text{ if } \\Theta^T x \\geq 0, \\text{ that is } h_\\Theta(x)=g(\\Theta x) \\geq 0.5\\\\\n\\text{ predict } 0 & \\text{ otherwise } \\\\\n\\end{cases}\n\\end{align}\n\n\nLet's distinguish between the two cases when classifying an example \\(x^{(i)}\\):\n\n\n\n\n(1) If \\(y^{(i)} = 1\\), then we want \\(h_\\Theta(x) = g(\\Theta x) \\approx 1\\), which means we want \\(\\Theta \\cdot x >> 0\\). \n\n\n(2) If \\(y^{(i)} = 0\\), then we want \\(h_\\Theta(x) = g(\\Theta x) \\approx 0\\), which means we want \\(\\Theta \\cdot x << 0\\). \n\n\n\n\nAs we can see in the following graph, the bigger \\(z = \\Theta x\\) the closer \\(g(z)\\) is to one and vice versa. \n\n\n\n\n\n\nFormal Definition\n\n\nThe functional margin of the hyperplane defined by \\((w, b)\\) with respect to the example \\((x^{(i)}, y^{(i)})\\) is defined as:\n\n\n\\begin{align}\n\\hat{\\gamma}^{(i)} = y^{(i)}(w^Tx^{(i)}+b)\n\\end{align}\n\n\nSo, if we modify slightly the two statements above and use the new notation for SVMs:\n\n\n\n\nIf \\(y^{(i)} = 1\\), then we want \\(w^T \\cdot x + b >> 0\\). \n\n\nIf \\(y^{(i)} = 0\\), then we want \\(w^T \\cdot x + b << 0\\). \n\n\n\n\nThe combination of these two declarations yields the definition of the functional margin. Why?, well:\n\n\n\n\nWhen \\(y^{(i)}\\) is positive, we want to have \\(w^Tx^{(i)} + b >> 0\\) by (1), so \\(\\hat{\\gamma}^{(i)}\\) will be large, because both values are positive\n\n\nWhen \\(y^{(i)}\\) is negative, we want to have \\(w^Tx^{(i)} + b << 0\\) by (2), so \\(\\hat{\\gamma}^{(i)}\\) will be large, because both values are negative\n\n\n\n\n\n\nSo, given an example \\(x^{(i)}\\), if \\(\\hat{\\gamma}^{(i)} > 0\\) that means either\n\n\n\n\n\\(y^{(i)} = 1\\) and \\(w^Tx + b > 0\\) or \n\n\n\\(y^{(i)} = -1\\) and \\(w^Tx + b < 0\\)\n\n\n\n\nwhich shows that the classification is correct.\n\n\nEvaluation\n\n\nTo evaluate the functional margin with respect to the training set we make use of the worst case notion:\n\n\n\\begin{align}\n\\hat{\\gamma} = \\underset{i}{\\min} \\hat{\\gamma}^{(i)} \n\\end{align}\n\n\nThat is, we evaluate how well we are doing in the worst example.\n\n\nNormalizing the Functional Margin\n\n\nNote that the functional margin is very easy to cheat (to increase its value with any meaningful change to the decision boundary). Given our definition for \\(g\\):\n\n\n\\begin{align}\ng = \\begin{cases}\n1, & \\text{ if } z \\geq 0 \\\\\n-1, & \\text{ otherwise }\n\\end{cases}\n\\end{align}\n\n\nIt follows that  \\(h_{w,b}(x^{(i)}) = g(2w^Tx^{(i)} + 2b) = g(w^Tx^{(i)} + b)\\), because what matters is the sign, not the magnitude.\n\n\n\nHowever, if you scale \\(w\\) and \\(b\\) by a factor of \\(n\\) where \\(n\\) is a positive number then \\(\\gamma \\) increases because:\n\n\n\\begin{align}\n\\hat{\\gamma}^{(i)} = (w^Tx + b) \n\\end{align}\n\n\nso,\n\n\n\\begin{align}\nn \\cdot \\hat{\\gamma}^{(i)} = n \\cdot (w^Tx + b) \n\\end{align}\n\n\nwhere,\n\n\n\\begin{align}\n\\hat{\\gamma}^{(i)} < n \\cdot \\hat{\\gamma}^{(i)} \n\\end{align}\n\n\nOne way to avoid this is to normalize the length of the parameters, that is either:\n\n\n\n\nAdd a constraint where \\(||w|| = 1\\) or\n\n\nSet \\((w, b)\\) to be \\((\\frac{w}{||w||}, \\frac{b}{||b||})\\)\n\n\n\n\nIn both cases we are re-scaling the parameters.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Grandes Datasets.html",
    "title": "Grandes Datasets",
    "body": "\n\nBack\n\n\nGrandes Datasets\n\n\n\n\nCuando los conjuntos de datos son muy grandes los algoritmos son computacionalmente más caros:\n\n\n\n\nVarianza elevada: se obtiene mejor rendimiento con más ejemplos.\n\n\nSesgo/bias elevado: se obtiene mejor rendimiento con más características.\n\n\n\nStochastic Gradient Descent\n\n\nEl algoritmo de Stochastic Gradient Descent es el siguiente:\n\n\n\n\nReordenar aleatoriamente el conjunto de datos\n\n\nPara cada ejemplo \\(i\\) y cada característica \\(j\\):\n\n\n\n\\(\\theta_j = \\theta_j - \\alpha (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j\\)\n\n\nEs decir, se ajusta \\(\\theta\\) para cada ejemplo, en lugar de hacer el cálculo sobre todo el conjunto de datos\n\n\nCada iteración es más rápida\n\n\nNo converge como Batch Gradient Descent, llega a una aproximación.\n\n\n\n\nMini Batch Gradient Descent\n\n\nEsta técnica lo que hace el utilizar \\(b\\) ejemplos para calcular el gradiente:\n\n \n\n\nPara cada \\(b\\) ejemplos y cada característica \\(j\\):\n\n\n\n\\(\\theta_j = \\theta_j - \\alpha \\frac{1}{b}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j\\)\n\n\nPermite vectorización\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Datos Artificiales.html",
    "title": "Datos Artificiales",
    "body": "\n\nBack\n\n\nDatos Artificiales\n\n\n\n\nCómo podemos generar datos?\n\n\n\n\nManualmente\n\n\nModificando los datos de entrada (añadir ruido en sonido, distorsionar imagen, etc)\n\n\n\n\nNo obstante, debemos evitar añadir ruido aleatorio, ya que esto no ayuda a extraer características significativas del conjunto de datos.\n\n\n\nEstos métodos se suelen utilizar si el modelos tiene un sesgo bajo y se produce underfitting, (por lo que hace falta añadir características).\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Sistemas de Recomendación.html",
    "title": "Sistemas de Recomendación",
    "body": "\n\nBack\n\n\nSistemas de Recomendación\n\n\n\n\nDados los parámetros:\n\n\n\n\n\\(n_\\mu\\): número de usuarios\n\n\n\\(n_m\\): número de ítems valorables\n\n\n\\(r(i,j)\\): marcador de si el ítem ha sido valorado, tal que:\n\n\n\n\\begin{align}\nr(i, j) = \\begin{cases} \n1, & \\text{ si el usuario j ha valorado el ítem i} \\\\\n0, & \\text{ en cualquier otro caso}\n\\end{cases}\n\\end{align}\n\n\n\n\\(y^{(i, j)}\\): valoración del usuario \\(j\\) al ítem \\(i\\).\n\n\n\n\nEl objetivo de un sistema de recomendación es predecir los valores de las valoraciones donde \\(r(i, j) \\neq 1\\) (es decir predecir las valoraciones de usuarios hacia ítems que no han valorado con anteioridad)\n\n\n\nContent Based Recommendations\n\n\n\nCada ítem está definido por \\(n\\) características.\n\n\nPara cada usuario \\(j\\), debemos obtener \\(\\theta^{(j)} \\in \\mathbb{R}^{n+1}\\), de tal manera que para predecir la valoración de \\(x^{(i)} \\rightarrow h_\\theta(x^{(i)}) = (\\theta^{(j)})^T x^{(i)}\\)\n\n\n\nFunción de coste\n\n\nSea \\(m^{(j)}\\) el número de ítems valorados por el usuario \\(j\\), entonces la función de coste se define como:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{2m^{(j)}}\\sum_{j=1}^{n_\\mu} \\sum_{i; r(i, j) = 1} ((\\theta^{(j)})^T x^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2m^{(j)}} \\sum_{k=1}^{n_\\mu} \\theta^{(j)}_k\n\\end{align}\n\n\ndonde \\(\\Theta = \\{\\theta_1, \\cdots, \\theta_{n_\\mu}\\}\\)\n\n\n\nEs decir queremos minimizar la \"distancia\" entre lo predicho \\((\\theta^{(j)})^T x^{(i)}\\) para el ítem (que ha sido valorado, por lo tanto \\(r(i, j) = 1\\)) y el usuario \\(i\\) y la valoración real \\(y^{(i, j)}\\).\n\n\nDescenso Gradiente\n\n\nLo que queremos es minimizar el coste, por lo tanto, calculamos \\(\\frac{\\delta J(\\Theta)}{\\delta \\theta_j}\\) para obtener el vector en dirección al mayor incremento en la función, seguidamente, utilizar su opuesto, obtenemos el vector que apunta a la dirección de menor incremento. Es decir, aplicamos descenso gradiente como sigue:\n\n\n\nPara \\(k = 0\\):\n\n\n\\begin{align}\n\\theta_k^{(j)} = \\theta_k^{(j)} - \\alpha \\left(\\sum_{i; r(i,j)=1} (\\theta^{(j)})^Tx^{(i)} - y^{(i,j)}x^{(i)}_k \\right)\n\\end{align}\n\n\nPara \\(k \\neq 0\\):\n\n\n\\begin{align}\n\\theta_k^{(j)} = \\theta_k^{(j)} - \\alpha \\left(\\sum_{i; r(i,j)=1} (\\theta^{(j)})^Tx^{(i)} - y^{(i,j)}x^{(i)}_k + \\lambda \\theta_k^{(j)} \\right)\n\\end{align}\n\nCollaborative Filtering\n\n\nCollaborative filtering consiste en calcular las características de cada usuario (ejemplo \\(x^{(i)}\\)) en función de los pesos \\(\\theta^{(j)}\\). Una vez hecho esto se calculan los pesos óptimos que que minimizan la función de coste y volvemos a obtener las características de cada usuario en función de estes nuevos pesos.\n\n\n\nEste proceso se describe más formalmente a continuación:\n\n\nProblema de Optimización\n\n\nEl problema de optimización se describe como sigue:\n\n\n\nDados \\(\\theta^{(1)}, \\cdots, \\theta^{n_\\mu}\\):\n\n\n\nPara un ejemplo \\(x^{(i)}\\)\n\n\\begin{align}\n\\underset{x^{(i)}}{\\min{}} \\frac{1}{2} \\sum_{j:r(i,j)=1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\frac{\\lambda}{2} \\sum_{k=1}^n (x_k^{(i)})^2\n\\end{align}\n\n\nPara todos los ejemplos del conjunto \\(x^{0}, \\cdots, x^{(n_m)}\\):\n\n\\begin{align}\n\\underset{x^{(1)}, \\cdots, x^{(n_m)}}{\\min{}} \\frac{1}{2} \\sum_{i=1}^{n_m} \\sum_{j:r(i,j)=1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m}\\sum_{k=1}^n (x_k^{(i)})^2\n\\end{align}\n\n\nEs decir queremos minimizar la \"distancia\" entre lo predicho \\((\\theta^{(j)})^T x^{(i)}\\) para el ítem (que ha sido valorado, por lo tanto \\(r(i, j) = 1\\)) y el usuario \\(i\\) y la valoración real \\(y^{(i, j)}\\). Además como queremos obtener los valores de \\(x\\) que minimizan el coste, los añadimos como coste a problema de optimización para evitar overfitting.\n\n\nAlgoritmo\n\n\nEl algoritmo consta de los siguientes pasos:\n\n\n\n\nInicializar \\(x^{(1)}, \\cdots, x^{(m)}\\) y \\(\\theta^{(1)}, \\cdots, \\theta^{(n_\\mu)}\\) de forma aleatoria.\n\n\nCalcular \\(X\\) a partir de \\(\\Theta\\)\n\n\nCalcular \\(\\Theta\\) a partir de \\(X\\)\n\n\nVolvemos al paso 2.\n\n\n\n\nEs decir, queremos obtener \\(X\\) y \\(\\Theta\\) que optimice el siguiente problema:\n\n\n\\begin{align}\n\\underset{x^{(1)}, \\cdots, x^{(n_m)}, \\theta^{(1)}, \\cdots, \\theta^{(n_\\mu)}}{\\min{}} \\frac{1}{2} \\sum_{i=1}^{n_m} \\sum_{j:r(i,j)=1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m}\\sum_{k=1}^n (x_k^{(i)})^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_\\mu}\\sum_{k=1}^n (\\theta_k^{(i)})^2\n\\end{align}\n\n\nObserva que, como estamos optimizando tanto \\(\\theta\\) como \\(x\\), entonces los añadimos como coste a la función de optimización para evitar overfitting:\n\n\n\n\n\\(\\frac{\\lambda}{2} \\sum_{i=1}^{n_m}\\sum_{k=1}^n (x_k^{(i)})^2\\)\n\n\n\\(\\frac{\\lambda}{2} \\sum_{i=1}^{n_\\mu}\\sum_{k=1}^n (\\theta_k^{(i)})^2\\)\n\n\n\n\nPara aplicar la optimización utilizamos descenso gradiente: primero en función de \\(x\\) y después en función de \\(\\theta\\):\n\n\n\\begin{align}\nx^{(i)}_k = x^{(i)}_k - \\alpha \\left( \\sum_{j:r(i, j)=1} ((\\theta^{(j)})^T x^{(i)} - y^{(i, j)}) \\theta_k^{(j)} + \\lambda x^{(i)}_k\\right)\n\\end{align}\n\n\\begin{align}\n\\theta^{(j)}_k = \\theta^{(j)}_k - \\alpha \\left( \\sum_{i:r(i, j)=1} ((\\theta^{(j)})^T x^{(i)} - y^{(i, j)}) x_k^{(i)} + \\lambda \\theta^{(j)}_k\\right)\n\\end{align}\n\nBuscar ítems Relacionados\n\n\nSi \\(||x^{(i)} - x^{(j)}\\)|| es un valor pequeño entonces los ítems \\(i\\) y \\(j\\) son similares.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Map Reduce.html",
    "title": "Map Reduce",
    "body": "\n\nBack\n\n\nMap Reduce\n\n\n\n\nMap Reduce nos permite paralelizar los algoritmos. Por ejemplo, supongamos que:\n\n\n\n\nTenemos \\(m = 400\\) datos\n\n\nUtilizamos Batch Gradient Descent para resolver el problema de optimización\n\n\nTenemos un número de PC equivalente a 4\n\n\nSea \\(i\\) el índice de un PC\n\n\n\nEste entrena sobre \\(x^{(i)}, \\cdots, x^{(i+100)}\\)\n\n\nCalculamos el coste parcial para este conjunto de datos como:\n\n\n\n\\(temp_j^{(k)} = \\sum_{i}^{i+100} (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j\\)\n\n\n\n\nAhora, combinamos todos los pesos y aplicamos descenso gradiente:\n\n\n\n\\(\\theta_j = \\theta_j - \\alpha \\frac{1}{400} \\left( \\sum_{i}^k temp_j^{(i)}\\right)\\)\n\n\n\n\n\nEste tipo de técnicas se utilizan si los algoritmos de entrenamiento pueden ser utilizamos como la suma de funciones, tanto el coste como el gradiente. También es aplicable a PCs con múltiples cores.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Evaluación de modelos.html",
    "title": "Evaluación de modelos",
    "body": "\n\nBack\n\n\nEvaluación de modelos\n\n\n\n\n\nSeparación de Datos\n\n\nEntrenamiento en Regresión Lineal\n\n\nEntrenamiento en Regresión Logística\n\n\nSelección de Modelos\n\n\n\nCross Validation\n\n\n\nProceso de Selección\n\n\n\n\nDiagnóstico: Sesgo vs Varianza\n\n\nRegresión Lineal con Regularización\n\n\nCurva de Aprendizaje\n\n\nDebugging un Algoritmo de Aprendizaje\n\n\nMedidas de Evaluación\n\n\n\nBalance entre Precisión y Recall\n\n\n\n\n\n\nSeparación de datos\n\n\nA la hora de entrenar un modelo, separamos los datos en dos conjuntos:\n\n\n\n\nConjunto de entrenamiento: \\(70\\%\\) - \\(80\\%\\)\n\n\nConjunto de test: \\(30\\%\\) - \\(20\\%\\)\n\n\n\nEntrenamiento en regresión lineal\n\n\nEl proceso de entrenamiento en la regresión lineal consiste en:\n\n\n\n\nEntrenar el modelo sobre el conjunto de entrenamiento y obtener la matriz de pesos \\(\\Theta\\) minimizando el coste \\(J(\\Theta)\\)\n\n\nCalcular el coste sobre el conjunto de test \\(J_{test}(\\Theta)\\)\n\n\n\n\\[%align\nJ_{test}(\\Theta) = \\frac{1}{2m} \\sum_{i=1}^{m_{test}} (h_\\Theta(x^{(i)}_{test}) - y^{(i)}_{test})^2\n\\]\n\nEntrenamiento en regresión logística\n\n\nEl proceso de entrenamiento en la regresión logística consiste en:\n\n\n\n\nEntrenar el modelo sobre el conjunto de entrenamiento y obtener la matriz de pesos \\(\\Theta\\) minimizando el coste \\(J(\\Theta)\\)\n\n\nCalcular el coste sobre el conjunto de test \\(J_{test}(\\Theta)\\)\n\n\n\n\\[%align\nJ_{test}(\\Theta) = - \\frac{1}{m} \\sum_{i=1}^{m_{test}} \\left[y^{(i)}_{test} \\log(h_\\Theta(x^{(i)}_{test})) + (1-y^{(i)}_{test})\\log(1-h_\\Theta(x^{(i)}_{test})) \\right] \n\\]\n\n\nEl error de clasificación en la regresión logística se define como sigue:\n\n\n\\begin{align}\nerror(h_\\Theta(x), y) =\n\\begin{cases}\n1, & \\text{ si } h_\\Theta(x) \\geq 0.5 \\rightarrow \\log(h_\\Theta(x)) = 1 \\text{ e } y = 0 \\\\\n1, & \\text{ si } h_\\Theta(x) < 0.5 \\rightarrow \\log(h_\\Theta(x)) = 0 \\text{ e } y = 1 \\\\\n0, \\text{ en cualquier otro caso } \\\\\n\\end{cases}\n\\end{align}\n\nSelección de modelos\n\n\nSupongamos que tenemos \\(n\\) modelos, tal que cada modelo es equivalente al anterior pero con una característica más en sus datos:\n\n\n\n\nModelo 1: \\(h_\\Theta(x) = \\theta_0 + \\theta_1 \\cdot x_1\\)\n\n\nModelo 2: \\(h_\\Theta(x) = \\theta_0 + \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2\\)\n\n\nModelo n: \\(h_\\Theta(x) = \\theta_0 + \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\cdots + \\theta_n \\cdot x_n\\)\n\n\n\n\nPara evaluar los modelos lo que hacemos es escoger el que menor coste obtenga sobre el conjunto de test, tras ser entrenado sobre el conjunto de entrenamiento. \n\n\n\\begin{align}\n\\begin{bmatrix}\n\\Theta^{(1)} \\\\\n\\Theta^{(2)} \\\\\n\\vdots \\\\\n\\Theta^{(n)} \\\\\n\\end{bmatrix} \\rightarrow\n\\begin{bmatrix}\nJ_{test}(\\Theta^{(1)}) \\\\\nJ_{test}(\\Theta^{(2)}) \\\\\n\\vdots \\\\\nJ_{test}(\\Theta^{(n)}) \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nSin embargo, se puede dar el problema de que el mejor simplemente produzca overfitting sobre el conjunto de test (lo cual es probable cuando el vector de pesos tiene dimensiones grandes). Para solventar este problema:\n\n\nCross Validation\n\n\nSepararemos el conjunto de datos en tres conjuntos:\n\n\n\n\nConjunto de entrenamiento: \\(60\\%\\)\n\n\nConjunto de validación cruzada (Cross validation): \\(20\\%\\)\n\n\nConunto de test: \\(20\\%\\)\n\n\n\n\nPor lo tanto ahora la función de coste para cada conjunto tiene la forma:\n\n\n\n\nFunción de coste para el conjunto de entrenamiento: \n\\begin{align}\nJ_{train}(\\Theta) = \\frac{1}{2m_{train}} \\sum_{i=1}^{m_{train}} error(h_\\Theta(x^{(i)}), y^{(i)})\n\\end{align}\n\n\nFunción de coste para el conjunto de test: \n\\begin{align}\nJ_{test}(\\Theta) = \\frac{1}{2m_{test}} \\sum_{i=1}^{m_{test}} error(h_\\Theta(x^{(i)}), y^{(i)})\n\\end{align}\n\n\nFunción de coste para el conjunto de validación cruzada: \n\\begin{align}\nJ_{cv}(\\Theta) = \\frac{1}{2m_{cv}} \\sum_{i=1}^{m_{cv}} error(h_\\Theta(x^{(i)}), y^{(i)})\n\\end{align}\n\n\n\nProceso de selección\n\n\nEntonces ahora para seleccionar un modelo lo que hacemos que para cada modelo \\(q\\):\n\n\n\n\nMinimizamos \\(J_{train}(\\Theta^{(q)})\\) para obtener los pesos \\(\\Theta^{(q)}\\) óptimos.\n\n\nCalculamos el coste sobre el conjunto de validación cruzada \\(J_{cv}(\\Theta^{(q)})\\)\n\n\n\n\nUna vez hecho esto para todos, escogemos el modelo que ofrezca el mejor coste sobre el conjunto de validación cruzada y calculamos \\(J_{test}(\\Theta^{(q)})\\) para evaluar la capacidad de generalización del modelo.\n\n\nDiagnóstico: Sesgo vs Varianza\n\n\n\nUnderfitting: cuando se produce underfitting el coste de entrenamiento y el coste de validación tienen valores similares y ambos tiene valores bastante altos\n\n\nOverfitting: cuando se produce overfitting el coste de entrenamiento es mucho menor que el coste de validación cruzada.\n\n\n\n\n\n\n\nRegresión lineal con regularización\n\n\nTambién es importante observar cómo afecta el parámetro de regularización a nuestros modelos. Por ejemplo, en la regresión linear, la función de coste tiene la forma:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{2m}\\sum_{j=1}^m (h_\\Theta(x_j) - y_j)^2 + \\frac{1}{2m} \\lambda \\sum_{i=1}^n \\theta_i^2\n\\end{align}\n\n\nPor lo tanto, el aumentar o reducir \\(\\lambda\\) es directamente proporcional al coste.\n\n\n\n\nSi el parámetro de regularización \\(\\lambda\\) es muy grande entonces los pesos van a tender a ser muy pequeños (ya que el coste aumenta al aumentar el valor de \\(\\lambda\\)) \n\n\nSi el parámetro de regularización \\(\\lambda\\) es muy pequeño entonces los pesos van a poder ser grandes (ya que el coste se reduce al reducir el valor de \\(\\lambda\\)) \n\n\n\n\n\n\n\nEscoger el parámetro de regularización\n\n\nPara escoger el parámetro de regularización seguimos el mismo proceso que para escoger el mejor modelo, para cada modelo \\(q\\):\n\n\n\n\nMinimizamos \\(J_{train}(\\Theta^{(q)})\\) para obtener los pesos \\(\\Theta^{(q)}\\) óptimos.\n\n\nCalculamos el coste sobre el conjunto de validación cruzada \\(J_{cv}(\\Theta^{(q)})\\)\n\n\n\n\nUna vez hecho esto para todos, escogemos el modelo que ofrezca el mejor coste sobre el conjunto de validación cruzada y calculamos \\(J_{test}(\\Theta^{(q)})\\) para evaluar la capacidad de generalización del modelo.\n\n\nCurva de aprendizaje\n\n\nA continuación vamos a estudiar cómo afecta el tamaño del conjunto de datos \\(m\\), el sesgo y la varianza a nuestro modelo:\n\n\n\n\nCuanto mayor es el tamaño, más difícil es encontrar una hipótesis que se adapte (\\(J_{train}(\\Theta)\\) es mayor), pero el modelo generaliza mejor (\\(J_{cv}(\\Theta)\\) es menor)\n\n\n\n\n\nCuando el sesgo (bias) es grande, entonces se produce underfitting y las predicciones de nuestro modelo son malas:\n\n\n\nEl error del modelo es elevado, tanto sobre el conjunto de entrenamiento como sobre el conjunto de validación cruzada\n\n\nTener más ejemplos ayuda al modelo\n\n\n\n   \n\n\nCuando la varianza (variance) es grande, entonces se produce overfitting, tal que el error en el conjunto de validación cruzada es muy alto:\n\n\n\nEl modelo se adapta al conjunto de datos, por lo que el error de entrenamiento es menor\n\n\nTener más muestras ayuda al modelo\n\n\n\n\nDebugging un algoritmo de aprendizaje\n\n\nPara arreglar el overfitting que se produce cuando la varianza es elevada:\n\n\n\n\nObtener más datos de entrenamiento\n\n\nUtilizar menos características (reducir el grado del vector de pesos), pero tras un proceso de selección de aquellas más relevantes\n\n\nIntentar aumentar el parámetro de regularización\n\n\n\n\nPara arregar el underfitting que se produce cuando el sesgo es elevado:\n\n\n\n\nAñadir más características\n\n\nAñadir características polinómicas\n\n\nIntentar reducir el parámetro de regularización\n\n\n\n\nEn las redes neuronales:\n\n\n\n\nLas redes pequeñas tienden a producir underfitting pero son menos costosas computacionalmente\n\n\nLas redes grandes tienen más características, por lo tanto hay una mayor probabilidad de overfitting\n\n\n\n\nGestionar datos sesgados:\n\n\n\n\nHay que ser consciente que a veces, por ejemplo en problemas de clasificación, hay categorías que con más comunes que el resto\n\n\n\nMedidas de evaluación\n\n\nLa precisión y el recall son medidas de evaluación que se complementan:\n\n\n\n\n\n \n\n\n \n\n\nResultado\n\n\nResultado\n\n\n\n\n \n\n\n \n\n\n1\n\n\n0\n\n\n\n\nPredicción\n\n\n1\n\n\nVerdadero positivo (TP)\n\n\nFalso positivo (FP)\n\n\n\n\nPredicción\n\n\n0\n\n\nFalso negativo (FN)\n\n\nVerdadero negativo (TN)\n\n\n\n\n\n\nPrecisión = \\(\\frac{TP}{\\text{ # positivos predichos }} = \\frac{TP}{TP + FP}\\)\n\n\nRecall = \\(\\frac{TP}{\\text{ # positivos reales }} = \\frac{TP}{TP + FN}\\)\n\n\n\nBalance entre precisión y recall\n\n\nCuánto mayor es la precisión menor es el recall y viceversa. Entonces \n\n\n\n\nSi queremos un modelo más preciso:\n\n\n\n\\begin{align}\n\\begin{cases}\n\\text{Predecir } 1, \\text{ si } h_\\Theta(x) \\geq 0.7 \\\\\n\\text{Predecir } 0, \\text{ si } h_\\Theta(x) < 0.7 \\\\\n\\end{cases}\n\\end{align}\n\n\nEntonces, la precisión es mayor ya que el número de \\(FP\\) es menor, pero el recall es menor, ya que el número de \\(FN\\) es mayor.\n\n\n\n\nLo mismo pasa si queremos evitar falsos negativos, entonces hacemos:\n\n\n\n\\begin{align}\n\\begin{cases}\n\\text{Predecir } 1, \\text{ si } h_\\Theta(x) \\geq 0.5 \\\\\n\\text{Predecir } 0, \\text{ si } h_\\Theta(x) < 0.5 \\\\\n\\end{cases}\n\\end{align}\n\n\nTal que se reduce el número de \\(FN\\), y se aumenta el recall, pero el número de \\(FP\\) es mayor, por lo que se reduce la precisión.\n\n\n\nEntonces, para encontrar un punto de balance entre las dos medidas tenemos que seleccionar un valor límite, tal que hacemos la predicción en base a \\(h_\\Theta(x) \\geq \\text{ limite }\\).\n\n\n\nPara calibrar ese límite podemos utilizar dos métricas de evaluación:\n\n\n\n\nLa media de ambas métricas: \\(\\frac{P + R}{2}\\), funciona mal cuando \\(P >> R\\) o \\(R >> P\\), ya que el valor va a ser alto, pero no se ha encontrado un equilibrio. \n\n\nLa puntuación \\(F_1 = 2 \\cdot \\frac{P\\cdot R}{(P + R)}\\), tal que cuanto mayor sea esta puntuación mejor\n\n\n\nAhora  \n\\begin{align}\n  \\begin{cases}\n    F_1 \\approx 0, && P >> R \\\\ \n    F_1 \\approx 0, && R >> P \\\\ \n  \\end{cases}\n\\end{align}\n\n\n\n\n\nPara escoger el límite lo que se hace es calcular la puntuación \\(F_1\\) sobre el conjunto de validación cruzada, y se escoge aquel límite que ofrezca la mayor puntuación.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Gradient Checking.html",
    "title": "Gradient Checking",
    "body": "\n\nBack\n\n\nGradient Checking\n\n\n\n\nConsiste en la estimación numérica de los gradientes, tal que:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\Theta} \\approx \\frac{J(\\Theta - \\epsilon) - J(\\Theta + \\epsilon)}{2 \\cdot \\epsilon}\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_j} \\approx \\frac{J(\\theta_0, ..., \\theta_j - \\epsilon, ..., \\theta_n) - J(\\theta_0, ..., \\theta_j + \\epsilon, ..., \\theta_n)}{2 \\cdot \\epsilon}\n\\end{align}\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Clustering.html",
    "title": "Clustering",
    "body": "\n\nBack\n\n\nClustering\n\n\n\nK-Means\n\n\n\nEscogemos e inicializamos \\(K\\) centroides que servirán para hacer de clústers.\n\n\nPara cada ejemplo \\(j\\): asignamos el centroide más cercano\n\n\nUna vez asignados todos los ejemplos, resituamos cada centroide en función de los ejemplos asignados al mismo.\n\n\nVolvemos al paso 2.\n\n\n\nAlgoritmo\n\n\nEntrada:\n\n\n\n\nNúmero de clústers \\(K\\)\n\n\nConjunto de entrenamiento: \\(\\{x^{(0)}, \\cdots, x^{(m)}\\}\\), con \\(x^{(i)} \\in \\mathbb{R}^n\\)\n\n\n\n\n\nInicializamos los \\(K\\) centroides \\((\\mu_1, \\cdots, \\mu_k) \\in \\mathbb{R}^n\\) de forma aleatoria.\n\n\nRepetimos:\n\n\n\nPara cada ejemplo \\(x^{(j)}\\), \\(C^{(j)}\\) es el índice del centroide más cercano a \\(x^{(j)}\\): \\(\\underset{i}{min}||x^{(j)} - \\mu_i||\\)\n\n\nPara cada clúster:\n\n\n\n\\(\\mu_i\\) es la media de los puntos \\(x^{(j)}\\) asignados al centroide \\(i\\): \\(\\mu_i = \\frac{1}{t} \\left[\\sum_{j=1}^t x^{(j)} \\text{ donde } C^{(j)} = i\\right]\\), donde \\(t\\) es el número de ejemplos asignados al centroide \\(i\\).\n\n\nSi el centroide no tiene puntos, se elimina o se vuelve a inicializar de forma aleatoria.\n\n\n\n\n\nClústers no claramente separables\n\n\nCuando los datos contienen mucho ruido lo que se hace es resolver el siguiente problema de optimización:\n\n\n\\begin{align}\n\\underset{C^{(1)}, \\cdots, C^{(m)}, \\mu_1, \\cdots, \\mu_k}{min} J(C^{(1)}, \\cdots, C^{(m)}, \\mu_1, \\cdots, \\mu_k)\n\\end{align}\n\n\nDonde la función de coste \\(J\\) se define como:\n\n\n\\begin{align}\nJ(C^{(i)}, \\mu_i) = \\frac{1}{m} \\sum_{i=1}^m ||x^{(i)} - \\mu_{C^{(i)}}||^2\n\\end{align}\n\n\nEs decir, el coste es equivalente a la suma de la distancia entre el ejemplo \\(x^{(i)}\\) y su clúster asignado \\(\\mu_{C^{(i)}}\\), para cada ejemplo.\n\n\n\nEl algoritmo de optimización lo que hace es:\n\n\n\n\nMinimiza el coste con respecto a \\(C\\)\n\n\nMinimiza el coste con respecto a \\(\\mu\\)\n\n\n\nInicialización aleatoria\n\n\n\nDebemos escoger un número de centroides \\(K\\) menor que el número de ejemplos \\(m\\).\n\n\nInicializamos cada centroide equivalente a un ejemplo aleatorio del conjunto de entrenamiento: \\(\\mu_i = x^{(j)}\\)\n\n\n\n\nHay que tener en cuenta que, en función de la inicialización de los centroides, se pueden obtener distintos resultados en el problema de optimización, por ello lo que se hace es:\n\n\n\n\nAplicar el algoritmo muchas veces\n\n\nEscoger el modelo que obtuvo menor coste\n\n\n\n\nEste proceso es viable si el número de clústers es pequeño.\n\n\nParametrización de Clústering\n\n\nUna forma de escoger el número de clústers \\(K\\) es utilizando el método del codo:\n\n\n\n\nSe aplica el modelo con un número distinto de clústers\n\n\nSe evalúa con alguna métrica el rendimiento (coste) del modelo y \n\n\nSe elige el ofrece una mayor mejora con respecto a un número de clústers menor\n\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Regresión Lineal.html",
    "title": "Regresión Lineal",
    "body": "\n\nBack\n\n\nRegresión Lineal\n\n\n\n\n\nDescripción de los datos\n\n\nHipótesis\n\n\nFuncion de coste\n\n\nDescenso gradiente\n\n\n\n\n\nDescripción de los datos\n\n\n\n\\(X = (x_{ij})\\) una matriz \\(n \\times m\\) donde cada \\(x_{ij}\\) es la característica \\(i\\) del ejemplo \\(j\\), tal que \n\\begin{align}\nX = \n\\begin{bmatrix}\nx_{11} & \\cdots & x_{1m} \\\\\n\\cdots & \\ddots & \\cdots \\\\\nx_{n1} & \\cdots & x_{nm} \\\\\n\\end{bmatrix} \n\\end{align}\n\n\n\n\nCada columna es un ejemplo\n\n\n\nEn cada fila están los valores de una característica\n\n\n\n\n\\(\\Theta = (\\theta_i)\\) es un vector fila \\(1\\times n\\) donde cada \\(\\theta_i\\) es el peso de la característica \\(i\\), tal que:\n\n\n\n\\begin{align}\n\\Theta = \\begin{bmatrix} \\theta_1 & \\cdots & \\theta_n\\end{bmatrix} \n\\end{align}\n\n\n\n\\(Y = (y_j)\\) es un vector fila \\(1\\times m\\) donde cada \\(y_j\\) es la salida real para el ejemplo \\(j\\), tal que:\n\n\n\n\\begin{align}\nY = \\begin{bmatrix} y_1 & \\cdots & y_m\\end{bmatrix} \n\\end{align}\n\nHipótesis\n\n\n\nDado un ejemplo, es decir un vector columna \\(x\\), de dimensiones \\(n \\times 1\\), la hipótesis se define como:\n\n\n\n\\begin{align}\nh_\\Theta(x) = \\sum_{i=1}^n \\theta_i \\cdot x_i\n\\end{align}\n    \n\n\nDado un conjunto de \\(m\\) datos, es decir matriz \\(X\\), de dimensiones \\(n \\times m\\), la hipótesis se define como:\n\n\n\n\\begin{align}\nh_\\Theta(x) = \\Theta\\cdot X = \\begin{bmatrix}\\sum_{i=1}^n \\theta_i \\cdot x_{i1} & \\cdots & \\sum_{i=1}^n \\theta_i \\cdot x_{im}\\end{bmatrix}\n\\end{align}\n\n\nEl resultado es un vector fila \\(1 \\times m\\), es decir como el vector de salidas \\(Y\\)\n\n    \nFuncion de coste\n\n\nSe define la función de coste, \\(J(\\Theta)\\) como:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{2m}\\sum_{j=1}^m (h_\\Theta(x_j) - y_j)^2\n\\end{align}\n\n\nEsta función de coste se denomina Mínimos cuadrados.\n\n    \nRegularización\n\n\nCon regularización, se define la función de coste, \\(J(\\Theta)\\) como:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{2m}\\sum_{j=1}^m (h_\\Theta(x_j) - y_j)^2 + \\frac{1}{2m} \\lambda \\sum_{i=1}^n \\theta_i^2\n\\end{align}\n\nDescenso gradiente\n\n\nPara actualizar el vector de pesos \\(\\Theta\\) aplicamos el descenso gradiente. Para cada peso \\(\\theta_i\\):\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right)\n\\end{align}\n\n\n\n\nLa derivada del coste en función del peso \\(\\theta_i\\) se calcula como sigue:\n\n\n\nSustituimos la función de coste\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = \\frac{\\delta}{\\delta \\theta_i} \\left(\\frac{1}{2m}\\sum_{j=1}^m (h_\\Theta(x_j) - y_j)^2\\right) =\n\\end{align}\n\n\nSacamos el factor constante de la derivada\n\n\n\\begin{align}\n = \\frac{1}{2m} \\frac{\\delta}{\\delta \\theta_i} \\left(\\sum_{j=1}^m (h_\\Theta(x_j) - y_j)^2\\right)\n\\end{align}\n\n\nAplicamos la propiedad que dice que la derivada de una suma equivale a la suma de las derivadas\n\n\n\\begin{align}\n = \\frac{1}{2m} \\left(\\sum_{j=1}^m \\frac{\\delta}{\\delta \\theta_i}(h_\\Theta(x_j) - y_j)^2\\right)\n\\end{align}\n\n\nAplicamos la regla de la cadena\n\n\n\\begin{align}\n = \\frac{1}{2m} \\left(\\sum_{j=1}^m \\frac{\\delta(h_\\Theta(x_j) - y_j)^2}{\\delta (h_\\Theta(x_j) - y_j)} \\frac{\\delta (h_\\Theta(x_j) - y_j)}{\\delta \\theta_i}\\right)\n\\end{align}\n\n\nAplicamos aritmética\n\n\n\\begin{align}\n = \\frac{1}{2m} \\left(\\sum_{j=1}^m 2(h_\\Theta(x_j) - y_j) \\left[\\frac{\\delta (h_\\Theta(x_j))}{\\delta \\theta_i} - \\frac{\\delta (y_j)}{\\delta \\theta_i}\\right]\\right)\n\\end{align}\n\n\n\n\nComo la derivada de \\(y_i\\) es función de \\(\\theta_i\\) es cero, procedemos a calcular la derivada de \\(h_\\Theta(x_j)\\):\n\n\n\\begin{align}\n\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} = \\frac{\\delta}{\\delta \\theta_i} \\sum_{k=1}^n \\theta_k x_{kj} = \\sum_{k=1}^n \\frac{\\delta}{\\delta \\theta_i} \\theta_k x_{kj}\n\\end{align}\n\n\nDonde\n\n\n\\begin{align}\n\\frac{\\delta}{\\delta \\theta_i} \\theta_k x_{kj} = \n\\begin{cases} \nx_{kj}, & k = i \\\\\n0, & k \\neq i \\\\\n\\end{cases}\n\\end{align}\n\n\nComo para todo \\(k\\), con \\(1 \\leq k \\leq n\\) sólo hay un \\(k\\), tal que \\(k = i\\), entonces:\n\n\n\\begin{align}\n\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} = x_{kj}\n\\end{align}\n\n\n\n\nVolemos a la derivada del peso, con \\(\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} = x_{kj}\\) y \\(\\frac{\\delta y_j}{\\delta \\theta_i} = 0\\):\n\n\n\n\\begin{align}\n = \\frac{1}{2m} \\left(\\sum_{j=1}^m 2(h_\\Theta(x_j) - y_j) \\left[x_{ij} - 0\\right]\\right)\n\\end{align}\n\n\\begin{align}\n = \\frac{1}{2m} \\left(\\sum_{j=1}^m 2(h_\\Theta(x_j) - y_j) \\cdot x_{ij}\\right)\n\\end{align}\n\n\nSacamos el factor constante 2 como factor común que se elimina con 1/2\n\n\n\\begin{align}\n = \\frac{1}{m} \\left(\\sum_{j=1}^m (h_\\Theta(x_j) - y_j) \\cdot x_{ij}\\right)\n\\end{align}\n\n\n\n\nFinalmente, sustituimos todo en la función del gradiente:\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right) = \\theta_i - \\alpha \\left[\\frac{1}{m} \\left(\\sum_{j=1}^m (h_\\Theta(x_j) - y_j) \\cdot x_{ij}\\right)\\right]\n\\end{align}\n\nRegularización\n\n\nCon regularización debemos derivar la función que coste que incluye el parámetro de regularización:\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right) + \\frac{\\lambda}{2m} \\sum_{k=1}^n \\theta_k^2\n\\end{align}\n\n\nEl primer término ya lo hemos derivado, por lo tanto procedemos a derivar el segundo término:\n\n\n\\begin{align}\n\\frac{\\delta}{\\delta \\theta_i} \\left(\\frac{\\lambda}{2m} \\sum_{k=1}^n \\theta_k^2\\right) = \\frac{\\lambda}{2m} \\left(\\sum_{k=1}^n \\frac{\\delta}{\\delta \\theta_i} \\theta_k^2\\right)\n\\end{align}\n\n\nDonde \n\n\n\\begin{align}\n\\frac{\\delta}{\\delta \\theta_i} \\theta_k^2 =\n\\begin{cases}\n2 \\theta_k, & k = i \\\\\n0, & k \\neq i\n\\end{cases}\n\\end{align}\n\n\nComo para todo \\(k\\), con \\(1 \\leq k \\leq n\\) sólo hay un \\(k\\), tal que \\(k = i\\), entonces:\n\n\n\\begin{align}\n\\frac{\\delta}{\\delta \\theta_i} \\left(\\frac{\\lambda}{2m} \\sum_{k=1}^n \\theta_k^2\\right) = \\frac{\\lambda}{2m} 2\\theta_i = \\frac{\\lambda}{m} \\theta_i\n\\end{align}\n\n\n\n\nPor lo tanto la función del descenso gradiente equivale a:\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right) = \\theta_i - \\alpha \\left[\\frac{1}{m} \\left(\\sum_{j=1}^m (h_\\Theta(x_j) - y_j) \\cdot x_{ij}\\right) + \\frac{\\lambda}{m}\\theta_i\\right]\n\\end{align}\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Regresión Logística.html",
    "title": "Regresión Logística",
    "body": "\n\nBack\n\n\nRegresión Logística\n\n\n\n\n\nDescripción de los datos\n\n\nHipótesis\n\n\nFuncion de coste\n\n\nDescenso gradiente\n\n\n\n\n\nDescripción de los datos\n\n\n\n\\(X = (x_{ij})\\) una matriz \\(n \\times m\\) donde cada \\(x_{ij}\\) es la característica \\(i\\) del ejemplo \\(j\\), tal que \n\\begin{align}\nX = \n\\begin{bmatrix}\nx_{11} & \\cdots & x_{1m} \\\\\n\\cdots & \\ddots & \\cdots \\\\\nx_{n1} & \\cdots & x_{nm} \\\\\n\\end{bmatrix} \n\\end{align}\n\n\n\n\nCada columna es un ejemplo\n\n\n\nEn cada fila están los valores de una característica\n\n\n\n\n\\(\\Theta = (\\theta_i)\\) es un vector fila \\(1\\times n\\) donde cada \\(\\theta_i\\) es el peso de la característica \\(i\\), tal que:\n\n\n\n\\begin{align}\n\\Theta = \\begin{bmatrix} \\theta_1 & \\cdots & \\theta_n\\end{bmatrix} \n\\end{align}\n\n\n\n\\(Y = (y_j)\\) es un vector fila \\(1\\times m\\) donde cada \\(y_j\\) es la salida real para el ejemplo \\(j\\), tal que:\n\n\n\n\\begin{align}\nY = \\begin{bmatrix} y_1 & \\cdots & y_m\\end{bmatrix} \n\\end{align}\n\n\nDonde cada salida \\(y_j\\), para un clasificador de dos clases sólo puede tener los valores \\(0\\) o \\(1\\).\n\n\nHipótesis\n\n\n\nPara un valor \\(z\\), la función sigmoide \\(g\\) se define como:\n\n\n\n\\begin{align}\ng(z) = \\frac{e^z}{(1+e^z)} = \\frac{1}{(1 + e^{-z})}\n\\end{align}\n\n\n\nSea \\(g\\) la función sigmoide. Dado un ejemplo, es decir un vector columna \\(x\\), de dimensiones \\(n \\times 1\\), la hipótesis se define como:\n\n\n\n\\begin{align}\nh_\\Theta(x) = g\\left(\\sum_{i=1}^n \\theta_i \\cdot x_i\\right) =\n\\begin{cases}\n0, & h_\\Theta(x) < 0.5 \\\\\n1, & h_\\Theta(x) \\geq 0.5 \\\\\n\\end{cases}\n\\end{align}\n    \n\n\nDado un conjunto de \\(m\\) datos, es decir matrix \\(X\\), de dimensiones \\(n \\times m\\), la hipótesis se define como:\n\n\n\n\\begin{align}\nh_\\Theta(x) = \\Theta\\cdot X = \\begin{bmatrix}g(\\sum_{i=1}^n \\theta_i \\cdot x_{i1}) & \\cdots & g(\\sum_{i=1}^n \\theta_i \\cdot x_{im})\\end{bmatrix}\n\\end{align}\n\n\nEl resultado es un vector fila \\(1 \\times m\\), es decir como el vector de salidas \\(Y\\)\n\n    \nFuncion de coste\n\n\nSe define la función de coste, \\(J(\\Theta)\\) como:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{m}\\sum_{j=1}^m \\text{coste}(h_\\Theta(x_j))\n\\end{align}\n\n\nDonde \\(\\text{coste}\\) es una función definida como sigue:\n\n\n\\begin{align}\n\\text{coste}(h_\\Theta(x_j)) = [-y_j \\log(h_\\Theta(x_j))] - [(1-y_j)\\log(1-h_\\Theta(x_j))]\n\\end{align}\n    \nRegularización\n\n\nCon regularización, se define la función de coste, \\(J(\\Theta)\\) como:\n\n\n\\begin{align}\nJ(\\Theta) = -\\frac{1}{m}\\sum_{j=1}^m [y_j \\log(h_\\Theta(x_j))] + [(1-y_j)\\log(1-h_\\Theta(x_j))] + \\frac{1}{2m} \\lambda \\sum_{i=1}^n \\theta_i^2\n\\end{align}\n\nDescenso gradiente\n\n\nPara actualizar el vector de pesos \\(\\Theta\\) aplicamos el descenso gradiente. Para cada peso \\(\\theta_i\\):\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right)\n\\end{align}\n\n\n\n\nLa derivada del coste en función del peso \\(\\theta_i\\) se calcula como sigue:\n\n\n\nSustituimos la función de coste\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = \\frac{\\delta}{\\delta \\theta_i} \\left(-\\frac{1}{m}\\sum_{j=1}^m [y_j \\log(h_\\Theta(x_j))] + [(1-y_j)\\log(1-h_\\Theta(x_j))]\\right) =\n\\end{align}\n\n\nSacamos el factor constante \\(\\frac{1}{m}\\) y aplicamos la propiedad \"La derivada de una suma equivale a la suma de las derivadas\", tal que:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m \\frac{\\delta}{\\delta \\theta_i} \\left([y_j \\log(h_\\Theta(x_j))] + [(1-y_j)\\log(1-h_\\Theta(x_j))]\\right) =\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m  \\left(\\frac{\\delta}{\\delta \\theta_i} [y_j \\log(h_\\Theta(x_j))]\\right) + \\left(\\frac{\\delta}{\\delta \\theta_i}[(1-y_j)\\log(1-h_\\Theta(x_j))]\\right) =\n\\end{align}\n\n\nSacamos los factores constantes \\(y_j\\) y \\(1-y_j\\) y aplicamos la regla de la cadena:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m  \\left(y_j\\frac{\\delta\\log(h_\\Theta(x_j))}{\\delta h_\\Theta(x_j)} \\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i}\\right) + \\left((1-y_j)\\frac{\\delta\\log(1-h_\\Theta(x_j))}{\\delta (1- h_\\Theta(x_j))}\\frac{\\delta (1- h_\\Theta(x_j))}{\\delta \\theta_i}\\right) =\n\\end{align}\n\n\nTenemos que, para el último término:\n\n\n\\begin{align}\n\\frac{\\delta (1- h_\\Theta(x_j))}{\\delta \\theta_i} = \\frac{\\delta(1)}{\\delta \\theta_i} - \\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} = - \\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i}\n\\end{align}\n\n\nPor lo tanto, si sustituimos:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m  \\left(y_j\\frac{\\delta\\log(h_\\Theta(x_j))}{\\delta h_\\Theta(x_j)} \\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i}\\right) + \\left((1-y_j)\\frac{\\delta\\log(1-h_\\Theta(x_j))}{\\delta (1- h_\\Theta(x_j))}(-1)\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i}\\right) =\n\\end{align}\n\n\nAplicamos la regla \\(\\frac{\\delta \\log(x)}{\\delta x} = \\frac{1}{x}\\), sacamos la expresión \\(\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i}\\) como factor común y hacemos negativo el segundo término:\n\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m  \\left(\\frac{y_j}{h_\\Theta(x_j)} \\right) - \\left(\\frac{(1 - y_j)}{1-h_\\Theta(x_j)}\\right) \\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} =\n\\end{align}\n\n\nAplicamos operationes aritméticas:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m  \\left(\\frac{(y_j)(1-h_\\Theta(x_j)) - (1-y_j)(h_\\Theta(x_j))}{h_\\Theta(x_j)(1-h_\\Theta(x_j))} \\right)\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} =\n\\end{align}\n\n\n\n\nCentrémonos ahora en \\(\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i}\\). Para calcular esta derivada, primero expresamos la hipótesis utilizando la función sigmoide:\n\n\n\n\\begin{align}\n\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} = \\frac{\\delta}{\\delta \\theta_i} g(\\Theta x_j) \n\\end{align}\n\n\nAplicamos la regla de la cadena\n\n\n\\begin{align}\n\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} = \\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j} \\frac{\\delta \\Theta x_j}{\\delta \\theta_i}\n\\end{align}\n\n\nSabemos que la derivada del segundo término \\(\\frac{\\delta \\Theta x_j}{\\delta \\theta_i}\\) equivale a \\(x_{ij}\\), por lo tanto, calcularemos sólo \\(\\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j}\\)\n\n\n\n\n\nSea:\n\n\n\\begin{align}\ng(\\Theta x_j) = \\frac{1}{1 + e^{-\\Theta x_j}} = (1 + e^{-\\Theta x_j})^{-1}\n\\end{align}\n\n\nAplicamos la regla de la cadena\n\n\n\\begin{align}\n\\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j} = \\frac{\\delta(1 + e^{-\\Theta x_j})^{-1}}{\\delta(1+e^{-\\Theta x_j})}\\frac{\\delta(1+e^{-\\Theta x_j})}{\\delta \\Theta x_j}\n\\end{align}\n\n\nResolvemos la primera derivada aplicando las propiedades de las derivadas sobre los polinomios y volvemos a aplicar la propiedad de que la derivada de una suma equivale a la suma de las derivadas en el segundo término:\n\n\n\\begin{align}\n\\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j} = (-1)(1 + e^{-\\Theta x_j})^{-2}\\left[\\frac{\\delta (1)}{\\delta \\Theta x_j} + \\frac{\\delta e^{-\\Theta x_j}}{\\delta \\Theta x_j} \\right]\n\\end{align}\n\n\nComo \\(\\frac{\\delta (1)}{\\delta \\Theta x_j}\\) equivale a cero:\n\n\n\\begin{align}\n\\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j} = (-1)(1 + e^{-\\Theta x_j})^{-2} \\frac{\\delta e^{-\\Theta x_j}}{\\delta \\Theta x_j}\n\\end{align}\n\n\nResolvemos la última derivada, sabiendo que \\(\\frac{\\delta e^x}{\\delta x} = e^x\\)\n\n\n\\begin{align}\n\\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j} = (-1)(1 + e^{-\\Theta x_j})^{-2} (-1) e^{-\\Theta x_j} = (1 + e^{-\\Theta x_j})^{-2} e^{-\\Theta x_j} = \\frac{e^{-\\Theta x_j}}{(1 + e^{-\\Theta x_j})^2}\n\\end{align}\n\n\nComo \\(\\frac{e^{-\\Theta x_j}}{(1 + e^{-\\Theta x_j})^2} = \\left(\\frac{1}{1+e^{-\\Theta x_j}}\\right)\\left(1 - \\frac{1}{1 + e^{-\\Theta x_j}}\\right)\\), entonces:\n\n\n\\begin{align}\n\\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j} = \\frac{e^{-\\Theta x_j}}{(1 + e^{-\\Theta x_j})^2} = \\left(\\frac{1}{1+e^{-\\Theta x_j}}\\right)\\left(1 - \\frac{1}{1 + e^{-\\Theta x_j}}\\right) = h_\\Theta(x_j) (1- h_\\Theta(x_j))\n\\end{align}\n\n\nYa que según la definición de la hipótesis \\(h_\\Theta(x_j) = \\frac{1}{1 + e^{-\\Theta x_j}}\\)\n\n\n\n\n\nPor lo tanto, juntado los resultados, tenemos que:\n\n\n\\begin{align}\n\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i} = \\frac{\\delta g(\\Theta x_j)}{\\delta \\Theta x_j} \\frac{\\delta \\Theta x_j}{\\delta \\theta_i} = h_\\Theta(x_j) (1- h_\\Theta(x_j)) x_{ij}\n\\end{align}\n\n\nVolvemos, entonces, a la derivada de la función de coste y sustituimos \\(\\frac{\\delta h_\\Theta(x_j)}{\\delta \\theta_i}\\)\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m  \\left(\\frac{(y_j)(1-h_\\Theta(x_j)) - (1-y_j)(h_\\Theta(x_j))}{h_\\Theta(x_j)(1-h_\\Theta(x_j))} \\right) h_\\Theta(x_j) (1- h_\\Theta(x_j)) x_{ij} =\n\\end{align}\n\n\nLos términos \\(h_\\Theta(x_j) (1- h_\\Theta(x_j))\\) se cancelan tal que:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m  \\left((y_j)(1-h_\\Theta(x_j)) - (1-y_j)(h_\\Theta(x_j)) \\right) x_{ij} =\n\\end{align}\n\n\nAplicamos operaciones aritméticas:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m (y_j - y_jh_\\Theta(x_j) - h_\\Theta(x_j) + y_jh_\\Theta(x_j)) x_{ij}\n\\end{align}\n\n\nEl término \\(y_jh_\\Theta(x_j)\\) se cancela, tal que:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = -\\frac{1}{m}\\sum_{j=1}^m (y_j - h_\\Theta(x_j)) x_{ij}\n\\end{align}\n\n\nFinalmente movemos el \\((-1)\\) dentro del sumatorio:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} = \\frac{1}{m}\\sum_{j=1}^m (h_\\Theta(x_j)-y_j) x_{ij}\n\\end{align}\n\n\n\n\nPor lo tanto la función del descenso gradiente equivale a:\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right) = \\theta_i - \\alpha \\left[\\frac{1}{m} \\left(\\sum_{j=1}^m (h_\\Theta(x_j) - y_j) \\cdot x_{ij}\\right) \\right]\n\\end{align}\n\n\nObserva que tiene la misma forma que para la regresión lineal, pero la hipótesis para la regresión logística está definida en términos de la función sigmoide\n\n\nRegularización\n\n\nCon regularización debemos derivar la función de coste que incluye el parámetro de regularización:\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right) + \\frac{\\lambda}{2m} \\sum_{k=1}^n \\theta_k^2\n\\end{align}\n\n\nEl primer término ya lo hemos derivado, por lo tanto procedemos a derivar el segundo término:\n\n\n\\begin{align}\n\\frac{\\delta}{\\delta \\theta_i} \\left(\\frac{\\lambda}{2m} \\sum_{k=1}^n \\theta_k^2\\right) = \\frac{\\lambda}{2m} \\left(\\sum_{k=1}^n \\frac{\\delta}{\\delta \\theta_i} \\theta_k^2\\right)\n\\end{align}\n\n\nDonde \n\n\n\\begin{align}\n\\frac{\\delta}{\\delta \\theta_i} \\theta_k^2 =\n\\begin{cases}\n2 \\theta_k, & k = i \\\\\n0, & k \\neq i\n\\end{cases}\n\\end{align}\n\n\nComo para todo \\(k\\), con \\(1 \\leq k \\leq n\\) sólo hay un \\(k\\), tal que \\(k = i\\), entonces:\n\n\n\\begin{align}\n\\frac{\\delta}{\\delta \\theta_i} \\left(\\frac{\\lambda}{2m} \\sum_{k=1}^n \\theta_k^2\\right) = \\frac{\\lambda}{2m} 2\\theta_i = \\frac{\\lambda}{m} \\theta_i\n\\end{align}\n\n\n\n\nPor lo tanto la función del descenso gradiente equivale a:\n\n\n\\begin{align}\n\\theta_i = \\theta_i - \\alpha \\left( \\frac{\\delta J(\\Theta)}{\\delta \\theta_i}\\right) = \\theta_i - \\alpha \\left[\\frac{1}{m} \\left(\\sum_{j=1}^m (h_\\Theta(x_j) - y_j) \\cdot x_{ij}\\right) + \\frac{\\lambda}{m}\\theta_i\\right]\n\\end{align}\n\n\nAl igual que antes, observa que tiene la misma forma que para la regresión lineal, pero la hipótesis para la regresión logística está definida en términos de la función sigmoide\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Ceiling Analysis.html",
    "title": "Ceiling Analysis",
    "body": "\n\nBack\n\n\nCeiling Analysis\n\n\n\n\nSupongamos que tenemos un pipeline que conforma todo nuestro sistema de aprendizaje automático y está formado por:\n\n\n\n\nObtención de la imagen\n\n\nDetección de texto\n\n\nSegmentación de caracteres\n\n\nReconocimiento de caracteres\n\n\n\n\nLo que hacemos es determinar una o varias métricas de evaluación, por ejemplo nosotros utilizaremos la precisión. Entonces, ahora creamos una tabla indicando el valor de métrica para cada parte del sistema así como para el sitema completo:\n\n\n\n\n\nComponente\n\n\nPrecisión\n\n\n\n\nDetección del texto\n\n\n82%\n\n\n\n\nSegmentación de caracteres\n\n\n90%\n\n\n\n\nReconocimiento de caracteres\n\n\n100%\n\n\n\n\nTotal\n\n\n72%\n\n\n\n\n\nA partir de esta tabla podemos comprobar que mejorar la Detección en el texto y la Segmentación de caracteres mejora el rendimiento del modelo.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/DimensionalityReduction/Dimensionality Reduction.html",
    "title": "Dimensionality Reduction",
    "body": "\n\nBack\n\n\nDimensionality Reduction\n\n\n\n\n\nStandardize Data\n\n\nPCA\n\n\n\nFind Underlying Space\n\n\nRepresent the Subspace\n\n\nAlgorithm Layout\n\n\nPerforming Eigen Decomposition\n\n\n\nICA\n\n\n\nIntuition\n\n\nSolution\n\n\n\n\n\n\n\nGiven examples \\(\\{x^{(i)}\\}_{i=1}^n\\) where \\(x^{(i)} \\in \\mathbb{R}^d\\), we want to find out if our data lives is a low dimensional space. Look at the next example:\n\n\n\n\n\n\n\nWe can see that the two features are correlated, and we can project the points onto a line, reducing the space from two dimensions to one.\n\n\n\nSo it might be the case that some features are highly correlated, and so de d-dimensional space can be as a k-dimensional space where \\(0 < k < d\\):\n\n\n\\begin{align}\n\\begin{bmatrix}\nx_{11} & \\cdots & x_{1d} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nx_{n1} & \\cdots & x_{nd} \\\\\n\\end{bmatrix} \\rightarrow\n\\begin{bmatrix}\nx_{11} & \\cdots & x_{1k} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nx_{n1} & \\cdots & x_{nk} \\\\\n\\end{bmatrix}\n\\end{align}\n\nStandardize Data\n\n\nA lot of the times the units of each feature in the data make the values in one column (feature) be much bigger than the values in another column. Thus, the first step is to standardize your data:\n\n\n\n\nCenter data\n\n\nHave it have variance equal to one \n\n\n  \n\nSo we transform our data as follows:\n\n\n\\begin{align}\nx_j^{(i)} = \\frac{x_j^{(i)} - \\mu_j}{\\sigma_j}\n\\end{align}\n\n\nWhere:\n\n\n\n\n\\(u_j\\) is the mean of the feature \\(j\\) over the \\(n\\) examples, such that \\(u_j = \\frac{1}{n}\\sum_{i=1}^nx^{(i)}_j\\)\n\n\n\\(\\sigma_j\\) is the standard deviation of the feature \\(j\\) over the \\(n\\) examples, where \\(\\sigma_j^2 = \\frac{1}{n}\\sum_{i=1}^n(x^{(i)}_j - \\mu_j)^2\\)\n\n\n\nPCA\n\nFind Underlying Space\n\n\nTo reduce the dimensionality of our data we first define a subspace and then we project each point onto the subspace. \n\n\n\nThis projection is the closes point in the subspace to the point we are trying to project, this has as a consequence that the \"line\" connecting the point to its projection is always perpendicular to the subspace:\n\n\n\n\n\n\n\nThe goal is to choose the subspace that maximizes the variance of the projected points, to retain the maximum possible variance of the data. As you can see if we choose the blue line as the subspace the variance \nis much bigger that if we choose the red line:\n\n\n\n\n\n\n\n\n\n\nRepresent the Subspace\n\n\nLet us suppose the subspace is defined by a basis vector \\(u \\in \\mathbb{R}^d\\) where \\(u\\) is a unit vector, then projection of \\(\\overrightarrow{x^{(i)}}\\) on to the space spanned by \\(u\\) will be:\n\n\n\\begin{align}\nProj(u)\\overrightarrow{x^{(i)}}\n\\end{align}\n\n\nWhere \\(Proj(u)\\) is the projection matrix and \\(x^{(i)} \\in \\mathbb{R}^d\\). So, because \\(Proj(u) = \\frac{uu^T}{u^Tu}\\), then the projected point is defined as:\n\n\n\\begin{align}\nProj(u)\\overrightarrow{x^{(i)}} = \\frac{uu^T}{u^Tu} \\overrightarrow{x^{(i)}} = ((x^{(i)})^Tu)u\n\\end{align}\n\n\nWhere \\(((x^{(i)})^Tu)\\) is an scalar. \n\n\n\nSo, now our goal is to find a \\(u\\) that maximizes the variance across the \\(n\\) examples. That is, we want to maximize the sum of the square of the norms of the projected points:\n\n\n\n\n\n\n\nMore formally:\n\n\n\\begin{align}\nu = \\underset{u}{\\arg \\max} \\frac{1}{n}\\sum_{i=1}^n ||Proj(u)x^{(i)}||^2 = \\frac{1}{n}\\sum_{i=1}^n ||((x^{(i)})^Tu)u||^2\n\\end{align}\n\n\nBecause the norm of a unit vector multiplied by a scalar is just the square of the scalar (for \\(3 \\cdot \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix}\\): \\(||\\begin{pmatrix} 3 & 0 & 0 \\end{pmatrix}|| = (\\sqrt{3^2 + 0^2 + 0^2})^2 = 3^2\\)):\n\n\n\\begin{align}\nu = \\underset{u}{\\arg \\max} \\frac{1}{n}\\sum_{i=1}^n ((x^{(i)})^Tu)^2 = \\frac{1}{n}\\sum_{i=1}^n ((x^{(i)})^Tu)^T((x^{(i)})^Tu) = \\frac{1}{n}\\sum_{i=1}^n u^T x^{(i)} (x^{(i)})^T u\n\\end{align}\n\n\nBecause \\(u, u^T\\) are a common factor in the sum:\n\n\n\\begin{align}\nu = \\underset{u}{\\arg \\max} \\left[u^T \\left(\\frac{1}{n}\\sum_{i=1}^n x^{(i)} (x^{(i)})^T \\right) u\\right]\n\\end{align}\n\n\n\n\nNow, we know that given the optimization problem of the form \\(\\underset{u}{\\arg \\max} \\left[u^T A u\\right]\\), the solution \\(u\\) is the eigenvector corresponding to the largest eigenvalue of \\(A\\).\n\n\n\nIn this scenario, \\(A = \\left(\\frac{1}{n}\\sum_{i=1}^n x^{(i)} (x^{(i)})^T \\right)\\), which equals the sample covariance matrix, which is defined as:\n\n\n\\begin{align}\n\\frac{1}{n} \\sum_{i=1}^n (x^{(i)} - \\mu)^T (x^{(i)} - \\mu) = \\frac{1}{n} \\sum_{i=1}^n (x^{(i)} - 0)^T (x^{(i)} - 0) = \\frac{1}{n} \\sum_{i=1}^n (x^{(i)})^T x^{(i)}\n\\end{align}\n\n\nNote that, because our data is now centered after standardizing it, the mean \\(\\mu\\) equals zero.\n\n\n\nHence, we want to calculate the eigenvectors of the sample covariance matrix of x.\n\n\n\nMind you, we have derived this solution for a space defined by only one vector \\(u\\). However given basis vectors \\((u_1, \\cdots, u_k)\\) the optimization problem holds and the solution are the \\(k\\) eigenvectors corresponding to the \\(k\\) largest eigenvalues of \\(A\\).\n\n\nAlgorithm Layout\n\n\nThe steps of PCA are the following:\n\n\n\n\nCalculate the sample covariance matrix as \\(x^Tx\\)\n\n\nCalculate the eigenvector and eigenvalues of \\(x^Tx\\), such that:\n\n\n\n\\begin{align}\n\\begin{matrix}\n(\\lambda_1, u_1) \\\\\n(\\lambda_2, u_2) \\\\\n\\vdots \\\\\n(\\lambda_d, u_d) \\\\\n\\end{matrix}\n\\end{align}\n\n\nAre the \\(d\\) eigenvectors (\\(u_i\\)) and eigenvalues (\\(\\lambda_i\\)). We assume the tuples are ordered in decreasing order with respect to the eigenvalues, such that if \\(i > j\\) then \\(\\lambda_i > \\lambda_j\\).\n\n\n\n\nFind \\(k\\) such that we satisfy a confidence level with respect to the variance, i.e. suppose you want to preserve 95% of the variance of the original data then:\n\n\n\n\\begin{align}\n\\frac{\\sum_{i=1}^k \\lambda_i}{\\sum_{j=1}^d \\lambda_j} = 95\\%\n\\end{align}\n\n\n\nChoose the \\(k\\) eigenvectors with the largest corresponding eigenvalues.\n\n\n\nPerforming Eigen-decomposition\n\n\nFirst of all, let us present two properties regarding eigen-decompositions of a matrix \\(X\\):\n\n\n\n\nIf \\(X\\) is a square matrix and symmetric then \\(X\\) has orthogonal eigenvectors and real eigenvalues.\n\n\nIf \\(X\\) is also positive semi-definite then the eigenvalues are positive.\n\n\n\n\nIn our case, the eigen-decomposition is done over \\(x^Tx\\), therefore this matrix is guaranteed to be a square matrix, symmetric and positive semi-definite.\n\n\n\nThen, performing the eigen decomposition of \\(x^Tx\\) is equivalent to performing singular value decomposition (SVD) over \\(x\\), such that the single values equal the square root of the eigenvalues.\n\n\nLarge Datasets\n\n\nTo perform PCA on large datasets we use a technique called Power Iteration, which consists on:\n\n\n\n\nFor \\(i=0\\), initialize \\(U^{(i)}\\) to random values other than zero\n\n\nSet \\(i = i+1\\), and \\(U^{(i)} = (X^TX)U^{(i-1)}\\)\n\n\nRe-scale \\(U^{(i)}\\) to have unit length such that: \\(U^{(i)}=\\frac{(X^TX)U^{(i-1)}}{||(X^TX)U^{(i-1)}||}\\)\n\n\nGo to step 2.\n\n\n\n\nEventually it will converge to the largest eigenvector.\n\n\nRephrasing PCA\n\n\nAnother way to describe the problem solved by PCA, equivalent to the maximization variance perspective, is:\n\n\n\nFind a subspace such that the projection of the points are as close to the original data as possible, that is minimize the sum of the distances between the projected points and the original points.\n\n\n\n\n\n\nICA\n\n\nThis algorithm pretends to solve what is commonly known as the source separation problem, where we are given a dataset \\(X\\) that is a mixture of some source data \\(S\\). We then use these mixed sources \\(X\\) to construct a unmixing matrix \\(W\\) to recover the source \\(S\\). \n\n\nIntuition\n\n\nImagine there are \\(d\\) speakers and \\(d\\) microphones randomly distributed in a room, such that:\n\n\n\n\n\\(s \\in \\mathbb{R}^d\\) is the representation of what a speaker says. So \\(S_j^{(i)}\\) is what the \\(j\\) speaker said in moment \\(i\\).\n\n\n\\(x \\in \\mathbb{R}^d\\) is the representation of what a microphone records. So \\(x_j^{(i)}\\) is what the \\(j\\) microphone recorded in moment \\(i\\).\n\n\n\n\nFor example, given two speaker, what they say is represented as follows:\n\n\n\n\n\n\n\nMeanwhile the recordings of the microphones are the following:\n\n\n\n\n\n\n\nWe are only given \\(X\\), and the goal is to recover the original speech signal spoken by each speaker. We assume that \\(X\\) is a linear combination of what each speaker says, thus \\(X = AS\\), where \\(A\\) is a quare matrix \\(d \\times d\\) and is called the mixing matrix. \n\n\n\nWhat we want to do is to compute the inverse of \\(A\\), \\(W\\) such that \\(W = A^{-1}\\), where \\(W\\) is called the unmixing matrix.\n\n\n\nThen:\n\n\n\\begin{align}\nA^{-1}X = A^{-1}AS \\rightarrow A^{-1}X = S \\rightarrow WX = S \\rightarrow S = WX\n\\end{align}\n\nSolution\n\n\nTo solve this problem we make the following assumptions:\n\n\n\n\nThe number of sources \\(S\\) are equal to the number of \"examples\" in the mixed dataset \\(X\\)\n\n\n\\(X\\) is a linear combination of \\(S\\), such that \\(S = WX\\)\n\n\n\\(S_j\\) is independent of \\(S_k\\), whenever \\(j \\neq k\\). That is to say, each belongs to a different probability distribution, and are two independent random variables.\n\n\nEach \\(S_j\\) is not Gaussian.\n\n\n\n\n\nIntuition\n\n\nSuppose we are given a random variable \\(X\\) such that \\(X ~ Unif [0,1]\\), then the probability density function is:\n\n\n\n\n\n\n\nLet us define a new distribution as follows \\(y=2x\\), then the probability density function is:\n\n\n\n\n\n\n\nNote, that the function is \"stretched\" as to always satisfy the condition that the integral of \\(PDF\\) must equal 1, which is the same as saying the area under the function is 1. So now, \\(P_y (y) = P_x(x) \\cdot \\frac{1}{2} = P_x(\\frac{y}{2})\\cdot\\frac{1}{2}\\), because \\(x = \\frac{y}{2}\\).\n\n\n\nBut what happens in a higher dimension? That is, what happens when we multiply \\(x \\in \\mathbb{R}^d\\) by a mixing matrix \\(W \\in \\mathbb{R}^{d \\times d}\\). Well, given \\(y \\in \\mathbb{R}^{d \\times d}\\), such that \\(y=WX\\), then to perform a change of random variable we use the Jacobian:\n\n\n\\begin{align}\nP_y(y) = P_x(X)\\frac{1}{|W|} = P_x(W^{-1}Y)\\frac{1}{|W|}\n\\end{align}\n\n\nWhere \\(|W|\\) is the determinant of \\(W\\).\n\n\n\n\n\nFirst of all we define the distribution of the mixed dataset as follows:\n\n\n\\begin{align}\nP_X(x) = \\prod_{j=1}^d P_S (S_j) |W| = \\prod_{j=1}^d P_S (W_j^TX) |W|\n\\end{align}\n\n\nNote that \\(S_j=(W_j)^TX\\). \n\n\n\nWe also assume that \\(P_S\\) is distributed according to a logistic distribution, thus:\n\n\n\n\nCumulative Distribution Function (CDF): \\(\\frac{1}{1+e^{-x}} = \\sigma(x)\\)\n\n\nProbability Density Function (pdf): \\(\\sigma(x)\\sigma(1-x)\\)\n\n\n\n\nSo, we obtain the likelihood of \\(W\\) as follows:\n\n\n\\begin{align}\nl(W) = \\sum_{i=1}^n \\left[\\left(\\sum_{j=1}^d \\log[\\sigma(x^{(i)})(1-\\sigma(x^{(i)}))]\\right) + \\log{|W|}\\right]\n\\end{align}\n\n\nWhere \\(W\\) is the parameter we are trying to obtain. So, to solve the optimization problem:\n\n\n\n\nWe define the maximization of the likelihood as the objective\n\n\nWe compute the derivative of \\(l(W)\\) and perform gradient descent, such that the update step is as follows:\n\n\n\n\\begin{align}\nW = W - \\alpha \\left\\{\\begin{bmatrix}\n(1- 2\\sigma(W_1^Tx^{(i)})) \\\\\n(1- 2\\sigma(W_2^Tx^{(i)})) \\\\\n\\vdots \\\\\n(1- 2\\sigma(W_d^Tx^{(i)})) \\\\\n\\end{bmatrix} (x^{(i)})^T + (W^T)^{-1}\n\\right\\}\n\\end{align}\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Ecuación Normal.html",
    "title": "Ecuación Normal",
    "body": "\n\nBack\n\n\nEcuación Normal\n\n\n\n\n\nDescripción de los datos\n\n\nHipótesis\n\n\nFuncion de coste\n\n\nMinimización del coste\n\n\nAnotaciones\n\n\n\n\n\nDescripción de los datos\n\n\n\n\\(X = (x_{ij})\\) una matriz \\(m \\times (n + 1)\\) donde cada \\(X_{i}\\) es un vector fila \\(1 \\times (n+1)\\), que incluye los valores de todas las características para el ejemplo \\(i\\).\n\\begin{align}\nX = \n\\begin{bmatrix}\nX_1 \\\\\n\\vdots \\\\\nX_i \\\\\n\\vdots \\\\\nX_m \\\\\n\\end{bmatrix} \n\\end{align}\n\n\n\n\nCabe destacar que \\(X_{i0} = 1\\), es el término independiente.\n\n\n\n\n\\(\\Theta = (\\theta_i)\\) es un vector columna \\((n+1)\\times 1\\) donde cada \\(\\theta_i\\) es el peso de la característica \\(i\\), tal que:\n\n\n\n\\begin{align}\n\\Theta = \\begin{bmatrix} \\theta_0 \\\\ \\vdots \\\\ \\theta_n\\end{bmatrix} \n\\end{align}\n\n\n\n\\(Y = (y_j)\\) es un vector columna \\(m\\times 1\\) donde cada \\(y_j\\) es la salida real para el ejemplo \\(j\\), tal que:\n\n\n\n\\begin{align}\nY = \\begin{bmatrix} y_1 \\\\ \\cdots \\\\ y_m\\end{bmatrix} \n\\end{align}\n\nHipótesis\n\n\n\nDado un conjunto de \\(m\\) datos, es decir matriz \\(X\\), de dimensiones \\(m \\times (n+1)\\), la hipótesis se define como:\n\n\n\n\\begin{align}\nh_\\Theta(x) = X \\cdot \\Theta = \n\\begin{bmatrix}\nX_1 \\cdot \\Theta = \\sum_{i=0}^{n+1} \\theta_i x_{1i} \\\\\n\\vdots \\\\\nX_j \\cdot \\Theta = \\sum_{i=0}^{n+1} \\theta_i x_{ji} \\\\\n\\vdots \\\\\nX_m \\cdot \\Theta = \\sum_{i=0}^{n+1} \\theta_i x_{mi} \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nObserva que ahora \\(X\\) y \\(\\Theta\\) están colocados de forma inversa a como lo hacíamos en la regresión lineal y la regresión logística. Esto es debido a que hemos transpuesto las matrices \\(X\\) y \\(\\Theta\\), con respecto a como las habíamos definido en las secciones anteriores. El cálculo es el mismo.\n\n\nFuncion de coste\n\n\nSe define la función de coste, \\(J(\\Theta)\\) como:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{2m} (X\\Theta - Y)^T(X\\Theta - Y)\n\\end{align}\n\n\nLa expresión \\((X\\Theta - Y)^T(X\\Theta - Y)\\) es equivalente a \\((h_\\Theta(x) - y)^2\\), que se utilizaba en la función de coste de la regresión lineal.\n\n\nRegularización\n\n\nCon regularización, se define la función de coste, \\(J(\\Theta)\\) como:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{2m} (X\\Theta - Y)^T(X\\Theta - Y) + \\frac{1}{2m} \\lambda \\Theta^T\\Theta\n\\end{align}\n\n\nMinimización del coste\n\n\nCon la ecuación normal, en lugar de actualizar el vector de pesos \\(\\Theta\\) de forma iterativa, lo que hacemos es igualar la derivada del coste en base a los pesos a cero utilizando derivación matricial:\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) = \n\\begin{bmatrix}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_0} \\\\\n\\vdots \\\\\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_i} \\\\\n\\vdots \\\\\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_n} \\\\\n\\end{bmatrix}\n= \n\\begin{bmatrix}\n0 \\\\\n\\vdots \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\\n\\end{bmatrix}\n= \n\\overrightarrow{0}\n\\]\n\n\n\n\nA continuación exponemos cómo se calcula la derivada:\n\n\n\nSustituímos la función de coste:\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\Delta_\\Theta \\frac{1}{2m}(X \\Theta - Y)^T (X \\Theta - Y)\n\\]\n\n\nAplicamos la propiedad \\((A + B)^T = A^T + B^T\\) \n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\Delta_\\Theta \\frac{1}{2m}((X\\Theta)^T - Y^T) (X \\Theta - Y)\n\\]\n\n\nSacamos el factor constante de la derivada y realizamos la multiplicación:\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{2m} \\Delta_\\Theta (X\\Theta)^T(X\\Theta) - (X\\Theta)^TY -Y^TX\\Theta + Y^TY\n\\]\n\n\nAplicamos la propiedad \\(AB = B^TA^T\\), tal que \\(Y^T(X\\Theta) = (X\\Theta)^T((Y)^T)^T = (X\\Theta)^TY\\)\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{2m} \\Delta_\\Theta (X\\Theta)^T(X\\Theta) - (X\\Theta)^TY - (X\\Theta)^TY + Y^TY\n\\]\n\n\nAgrupamos términos compatibles:\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{2m} \\Delta_\\Theta (X\\Theta)^T(X\\Theta) - 2(X\\Theta)^TY + Y^TY\n\\]\n\n\nComo \\(\\Delta_\\Theta Y^TY=0\\):\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{2m} \\Delta_\\Theta (X\\Theta)^T(X\\Theta) - 2(X\\Theta)^TY\n\\]\n\n\nFinalmente calculamos la derivada matricial:\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{2m} 2X^T(X\\Theta) - 2X^TY = \\frac{1}{m} X^T(X\\Theta) - X^TY\n\\]\n\n\n\n\nAhora igualamos la expresión obtenida a cero:\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{m} [X^TX\\Theta - X^TY] = 0\n\\]\n\n\nMultiplicamos por \\(m\\) en ambos lados de la ecuación:\n\n\n\\[%align\nX^TX\\Theta - X^TY = 0\n\\]\n\n\nSumamos \\(X^TY\\) en ambos lados de la ecuación:\n\n\n\\[%align\nX^TX\\Theta - X^TY + X^TY= X^TY\n\\]\n\n\\[%align\nX^TX\\Theta = X^TY\n\\]\n\n\nMultiplicamos por \\((X^TX)^{-1}\\) por la izquierda en ambos lados de la ecuación:\n\n\n\\[%align\n(X^TX)^{-1}X^TX\\Theta = (X^TX)^{-1}X^TY\n\\]\n\n\\[%align\nI\\Theta = (X^TX)^{-1}X^TY\n\\]\n\n\\[%align\n\\Theta = (X^TX)^{-1}X^TY\n\\]\n\n\nDe tal manera que ahora hemos calculado el vector de pesos óptimo que minimiza el coste.\n\n\nRegularización\n\n\nCon regularización debemos derivar la función que coste que incluye el parámetro de regularización:\n\n\n\\begin{align}\nJ(\\Theta) = \\frac{1}{2m} (X\\Theta - Y)^T(X\\Theta - Y) + \\frac{1}{2m} \\lambda \\Theta^T\\Theta\n\\end{align}\n\n\nEl primer término ya lo hemos derivado, por lo tanto procedemos a derivar el segundo término:\n\n\n\\[%align\n\\Delta_\\Theta \\frac{1}{2m} \\lambda \\Theta^T\\Theta\n\\]\n\n\nSacamos el factor constante \\(\\frac{\\lambda}{2m}\\) fuera de la derivada\n\n\n\\[%align\n\\frac{\\lambda}{2m} \\Delta_\\Theta [\\Theta^T\\Theta]\n\\]\n\n\nLlevamos a cabo la derivada matricial:\n\n\n\\[%align\n\\frac{\\lambda}{2m} 2 \\Theta = \\frac{\\lambda}{m} \\Theta\n\\]\n\n\n\n\nJuntamos las derivadas de ambos términos:\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{m} [X^TX\\Theta - X^TY] + \\frac{\\lambda}{m} \\Theta\n\\]\n\n\nSacamos \\(\\frac{1}{m}\\) como factor común e igualamos a cero\n\n\n\\[%align\n\\Delta_\\Theta J(\\Theta) =  \\frac{1}{m} (X^TX\\Theta - X^TY + \\lambda\\Theta) = 0\n\\]\n\n\nMultiplicamos por \\(m\\) en ambos lados de la ecuación:\n\n\n\\[%align\nX^TX\\Theta - X^TY + \\lambda\\Theta = 0\n\\]\n\n\nSumamos \\(X^TY\\) en ambos lados de la ecuación:\n\n\n\\[%align\nX^TX\\Theta - X^TY + X^TY + \\lambda\\Theta = X^TY\n\\]\n\n\\[%align\nX^TX\\Theta + \\lambda\\Theta = X^TY\n\\]\n\n\nSacamos \\(\\Theta\\) como factor común\n\n\n\\[%align\n(X^TX + \\lambda I)\\Theta = X^TY\n\\]\n\n\nDonde \\(I\\) es la matriz identidad e dimensiones \\((n+1) \\times (n+1)\\). Multiplicamos \\((X^TX + \\lambda I)^{-1}\\) por la izquierda en ambos lados de la ecuación:\n\n\n\\[%align\n(X^TX + \\lambda I)^{-1}(X^TX + \\lambda I)\\Theta = (X^TX + \\lambda I)^{-1}X^TY\n\\]\n\n\\[%align\nI\\Theta = (X^TX + \\lambda I)^{-1}X^TY\n\\]\n\n\\[%align\n\\Theta = (X^TX + \\lambda I)^{-1}X^TY\n\\]\n\n\nDe tal forma que hemos calculado el \\(\\Theta\\) óptimo que minimiza el coste, utilizando regularización.\n\n\n\n\nAnotaciones\n\n\n\nNo se debe utilizar la ecuación normal cuando el número de ejemplos \\(m\\) es muy grande, ya que es rendimiento del algoritmo es malo\n\n\nHay que tener cuidado con si las matrices son inversibles\n\n\nSi \\(m \\leq n\\), entonces las matrices no son invertibles.\n\n\nSi \\(\\lambda > 0\\), entonces aseguramos la inversibilidad de las matrices.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/index.html",
    "title": "Machine Learning Stanford Coursera",
    "body": "\n\nBack\n\n\nMachine Learning Stanford Coursera\n\n\n\nApredizaje supervisado\n\n\n\nRegresión Lineal\n\n\nRegresión Logística\n\n\nEcuación Normal\n\n\nNeural Networks\n\n\nGradient Checking\n\n\nInicialización aleatoria\n\n\nEvaluación de modelos\n\n\nSVM\n\n\n\nAprendizaje no supervisado\n\n\nEn el aprendizaje no supervisado, los ejemplos de entrenamiento no tienen etiquetas (\\(y\\)). Se utilizan para buscar correlación y patrones en los ejemplos de entrenamiento.\n\n\n\n\nClustering\n\n\nDimensionality Reduction\n\n\nExpectation-Maximization Algorithms\n\n\nSistemas de Recomendación\n\n\nGrandes Datasets\n\n\nAprendizaje Online\n\n\nMap Reduce\n\n\nDatos Artificiales\n\n\nCeiling Analysis\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/Inicialización aleatoria.html",
    "title": "Inicialización aleatoria",
    "body": "\n\nBack\n\n\nInicialización aleatoria\n\n\n\n\nCuando creamos una red neuronal, si inicializamos todos los pesos \\(\\theta\\) a cero, entonces todos los nodos serán iguales. Por ello se inicializa \\(\\theta\\) con valores aleatorios dentro de un rango \\([- \\epsilon, \\epsilon]\\)\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Anexo/Explicación de la retropropagación.html",
    "title": "Explicación de la retropropagación",
    "body": "\n\nBack\n\n\nExplicación de la retropropagación\n\n\n\n\n\nDescenso Gradiente\n\n\n\nDerivada del Error\n\n\n\nGradiente\n\n\n\nCapa de salida\n\n\nRetropropagación del Gradiente\n\n\nGradiente Acumulado\n\n\nDerivadas de las Funciones de Activación\n\n\n\n\n\n\n\nComponentes:\n\n\n\n\n\\(w_j^k\\): peso de la neurona \\(j=1...I_k\\) en la capa \\(k=1...H\\)\n\n\n\n\n\n\\(a_{ij}^k=(w_j^k)^Th_i^{k-1}+b_j^k\\): \\(i=1...N\\) (patrón), \\(k=1...H\\)(capa), \\(j=1...I_k\\) (neurona de la capa \\(k\\)). \n\n\n\n\n\n\\(h_i^{k-1}\\): salida de la capa \\(k-1\\) con \\(I_{k-1}\\) valores (uno por cada neurona \\(j=1...I_{k-1}\\) para cada patrón \\(x_i\\).\n\n\n\n\n\n\\(h_i^k\\): salida de la capa \\(k\\) para cada patrón \\(x_i\\): \\(h_{ij}=f(a_{ij}^k)\\) con \\(j=1...I_k\\)\n\n\n\n\n\n\\(y_{ij}\\): salida verdadera de la neurona de salida \\(j\\) y el patrón \\(x_i\\).\n\n\n\n\nDescenso gradiente\n\n\\begin{align}\n\\Delta w_j^k=-\\mu \\frac{\\delta J}{\\delta w_j^k}\n\\end{align}\n\n\\begin{align}\n\\Delta b_j^k=-\\mu \\frac{\\delta J}{\\delta b_j^k}\n\\end{align}\n\n\nPara \\(k=1...H\\). De tal forma que se actualizan los pesos \\(w_j^k\\) y el offset \\(b_j^k\\) de la capa \\(k\\) y de la neurona \\(j\\).\n\n\n\nTenemos que la capa de salida está compuesta de \\(I_H\\) neuronas que se recorren con el índice \\(j\\). Accedemos a la salida verdadera del ejemplo \\(i\\) para la neurona \\(j\\) (\\(y_{ij}\\)) y restamos la salida predicha \\(h_{ij}^H\\) que hace referencia a la salida de la función de activación de la capa \\(H\\) para la neurona \\(j\\) y el ejemplo \\(i\\). La diferencia se eleva al cuadrado para obtener MSE. También se puede vectorizar restando los vectores \\(y_i\\) y \\(h_i^H \\in \\mathbb{R}^j\\). De esta manera obtenemos el error para el patrón \\(x_i\\): \\(J_i\\).\n\n\nDerivada del error\n\n\nAplicamos la regla de la cadena sobre \\(J_i\\), ya que este depende de \\(a_{ij}^k\\):\n\n\n\\begin{align}\n\\frac{\\delta J_i}{\\delta w_j^k}=\\frac{\\delta J_i}{\\delta a_{ij}^k}\\frac{\\delta a_{ij}^k}{\\delta w_j^k}\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta J_i}{\\delta b_j^k}=\\frac{\\delta J_i}{\\delta a_{ij}^k}\\frac{\\delta a_{ij}^k}{\\delta b_j^k}\n\\end{align}\n\n\nDefinimos:\n\n\n\\begin{align}\n\\delta_{ij}^k \\equiv \\frac{\\delta J_i}{\\delta a_{ij}^k}\n\\end{align}\n\n\nEste indica el gradiente de la capa siguiente, para evitar tener que calcularlo.\n\n\n\\begin{align}\n\\frac{\\delta a_{ij}^k}{\\delta w_j^k} = h_i^{k-1}\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta a_{ij}^k}{\\delta b_j^k} = 1\n\\end{align}\n\n\nDebido a que el valor de \\(a_{ij}^k\\) es la combinación lineal de la entradas y los pesos, donde las entradas son las salidas de la capa anterior (\\(k-1\\)), es decir \\(h_i^{k-1}\\), de tal manera que:\n\n\n\\begin{align}\na_{ij}^k = (w_j^k)^Th_i^{k-1}+b_j^k\n\\end{align}\n\n\nPor lo que la derivada en función de \\(w_j^k\\) se corresponde con \\(h_i^{k-1}\\) y la derivada en función de \\(b_j^k\\) es 1.\n\n\n\nGradiente\n\n\nSi sustituimos \\(\\delta_{ij}^k \\equiv \\frac{\\delta J_i}{\\delta a_{ij}^k}\\) y \\(\\frac{\\delta a_{ij}^k}{\\delta w_j^k} = h_i^{k-1}\\) en \\(\\frac{\\delta J_i}{\\delta w_j^k}=\\frac{\\delta J_i}{\\delta a_{ij}^k}\\frac{\\delta a_{ij}^k}{\\delta w_j^k}\\) obtenemos:\n\n\n\\begin{align}\n\\Delta w_j^k=-\\mu \\frac{\\delta J}{\\delta w_j^k}\n\\end{align}\n\n\\begin{align}\n\\Delta w_j^k=-\\mu \\sum_{i=1}^N \\frac{\\delta J_i}{\\delta a_{ij}^k}\\frac{\\delta a_{ij}^k}{\\delta w_j^k} = -\\mu \\sum_{i=1}^N\\delta_{ij}^kh_i^{k-1}\n\\end{align}\n\n\nHacemos los mismo para el offset sustituyendo \\(\\delta_{ij}^k \\equiv \\frac{\\delta J_i}{\\delta a_{ij}^k}\\) y \\(\\frac{\\delta a_{ij}^k}{\\delta b_j^k} = 1\\) en \\(\\frac{\\delta J_i}{\\delta b_j^k}=\\frac{\\delta J_i}{\\delta a_{ij}^k}\\frac{\\delta a_{ij}^k}{\\delta b_j^k}\\) obtenemos:\n\n\n\\begin{align}\n\\Delta b_j^k=-\\mu \\frac{\\delta J}{\\delta b_j^k}\n\\end{align}\n\n\\begin{align}\n\\Delta b_j^k= -\\mu \\sum_{i=1}^N\\frac{\\delta J_i}{\\delta a_{ij}^k}\\frac{\\delta a_{ij}^k}{\\delta b_j^k}=-\\mu \\sum_{i=1}^N\\delta_{ij}^k\n\\end{align}\n\nCapa de salida\n\n\nCalculamos  \\(\\delta_{ij}^k\\) en la capa de salida (\\(k=H\\)), cuyo valor se va a propagar hacia las capas anteriores. Lo que vamos a calcular es \\(\\delta_{ij}^k \\equiv \\frac{\\delta J_i}{\\delta a_{ij}^k}\\). Tenemos que la función de coste para el patrón \\(i\\), \\(J_i\\) viene definida por:\n\n\n\\begin{align}\nJ_i=\\frac{1}{2}\\sum_{j=1}^{I_H}(y_{ij}-h_{ij}^H)^2=\\frac{|y_i-h_i^H|^2}{2}\n\\end{align}\n\n\nAdemás el valor de \\(a_{ij}^k\\), que es la combinación lineal de las entradas (salidas de las neuronas capa anterior, \\(k-1\\)) y los pesos junto con el offset:\n\n\n\\begin{align}\na_{ij}^k=(w_j^k)^Th_i^{k-1}+b_j^k\n\\end{align}\n\n\nPor lo tanto en la capa final:\n\n\n\\begin{align}\n\\frac{\\delta J_i}{\\delta a_{ij}^H}=\\frac{1}{2}\\frac{\\delta (y_{ij}-h_{ij}^H)^2}{\\delta (y_{ij}-h_{ij}^H)}\\frac{\\delta (y_{ij}-h_{ij}^H)}{\\delta a_{ij}^H}\n\\end{align}\n\n\nDonde:\n\n\n\\begin{align}\n\\frac{\\delta (y_{ij}-h_{ij}^H)^2}{\\delta (y_{ij}-h_{ij}^H)}=2(y_{ij}-h_{ij}^H)\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta (y_{ij}-h_{ij}^H)}{\\delta a_{ij}^H}=\\frac{\\delta y_{ij}}{\\delta a_{ij}^H}-\\frac{\\delta h_{ij}^H}{\\delta a_{ij}^H}=0-f'(a_{ij}^H)\n\\end{align}\n\n\nYa que sabemos que \\(h_{ij}^H=f(a_{ij}^H)\\), por lo que:\n\n\n\\begin{align}\n\\frac{\\delta h_{ij}^H}{\\delta a_{ij}^H}=\\frac{\\delta f(a_{ij}^H)}{\\delta a_{ij}^H}=f'(a_{ij}^H)\n\\end{align}\n\n\nUna vez desarrollado todo esto sustiuimos los resultados en \\(\\frac{\\delta J_i}{\\delta a_{ij}^H}\\):\n\n\n\\begin{align}\n\\frac{\\delta J_i}{\\delta a_{ij}^H}=\\frac{1}{2}2(y_{ij}-h_{ij}^H)(-f'(a_{ij}^H))=(y_{ij}-h_{ij}^H)f'(a_{ij}^H)\n\\end{align}\n\n\nDe tal forma que:\n\n\n\\begin{align}\n\\delta_{ij}^H=\\frac{\\delta J_i}{\\delta a_{ij}^H}=(y_{ij}-h_{ij}^H)f'(a_{ij}^H)=\\epsilon_{ij}^Hf'(a_{ij}^H)\n\\end{align}\n\n\nDonde se define \\(\\epsilon_{ij}^H\\) como:\n\n\n\\begin{align}\n\\epsilon_{ij}^H=y_{ij}-h_{ij}^H\n\\end{align}\n\n\nFinalmente obtenemos que el antigradiente en la última capa \\(H\\) viene dado por:\n\n\n\\begin{align}\n\\Delta w_j^H=-\\mu \\sum_{i=1}^N\\delta_{ij}^Hh_i^{H-1}=-\\mu\\sum_{i=1}^N\\epsilon_{ij}^Hf'(a_{ij}^H)h_i^{H-1}\n\\end{align}\n\n\\begin{align}\n\\Delta b_j^H=-\\mu \\sum_{i=1}^N\\delta_{ij}^H=-\\mu\\sum_{i=1}^N\\epsilon_{ij}^Hf'(a_{ij}^H)\n\\end{align}\n\nRetropropagación del gradiente\n\n\nPara las capas anteriores a la capa de salida (\\(k<H\\)):\n\n\n\\begin{align}\n\\delta_{ij}^k=\\frac{\\delta J_i}{\\delta a_{ij}^k}=\\sum_{l=1}^{I_{k+1}}\\frac{\\delta J_i}{\\delta a_{il}^{k+1}}\\frac{\\delta a_{il}^{k+1}}{\\delta a_{ij}^k}=\\sum_{l=1}^{I_{k+1}}\\delta_{il}^{k+1}\\frac{\\delta a_{il}^{k+1}}{\\delta a_{ij}^k}\n\\end{align}\n\n\nEn este caso se utiliza la regla de la cadena para obtener \\(\\delta_{ij}^k\\) de modo que se tienen en cuenta todas las combinaciones del gradiente acumulado \\(\\delta a_{il}^{k+1}\\) con la neurona actual (\\(\\delta a_{ij}^k\\)) donde \\(l=1...I_{k+1}\\), es decir se tienen encuenta todas las neuronas de la capa siguiente. \n\n\n\nCon grafos, la regla de la cadena se puede interpretar como todos los caminos posibles desde la capa de salida hasta la neurona \\(j\\) en la capa \\(k\\). Cada camino une cada neurona \\(l\\) de la capa siguiente: \\(\\delta_{il}^{k+1}\\) (el cual ya tiene el gradiente acumulado de las capas siguientes) con una neurona \\(j\\) de la capa actual: \\(\\delta a_{ij}^k\\) de la siguiente forma: \\(\\delta_{il}^{k+1}\\frac{\\delta a_{il}^{k+1}}{\\delta a_{ij}^k}\\). Además se suman todas las combinación posibles: \\(\\sum_{l=1}^{I_{k+1}}\\).\n\n\n\nEsto nos permite utilizar el gradiente acumulado calculado en la capa siguiente que se propaga hacia atrás en la red neuronal, lo que evita tener que calcular \\(\\frac{\\delta J_i}{\\delta a_{ij}^k}\\).\n\n\n\nPor otro lado tenemos:\n\n\n\\begin{align}\na_{il}^{k+1}=(w_l^{k+1})^Th_i^{k}+b_l^{k+1}\n\\end{align}\n\n\nQue es el cálculo de la neurona \\(l\\) de la capa siguiente, por lo que utiliza como entradas las salidas de la neurona de esta capa \\(h_i^{k}\\). Esta es la versión vectorizada del cálculo, si lo expresamos como sumatorio:\n\n\n\\begin{align}\na_{il}^{k+1}=\\sum_{m=1}^{I_k}w_{lm}^{k+1}h_{im}^{k}+b_{lm}^{k+1}=\\sum_{m=1}^{I_k}w_{lm}^{k+1}f(a_{im}^{k})+b_{lm}^{k+1}\n\\end{align}\n\n\nDe tal forma que se multiplican los \\(I_k\\) pesos de la capa siguiente (\\(w_{lm}^{k+1}\\)) con las \\(I_k\\) salidas de la capa actual (\\(h_{im}^{k}\\)) y sumamos los offset (\\(b_{lm}^{k+1}\\)). Además sabemos que \\(h_{im}^{k}=f(a_{im}^{k})\\). Por lo tanto:\n\n\n\\begin{align}\n\\frac{\\delta a_{il}^{k+1}}{\\delta a_{ij}^k}=\\sum_{m=1}^{I_k}(\\frac{\\delta(w_{lm}^{k+1}f(a_{im}^{k}))}{\\delta a_{ij}^k}+\\frac{\\delta b_{lm}^{k+1}}{\\delta a_{ij}^k})\n\\end{align}\n\n\nLa primera derivada tiene la siguiente forma:\n\n\n\\begin{align}\n\\frac{\\delta(w_{lm}^{k+1}f(a_{im}^{k}))}{\\delta a_{ij}^k}=w_{lm}^{k+1}\\frac{\\delta f(a_{im}^{k})}{\\delta a_{ij}^k}\n\\end{align}\n\n\\begin{align}\n\\frac{\\delta f(a_{im}^{k})}{\\delta a_{ij}^k} =\\begin{cases}\nf'(a^k_{im})=f'(a^k_{ij}) & m=j\\\\\n0 & m \\ne j\n\\end{cases}\n\\end{align}\n\n\nPor lo que podemos eliminar el sumatorio sobre \\(m\\) y la derivada sobre el offset ya que su valor es nulo:\n\n\n\\begin{align}\n\\frac{\\delta a_{il}^{k+1}}{\\delta a_{ij}^k}=w_{lj}^{k+1}f'(a^k_{ij}) + 0\n\\end{align}\n\nGradiente acumulado\n\n\nSi volvemos a \\(\\delta_{ij}^k=\\frac{\\delta J_i}{\\delta a_{ij}^k}=\\sum_{l=1}^{I_{k+1}}\\delta_{il}^{k+1}\\frac{\\delta a_{il}^{k+1}}{\\delta a_{ij}^k}\\). Sustituimos \\(\\frac{\\delta a_{il}^{k+1}}{\\delta a_{ij}^k}\\) obteniendo:\n\n\n\\begin{align}\n\\delta_{ij}^k=\\frac{\\delta J_i}{\\delta a_{ij}^k}=\\sum_{l=1}^{I_{k+1}}\\delta_{il}^{k+1}w_{lj}^{k+1}f'(a^k_{ij})\n\\end{align}\n\n\nPodemos extraer \\(f'(a^k_{ij})\\) ya que esta no depende de \\(l\\):\n\n\n\\begin{align}\n\\delta_{ij}^k=f'(a^k_{ij})\\sum_{l=1}^{I_{k+1}}\\delta_{il}^{k+1}w_{lj}^{k+1}\n\\end{align}\n\n\nSi definimos:\n\n\n\\begin{align}\n\\epsilon_{ij}^k=\\sum_{l=1}^{I_{k+1}}\\delta_{il}^{k+1}w_{lj}^{k+1}\n\\end{align}\n\n\nTenemos que:\n\n\n\\begin{align}\n\\delta_{ij}^k=f'(a^k_{ij})\\epsilon_{ij}^k\n\\end{align}\n\nDerivadas de las funciones de activación\n\n\nLa derivada de la función sigmoide:\n\n\n\\begin{align}\nf'(t)=af(t)(1-f(t))\n\\end{align}\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Anexo/Ejemplo Cálculo Función de Coste.html",
    "title": "Ejemplo Cálculo Función de Coste",
    "body": "\n\nBack\n\n\nEjemplo Cálculo Función de Coste\n\n\n\n\nUtilizamos como ejemplo la figura de multiclasificación donde tenemos que \\(c=3\\), y la hipótesis tiene los valores:\n\n\n\\begin{align}\nh_\\Theta(x_1) = \n\\begin{bmatrix}\n0.02 \\\\\n0.1 \\\\\n0.88 \\\\\n\\end{bmatrix}\n\\end{align}\n\n\ny la salida real para el ejemplo \\(x_1\\) tiene los valores:\n\n\n\\begin{align}\ny_1 = \n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n1 \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nEntonces la función de coste se calcularía como (observa que esto es sólo para un ejemplo, por lo que obviamos el primer sumatorio):\n\n\n\\begin{align}\nJ(\\Theta) = - \\sum_{i=1}^c [y_{ij}\\cdot \\log(h_\\Theta(x_j)_i)] + [(1-y_{ij})\\cdot \\log(1-(h_\\Theta(x_j)_i))]\n\\end{align}\n\n\\begin{align}\nJ(\\Theta) = - \\{[(y_{11}\\cdot\\log(h_\\Theta(x_1)_{1})) + (1-y_{11})\\cdot\\log(1-h_\\Theta(x_1)_{1})] +\n\\end{align}\n\n\\begin{align}\n+ [(y_{21}\\cdot\\log(h_\\Theta(x_1)_{2})) + (1-y_{21})\\cdot\\log(1-h_\\Theta(x_1)_{2})] +\n\\end{align}\n\n\\begin{align}\n+ [(y_{31}\\cdot\\log(h_\\Theta(x_1)_{3})) + (1-y_{31})\\cdot\\log(1-h_\\Theta(x_1)_{3})]\\}\n\\end{align}\n\n\nSustituimos los valores de cada vector:\n\n\n\\begin{align}\nJ(\\Theta) = - \\{ [(0\\cdot\\log(0.02)) + (1-0)\\cdot\\log(1-0.02)] +\n\\end{align}\n\n\\begin{align}\n+ [(0\\cdot\\log(0.1)) + (1-0)\\cdot\\log(1-0.1)] +\n\\end{align}\n\n\\begin{align}\n+ [(1\\cdot\\log(0.88)) + (1-1)\\cdot\\log(1-0.88)] \\} = \n\\end{align}\n\n\nCalculamos los valores:\n\n\n\\begin{align}\nJ(\\Theta) = - (\\log(0.98) + \\log(0.9) + \\log(0.88)) \n\\end{align}\n\n\\begin{align}\nJ(\\Theta) = - (-0.009 - 0.046 -0.056) = - (-0.111) = 0.111\n\\end{align}\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Anexo/Derivadas capas intermedias.html",
    "title": "Derivadas capas intermedias",
    "body": "\n\nBack\n\n\nDerivada capas intermedias\n\n\nDonde \\(q\\) denota la capa, con \\(1 \\leq q \\leq (k-1)\\). Pues lo que tenemos que hacer es, de nuevo, aplicar la regla de la cadena, entre el peso \\(\\theta_{it}^{(q)}\\) (peso \\(t\\) del nodo \\(i\\) de la capa \\(q\\)) y todo nodo \\(a_{lj}^{(q+1)}\\)(es decir para el nodo \\(l\\) en la capa \\(q+1\\) para el ejemplo \\(j\\)).\n\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(q)}} = \\frac{J(\\Theta)}{\\delta a^{(q+1)}_{1j}}\\frac{\\delta a_{1j}^{(q+1)}}{\\delta \\theta_{it}^{(q)}} + \\cdots + \\frac{J(\\Theta)}{\\delta a^{(q+1)}_{(S_(q+1))j}}\\frac{\\delta a_{(S_(q+1))j}^{(q+1)}}{\\delta \\theta_{it}^{(q)}}\n\\]\n\n\n\nDonde \\(S_{(q+1)}\\) es el número de nodos en la capa \\(q+1\\). Para cada término \\(l\\) de la suma, debemos volver a aplicar la regla de la cadena, tal que:\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(q)}} = \\frac{J(\\Theta)}{\\delta a^{(q+1)}_{lj}}\\frac{\\delta a_{lj}^{(q+1)}}{\\delta a_{lj}^{(q)}}\\frac{\\delta a_{lj}^{(q)}}{\\delta \\theta_{it}^{(q)}}\n\\]\n\n\nEs decir:\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(q)}} = \\sum_{l=1}^{S_{(q+1)}} \\frac{J(\\Theta)}{\\delta a^{(q+1)}_{lj}}\\frac{\\delta a_{lj}^{(q+1)}}{\\delta a_{lj}^{(q)}}\\frac{\\delta a_{lj}^{(q)}}{\\delta \\theta_{it}^{(q)}}\n\\]\n\n\nCabe destacar que \\(\\frac{\\delta a_{lj}^{(q)}}{\\delta \\theta_{it}^{(q)}} = \\frac{\\delta g(z_{lj}^{(q)})}{\\delta z_{lj}^{(q)}} \\frac{\\delta z_{lj}^{(q)}}{\\delta \\theta_{it}^{(q)}}\\) (explicado en Derivada de la función del coste).\n\n\n\nEntonces, si generalizamos para todos los ejemplos, \\(m\\):\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(q)}} = \\sum_{j=1}^m\\sum_{l=1}^{S_{(q+1)}} \\frac{J(\\Theta)}{\\delta a^{(q+1)}_{lj}}\\frac{\\delta a_{lj}^{(q+1)}}{\\delta a_{lj}^{(q)}}\\frac{\\delta a_{lj}^{(q)}}{\\delta \\theta_{it}^{(q)}}\n\\]\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Anexo/index.html",
    "title": "Anexo",
    "body": "\n\nBack\n\n\nAnexo\n\n\n\n\n\nClasificación múltiple\n\n\nFunción de coste\n\n\nRetropropagación\n\n\nAlgoritmo\n\n\n\n\n\nClasificación múltiple\n\n\nPara crear una red neuronal que permita trabajar con \\(c\\) clases lo que hacemos es hacer que la red neuronal tenga \\(c\\) nodos en su capa de salida. Esto se ilustra en la siguiente imagen:\n\n\n\n\n\n\n\nDe tal manera que ahora, cada salida \\(y_j\\) será un vector columna \\(c\\times1\\), donde existe un valor por cada categoría, al igual que la hipótesis para el ejemplo \\(j\\), \\(h_\\Theta(x_j)\\), es un vector columna \\(c\\times1\\).\n\n\n\nComo podemos ver, los valores de \\(y_j\\) indican claramente a qué clase pertenece el ejemplo \\(j\\) (clase 3), mientras que la hipótesis \\(h_\\Theta(x_j)\\) ofrece, para cada clase (columna) la probabilidad de que el ejemplo \\(j\\) pertenezca a esa clase.\n\n\n\nFunción de coste\n\nNotación\n\n\nComo ya hemos visto en función del número de clases la salida tendrá distinta forma:\n\n\n\n\nClasificación binaria: para cada ejemplo \\(j\\), \\(y_j \\in \\{0, 1\\}\\), \\(h_\\Theta(x_j) \\in \\mathbb{R}\\)\n\n\nClasificación múltiple: para cada ejemplo \\(j\\), \\(y \\in \\mathbb{R}^c\\), \\(h_\\Theta(x_j) \\in \\mathbb{R}^c\\), donde \\(c\\) es el número de clases\n\n\nSea \\(k\\) el número de capas y \\(S_i\\) el número de nodos en la capa \\(i\\).\n\n\nSea \\(Y=(y_{ij})\\) una matriz \\(c\\times m\\), donde \\(m\\) es el número de ejemplos y cada \\(y_{j}\\) es el vector columna \\(c\\times1\\) de salida para el ejemplo \\(j\\).\n\n\n\n\n\n\nDefinimos la función de coste como sigue:\n\n\n\\begin{align}\nJ(\\Theta) = - \\frac{1}{m} \\left\\{ \\sum_{j=1}^m \\sum_{i=1}^c [y_{ij}\\cdot \\log(h_\\Theta(x_j)_i)] + [(1-y_{ij})\\cdot \\log(1-(h_\\Theta(x_j)_i))]\\right\\}\n\\end{align}\n\n\nEl primer sumatorio que va de 1 a \\(m\\) se encarga de calcular el coste para cada ejemplo \\(j\\). Mientras que el segundo sumatorio, que va de 1 a \\(c\\), se encarga de calcular el coste para cada nodo de salida.\n\n\n\nEsta función se aplica sobre los \\(k\\) nodos en la capa de salida. \n\n\n\nEjemplo Cálculo Función de Coste\n\n\n\nRegularización\n\n\nDefinimos la función de coste introduciendo regularización como sigue:\n\n\n\\begin{align}\nJ(\\Theta) = - \\frac{1}{m} \\left\\{ \\sum_{j=1}^m \\sum_{i=1}^c [y_{ij}\\cdot \\log(h_\\Theta(x_j)_i)] + [(1-y_{ij})\\cdot \\log(1-(h_\\Theta(x_j)_i))]\\right\\} + \\frac{\\lambda}{2m} \\sum_{q=1}^k \\sum_{i=1}^{S_q}\\sum_{j=1}^{S_{q+1}} (\\theta_{ji}^{(q)})^2\n\\end{align}\n\n\n\nAntes de nada, recordar que \\(S_q\\) denota el número de nodos en la capa \\(q\\). Entonces, el primer término de la función es igual que cuando no se aplicaba regularización. Expliquemos el segundo término. La regularización, en este caso, consiste en sumar todos los pesos de la red neuronal, por lo tanto:\n\n\n\n\nPor cada capa \\(q\\), con \\(1 \\leq q \\leq k\\), sumamos todos los elementos de la matriz de pesos \\(\\Theta^{q}\\), que como sabemos tiene dimensiones \\(S_{q} \\times S_{q-1}\\) \n\n\nDada la matriz \\(\\Theta^{(q)}\\)\n\n\n\nRecorremos cada columna \\(i\\), con \\(1 \\leq i \\leq S_{q-1}\\)\n\n\nRecorremos cada elemento \\(j\\) de la columna \\(i\\), con \\(1 \\leq j \\leq S_{q}\\)\n\n\nSumamos al total cada elemento de la matriz \\(\\Theta^{(q)}_{ji}\\)\n\n\n\nUna vez se han sumado todas las matrices de pesos obtenemos un escalar, que multiplicamos por \\(\\frac{\\lambda}{2m}\\)\n\n\n\nMúltiple Ejemplos\n\n\nLa salida de cada capa \\(q\\) es una matriz \\(S_q \\times m\\), donde \\(S_q\\) denota el número de nodos en la capa \\(q\\) y \\(m\\) denota el número de ejemplos. \n\n\n\nComo vimos en nuestras figuras, donde se presentaban los cálculos sólo para un ejemplo, en cada capa \\(q\\) podemos mapear la salida de los \\(S_q\\) nodos a un vector columna \\(S_q \\times 1\\). \n\n\n\nSi generalizamos esto a \\(m\\) ejemplos tenemos que la salida de cada capa es una matriz \\(S_q \\times m\\). Esto se ilustra en la siguiente imagen:\n\n\n\n\n\n\n\nRetropropagación\n\n\nVamos, ahora a explicar cómo se aplica la retropropagación. Lo primero que debemos tener en cuenta es que este proceso se basa en la misma idea de optimización que la Regresión Lineal y la Regresión Logística, es decir, lo que queremos hacer es minimizar el coste, \\(J(\\Theta)\\)\n\n\n\n\nSea \\(c\\) el número de nodos en la última capa, \\(\\theta_{it}\\) el peso \\(t\\) del nodo \\(i\\) de la última capa \\(k\\), \\(a_{ij}^{(k)}\\) la salida del nodo \\(i\\) para el ejemplo \\(j\\) en la capa \\(k\\):\n\n\n\nCalculamos el gradiente de la última capa \\(k\\) como: \\(\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\frac{\\delta J(\\Theta)}{\\delta a_{1j}^{(k)}}\\frac{\\delta a_{1j}^{(k)}}{\\delta \\theta_{it}^{(k)}}\\)\n\n\nCalculamos el gradiente en capas intermedias utilizando la regla de la cadena como: \\(\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(q)}} = \\sum_{i=1}^{S_{(q+1)}} \\frac{\\delta J(\\Theta)}{\\delta a_{ij}^{(q+1)}}\\frac{\\delta a_{ij}^{(q+1)}}{\\delta a_{ij}^{(q)}}\\frac{\\delta a_{ij}^{(q)}}{\\delta \\theta_{it}^{(q)}}\\)\n\n\n\n\nNormalmente en las capas intermedias, \\(q\\), nos referimos al término \\(\\frac{\\delta J(\\Theta)}{\\delta a_{ij}^{(q+1)}}\\) como \\(\\Delta^{(q+1)}_{ij}\\).\n\n\n\nExplicación de la retropropagación\n\n\n\n\n\nDerivada de la función de coste\n\n\nA continuación explicamos cómo derivar la función de coste (Paso 1).\n\n\n\nDerivada de la función de coste\n\n\n\n\n\nCapas intermedias\n\n\nVeamos, ahora, cómo llevar a cabo el Paso 2: ¿cómo calculamos el gradiente (o lo que contribuye el peso \\(it\\) en el error) para los pesos de las capas intermedias?, es decir, cómo calculamos:\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(q)}} \n\\]\n\n\nDerivadas capas intermedias\n\n\n\n\nEjemplo de retropropagación\n\n\nEjemplo de retropropagación\n\n\n\n\n\nAlgoritmo\n\n\nPartes del algoritmo en python\n\n\nNotación\n\n\n\nÉpoca: iteración en el entrenamiento\n\n\nPesos (\\(w_j^k, b_j^k\\)): se inicializan de forma aletoria (evitar simetría) y con valores bajos.\n\n\nCriterios de finalización\n\n\n\n\\(J\\) o gradiente de \\(J\\) inferior a un umbral\n\n\nNúmero máximo de épocas\n\n\n\nVelocidad de apredizaje \\(\\mu\\) intermedia: evita lentitud en las oscilaciones\n\n\nCaída en mínimos locales que pueden tener \\(J\\) elevado. Es por ello que se ejecuta varias veces el entrenamiento y se selecciona aquel que obtenga mejor resultado.\n\n\nActualización de pesos patrón a patrón en lugar de tras computar el error sobre todo el dataset. Puede evitar mínimos locales y converge antes.\n\n\nFunción de activación sigmoide para clasificación o linear para regresión\n\n\n\nPseudocódigo\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Anexo/Ejemplo de retropropagación.html",
    "title": "Ejemplo de retropropagación",
    "body": "\n\nBack\n\n\nEjemplo de retropropagación\n\n\n\n\nPor ejemplo, supongamos que tenemos una red con tres capas, entonces \\(k=3\\), dado un ejemplo \\(x_j\\). En este caso tenemos que \n\n\nCapa 3\n\n\nLa derivada en la última capa, para el único vector de pesos \\(\\theta^{(3)}_1\\) que tiene \\(n\\) elementos (features o características), es: \\(\\frac{\\delta J(\\Theta)}{\\delta \\theta_{1t}^{(3)}}\\), para cada \\(t\\), \\(0 \\leq t \\leq n\\)\n\n\n\nComo: \n\n\n\\begin{align}\nJ(\\Theta) = E^{(3)}(a_1^{(3)}) = E^{(3)}(g(z_1^{(3)})) = E^{(3)}(g(\\Theta^{(3)}\\cdot a^{(2)}))\n\\end{align}\n\n\nDonde denotamos la función que calcula el error entre lo predicho y la salida real como \\(E\\), y \\(g\\) es la función de activación.\n\n\n\nEntonces, aplicamos la regla de la cadena para cada elemento \\(t\\) en el vector de pesos:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{1t}^{(3)}} = \\frac{\\delta J(\\Theta)}{\\delta a_1^{(3)}}\\frac{\\delta a_1^{(3)}}{\\delta z_1^{(3)}}\\frac{\\delta z_1^{(3)}}{\\delta \\theta_{1t}^{(3)}}\n\\end{align}\n\n\nSi vectorizamos:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{1}^{(3)}} = \\frac{\\delta J(\\Theta)}{\\delta a_1^{(3)}}\\frac{\\delta a_1^{(3)}}{\\delta z_1^{(3)}}\\frac{\\delta z_1^{(3)}}{\\delta \\theta_{1}^{(3)}}\n\\end{align}\n\nCapa 2\n\n\nSi ahora queremos obtener la derivada para uno de los vectores de pesos en la capa \\(2\\), volvemos a aplicar la regla de la cadena. Tenemos ahora que desestructurar la función de coste todavía más, hasta obtener la expresión que incluye las salidas de la capa \\(1\\), \\(a^{(1)}\\).\n\n\n\\begin{align}\nJ(\\Theta) = E^{(3)}(g(\\Theta^{(3)}\\cdot a^{(2)})) = E^{(3)}(g(\\Theta^{(3)}\\cdot g(z^{(2)}))) = E^{(3)}(g(\\Theta^{(3)}\\cdot g(\\Theta^{(2)} \\cdot a^{(1)})))\n\\end{align}\n\n\nSea \\(\\Delta^{(3)}_{1j}\\):\n\n\n\\begin{align}\n\\Delta^{(3)}_{1j} = \\frac{\\delta J(\\Theta)}{\\delta a_{1j}^{(3)}}\\frac{\\delta a_{1j}^{(3)}}{\\delta z_{1j}^{(3)}}\n\\end{align}\n\n\nEntonces, aplicamos la regla de la cadena para cada nodo \\(i\\) de la capa \\(2\\) y para cada elemento \\(t\\): \n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(2)}} = \\sum_{l=1}^{S_{(3)}} \\Delta_{lj}^{(3)}\\frac{\\delta z_{lj}^{(3)}}{\\delta a_{lj}^{(2)}}\\frac{\\delta a_{lj}^{(2)}}{\\delta z_{lj}^{(2)}}\\frac{\\delta z_{lj}^{(2)}}{\\delta \\theta_{it}^{(2)}} = \\Delta_{1j}^{(3)}\\frac{\\delta z_{1j}^{(3)}}{\\delta a_{1j}^{(2)}}\\frac{\\delta a_{1j}^{(2)}}{\\delta z_{1j}^{(2)}}\\frac{\\delta z_{1j}^{(2)}}{\\delta \\theta_{it}^{(2)}}\n\\end{align}\n\n\nSi vectorizamos:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{i}^{(2)}} = \\Delta_{j}^{(3)}\\frac{\\delta z^{(3)}}{\\delta a_{j}^{(2)}}\\frac{\\delta a_{j}^{(2)}}{\\delta z_{j}^{(2)}}\\frac{\\delta z_{j}^{(2)}}{\\delta \\theta_{i}^{(2)}}\n\\end{align}\n\nCapa 1\n\n\nPara la capa \\(1\\), volvemos a expandir la función de coste para ver cómo aplicar la regla de la cadena:\n\n\n\n\\begin{align}\nJ(\\Theta) = E^{(3)}(g(\\Theta^{(3)}\\cdot g(\\Theta^{(2)} \\cdot a^{(1)}))) = E^{(3)}(g(\\Theta^{(3)}\\cdot g(\\Theta^{(2)} \\cdot g(z^{(1)})))) =\n\\end{align}\n\n\\begin{align}\n= E^{(3)}(g(\\Theta^{(3)}\\cdot g(\\Theta^{(2)} \\cdot g(\\Theta^{(1)} x_j))))\n\\end{align}\n\n\nPara simplificar la notación: sea, para cada nodo \\(l\\) de la capa \\(2\\)\n\n\n\\begin{align}\n\\Delta^{(2)}_{lj} = \\Delta_{1j}^{(3)}\\frac{\\delta z_1^{(3)}}{\\delta a_{lj}^{(2)}}\\frac{\\delta a_{lj}^{(2)}}{\\delta z_{lj}^{(2)}}\n\\end{align}\n\n\n\n\nAplicamos la regla de la cadena, tal que para cada nodo \\(l\\) de la capa \\(2\\):\n\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(1)}} = \\sum_{l=1}^{S_{(2)}} \\Delta_{lj}^{(2)}\\frac{\\delta z_{lj}^{(2)}}{\\delta a_{lj}^{(1)}}\\frac{\\delta a_{lj}^{(1)}}{\\delta z_{lj}^{(1)}}\\frac{\\delta z_{lj}^{(1)}}{\\delta \\theta_{it}^{(1)}}\n\\end{align}\n\n\nSi vectorizamos:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{i}^{(1)}} = \\Delta_{j}^{(2)}\\frac{\\delta z_{j}^{(2)}}{\\delta a_{j}^{(1)}}\\frac{\\delta a_{j}^{(1)}}{\\delta z_{j}^{(1)}}\\frac{\\delta z_{j}^{(1)}}{\\delta \\theta_{i}^{(1)}}\n\\end{align}\n\n\nEl procedimiento se ilustra en la siguiente figura:\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Anexo/Partes del algoritmo en python.html",
    "title": "Algoritmo",
    "body": "\n\nBack\n\n\nAlgoritmo\n\n\n\n\nDado un conjunto de entrenamiento \\(X\\), donde \\(X\\) es una matriz \\((n + 1) \\times m\\) con \\(m\\) ejemplos:\n\n\n\n\nPropagación hacia adelante\ndef feed_forward(self, theta=None, capa=None, test=False):\n\n    if theta is None:                                                   # Si no se introduce theta como argumento\n        theta = self.theta                                              # Inicializar theta con el almacenado en el objeto\n\n    if test:                                                            # Si se indica utilizar X_test\n        a = self.X_test\n        n, m = self.X_test.shape                                        # Guardar dimensiones de test\n    else:\n        a = self.X                                                      # La primera entrada es X\n        n, m = self.X.shape                                             # Guardar dimensiones de train\n\n    if capa is not None:                                                # Si se ha indicado una capa\n        if capa <= len(theta) and capa >= 0:                            # Chequeamos que la capa esta dentro de los limites\n            for i in range(capa):                                       # Recorremos las capas\n                a = self.sigmoid(theta[i], a)                           # Calculamos la salida de la capa\n                a = np.concatenate((np.matrix(np.ones(m)), a))          # Añadimos una fila de unos\n            return a\n        else:\n            print(\"El número de capa no es válido\")                     # Mensaje de error\n    else:\n        for elemento in theta:\n            a = self.sigmoid(elemento, a)                               # Calculamos la salida de la capa actual\n            a = np.concatenate((np.matrix(np.ones(m)), a))              # Añadimos una fila de unos\n        h = a[1:, :]                                                    # Eliminamos los 1 en la última capa\n        return h\n\n\n\nCalculo del coste en la última capa\ndef calculo_coste(self, theta=None, unrolled=False):\n\n    if theta is None:                                                                                                   # Si no se introduce theta como argumento\n        theta = self.theta                                                                                              # Inicializar theta con el almacenado en el objeto\n\n    if unrolled:                                                                                                        # Si theta se ha flatten en un vector de una dimension\n        theta = self._roll_theta(theta)                                                                                 # Crear lista con matriz theta de capa capa\n\n    h = self.feed_forward(theta)                                                                                        # Obtener la salida para todos los ejemplo\n    coste = -np.sum(np.diagonal(self.y_hot_enc.T.dot(np.log(h)) + (1 - self.y_hot_enc.T).dot(np.log(1 - h))))/self.m    # Calcular el error con la matriz codificada de y\n\n    if self.reg:                                                                                                        # Si se ha indicado que se aplica regularizacion\n        reg_parcial = 0                                                                                                 # Inicializamos la variable temporal\n        for elemento in theta:                                                                                          # Para capa\n            reg_parcial += np.sum(np.power(elemento[:, 1:], 2))                                                         # No sumar el término independiente en cada nodo: primera fila\n        reg_result = self.reg_par/(2*self.m)*(reg_parcial)                                                              # Calcular la regularizacion\n        coste = coste + reg_result\n    \n    return coste\n\n\n\nActualizar los pesos con propagación hacia atrás:\ndef back_propagation(self, theta=None, unrolled=False, unroll=False):\n  \n        if theta is None:                                                                               # Si no se ha indicado ningun theta como argumento\n            theta = self.theta                                                                          # Inicializar theta con el almacenado en el objeto\n        \n        if unrolled:\n            theta = self._roll_theta(theta)                                                             # Creamos una lista del array\n\n        delta = []                                                                                      # Inicializamos las lista temporal que contendra el delta de cada nodo\n        delta_sum = []                                                                                  # Inicializamos la lista temporal que contendra el sumatorio delta\n        gradientes = []                                                                                 # Inicializamos la lista que contendrá los gradientes de cada capa\n\n        h = self.feed_forward(theta=theta)                                                              # Calculamos el valor del la salida para empezar a propagar hacia atras   \n\n        delta_next = h - self.y_hot_enc                                                                 # Calculamos el primer delta: el de la ultima capa\n        delta.append(delta_next)                                                                        # Lo añadimos a la lista temporal\n        indice = self.numero_capas - 1                                                                  # El indice indica hasta que capa calcular la salida\n        \n        for elemento in reversed(theta[1:]):                                                            # Recorremos las capas de atras hacia adelante\n            h = self.feed_forward(theta=theta, capa=indice)                                             # Calculamos la salida de la capa actual\n            delta_aux = np.multiply(elemento.T.dot(delta_next), self.sigmoid_gradient(elemento, h))     # Aplicamos la formula del gradiente\n            delta_next = delta_aux[1:, :]                                                               # No cogemos el elemento independiente\n            delta.append(delta_next)                                                                    # Lo añadimos a la lista de delta\n            indice -= 1                                                                                 # Actualizamos el indice\n        \n        delta.reverse()                                                                                 # Damos la vuelta a la lista\n        for indice in range(len(delta)):                                \n            h = self.feed_forward(theta=theta, capa=indice)                                             # Obtenemos la salida de cada capa\n            delta_sum.append(delta[indice].dot(h.T))                                                    # Añadimos (delta * a) a la lista de delta_mayuscula -> sumatorio\n\n        for indice in range(len(delta_sum)):\n            gradiente = (1/self.m) * delta_sum[indice]                                                  # Calculamos el grandiente: delta_mayuscula / m\n            if self.reg:\n                gradiente[1:, :] += (self.reg_par/self.m) * theta[indice][1:, :]                        # Si se indica regularizacion aplicarla: no regularizan primer elemento\n            gradientes.append(gradiente)                                                                # Lo añadimos a la lista\n\n        coste = self.calculo_coste(theta=theta)\n\n        if unroll:                                                                                      # Si se ha indicado que se quiere hacer flatten a un vector de una dimension\n            return coste, self._unroll_theta(gradientes)\n        else:\n            return coste, gradientes\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Anexo/Derivada de la función de coste.html",
    "title": "Derivada de la función de coste",
    "body": "\n\nBack\n\n\nDerivada de la Función de Coste\n\n\nSabemos que la función de coste:\n\n\n\\[%align\nJ(\\Theta) = - \\frac{1}{m} \\left\\{ \\sum_{j=1}^m\\sum_{i=1}^c (y_{ij}\\cdot \\log(h_\\Theta(x_j)_i)) + [(1-y_{ij})\\log(1-h_\\Theta(x_j)_i)]\\right\\}\n\\]\n\n\nDonde \\(\\theta_{it}^{(k)}\\) es el peso que conecta el nodo \\(i\\) de la capa \\(k\\) con el nodo \\(t\\) de la capa \\((k-1)\\), es decir, es el elemento en la fila \\(i\\) columna \\(t\\) de la matriz de pesos de la capa \\(k\\), \\(\\Theta^{(k)}\\).\n\n\n\nPor la regla de la cadena, separamos la derivada de la función del coste en función de los pesos en dos términos:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\sum_{j=1}^m \\sum_{i=1}^c \\frac{\\delta E^{(k)}}{\\delta a_{ij}^{(k)}} \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}}\n\\end{align}\n\n\nCapa de salida\n\n\nProcedemos a calcular la derivada:\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\frac{\\delta}{\\delta \\theta_{it}^{(k)}} \\left(- \\frac{1}{m}\\right) \\left\\{ \\sum_{j=1}^m\\sum_{i=1}^c (y_{ij}\\cdot \\log(h_\\Theta(x_j)_i)) + [(1-y_{ij})\\log(1-h_\\Theta(x_j)_i)]\\right\\}\n\\]\n\n\nSacamos el término constante de la derivada y aplicamos la propiedad: \"La derivada de una suma equivale a la suma de las derivadas\"\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c \\frac{\\delta}{\\delta \\theta_{it}^{(k)}} \\left\\{(y_{ij}\\cdot \\log(h_\\Theta(x_j)_i)) + [(1-y_{ij})\\log(1-h_\\Theta(x_j)_i)]\\right\\}\n\\]\n\n\nSea \\(h_\\Theta(x_j) = a^{(k)}_j\\), es decir la salida de la última capa para el ejemplo \\(j\\).\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c \\frac{\\delta}{\\delta \\theta_{it}^{(k)}} \\left\\{(y_{ij}\\cdot \\log(a^{(k)}_{ij})) + [(1-y_{ij})\\log(1-a^{(k)}_{ij})]\\right\\}\n\\]\n\n\n\nSacaremos el término \\(y_{ij}\\) de la derivada y juntemos todas las expresiones:\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c  \\left\\{y_{ij} \\left(\\frac{\\delta}{\\delta \\theta_{it}^{(k)}} \\log(a^{(k)}_{ij}) \\right) + (1-y_{ij}) \\left(\\frac{\\delta}{\\delta \\theta_{it}^{(k)}} \\log(1-a^{(k)}_{ij})\\right)\\right\\}\n\\]\n\n\nAplicamos la regla de la cadena sobre el logaritmo:\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c  \\left\\{y_{ij} \\left(\\frac{\\delta \\log(a_{ij}^{(k)})}{\\delta a_{ij}^{(k)}}  \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} \\right) + (1-y_{ij}) \\left(\\frac{\\delta \\log(1-a^{(k)}_{ij})}{\\delta (1-a^{(k)}_{ij})} \\frac{\\delta (1-a^{(k)}_{ij})}{\\delta \\theta_{it}^{(k)}} \\right)\\right\\}\n\\]\n\n\nComo sabemos:\n\n\n\n\n\\(\\frac{\\delta (1)}{\\delta \\theta_{it}^{(k)}} = 0\\), entonces\n\n\n\\(\\frac{\\delta(1-a_{ij}^{(k)})}{\\delta \\theta_{it}^{(k)}} = \\frac{\\delta (1)}{\\delta \\theta_{it}^{(k)}} - \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} = 0 + (-1) \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}}\\)\n\n\n\n\nEntonces\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c  \\left\\{y_{ij} \\left(\\frac{\\delta \\log(a_{ij}^{(k)})}{\\delta a_{ij}^{(k)}}  \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} \\right) + (1-y_{ij}) \\left((-1)\\frac{\\delta \\log(1-a^{(k)}_{ij})}{\\delta (1-a^{(k)}_{ij})} \\frac{\\delta a^{(k)}_{ij}}{\\delta \\theta_{it}^{(k)}} \\right)\\right\\}\n\\]\n\n\nSacamos \\(\\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}}\\) como factor común y aplicamos el \\((-1)\\):\n\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c  \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}}\\left\\{y_{ij} \\frac{\\delta \\log(a_{ij}^{(k)})}{\\delta a_{ij}^{(k)}} -  \\left((1-y_{ij})\\frac{\\delta \\log(1-a^{(k)}_{ij})}{\\delta (1-a^{(k)}_{ij})} \\right)\\right\\}\n\\]\n\n\nSustituimos \\(\\frac{\\delta E^{(k)}}{\\delta a_{ij}^{(k)}} = \\left\\{y_{ij} \\frac{\\delta \\log(a_{ij}^{(k)})}{\\delta a_{ij}^{(k)}} -  \\left((1-y_{ij})\\frac{\\delta \\log(1-a^{(k)}_{ij})}{\\delta (1-a^{(k)}_{ij})} \\right)\\right\\}\\)\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c \\frac{\\delta E^{(k)}}{\\delta a_{ij}^{(k)}} \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} \n\\]\n\n\nSi resolvemos las derivadas de los logaritmos obtenemos:\n\n\n\\[%align\n\\frac{\\delta E^{(k)}}{\\delta a_{ij}^{(k)}} = y_{ij} \\frac{\\delta \\log(a_{ij}^{(k)})}{\\delta a_{ij}^{(k)}} - (1-y_{ij})\\frac{\\delta \\log(1-a_{ij}^{(k)})}{\\delta (1-a_{ij}^{(k)})}\n\\]\n\n\n\n\nNos centraremos ahora en la derivada que nos falta \\(\\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}}\\):\n\n\n\nSabemos que, vectorizando la operación, \\(a^{(k)}_j = g(z^{(k)}_j)\\), donde \\(g\\) es la función de activación (en este caso sigmoide).\n\n\n\nAdemás:\n\n\n\\[%align\nz^{(k)}_j = \\Theta^{k} \\cdot a^{(k-1)}_j\n\\]\n\n\nPor lo tanto, para cada nodo \\(i\\) en la última capa \\(k\\):\n\n\n\\[%align\nz^{(k)}_{ij} = \\sum_{l=1}^{S_{(k-1)}} \\theta^{(k)}_{il} \\cdot a^{(k-1)}_{lj}\n\\]\n\n\nDonde \\(S_{(k-1)}\\) es el número de nodos en la capa \\(k-1\\). Entonces, aplicamos de nuevo la regla de la cadena:\n\n\n\\[%align\n\\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} =  \\frac{\\delta g(z_{ij}^{(k)})}{\\delta z_{ij}^{(k)}} \\frac{\\delta z_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}}\n\\]\n\n\nResolvemos la derivada para el segundo término:\n\n\n\\[%align\n\\frac{\\delta z_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} = \\sum_{l=1}^{S_{(k-1)}} \\frac{\\delta}{\\delta \\theta_{it}^{(k)}} \\theta^{(k)}_{il} \\cdot a^{(k-1)}_{lj}\n\\]\n\n\nTal que:\n\n\n\\[%align\n\\frac{\\delta}{\\delta \\theta_{it}^{(k)}} \\theta^{(k)}_{il} \\cdot a^{(k-1)}_{lj} =\n\\begin{cases}\na_{lj}^{(k-1)}, & t = l \\\\\n0, & t \\neq l \\\\\n\\end{cases}\n\\]\n\n\nPor lo tanto, como sólo hay un \\(l\\) con \\(l = t\\) donde \\(1 \\leq l \\leq S_{(k-1)}\\), entonces:\n\n\n\\[%align\n\\frac{\\delta z_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} = a_{lj}^{(k-1)} = a_{tj}^{(k-1)}\n\\]\n\n\nJuntamos ambos términos de la derivada inicial, con \\(\\frac{\\delta g(z_{ij}^{(k)})}{\\delta z_{ij}^{k}} = \\sigma'(z_{ij}^{(k)})\\)\n\n\n\\[%align\n\\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} =  \\frac{\\delta g(z_{ij}^{(k)})}{\\delta z_{ij}^{(k)}} \\frac{\\delta z_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}} = \\sigma'(z_{ij}^{(k)}) a_{tj}^{(k-1)}\n\\]\n\n\n\n\nVamos a resumir lo que tenemos hasta ahora. Por la regla de la cadena, separamos la derivada de la función del coste en función de los pesos en dos términos:\n\n\n\\begin{align}\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\sum_{j=1}^m \\sum_{i=1}^c \\frac{\\delta E^{(k)}}{\\delta a_{ij}^{(k)}} \\frac{\\delta a_{ij}^{(k)}}{\\delta \\theta_{it}^{(k)}}\n\\end{align}\n\n\nSi sustituimos ambos términos, para la capa de salida \\(k\\):\n\n\n\\[%align\n\\frac{\\delta J(\\Theta)}{\\delta \\theta_{it}^{(k)}} = \\left(- \\frac{1}{m}\\right)  \\sum_{j=1}^m\\sum_{i=1}^c  \\sigma'(z_{ij}^{(k)}) a_{tj}^{(k-1)}\\left\\{ \\frac{y_{ij}}{a_{ij}^{(k)}} -  \\left(\\frac{(1-y_{ij})}{(1-a^{(k)}_{ij})} \\right)\\right\\}\n\\]\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/DataScience/(DS0001)_MLStanfordCoursera/NeuralNetworks/Neural Networks.html",
    "title": "Neural Networks",
    "body": "\n\nBack\n\n\nNeural Networks\n\n\n\n\n\nArchitecture\n\n\n\nAlgorithm\n\n\nOutput Layer\n\n\n\nForward Propagation\n\n\n\nParameters\n\n\nOutputs\n\n\nGraphical Representation\n\n\n\nOptimization Problem\n\n\n\nLoss Function\n\n\nOptimization\n\n\nBack-Propagation\n\n\nVectorization\n\n\n\nImproving a Neural Network\n\n\n\nActivation Functions\n\n\nInitialization Techniques\n\n\n\nAnexo\n\n\n\n\n\nArchitecture\n\n\n\nInput: Given any input \\(X\\) the first thing we do is flatten it. For example if \\(X\\) is a rgb image of \\(64 \\times 64\\), then \\(X \\in \\mathbb{R}^{64 \\times 64 \\times 3}\\) (for each of the \\(64 \\times 64\\) pixels we have three color channels: red, green, blue), is flattened into a vector in \\(\\mathbb{R}^{(64*64*3) \\times 1}\\)\n\n\nNeuron: is an operation that has two parts:\n\n\n\nLinear part: we denote the linear part like \\(z^{[i]}\\), where \\(i\\) is the current layer.\n\n\n\n  \n\n  \n\n\n\nActivation part\n\n\n  \n\n  \n\n\n\nLayer: a layer is a compound of neurons that are not connected with each other.\n\n\n  \n\n  \n\n\nAlgorithm\n\n\nThe principal steps of the algorithm are:\n\n\n\n\nInitialize the weights \\(w\\) and biases \\(b\\) randomly\n\n\nFind the optimal \\(w, b\\)\n\n\nUse the optimized \\(w, b\\) to predict the output by using the formula \\(\\hat{y} = \\sigma(wx +b)\\)\n\n\n\nOutput Layer\n\nSigmoid\n\n\nThe output layer will be different depending on the problem we are tackling. For example if we want to discriminate between 3 classes then the output layer could be as follows:\n\n\n\n\n\n\n\nSo now the output is a vector \\(\\hat{y} \\in \\mathbb{R}^{c \\times 1}\\) where \\(c\\) is the number of classes.\n\n\nSoftmax\n\n\nThe previous classifier allows for outputting multiples classes in the result, that is we can obtain a predicted output of the form \\(\\hat{y} = \\begin{bmatrix} 1 \\\\1 \\\\ 0 \\end{bmatrix}\\). What if we want to add a constraint such that only one class can be predicted. Then we use the softmax function as the activation function on the output layer:\n\n\n\n\n\n\n\nThus, instead of a probability for each class what we obtain is a probability distribution for all the classes.\n\n\nReLU\n\n\nOn linear regression we do not want the activation function to be linear, because then the whole network becomes a very large linear regression. Instead we use as an activation function the ReLU function (Rectified Linear Unit), whose output is zero if the input value is negative and linear otherwise.\n\n\n\n\n\n\nLoss Function\n\n\nThe loss function when using the sigmoid function on the output layer is as follows:\n\n\n\\begin{align}\n\\mathcal{L} = - \\frac{1}{Q} \\sum_{k=1}^Q [y^{(k)} \\log(\\hat{y}^{(k)}) + (1- y^{(k)})\\log(1-\\hat{y}^{(k)})]\n\\end{align}\n\n\nWhere \\(\\hat{y}^{(k)}\\) are the predicted values and \\(Q\\) is the total number of neurons on the output layer.\n\n\n\n\n\nHowever, if we use the softmax function as the activation function on the last layer we have to use a different derivative because this function does depend on the outputs of the other neurons. Thus, we make use of a function called cross entropy loss:\n\n\n\\begin{align}\n\\mathcal{L}_{CE} = - \\sum_{k=1}^Q y^{(k)} \\log(\\hat{y}^{(k)})\n\\end{align}\n\n\n\n\nFor linear regression we use as the loss function the L1-Norm or the L2-Norm. The latter is defined as follows:\n\n\n\\begin{align}\n\\mathcal{L} = || \\hat{y} - y ||_2^2\n\\end{align}\n\nForward Propagation\n\n\nThe forward propagation equations are the following:\n\n\n\\begin{align}\nz^{[i]} = w^{[i]} a^{[i-1]} + b^{[i]} \\tag{1}\n\\end{align}\n\n\nWhere \\(i\\) is the layer with \\(i \\geq 1\\), and the first layer equals the input matrix, that is \\(a^{[0]} = X\\). By applying the activation function over \\((1)\\):\n\n\n\\begin{align}\na^{[i]} = g(z^{[i]})\n\\end{align}\n\n\nWhere \\(g\\) is the activation function (e.g \\(\\sigma(z^{[i]})\\)).\n\n\n\nNow, what are the shapes of these matrices?\n\n\n\n\n\\(z^{[i]} \\in \\mathbb{R}^{S_i \\times m}\\)\n\n\n\\(a^{[i]} \\in \\mathbb{R}^{S_i \\times m}\\)\n\n\n\n\nWhere \\(S_i\\) is the number of neurons on the ith layer and \\(m\\) is the number of examples. Note that the shape of the final layer changes depending on the task. So if \\(K\\) is the number of layers:\n\n\n\n\nIn linear regression: \\(\\hat{y} = a^{[K]} \\in \\mathbb{R}^{1 \\times m}\\)\n\n\nIn multi-class classification: \\(\\hat{y} = a^{[K]} \\in \\mathbb{R}^{c \\times m}\\), where \\(c\\) is the number of classes.\n\n\n\n\nAlso the shape of the weights are \\(w[i] \\in \\mathbb{R}^{S_i \\times S_{i-1}}\\), that is, this matrix is compatible with the outputs of the previous layer (\\(a^{[i-1]} \\in \\mathbb{R}^{S_{i-1} \\times m}\\)) and the linear part of the next layer (\\(z^{[i]} \\in \\mathbb{R}^{S^i \\times m}\\)).\n\n\n\nHowever, the bias are \\(b^{[i]} \\in \\mathbb{R}^{S^i \\times 1}\\), therefore we cannot perform an element wise summation because the shape of \\((w^{[i]} a^{[i-1]}) \\in \\mathbb{R}^{S_i \\times m}\\) and \\(b^{[i]}\\) are not compatible. To avoid this problem we apply a technique called broadcasting to \\(b\\), such that we replicate \\(b^{[i]}\\) \\(m\\) times:\n\n\n\\begin{align}\n\\hat{b}^{[i]} = \\begin{bmatrix}\n| &  | & \\cdots & | \\\\\nb^{[i]} & b^{[i]} & \\cdots & b^{[i]} \\\\\n| & | & \\cdots & | \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{S_i \\times m}\n\\end{align}\n\n\n\n\nTo sum up, the shapes of the data and the parameters on each layer \\(i\\) are:\n\n\nParameters\n\n\\begin{align}\n\\hat{b}^{[i]} = \\begin{bmatrix}\n| &  | & \\cdots & | \\\\\nb^{[i]} & b^{[i]} & \\cdots & b^{[i]} \\\\\n| & | & \\cdots & | \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{S_i \\times m}\n\\end{align}\n\n\\begin{align}\nw^{[i]} = \\begin{bmatrix}\n| & | & \\cdots & | \\\\\nw^{[i](1)} & w^{[i](2)} & \\cdots & w^{[i](S_{i-1})} \\\\\n| & | & \\cdots & | \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{S_i \\times S_{i-1}}\n\\end{align}\n\nOutputs\n\n\nNote that for each example \\(j\\) on layer \\(i\\) \\(z^{[i](j)} = (w^{[i]} a^{[i-1](j)} + \\hat{b}^{[i]})\\), then:\n\n\n\\begin{align}\nz^{[i]} = \\begin{bmatrix}\n| &  | & \\cdots & | \\\\\nz^{[i](1)} & z^{[i](2)} & \\cdots & z^{[i](m)} \\\\\n| &  | & \\cdots & | \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{S_i \\times m}\n\\end{align}\n\n\\begin{align}\na^{[i]} = \\begin{bmatrix}\n| &  | & \\cdots & | \\\\\ng(z^{[i](1)}) & g(z^{[i](2)}) & \\cdots & g(z^{[i](m)}) \\\\\n| &  | & \\cdots & | \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{S_i \\times m}\n\\end{align}\n\nGraphical Representation\n\n\nNow we present a small example of how forward propagation works on neural networks:\n\n\n\n\n\n\nOptimization Problem\n\n\nWhat we want to do is find the parameters \\(w^{[i]}, b^{[i]}\\) for each layer \\(i\\) that minimize the cost.\n\n\nLoss Function\n\n\nSo first of all we define a cost function for the objective \\(\\mathcal{L}(\\hat{y}, y)\\), where \\(\\hat{y}\\) is the predicted output and \\(y\\) is the real output. The cost function will depend on the type of problem (classification, regression).\n\n\nOptimization\n\n\nThe we optimize the loss function we defined by using backward propagation. For each layer \\(l=1, \\cdots, K\\), where \\(K\\) is the number of layers, we apply Batch Gradient Descent (not mandatory, but here it is convenient as we can vectorize the derivatives) as follows:\n\n\n\\begin{align}\nw^{[l]} = w^{[l]} - \\alpha \\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w^{[l]}}\n\\end{align}\n\n\\begin{align}\nb^{[l]} = b^{[l]} - \\alpha \\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta b^{[l]}}\n\\end{align}\n\nBack-propagation\n\n\nTo compute the derivatives of the cost function with respect to \\(w^{[l]}\\) and \\(b^{[l]}\\) we use the chain rule. \n\n\nOutput Layer\n\n\nSuppose we have \\(K\\) layers, then we start by calculating \\(\\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w^{[K]}}\\)  and \\(\\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta b^{[K]}}\\), that is, the derivatives on the last layer. Thus, to update \\(w^{[K]}\\) (we apply the same logic for \\(b^{[K]}\\)):\n\n\n\\begin{align}\n\\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w^{[K]}} = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}(\\hat{y^{(i)}}, y^{(i)})}{\\delta w^{[K]}} = \n\\end{align}\n\n\nBecause \\(\\hat{y^{(i)}} = (a^{[K]})^{(i)}\\):\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta w^{[K]}}\n\\end{align}\n\n\nWe apply the chain rule on the derivative, therefore:\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta (a^{[K]})^{(i)}}{\\delta w^{[K]}}\n\\end{align}\n\n\nBecause \\((a^{[K]})^{(i)} = g((z^{[K]})^{(i)})\\), where \\(g\\) is the activation function:\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta g((z^{[K]})^{(i)})}{\\delta w^{[K]}}\n\\end{align}\n\n\nWe apply the chain rule on the last derivative, therefore:\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta g((z^{[K]})^{(i)})}{\\delta (z^{[K]})^{(i)}} \\frac{\\delta (z^{[K]})^{(i)}}{\\delta w^{[K]}}\n\\end{align}\n\nHidden Layers\n\n\nWhat about the previous layer \\(K-1\\)?\n\n\n\\begin{align}\n\\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w^{[K-1]}} = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}(\\hat{y^{(i)}}, y^{(i)})}{\\delta w^{[K-1]}} = \n\\end{align}\n\n\nBecause \\(\\hat{y^{(i)}} = (a^{[K]})^{(i)}\\):\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta w^{[K-1]}}\n\\end{align}\n\n\nWe apply the chain rule on the derivative, therefore:\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta (a^{[K]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\nBecause \\((a^{[K]})^{(i)} = g((z^{[K]})^{(i)})\\), where \\(g\\) is the activation function:\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta g((z^{[K]})^{(i)})}{\\delta w^{[K-1]}}\n\\end{align}\n\n\nWe apply the chain rule on the last derivative, therefore:\n\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta g((z^{[K]})^{(i)})}{\\delta (z^{[K]})^{(i)}} \\frac{\\delta (z^{[K]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\\begin{align}\n = \\sum_{i=1}^m \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta (a^{[K]})^{(i)}}{\\delta (z^{[K]})^{(i)}} \\frac{\\delta (z^{[K]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\nAs you can see the first two derivatives are the same as the derivatives on the layer \\(K\\), let's denote \\((\\Delta^{[K]})^{(i)} = \\frac{\\delta \\mathcal{L}((a^{[K]})^{(i)}, y^{(i)})}{\\delta (a^{[K]})^{(i)}} \\frac{\\delta (a^{[K]})^{(i)}}{\\delta (z^{[K]})^{(i)}}\\) the accumulated gradient on layer \\(K\\) for example \\(i\\), then:\n\n\n\\begin{align}\n = \\sum_{i=1}^m (\\Delta^{[K]})^{(i)} \\frac{\\delta (z^{[K]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\nBecause \\((z^{[K]})^{(i)} = w^{[K]} (a^{[K-1]})^{(i)} + b^{[k]}\\):\n\n\n\\begin{align}\n = \\sum_{i=1}^m (\\Delta^{[K]})^{(i)} \\frac{\\delta (w^{[K]} (a^{[K-1]})^{(i)} + b^{[k]})}{\\delta w^{[K-1]}}\n\\end{align}\n\n\\begin{align}\n = \\sum_{i=1}^m (\\Delta^{[K]})^{(i)} \\frac{\\delta (z^{[K-1]})^{(i)}}{\\delta (a^{[K-1]})^{(i)}} \\frac{\\delta (a^{[K-1]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\nBecause \\((a^{[K-1]})^{(i)} = g((z^{[K-1]})^{(i)})\\)\n\n\n\\begin{align}\n = \\sum_{i=1}^m (\\Delta^{[K]})^{(i)} \\frac{\\delta (z^{[K-1]})^{(i)}}{\\delta (a^{[K-1]})^{(i)}} \\frac{\\delta g((z^{[K-1]})^{(i)})}{\\delta (z^{[K-1]})^{(i)}} \\frac{\\delta (z^{[K-1]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\nWe apply the chain rule on the last derivative, hence:\n\n\n\\begin{align}\n = \\sum_{i=1}^m (\\Delta^{[K]})^{(i)} \\frac{\\delta (z^{[K-1]})^{(i)}}{\\delta (a^{[K-1]})^{(i)}} \\frac{\\delta g((z^{[K-1]})^{(i)})}{\\delta (z^{[K-1]})^{(i)}} \\frac{\\delta (z^{[K-1]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\\begin{align}\n = \\sum_{i=1}^m (\\Delta^{[K]})^{(i)} \\frac{\\delta (z^{[K-1]})^{(i)}}{\\delta (a^{[K-1]})^{(i)}} \\frac{\\delta (a^{[K-1]})^{(i)}}{\\delta (z^{[K-1]})^{(i)}} \\frac{\\delta (z^{[K-1]})^{(i)}}{\\delta w^{[K-1]}}\n\\end{align}\n\n\n\nVectorization\n\nOutput Layer\n\n\n\nAccumulated gradient for layer \\(K\\): \\(\\Delta_w^{[K]} = \\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta a^{[K]}} \\frac{\\delta a^{[K]}}{\\delta z^{[K]}}\\)\n\n\nGradient for layer \\(K\\): \\(\\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w^{[K]}} = \\Delta_w^{[K]} \\frac{\\delta z^{[K]}}{\\delta w^{[K]}}\\)\n\n\n\nHidden Layer\n\n\n\nAccumulated gradient for layer \\(K-1\\): \\(\\Delta_w^{[K-1]} = \\Delta_w^{[K]} \\frac{\\delta z^{[K]}}{\\delta a^{[K-1]}} \\frac{\\delta a^{[K-1]}}{\\delta z^{[K-1]}}\\)\n\n\nGradient for layer \\(K-1\\): \\(\\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w^{[K-1]}} = \\Delta_w^{[K-1]} \\frac{\\delta z^{[K-1]}}{\\delta w^{[K-1]}}\\)\n\n\n\nGraphical Representation\n\n\nOn the following image we show how to obtain the gradient of the first element of the first layer's first neuron's weights \\(w^{[1]}_{11}\\) on the first layer:\n\n\n\n\n\n\nImproving a Neural Network\n\nActivation Functions\n\n\nWhy do we need activation functions? Well, suppose you have the following network where the activation function is the identity function. That is \\(a^{[i]} = g(z^{[i]}) = z^{[i]}\\):\n\n\n\n\n\n\n\nThen:\n\n\n\\begin{align}\n\\hat{y} = a^{[3]} = z^{[3]} = w^{[3]} a^{[2]} + b^{[3]} = w^{[3]} z^{[2]} + b^{[3]} = w^{[3]} (w^{[2]} a^{[1]} + b^{[2]}) + b^{[3]} \n\\end{align}\n\n\\begin{align}\n= w^{[3]} (w^{[2]} z^{[1]} + b^{[2]}) + b^{[3]} = w^{[3]} (w^{[2]} (w^{[1]} x + b^{[1]}) + b^{[2]}) + b^{[3]}\n\\end{align}\n\n\\begin{align}\n= w^{[3]} (w^{[2]} w^{[1]} x + w^{[2]} b^{[1]} + b^{[2]}) + b^{[3]}\n\\end{align}\n\n\\begin{align}\n= w^{[3]} w^{[2]} w^{[1]} x + w^{[3]} w^{[2]} b^{[1]} + w^{[3]} b^{[2]} + b^{[3]}\n\\end{align}\n\n\nIf \n\n\n\\begin{align}\nW = w^{[3]} w^{[2]} w^{[1]}\n\\end{align}\n\n\\begin{align}\nB = w^{[3]} w^{[2]} b^{[1]} + w^{[3]} b^{[2]} + b^{[3]}\n\\end{align}\n\n\nThen: \n\n\n\\begin{align}\n\\hat{y} = WX + B\n\\end{align}\n\n\nAs you can see if we do not use activation functions, it does not mater how deep your network is, it is going to be equivalent to a linear regression.\n\n\n\n\n\nDepending on the task at hand we use different activation functions:\n\n\n\n\nSigmoid: \\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\), it maps \\(z \\in (-\\infty, \\infty)\\) to \\((0, 1)\\)\n\n\n\nIt is good for classification\n\n\nWorks well when the values are in the linear region of the function\n\n\nHowever when the values are on the extremes the gradient (slope) is very small, therefore it ends up vanishing in the network.\n\n\n\n\n\n\n\n\n\n\nReLU: \\(ReLU(z) = \\begin{cases}0 & z \\leq 0 \\\\ 1 & z > 0\\end{cases}\\)\n\n\ntanh: \\(tanh(z) = \\frac{e^z - e^{-z}}{(e^z + e^{-z})}\\)\n\n\n\nInitialization Techniques\n\n\nUsually we normalize the input to avoid having saturated activation functions. To normalize:\n\n\n\\begin{align}\nx^{(i)}_j = \\frac{x^{(i)}_j - \\mu_j}{\\sigma_j}\n\\end{align}\n\n\nFor every example \\(i\\) and feature \\(j\\). Where:\n\n\n\n\n\\(\\mu_j\\) is the mean of the \\(j\\) feature, thus: \\(\\mu_j = \\frac{1}{m} \\sum_{i=1}^m x^{(i)}_j\\)\n\n\n\\(\\sigma_j^2\\) is the variance of the \\(j\\) feature, thus: \\(\\sigma_j^2 = \\frac{1}{m} \\sum_{i=1}^m (x^{(i)}_j - \\mu_j)^2\\)\n\n\n\nVanishing/Exploding Gradients\n\n\nSuppose you have the following network, where the activation function is the identity function and \\(b=0\\).\n\n\n\n\n\n\n\nThen \\(\\hat{y} = w^{[L]} a^{[L-1]} = w^{[L]} w^{[L-1]} a^{[L-2]} = \\cdots = w^{[L]} w^{[L-1]} \\cdots w^{[1]} x\\)\n\n\n\nTherefore, if:\n\n\n\\begin{align}\nw^{[L]} = \\begin{bmatrix}\n1.5 & 0 \\\\\n0 & 1.5 \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nthen: \n\n\n\\begin{align}\n\\hat{y} = \\begin{bmatrix}\n1.5^L & 0 \\\\\n0 & 1.5^L \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nWhich means we end up with an exploding gradient. The inverse happens when:\n\n\n\\begin{align}\nw^{[L]} = \\begin{bmatrix}\n0.5 & 0 \\\\\n0 & 0.5 \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nthen:\n\n\n\\begin{align}\n\\hat{y} = \\begin{bmatrix}\n0.5^L & 0 \\\\\n0 & 0.5^L \\\\\n\\end{bmatrix}\n\\end{align}\n\n\nWhich results in a vanishing gradient.\n\n\n\nTo avoid this somewhat, we need to initialize the weights properly. What we want is for the weights to be very close to one to avoid the exploding/diminishing problem.\n\n\nIntuition\n\n\nGiven a single neuron:\n\n\n\n\n\n\n\nThen \\(a = g(z)\\) and \\(z = w_1 x_1 + \\cdots + w_n x_n\\). We can see that \\(z\\) will increase if \\(n\\) increases, therefore we would want \\(w_i\\) to be as small as \\(n\\) is large, that is:\n\n\n\\begin{align}\nw_i = \\frac{1}{n}\n\\end{align}\n\nInitialization Techniques\n\n\n\nIf we want the value of \\(w^{[L]}\\) to be proportional to the number of inputs coming from the layer \\(L\\) (\\(n^{[L-1]}\\)). It works very well for sigmoid activation:\n\n\n\nw[k] = np.random.randn(shape)*np.sqrt(1/n[L-1])\n\n\n\n\nFor ReLU:\n\n\n \nw[k] = np.random.randn(shape)*np.sqrt(2/n[L-1])\n\n\n\n\nXavier initialization (used with tanh): \\(w^{[L]} \\sim \\sqrt{\\frac{1}{n^{[L-1]}}}\\)\n\n\nHer initialization: \\(w^{[L]} \\sim \\sqrt{\\frac{2}{n^{[L]} + n^{[L-1]}}}\\)\n\n\n\n\nAlso you need to initialize the weights randomly, else you will run into the symmetry problem, where all neurons learn the same thing (that is they update very similarly).\n\n\nOptimization\n\nMini Batch Gradient Descent\n\n\nMini Batch Gradient Descent is a trade off between batch gradient descent and stochastic gradient descent. Also, because Mini Batch Gradient Descent is an approximation it introduces some noise on the loss function:\n\n\n\n\n\n\n\nHowever Mini Batch Gradient Descent is more used because Batch Gradient Descent can be very computationally expensive.\n\n\nMomentum Algorithm\n\n\nThis algorithm combines Gradient Descent and momentum. Suppose you have the following contour plot, where the horizontal axis is much more extended that the vertical axis. By default on Gradient Descent the gradient of the loss will be orthogonal to the contour at the given point, as we can see:\n\n\n\n\n\n\n\nHowever, what we would like, so it would converge faster, is to make it move more horizontally than vertically. In order to do that we use a technique called momentum. It takes intro account past updates to find the right way to go. If you take an average of past updates, then:\n\n\n\n\nVertical axis: it practically cancels itself because it oscillates a lot\n\n\nHorizontal axis: its value it's maintained because the past and present gradients go in the same direction\n\n\n\n\n\n\n\n\nTo update the weights we apply the following equation:\n\n\n\\begin{align}\n\\upsilon = \\beta \\upsilon + (1 - \\beta) \\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w}\n\\end{align}\n\n\nWhere:\n\n\n\n\n\\(\\upsilon\\): stores past updates\n\n\n\\(\\frac{\\delta \\mathcal{L}(\\hat{y}, y)}{\\delta w}\\): stores the current update\n\n\nWe average with \\(\\beta\\) and \\((1 - \\beta)\\)\n\n\n\n\nFinally we update the weights:\n\n\n\\begin{align}\nw = w - \\alpha \\upsilon\n\\end{align}\n\nAnexo\n\n\nFor more info about cost function and how to derive them:\n\n\n\nAnexo\n\n"
  },
  {
    "id": "https://albamr09.github.io/Notes/index.html",
    "title": "Notes",
    "body": "\n\nBack\n\n\nNotes\n\n\n\nWeb Development\n\nFrameworks\n\nFront\n\n\n\nReact\n\n\n \nBack\n\n\n\nNode.js\n\n\nDjango\n\n\nSpring\n\n\n\nTechnologies\n\n\n\nDocker\n\n\nGraphQL\n\n\n\nDB\n\n\n\nMongoDB\n\n\n\n\n\nData Science\n\n\n\nGoogle Data Analyst\n\n\nMachine Learning Stanford Coursera\n\n\n\n\n\nOther\n\n\n\nVimWiki\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/index.html",
    "title": "Registry Index",
    "body": "\nRegistry Index\n\n\n\n\n\nNotes\n\n\nStudy\n\n\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/Math/index.html",
    "title": "Math",
    "body": "\n\nBack\n\n\nMath\n\n\nFirst Year\n\nFirst semester\n\n\n\nDicrete Maths\n\n\n\nDiscrete Mathematics with Applications, 2nd edition by Susanna S. Epp\n\n\nDiscrete Mathematics Structures, 4th edition by Kolman, Busby and Ross\n\n\n\nProof writing (very advanced, do not expect to master anything in these books)\n\n\n\nMathematical Proofs: A transition to advanced mathematics by Gary Chartrand et. al (This one is better than the next one)\n\n\nAn introduction to Abstract Mathematics by Robert J. Bond and Wiliam J. Keane\n\n\n\n\nSecond semester\n\n\n\nPre-algebra (refresh really basic math)\n\n\n\nAGS Pre-Algebra (has solutions)\n\n\nFearon's Pre-Algebra (this one is better)\n\n\n\nCollege Algebra (after the pre-algebra one, if the pre-algebra books are too easy skip onto these ones)\n\n\n\nCollege Algebra by Kaufmann (more begginer friendly)\n\n\nCollege Algebra by Blitzer\n\n\n\n\n\n\n\nSecond Year\n\nFirst semester\n\n\n\nPre-calculus (once you are done with college algebra. If you know some basic algebra you can skip the college algebra and start in this section)\n\n\n\nA Graphical Approach to Algebra and Trigonometry by Hornsby, Lial, and Rockswold. 6th edition (Get the instructor's edition)\n\n\n\n\nSecond semester\n\n\n\nCalculus\n\n\n\nCalculus by James Stewart, 5th edition (Very famous book, to learn basic calculus. It has a lot of problems. Used to teach calculus I, II and III)\n\n\nCalculus by Michael Spivak, 3rd edition (It has less material but it is more advanced)\n\n\n\n\n\nThird Year\n\nFirst semester\n\n\n\nDifferential equations\n\n\n\nA First Course in Differential Equations by Zill\n\n\nOrdinary Differential Equations with Applications by Andrews (It is easier, good for beginners)\n\n\n\nLinear Algebra (try to learn as much as possible)\n\n\n\nElementary Linear Algebra by Howard Anton (Beginner friendly, with exercises)\n\n\nLinear Algebra by Friedgber, Insel, and Spence (It is harder and more difficult to read. It is proof based)\n\n\n\n\nSecond semester\n\n\n\nStatistics\n\n\n\nMathematical Statistics by Wackerly, Mendenhall, and Scheaffer\n\n\nA First Course in Probability by Ross\n\n\n\nComplex analysis (Calculus with complex numbers. Both are pretty much the same, very good beginner books)\n\n\n\nFundamentals of Complex Analysis by Saff and Snider, 3rd edition\n\n\nComplex Variables and Applications by Brown and Churchill, 7th edition\n\n\n\n\n\n\nFourth Year\n\nFirst semester\n\n\n\nReal analysis (one of the hardest subjects)\n\n\n\nAnalysis 1 and Analysis 2 by Terrance Tao (Easier to read, but the other two are standard)\n\n\nAdvanced Calculus by Fitzpatrick\n\n\nPrinciples of Mathematical Analysis by Rudin\n\n\nElements ofAnalysis by Ross (Expends a lot of time for proofs)\n\n\n\nAbstract algebra (study of groups, rings and fields. Very proof based)\n\n\n\nAbstract Algebra by Saracino (Very good for beginners)\n\n\nContemporary Abstract Algebra by Gallian (Also good for beginners)\n\n\n\n\nSecond semester\n\n\n\nTopology (optional)\n\n\n\nIntroduction to Topology by Gamelin and Greene (It has full solutions for all of the problems)\n\n\n\nCombinatorics (optional)\n\n\n\nApplied Combinatorics by Tucker\n\n\n\nNaive set theory (optional)\n\n\n\nNaive Set Theory by Halmos\n\n\n\nFunctional analysis (optional)\n\n\n\nFunctional Analysis by Kreyszig\n\n\n\nGraph Theory (optional)\n\n\n\nGraph Theory by Gould\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/DataScience/google-analytics.html",
    "title": "Google Data Analyst Certificate",
    "body": "\n\nBack\n\n\nGoogle Data Analyst Certificate\n\n\n\n\nSource\n\n\n\n\n\n\nFoundations: Data, Data, Everywhere\n\n\n\nIntroducing data analytics\n\n\nAll about analytical thinking\n\n\nThe wonderful world of data\n\n\nSet up your toolbox\n\n\nEndless career possibilities\n\n\n\n\n\n\nAsk Questions to Make Data-Driven Decisions\n\n\n\nEffective questions\n\n\nData driven decisions\n\n\nMore spreadsheets basics\n\n\nAlways remember the stakeholder\n\n\n\n\n\n\nPrepare Data for Exploration\n\n\n\nData types and structures\n\n\nBias, credibility, privacy, ethics and access\n\n\nDatabases: Where data lives\n\n\nOrganizing and protecting your data\n\n\nOptional: Engaging in the data community\n\n\n\n\n\n\nProcess Data from Dirty to Clean\n\n\n\nThe importance of integrity\n\n\nSparkling-clean data\n\n\nCleaning data with SQL\n\n\nVerify and report on your cleaning results\n\n\nOptional: Adding data to your resume\n\n\nCourse challenge\n\n\n\n\n\n\nAnalyze Data to Answer Questions\n\n\n\nOrganizing data to begin analysis\n\n\nFormatting and adjusting data\n\n\nAggregating data for analysis\n\n\nPerforming data calculations\n\n\n\n\n\n\nShare Data Through the Art of Visualization\n\n\n\nVisualizing Data\n\n\nCreating data visualization with Tableau\n\n\nCrafting data stories\n\n\nDeveloping presentations and slideshows\n\n\n\n\n\n\nData Analysis with R Programming\n\n\n\nProgramming and data analytics\n\n\nProgramming using RStudio\n\n\nWorking with data in R\n\n\nMore about visualizations, aesthetics, and annotations\n\n\nDocumentations and reports\n\n\n\n\n\n\nGoogle Data Analytics Capstone: Complete a Case Study\n\n\n\nLearn about capstone basics\n\n\nOptional: Building your portfolio\n\n\nOptional: Using your portfolio\n\n\nPutting your certificate to work\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/DataScience/ibm-analytics.html",
    "title": "IBM Data Science Certificate",
    "body": "\n\nBack\n\n\nIBM Data Science Certificate\n\n\n\nSource\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/DataScience/index.html",
    "title": "Data Science Study Guide",
    "body": "\n\nBack\n\n\nData Science Study Guide\n\n\n\nPractical courses\n\n\n\nGoogle Data Analyst Certificate (absolutely useless)\n\n\nIBM Data Analyst Certificate\n\n\nfreecodecamp\n\n\nKaggle courses\n\n\n\n\nTopics\n\n\nMainly covered in Mathematics for Machine Learning:\n\n\n\n\nOptimization\n\n\nLinear algebra (orthogonal matrices)\n\n\n\nBooks\n\n\nTo study in this order: \n\n\n\n\nMathematics for Machine Learning\n\n\nPattern Recognition and Machine Learning\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/DataScience/freecodecamp.html",
    "title": "FreeCodeCamp",
    "body": "\n\nBack\n\n\nFreeCodeCamp\n\n\n\n\nSource\n\n\n\nThere are data visualization, machine learning, data analysis in python courses\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Databases.html",
    "title": "Databases",
    "body": "\n\nBack\n\n\nDatabases\n\n\n\n\nStart with the recording and the go through the book (paper compilation)\n\n\n\n\n\nVideo Lectures\n\n\n\n\nCS186B Berkley\n\n\n\n\n\n\n\nBook\n\n\n\n\nReadings in Database Systems\n\n\n\n\n\n\nData Modelling\n\n\n\nBook: Data and Reality: A Timeless Perspective on Perceiving and Managing Information in Our Imprecise World.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Programming.html",
    "title": "Programming",
    "body": "\n\nBack\n\n\nProgramming\n\n\n\n\n\n\nBooks\n\n\n\n\nStructure and Interpretation of Computer Programs\n\n\n\n\n\n\n\nVideo Lectures\n\n\n\n\nBrian Harvey’s SICP lectures\n\n\n\n\n\n\nResources for the berkley course\n\n\nCode online on Scheme\n\n\nScheme on Arch (Download MIT/GNU Scheme)\n\n\n\n\n\nPlan 1\n\n\nNotes\n\n\n\nNotes\n\n\nWe recommend working through at least the first three chapters of SICP and doing the exercises. For additional practice, work through a set of small programming problems like those on exercism.\n\n\nAlternatives\n\n\nSame course but with python instead of Scheme (Stk)\n\n\n\n\nBooks: Composing Programs\n\n\nLectures: 61A taught by John DeNero at Berkley.\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Languages and Compilers.html",
    "title": "Languages and Compilers",
    "body": "\n\nBack\n\n\nLanguages and Compilers\n\n\n\n\n\n\nBooks\n\n\n\n\nIntroductory: Crafting Interpreters\n\n\n\n\nAs supplementary reference for video lectures: Compilers: Principles, Techniques & Tools\n\n\n\n\n\n\n\nVideo Lecutres\n\n\n\n\nAlex Aiken’s, on edX\n\n\n\n\nNotes\n\n\nFor introductory book: We suggest taking the time to work through the whole thing, attempting whichever of the \"challenges\" sustain your interest.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Distributed Systems.html",
    "title": "Distributed Systems",
    "body": "\n\nBack\n\n\nDistributed Systems\n\n\n\n\n\n\nBooks\n\n\n\n\nPractice oriented: Designing Data-Intensive Applications\n\n\n\n\nMore traditional: Distributed Systems, 3rd Edition\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Computer Architecture.html",
    "title": "Computer Architecture",
    "body": "\n\nBack\n\n\nComputer Architecture\n\n\n\n\nFirst go to the alternative and then go to the main book.\n\n\n\n\n\nBooks\n\n\n\n\nComputer Systems: A Programmer's Perspective\n\n\n\n\n\nMost courses go from chapter 1 to 6.\n\n\nAlternatives\n\n\nEach chapter involves building a small piece of the overall system, from writing elementary logic gates in HDL, through a CPU and assembler, all the way to an application the size of a Tetris game.\n\n\n\nThe Elements of Computing Systems (Nand2Tetris)\n\n\n\nWe recommend reading through the first six chapters of the book and completing the associated projects. This will develop your understanding of the relationship between the architecture of the machine and the software that runs on it.\n\n\n\nIn seeking simplicity and cohesiveness, Nand2Tetris trades off depth. In particular, two very important concepts in modern computer architectures are pipelining and memory hierarchy, but both are mostly absent from the text.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Operating Systems.html",
    "title": "Operating Systems",
    "body": "\n\nBack\n\n\nOperating Systems\n\n\n\n\n\n\nBooks\n\n\n\n\nOperating Systems: Three Easy Pieces\n\n\n\n\n\n\nLabs: xv6 labs\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Mathematics for Computer Science.html",
    "title": "Mathematics for Computer Science",
    "body": "\n\nBack\n\n\nMathematics for Computer Science\n\n\n\n\n\n\nBooks\n\n\n\n\nMIT Lecture Notes\n\n\n\n\n\n\nVideo Lectures\n\n\n\n\nMIT Video Lectures\n\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/index.html",
    "title": "Computer Science",
    "body": "\n\nBack\n\n\nComputer Science\n\n\n\n\nSource\n\n\n\n\n\n\nProgramming\n\n\nComputer Architecture\n\n\nAlgorithms and Data Structures\n\n\nMathematics for Computer Science\n\n\nOperating Systems\n\n\nComputer Networking\n\n\nDatabases\n\n\nLanguages and Compilers\n\n\nDistributed Systems\n\n\nAI and Machine Learning\n\n\n\n\n\nAI and Machine Learning\n\n\nCheck the source.\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Algorithms and Data Structures.html",
    "title": "Algorithms and Data Structures",
    "body": "\n\nBack\n\n\nAlgorithms and Data Structures\n\n\n\n\n\n\nBooks\n\n\n\n\nThe Algorithm Design Manual\n\n\n\n\n\n\n\nVideo Lectures\n\n\n\n\nSkiena's or Tim's on Coursera\n\n\n\n\n\n\nPractice: Leetcode\n\n\nProblem solving book after the manual: How to Solve It\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/CS/Computer Networking.html",
    "title": "Computer Networking",
    "body": "\n\nBack\n\n\nComputer Networking\n\n\n\n\n\n\nBooks\n\n\n\n\nComputer Networking: A Top-Down Approach\n\n\n\n\n\n\n\nVideo Lectures\n\n\n\n\nStandford: Introduction to Computer Networking course\n\n\n\n\n\nLabs: Wireshark labs\n\n\n"
  },
  {
    "id": "https://albamr09.github.io/Study/index.html",
    "title": "Study",
    "body": "\n\nBack\n\n\nStudy\n\n\n\nStudy Guides\n\n\n\nMath\n\n\nCS\n\n\nDataScience\n\n\nWeb Development\n\n\n\n\n\nCourse Plan\n\n\n\nCurrent\n\n\n\nCopy ML notes (at least 1h a day)\n\n\n\nLook into NN in books\n\n\nLook into NN in College subject on Machine Learning\n\n\nReview all notes of College subject on Machine Learning\n\n\nReview all homework of College subject on Machine Learning (add snippets to notes)\n\n\n\nReview React\n\n\n\nDo the React Crash Course.\n\n\nDo the Redux Crash Course\n\n\nChoose the Markdown previewer or the 25 + 5 clock (or both!!!! or neither!!!)\n\n\n\nFinish SICP Berkeley (at least 1h a day)\n\n\n\nFuture\n\n\nOrdered by priority, one choose one at a time\n\n\n\n\nBackend Dev\n\n\n\nSpring Boot (List of courses): Do the Spring Course (max 2 weeks)\n\n\nProjects\n\n\nDo the Back End Dev course from freecodecamp (max a week)\n\n\nContinue the Bookish project (add GraphQL)\n\n\n\nLearn C++\n\n\n\nTutorialspoints course (max a week)\n\n\nSearch for projects, some are:\n\n\n\nData Structure\n\n\n\n\nData Analysis with Python Course from freecodecamp\n\n\nData Visualization Course from freecodecamp\n\n\nCollege Algebra: Start from chapter 2\n\n\n\n\n\nTo search for more project go to Project Ideas, there are project listings for a lot of languages, frameworks.\n\n"
  }
]