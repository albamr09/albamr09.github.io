---
title: Advanced Techniques
type: docs
weight: 10
math: true
---

## Post-Processing

**Post-processing** is the process of adding effects by re-rendering the image of the scene with a shader that alters the final image. Some examples include the following:

- Grayscale
- Sepia tone
- Inverted colors
- Film grain
- Blur
- Wavy/dizzy effect

The basic technique for creating these effects is:

1. Create a framebuffer with the same dimensions as the canvas and have the entire scene rendered to it at the beginning of the draw cycle.
2. A quad is rendered to the default framebuffer using the texture that makes up the framebuffer's color attachment.
3. The shader used during the rendering of the quad is what contains the post-process effect. This shader can transform the color values of the rendered scene.

### Creating the Framebuffer

Since the texture will be exactly the same size as the canvas, and since we're rendering it as a full-screen quad, we've created a situation where the texture will be displayed at exactly a 1:1 ratio on the screen. **This means that no filters need to be applied and that we can use NEAREST filtering with no visual artifacts.**

### Creating the Geometry

```javascript
// 1. Define the geometry for the full-screen quad
const vertices = [-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1];
const textureCoords = [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1];

// 2. Create and bind VAO
const vao = gl.createVertexArray();
gl.bindVertexArray(vao);
// 3. Init the buffers
const vertexBuffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
gl.bufferData(
  gl.ARRAY_BUFFER,
  new Float32Array(vertices),
  // Configure instructions for VAO
  gl.STATIC_DRAW
);
gl.enableVertexAttribArray(program.aVertexPosition);
gl.vertexAttribPointer(program.aVertexPosition, 3, gl.FLOAT, false, 0, 0);
const textureBuffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, textureBuffer);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(textureCoords), gl.STATIC_DRAW);
// Configure instructions for VAO
gl.enableVertexAttribArray(program.aVertexTextureCoords);
gl.vertexAttribPointer(program.aVertexTextureCoords, 2, gl.FLOAT, false, 0, 0);
// 4. Clean up
gl.bindVertexArray(null);
gl.bindBuffer(gl.ARRAY_BUFFER, null);
```

### Setting up the Shader

```c
#version 300 es

precision mediump float;

in vec2 aVertexPosition;
in vec2 aVertexTextureCoords;

out vec2 vTextureCoords;

void main(void) {
    vTextureCoords = aVertexTextureCoords;
    gl_Position = vec4(aVertexPosition, 0.0, 1.0);
}
```

Notice that unlike the other vertex shaders we've worked with so far, this one doesn't use any matrices. That's because the vertices we declared in the previous step are **pretransformed**. Our vertex positions are already mapped to a $[-1, 1]$ range; therefore, no transformation is needed because they will map perfectly to the viewport bounds when we render.

The fragment shader is where most of the interesting operations happen. The fragment shader will be different for every post-process effect. Let's look at a simple **grayscale effect**:

```c
#version 300 es

precision mediump float;

uniform sampler2D uSampler;
in vec2 vTextureCoords;
out vec4 fragColor;

void main(void) {
    vec4 frameColor = texture(uSampler, vTextureCoords);
    float luminance = frameColor.r * 0.3 + frameColor.g * 0.59 + frameColor.b* 0.11;
        fragColor = vec4(luminance, luminance, luminance, frameColor.a);
}
```

## Point Sprites

A **particle effect** is a generic term for any special effect created by rendering groups of particles (displayed as points, textured quads, or repeated geometry) that are difficult to represent by a single geometric model.

One very efficient way of rendering particles is to use **point sprites**. You must render vertices with the [`POINTS`](../02/#drawelements-modes) primitive type, then each vertex will be rendered as a single pixel on screen.

A point stype is created by setting the `gl_PointSize` value in the vertex shader. If it's set to a number greater than one, the point is rendered as a quad that always faces the screen (also known as a **billboard**). The quad is centered on the original point and has a width and height equal to the `gl_PointSize` in pixels:

![Point Sprite](./assets/point_sprite.png)

When the point sprite is rendered, it also generates texture coordinates for the quad, covering a simple $[0, 1]$ range from the upper left to the lower right:

![Point Sprite Texture](./assets/point_sprite_texture.png)

The texture coordinates are accessible in the fragment shader by the built-in `vec2 gl_PointCoord`. Combining these properties gives us a simple point sprite vertex shader that looks like this:

```c
#version 300 es

precision mediump float;

uniform mat4 uModelViewMatrix;
uniform mat4 uProjectionMatrix;
uniform float uPointSize;

in vec4 aParticle;

out float vLifespan;

void main(void) {
  gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aParticle.xyz, 1.0);
  
  vLifespan = aParticle.w;
  
  gl_PointSize = uPointSize * vLifespan;
}
```

The corresponding fragment shader looks like this:

```c
#version 300 es

precision mediump float;

uniform sampler2D uSampler;

in float vLifespan;

out vec4 fragColor;

void main(void) {
  vec4 texColor = texture(uSampler, gl_PointCoord);
  fragColor = vec4(texColor.rgb, texColor.a * vLifespan);
}
```
