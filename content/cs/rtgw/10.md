---
title: Advanced Techniques
type: docs
weight: 10
math: true
---

## Post-Processing

**Post-processing** is the process of adding effects by re-rendering the image of the scene with a shader that alters the final image. Some examples include the following:

- Grayscale
- Sepia tone
- Inverted colors
- Film grain
- Blur
- Wavy/dizzy effect

The basic technique for creating these effects is:

1. Create a framebuffer with the same dimensions as the canvas and have the entire scene rendered to it at the beginning of the draw cycle.
2. A quad is rendered to the default framebuffer using the texture that makes up the framebuffer's color attachment.
3. The shader used during the rendering of the quad is what contains the post-process effect. This shader can transform the color values of the rendered scene.

### Creating the Framebuffer

Since the texture will be exactly the same size as the canvas, and since we're rendering it as a full-screen quad, we've created a situation where the texture will be displayed at exactly a 1:1 ratio on the screen. **This means that no filters need to be applied and that we can use NEAREST filtering with no visual artifacts.**

### Creating the Geometry

```javascript
// 1. Define the geometry for the full-screen quad
const vertices = [-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1];
const textureCoords = [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1];

// 2. Create and bind VAO
const vao = gl.createVertexArray();
gl.bindVertexArray(vao);
// 3. Init the buffers
const vertexBuffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
gl.bufferData(
  gl.ARRAY_BUFFER,
  new Float32Array(vertices),
  // Configure instructions for VAO
  gl.STATIC_DRAW
);
gl.enableVertexAttribArray(program.aVertexPosition);
gl.vertexAttribPointer(program.aVertexPosition, 3, gl.FLOAT, false, 0, 0);
const textureBuffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, textureBuffer);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(textureCoords), gl.STATIC_DRAW);
// Configure instructions for VAO
gl.enableVertexAttribArray(program.aVertexTextureCoords);
gl.vertexAttribPointer(program.aVertexTextureCoords, 2, gl.FLOAT, false, 0, 0);
// 4. Clean up
gl.bindVertexArray(null);
gl.bindBuffer(gl.ARRAY_BUFFER, null);
```

### Setting up the Shader

```c
#version 300 es

precision mediump float;

in vec2 aVertexPosition;
in vec2 aVertexTextureCoords;

out vec2 vTextureCoords;

void main(void) {
    vTextureCoords = aVertexTextureCoords;
    gl_Position = vec4(aVertexPosition, 0.0, 1.0);
}
```

Notice that unlike the other vertex shaders we've worked with so far, this one doesn't use any matrices. That's because the vertices we declared in the previous step are **pretransformed**. Our vertex positions are already mapped to a $[-1, 1]$ range; therefore, no transformation is needed because they will map perfectly to the viewport bounds when we render.

The fragment shader is where most of the interesting operations happen. The fragment shader will be different for every post-process effect. Let's look at a simple **grayscale effect**:

```c
#version 300 es

precision mediump float;

uniform sampler2D uSampler;
in vec2 vTextureCoords;
out vec4 fragColor;

void main(void) {
    vec4 frameColor = texture(uSampler, vTextureCoords);
    float luminance = frameColor.r * 0.3 + frameColor.g * 0.59 + frameColor.b* 0.11;
        fragColor = vec4(luminance, luminance, luminance, frameColor.a);
}
```
