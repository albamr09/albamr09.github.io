# Introducci√≥n a las arquitecturas de procesamiento de streams: Lambda y Kappa

## What are Data Streams?

A data stream is a series of data that comes into a system over time. It's like a river of information that never stops flowing. Here are some important things to remember about data streams:

- Order is Important: The order the data comes in matters because it can show how the data is related. Think about the temperature recorded every hour. The order helps us see how the temperature changes over the day.
- It Never Ends: Data streams can go on forever, so we can't store all the information. Imagine trying to keep all the tweets ever sent!
- We Only See a Part: At any given time, we can only see a small part of the data stream. It's like looking at a small section of a river.
- Speed Changes: The speed at which data arrives can change. Sometimes it's a trickle, and other times it's a flood!

## Challenges with Data Streams

Because data streams are different from traditional data, they pose unique challenges:

- Traditional data mining techniques assume we have all the data at once. With data streams, we only have a part of the data at any time.
- The way data is spread out (its distribution) can change over time. This is called concept drift and means that a model we built yesterday might not work well today.
- We may not get feedback on our models right away. This makes it harder to know if our models are working correctly.

## Key Elements for Analysing Data Streams

To work with data streams, we need special tools:

- Memory: This acts like a temporary storage space to hold incoming data until it can be processed.
- Algorithms: Special algorithms are needed to learn from the data and make decisions. These algorithms need to be fast and able to adapt to changing data.
- Change Monitoring: We need ways to watch for concept drift, which is when the patterns in the data change over time.
- Performance Evaluation: Traditional methods for evaluating models don't work well with data streams. New methods are needed to see how well our models are performing.

## Working with Data Streams: Data Windows

One important technique for handling data streams is called windowing. Since we can't store all the data, windows allow us to focus on the most recent data:

- Landmarks: We can define windows based on specific events. Think about analysing data between each time a sensor is reset.
- Sliding Windows: These windows keep a fixed amount of the most recent data. As new data arrives, old data is dropped.

Example: Imagine you are analysing tweets about a football match. A sliding window might keep only the last 10 minutes of tweets, allowing you to see what people are saying right now.

## Architectures for Handling Data Streams

There are two main ways to build systems for processing data streams:

- Lambda Architecture: This approach uses two paths: one for real-time processing (online) and one for batch processing (offline). It's like having a team that gives quick updates and another team that does a more detailed analysis later.
- Kappa Architecture: This approach uses only real-time processing. It's like having one team that can handle everything quickly.
