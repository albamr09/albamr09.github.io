<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../src/style/custom.css">
    <title>Camera</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="index.html">Back</a>
</p>

<div id="Camera"><h1 id="Camera" class="header"><a href="#Camera">Camera</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="04.html#WebGL%20Does%20Not%20Have%20Cameras">WebGL Does Not Have Cameras</a>

</li><li>
<a href="04.html#Vertex%20Transformations">Vertex Transformations</a>

<ul>
<li>
<a href="04.html#Homogeneous%20Coordinates">Homogeneous Coordinates</a>

</li><li>
<a href="04.html#Transformations">Transformations</a>

<ul>
<li>
<a href="04.html#Translation%20Matrices">Translation Matrices</a>

</li><li>
<a href="04.html#Scaling%20matrices">Scaling matrices</a>

</li><li>
<a href="04.html#Rotation%20Matrices">Rotation Matrices</a>

</li><li>
<a href="04.html#Cumulating%20transformations">Cumulating transformations</a>

</li></ul>
</li><li>
<a href="04.html#The%20Model%2C%20View%20and%20Projection%20matrices">The Model  View and Projection matrices</a>

<ul>
<li>
<a href="04.html#The%20Model%20Matrix">The Model Matrix</a>

</li><li>
<a href="04.html#The%20View%20Matrix">The View Matrix</a>

</li><li>
<a href="04.html#The%20Projection%20Matrix">The Projection Matrix</a>

</li></ul>
</li><li>
<a href="04.html#Perspective%20Division">Perspective Division</a>

</li></ul>
</li><li>
<a href="04.html#Normal%20Transformations">Normal Transformations</a>

<ul>
<li>
<a href="04.html#Calculating%20the%20Normal%20Matrix">Calculating the Normal Matrix</a>

</li></ul>
</li><li>
<a href="04.html#WebGL%20Implementation">WebGL Implementation</a>

</li><li>
<a href="04.html#The%20Model-View%20Matrix">The Model-View Matrix</a>

<ul>
<li>
<a href="04.html#Spatial%20Encoding%20of%20the%20World">Spatial Encoding of the World</a>

<ul>
<li>
<a href="04.html#Rotation%20Matrix">Rotation Matrix</a>

</li><li>
<a href="04.html#Translation%20Vector">Translation Vector</a>

</li><li>
<a href="04.html#The%20Mysterious%20Fourth%20Row">The Mysterious Fourth Row</a>

</li></ul>
</li></ul>
</li><li>
<a href="04.html#The%20Camera%20Matrix">The Camera Matrix</a>

<ul>
<li>
<a href="04.html#Camera%20Translation">Camera Translation</a>

</li><li>
<a href="04.html#Interpreting%20Transformations%20Using%20the%20Model-View%20Matrix">Interpreting Transformations Using the Model-View Matrix</a>

</li></ul>
</li><li>
<a href="04.html#Basic%20Camera%20Types">Basic Camera Types</a>

<ul>
<li>
<a href="04.html#The%20Camera%20Model">The Camera Model</a>

</li></ul>
</li></ul>
<hr>

<p>
Even though we have a camera within our 3D application, there is no camera object in the WebGL API—only matrices. That is because having matrices instead of a camera object gives WebGL the flexibility to represent complex projections and animations.
</p>

<div id="Camera-WebGL Does Not Have Cameras"><h2 id="WebGL Does Not Have Cameras" class="header"><a href="#Camera-WebGL Does Not Have Cameras">WebGL Does Not Have Cameras</a></h2></div>

<p>
WebGL does not have a camera object that you can manipulate. However, we can assume that what we render in the <code>canvas</code> is what our camera captures.
</p>

<p>
Every time we move our camera around, we need to update the objects according to the new camera position. So, we need to transform each vertex. Similarly, we need to make sure that the object normals and light directions are still consistent after the camera has moved. In summary, we need to analyze two different types of transformations: 
</p>

<ul>
<li>
vertex (points) and 

</li><li>
normal (vectors)

</li></ul>
<div id="Camera-Vertex Transformations"><h2 id="Vertex Transformations" class="header"><a href="#Camera-Vertex Transformations">Vertex Transformations</a></h2></div>

<p>
Each transformation is encoded by a \(4\)x\(4\) matrix. We multiply vertices that have three components, \((x, y, z)\), by this \(4\)x\(4\) matrix by adding a fourth component to each vertex called the Homogeneous coordinate.
</p>

<p>
<a href="https://jsantell.com/model-view-projection">This</a> article has a great visualization for each space: 
</p>

<ul>
<li>
World Space

</li><li>
Camera Space

</li><li>
Clip Space

</li></ul>
<div id="Camera-Vertex Transformations-Homogeneous Coordinates"><h3 id="Homogeneous Coordinates" class="header"><a href="#Camera-Vertex Transformations-Homogeneous Coordinates">Homogeneous Coordinates</a></h3></div>

<p>
Until now, we only considered 3D vertices as a \((x,y,z)\) triplet. Let’s introduce \(w\). Homogeneous coordinates make it possible to represent <span id="Camera-Vertex Transformations-Homogeneous Coordinates-affine transformations"></span><strong id="affine transformations">affine transformations</strong> (such as rotation, scaling, shear, and translation) and projective transformations as \(4\)x\(4\) matrices.
</p>

<p>
In Homogeneous coordinates, vertices have four components: \(x, y, z\), and \(w\). The first three components are the <span id="Camera-Vertex Transformations-Homogeneous Coordinates-vertex coordinates"></span><strong id="vertex coordinates">vertex coordinates</strong> in <span id="Camera-Vertex Transformations-Homogeneous Coordinates-Euclidian Space"></span><strong id="Euclidian Space">Euclidian Space</strong>. The fourth is the <span id="Camera-Vertex Transformations-Homogeneous Coordinates-perspective component"></span><strong id="perspective component">perspective component</strong>. So \((x, y, z, w)\) take us to a new space: the <span id="Camera-Vertex Transformations-Homogeneous Coordinates-Projective Space"></span><strong id="Projective Space">Projective Space</strong>.
</p>

<p>
This will be more clear soon, but for now, just remember this:
</p>

<p>
If \(w == 1\), then the vector \((x,y,z,1)\) is a position in space.
If \(w == 0\), then the vector \((x,y,z,0)\) is a direction.
</p>

<p>
What difference does this make? Well, for a rotation, it doesn’t change anything. When you rotate a point or a direction, you get the same result. However, for a translation (when you move the point in a certain direction), things are different. What could mean “translate a direction”? Not much. Homogeneous coordinates allow us to use a single mathematical formula to deal with these two cases.
</p>

<p>
Homogeneous coordinates make it possible to solve a system of linear equations where each equation represents a line that is parallel with all the others in the system. Remember that in Euclidian Space, a system like that does not have solutions, because there are no intersections. However, in Projective Space, this system has a solution—the lines will intersect at infinity. This fact is represented by the perspective component having a value of \(0\).
</p>

<p>
<img src="https://albamr09.github.io/public/assets/projection_space.png" alt="Projective Space" style="width:400px">
</p>

<p>
It's easy to convert from Homogeneous coordinates to non-Homogeneous, old-fashioned, Euclidean coordinates by dividing each coordinate by \(w\):
</p>

\begin{align}
h(x, y, z, w) = v(\frac{x}{w}, \frac{y}{w}, \frac{z}{w})
\end{align}

<p>
Consequently, if you want to go from Euclidean to Projective space, you add the fourth component, \(w\), and make it \(1\):
</p>

\begin{align}
v(x, y, z) = h(x, y, z, 1)
\end{align}

<p>
In fact, this is what we've been doing throughout the first three chapters:
</p>

<pre javascript="">#version 300 es

precision mediump float;

uniform mat4 uModelViewMatrix;
uniform mat4 uProjectionMatrix;
uniform mat4 uNormalMatrix;

in vec3 aVertexPosition;

void main(void) {
  gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aVertexPosition, 1.0);
}
</pre>

<p>
There is one more thing to note about Homogeneous coordinates: while vertices have a Homogeneous coordinate, \(w = 1\), vectors have a Homogeneous coordinate, \(w = 0\). This is because in the Phong vertex shader, the line that processes the normals looks like this:
</p>

<pre javascript="">vVertexNormal = vec3(uNormalMatrix * vec4(aVertexNormal, 0.0));
</pre>

<div id="Camera-Vertex Transformations-Transformations"><h3 id="Transformations" class="header"><a href="#Camera-Vertex Transformations-Transformations">Transformations</a></h3></div>

<div id="Camera-Vertex Transformations-Transformations-Translation Matrices"><h4 id="Translation Matrices" class="header"><a href="#Camera-Vertex Transformations-Transformations-Translation Matrices">Translation Matrices</a></h4></div>

<p>
These are the most simple tranformation matrices to understand. A translation matrix look like this:
</p>

\begin{align}
\being{bmatrix}
1 &amp; 0 &amp; 0 &amp; X \\
0 &amp; 1 &amp; 0 &amp; Y \\
0 &amp; 0 &amp; 1 &amp; Z \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}

<p>
where \(X,Y,Z\) are the values that you want to add to your position.
</p>

<p>
So if we want to translate the vector \((10,10,10,1)\) of \(10\) units in the X direction, we get:
</p>

\begin{align}
\being{bmatrix}
1 &amp; 0 &amp; 0 &amp; 10 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
* 
\being{bmatrix}
10 \\
10 \\
10 \\
1 \\
\end{bmatrix} = 
\being{bmatrix}
1 * 10 + 0 * 10 + 0 * 10 + 10 * 1 \\
0 * 10 + 1 * 10 + 0 * 10 + 0 * 1 \\
0 * 10 + 0 * 10 + 1 * 10 + 0 * 1 \\
0 * 10 + 0 * 10 + 0 * 10 + 1 * 1 \\
\end{bmatrix} = 
\being{bmatrix}
20 \\
10 \\
10 \\
1 \\
\end{bmatrix}
\end{align}

<p>
and we get a \((20,10,10,1)\) homogeneous vector! Remember, the \(1\) means that it is a position, not a direction. So our transformation didn’t change the fact that we were dealing with a position, which is good.
</p>

<div id="Camera-Vertex Transformations-Transformations-Scaling matrices"><h4 id="Scaling matrices" class="header"><a href="#Camera-Vertex Transformations-Transformations-Scaling matrices">Scaling matrices</a></h4></div>

<p>
Scaling matrices are quite easy too:
</p>

\begin{align}
\being{bmatrix}
x &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; y &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; z &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\end{align}

<p>
So if you want to scale a vector (position or direction, it doesn’t matter) by \(2.0\) in all directions:
</p>

\begin{align}
\being{bmatrix}
2 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
* 
\being{bmatrix}
x \\
y \\
z \\
w \\
\end{bmatrix} = 
\being{bmatrix}
2 * x + 0 * y + 0 * z + 0 * w \\
0 * x + 2 * y + 0 * z + 0 * w \\
0 * x + 0 * y + 2 * z + 0 * w \\
0 * x + 0 * y + 0 * z + 1 * w \\
\end{bmatrix} = 
\being{bmatrix}
2x \\
2y \\
2z \\
w \\
\end{bmatrix}
\end{align}

<div id="Camera-Vertex Transformations-Transformations-Rotation Matrices"><h4 id="Rotation Matrices" class="header"><a href="#Camera-Vertex Transformations-Transformations-Rotation Matrices">Rotation Matrices</a></h4></div>

<p>
<a href="https://www.opengl-tutorial.org/intermediate-tutorials/tutorial-17-quaternions/">TBC</a>
</p>

<div id="Camera-Vertex Transformations-Transformations-Cumulating transformations"><h4 id="Cumulating transformations" class="header"><a href="#Camera-Vertex Transformations-Transformations-Cumulating transformations">Cumulating transformations</a></h4></div>

<p>
So now we know how to rotate, translate, and scale our vectors. It would be great to combine these transformations. This is done by multiplying the matrices together:
</p>

<pre javascript="">TransformedVector = TranslationMatrix * RotationMatrix * ScaleMatrix * OriginalVector;
</pre>

<p>
This actually performs the scaling FIRST, and THEN the rotation, and THEN the translation. This is how matrix multiplication works.
</p>

<div id="Camera-Vertex Transformations-The Model, View and Projection matrices"><h3 id="The Model, View and Projection matrices" class="header"><a href="#Camera-Vertex Transformations-The Model, View and Projection matrices">The Model, View and Projection matrices</a></h3></div>

<p>
The Model, View and Projection matrices are a handy tool to separate transformations cleanly.
</p>

<div id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Model Matrix"><h4 id="The Model Matrix" class="header"><a href="#Camera-Vertex Transformations-The Model, View and Projection matrices-The Model Matrix">The Model Matrix</a></h4></div>

<p>
A model is defined by a set of vertices. The \(X,Y,Z\) coordinates of these vertices are defined relative to the object’s center: that is, if a vertex is at \((0,0,0)\), it is at the center of the object.
</p>

<p>
We'd like to be able to move this model (you just learnt to do so: <code>translation*rotation*scale</code>, and done. You apply this matrix to all your vertices at each frame and everything moves. Something that doesn't move will be at the center of the world.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/model_transform.png" alt="Model Transform" style="width:500px">
</p>

<p>
Your vertices are now in World Space. We went from <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Model Matrix-Model Space"></span><strong id="Model Space">Model Space</strong> (all vertices defined relatively to the center of the model) to <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Model Matrix-World Space"></span><strong id="World Space">World Space</strong> (all vertices defined relatively to the center of the world). See figure below:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/world_coordinates.png" alt="World Coordinates" style="width:500px">
</p>

<div id="Camera-Vertex Transformations-The Model, View and Projection matrices-The View Matrix"><h4 id="The View Matrix" class="header"><a href="#Camera-Vertex Transformations-The Model, View and Projection matrices-The View Matrix">The View Matrix</a></h4></div>

<p>
It you want to view a moutain from another angle, you can either move the camera... or move the mountain.
</p>

<p>
So initially your camera is at the origin of the World Space. In order to move the world, you simply introduce another matrix. Let’s say you want to move your camera of \(3\) units to the right (\(+X\)). This is equivalent to moving your whole world \(3\) units to the left (\(-X\)).
</p>

<p>
<img src="https://albamr09.github.io/public/assets/view_transform.png" alt="View Transform" style="width:500px">
</p>

<p>
We went from <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The View Matrix-World Space"></span><strong id="World Space">World Space</strong> (all vertices defined relatively to the center of the world, as we made so in the previous section) to <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The View Matrix-Camera Space"></span><strong id="Camera Space">Camera Space</strong> (all vertices defined relatively to the camera). The figure below shows how we go from model/object coordinates to world coordinates and finally to camera coordinates.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/camera_coordinates.png" alt="Camera Coordinates" style="width:500px">
</p>

<div id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix"><h4 id="The Projection Matrix" class="header"><a href="#Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix">The Projection Matrix</a></h4></div>

<p>
We're now in Camera Space. This means that after all theses transformations, a vertex that happens to have \(x==0\) and \(y==0\) should be rendered at the center of the screen. But we can't use only the \(x\) and \(y\) coordinates to determine where an object should be put on the screen: its distance to the camera (\(z\)) counts, too! For two vertices with equivalent \(x\) and \(y\) coordinates, the vertex with the biggest \(z\) coordinate will be more on the center of the screen than the other.
</p>

<p>
The operation is called the <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix-projection transform"></span><strong id="projection transform">projection transform</strong>. This operation determines how much of the view space will be rendered and how it will be mapped onto the computer screen. This region is known as the <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix-frustum"></span><strong id="frustum">frustum</strong> and it is defined by six planes (near, far, top, bottom, right, and left planes), as shown in the following diagram:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/projection_transform.png" alt="Projection Transform" style="width:500px">
</p>

<p>
These six planes are encoded in the <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix-Projection matrix"></span><strong id="Projection matrix">Projection matrix</strong>. Any vertices lying outside the frustum after applying the transformation are clipped out and discarded from further processing. Therefore, the frustum defines clipping coordinates, and the Projection matrix that encodes the frustum produces clipping coordinates.
</p>

<p>
 If the far and near planes have the same dimensions, the frustum will then determine an <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix-orthographic projection"></span><strong id="orthographic projection">orthographic projection</strong>. Otherwise, it will be a <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix-perspective projection"></span><strong id="perspective projection">perspective projection</strong>.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/orthographic_perspective_projection.png" alt="Orthographic vs Perspective projection" style="width:500px">
We went from <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix-Camera Space"></span><strong id="Camera Space">Camera Space</strong> (all vertices defined relatively to the camera) to <span id="Camera-Vertex Transformations-The Model, View and Projection matrices-The Projection Matrix-Homogeneous Space"></span><strong id="Homogeneous Space">Homogeneous Space</strong> (all vertices defined in a small cube. Everything inside the cube is onscreen).
</p>

<p>
Before projection, we’ve got our blue objects, in Camera Space, and the red shape represents the frustum of the camera: the part of the scene that the camera is actually able to see.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/projection_coordinates_before.png" alt="Projection Coordinates" style="width:500px">
</p>

<p>
Multiplying everything by the Projection Matrix has the following effect:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/projection_coordinates_after.png" alt="Projection Coordinates" style="width:500px">
</p>

<p>
Up to this point, we are still working with Homogeneous coordinates, so the clipping coordinates have four components: \(x\), \(y\), \(z\), and \(w\). The clipping is done by comparing the \(x\), \(y\), and \(z\) components against the Homogeneous coordinate, \(w\). If any of them is more than, \(+w\), or less than, \(-w\), then that vertex lies outside the frustum and is discarded.
</p>

<div id="Camera-Vertex Transformations-Perspective Division"><h3 id="Perspective Division" class="header"><a href="#Camera-Vertex Transformations-Perspective Division">Perspective Division</a></h3></div>

<p>
Once it has been determined how much of the viewing space will be rendered, the frustum is mapped into the near plane in order to produce a 2D image.
</p>

<p>
Different operative systems and displaying devices can have mechanisms to represent 2D information on screen. To provide robustness for all possible cases, WebGL and OpenGL ES provide an intermediate coordinate system that is independent from any specific hardware. This space is known as the <span id="Camera-Vertex Transformations-Perspective Division-Normalized Device Coordinates (NDC)"></span><strong id="Normalized Device Coordinates (NDC)">Normalized Device Coordinates (NDC)</strong>.
</p>

<p>
Normalized device coordinates are obtained by dividing the clipping coordinates by the \(w\) component. This is why this step is known as <span id="Camera-Vertex Transformations-Perspective Division-perspective division"></span><strong id="perspective division">perspective division</strong>. In the NDC space, the \(x\) and \(y\) coordinates represent the location of your vertices on a normalized 2D screen, while the z-coordinate encodes depth information, which is the relative location of the objects with respect to the near and far planes. 
</p>

<p>
This will allow WebGL to later determine how to display overlapping objects based on their distance from the nearest plane. When using normalized device coordinates, the depth is encoded in the \(z\) component.
</p>

<p>
The perspective division transforms the viewing frustum into a cube centered in the origin with the minimum coordinates of \([-1, -1, -1]\) and the maximum coordinates of \([1, 1, 1]\). Also, the direction of the z-axis is inverted.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normalized_device_coordinates.png" alt="Normalized Device Coordinates" style="width:500px">
</p>

<p>
Finally, NDCs are mapped to viewport coordinates. This step maps these coordinates to the available space in your screen. In WebGL, this space is provided by the HTML5 <code>canvas</code>:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/view_transform_1.png" alt="View Transform" style="width:500px">
</p>

<p>
Unlike the previous cases, the viewport transform is not generated by a matrix transformation. In this case, we use the WebGL viewport function. We will learn more about this function later in this chapter. 
</p>

<div id="Camera-Normal Transformations"><h2 id="Normal Transformations" class="header"><a href="#Camera-Normal Transformations">Normal Transformations</a></h2></div>

<p>
Whenever vertices are transformed, normal vectors should also be transformed so that they point in the right direction. We could consider using the Model-View matrix that transforms vertices to do this, but this approach is problematic: the Model-View matrix will not always keep the perpendicularity of normals:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_transformations.png" alt="Normal Transformations" style="width:400px">
</p>

<p>
This problem occurs if there is a unidirectional (one axis) scaling transformation or a shearing transformation in the Model-View matrix.
</p>

<div id="Camera-Normal Transformations-Calculating the Normal Matrix"><h3 id="Calculating the Normal Matrix" class="header"><a href="#Camera-Normal Transformations-Calculating the Normal Matrix">Calculating the Normal Matrix</a></h3></div>

<p>
Two vectors are perpendicular if their dot product is \(0\). In our example
</p>

\begin{align}
&lt;N, S&gt; = 0
\end{align}

<p>
Here, \(S\) is the surface vector and can be calculated as the difference of two vertices. Let \(M\) be the Model-View matrix. We can use \(M\) to transform \(S\) as follows:
</p>

\begin{align}
S' = MS
\end{align}

<p>
We want to find a matrix, \(K\), that allows us to transform normals in a similar way. For the \(N\) normal, we want the following:
</p>

\begin{align}
N' = KN
\end{align}

<p>
For the scene to be consistent after obtaining \(N'\) and \(S'\), these two need to keep the perpendicularity that the original vectors \(N\) and \(S\) had.
</p>

\begin{align}
&lt;N', S'&gt; = 0
\end{align}

<p>
Substituting \(N'\) and \(S'\):
</p>

\begin{align}
&lt;KN, MS&gt; = 0
\end{align}

\begin{align}
(KN)^T(MS) = 0
\end{align}

\begin{align}
N^TK^TMS = 0
\end{align}

\begin{align}
N^T(K^TM)S = 0
\end{align}

<p>
Now, remember that \(&lt;N, S&gt; = 0\) so \(N^TS = 0\). This means that in the previous equation, \((K^TM)\) needs to be the identity matrix, \(I\), so the original condition of N and S being perpendicular holds:
</p>

\begin{align}
K^TM = I
\end{align}

\begin{align}
K^TMM^{-1} = IM^{-1} = M^{-1}
\end{align}

\begin{align}
K^T = M^{-1}
\end{align}

\begin{align}
(K^T)^T = (M^{-1})^T
\end{align}

\begin{align}
K = (M^{-1})^T
\end{align}

<p>
\(K\) is obtained by transposing the inverse of the Model-View matrix (\(M\), in this example). We need to use \(K\) to multiply the normal vectors so that they keep being perpendicular to the surface when transformed.
</p>

<div id="Camera-WebGL Implementation"><h2 id="WebGL Implementation" class="header"><a href="#Camera-WebGL Implementation">WebGL Implementation</a></h2></div>

<p>
The following diagram shows the theory we have learned so far, along with the relationships between the steps in the theory and the implementation in WebGL.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/web_gl_transformations_pipeline.png" alt="WebGL Transformations" style="width:600px">
</p>

<p>
The five transformations that we apply to object coordinates to obtain viewport coordinates are grouped into three matrices and one WebGL method:
</p>

<ul>
<li>
The <span id="Camera-WebGL Implementation-Model-View matrix"></span><strong id="Model-View matrix">Model-View matrix</strong> that groups the model and view transform in one single matrix. When we multiply our vertices by this matrix, we end up in world coordinates.

</li><li>
The <span id="Camera-WebGL Implementation-Normal matrix"></span><strong id="Normal matrix">Normal matrix</strong> is obtained by inverting and transposing the Model-View matrix. This matrix is applied to normal vectors to ensure that they continue to be perpendicular to the surface. 

</li><li>
The <span id="Camera-WebGL Implementation-Projection matrix"></span><strong id="Projection matrix">Projection matrix</strong> groups the projection transformation and the perspective division, and as a result, we end up in normalized device coordinates.

</li></ul>
<p>
Finally, we use the <code>gl.viewport</code> operation to map NDCs to viewport coordinates:
</p>

<pre javascript="">gl.viewport(minX, minY, width, height);
</pre>

<p>
The viewport coordinates originate in the lower-left corner of the HTML5 canvas.
</p>

<div id="Camera-The Model-View Matrix"><h2 id="The Model-View Matrix" class="header"><a href="#Camera-The Model-View Matrix">The Model-View Matrix</a></h2></div>

<p>
The Model-View matrix allows us to perform <span id="Camera-The Model-View Matrix-affine transformations"></span><strong id="affine transformations">affine transformations</strong> in our scene. Affine is a mathematical name that describes transformations that do not change the structure of the object undergoing such transformations. In our 3D world scene, such transformations are rotation, scaling, reflection shearing, and translation. Let's take a look at how the Model-View matrix is constructed.
</p>

<div id="Camera-The Model-View Matrix-Spatial Encoding of the World"><h3 id="Spatial Encoding of the World" class="header"><a href="#Camera-The Model-View Matrix-Spatial Encoding of the World">Spatial Encoding of the World</a></h3></div>

<p>
By default, when you render a scene, you are looking at it from the origin of the world in the negative direction of the z-axis. As shown in the following diagram, the z-axis is coming out of the screen:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/spatial_world_encoding.png" alt="Spatial World Encoding" style="width:600px">
</p>

<div id="Camera-The Model-View Matrix-Spatial Encoding of the World-Rotation Matrix"><h4 id="Rotation Matrix" class="header"><a href="#Camera-The Model-View Matrix-Spatial Encoding of the World-Rotation Matrix">Rotation Matrix</a></h4></div>

<p>
The intersection of the first three rows with the first three columns defines the 3x3 Rotation matrix. This matrix contains information about rotations around the standard axis.
</p>

\begin{align}
\begin{bmatrix}
m_1 &amp; m_2 &amp; m_3 \\
m_5 &amp; m_6 &amp; m_7 \\
m_9 &amp; m_{10} &amp; m_{11} 
\end{bmatrix}
\end{align}

<div id="Camera-The Model-View Matrix-Spatial Encoding of the World-Translation Vector"><h4 id="Translation Vector" class="header"><a href="#Camera-The Model-View Matrix-Spatial Encoding of the World-Translation Vector">Translation Vector</a></h4></div>

<p>
The intersection of the first three rows with the last column defines a three-component Translation vector.
</p>

\begin{align}
\begin{bmatrix}
m_{13} &amp; m_{14} &amp; m_{15}
\end{bmatrix}
\end{align}

<div id="Camera-The Model-View Matrix-Spatial Encoding of the World-The Mysterious Fourth Row"><h4 id="The Mysterious Fourth Row" class="header"><a href="#Camera-The Model-View Matrix-Spatial Encoding of the World-The Mysterious Fourth Row">The Mysterious Fourth Row</a></h4></div>

<p>
The fourth row does not have any special meaning.
</p>

<ul>
<li>
The \(m_4\), \(m_8\), and \(m_{12}\) elements are always \(0\).

</li><li>
The \(m_{16}\) element (the Homogeneous coordinate) will always be \(1\).

</li></ul>
<div id="Camera-The Camera Matrix"><h2 id="The Camera Matrix" class="header"><a href="#Camera-The Camera Matrix">The Camera Matrix</a></h2></div>

<p>
Let's assume that our camera is located at the origin of the world and that it's oriented so that it's looking toward the negative z-axis direction. We already know what transformation represents such a configuration in WebGL (Identity matrix of rank four).
</p>

<div id="Camera-The Camera Matrix-Camera Translation"><h3 id="Camera Translation" class="header"><a href="#Camera-The Camera Matrix-Camera Translation">Camera Translation</a></h3></div>

<p>
Let's move the camera to \([0, 0, 4]\) in world coordinates. This means four units from the origin on the positive z-axis. If we applied:
</p>

<pre javascript="">mat4.translate(modelViewMatrix, modelViewMatrix, [0, 0, 4]);
</pre>

<p>
In such a case, the world would be translated 4 units on the positive z-axis, and since the camera position has not been changed, it would be located at \([0, 0, -4]\), which is exactly the opposite of what we want. Now, say that we applied the translation in the opposite direction:
</p>

<pre javascript="">mat4.translate(modelViewMatrix, modelViewMatrix, [0, 0, -4]);
</pre>

<p>
In such a case, the world would be moved 4 units on the negative z-axis and then the camera would be located at \([0, 0, 4]\) in the new world-coordinate system.
</p>

<p>
The Camera matrix transformation is the inverse of the Model-View matrix transformation.
</p>

<div id="Camera-The Camera Matrix-Interpreting Transformations Using the Model-View Matrix"><h3 id="Interpreting Transformations Using the Model-View Matrix" class="header"><a href="#Camera-The Camera Matrix-Interpreting Transformations Using the Model-View Matrix">Interpreting Transformations Using the Model-View Matrix</a></h3></div>

<p>
<img src="https://albamr09.github.io/public/assets/rotations_with_model_view_matrix.png" alt="Rotation on the Model-View Matrix" style="width:600px">
</p>

<p>
As we've just seen, understanding the rotation matrix (the \(3 \times 3\) upper-left corner of the Model-View matrix) is simple: the first \(3\) columns always tell us where the axis is.
</p>

<div id="Camera-Basic Camera Types"><h2 id="Basic Camera Types" class="header"><a href="#Camera-Basic Camera Types">Basic Camera Types</a></h2></div>

<p>
So far, we've learned how to generate rotations and translations in either world or camera coordinates. In both cases, however, we are always generating the rotations around the center of the world. This may be ideal when we're orbiting around a 3D object. We will refer to this type of camera as an <span id="Camera-Basic Camera Types-orbiting camera"></span><strong id="orbiting camera">orbiting camera</strong>.
</p>

<p>
If we are able to look left and right (rotations) and then move in the direction in which our
camera is pointing (translation), then this camera type can be designated as a <span id="Camera-Basic Camera Types-first-person camera"></span><strong id="first-person camera">first-person camera</strong> and it is generally known as a <span id="Camera-Basic Camera Types-tracking camera"></span><strong id="tracking camera">tracking camera</strong>.
</p>

<p>
When applying transformation the order of the operations affects the result. It is not the same to rotate around the origin and then translate away from it (orbiting camera), as compared to translating the origin and then rotating around it (tracking camera).
</p>

<p>
With an orbiting camera, the camera will always look toward the center of the world.
Therefore, we will always use the z-axis to move to and from the object we are examining.
However, with a tracking camera, since the rotation occurs at the camera location, we can
end up looking to any position in the world. Thus, we need to know the direction in which the camera is pointing in world coordinates (camera axis).
</p>

<div id="Camera-Basic Camera Types-The Camera Model"><h3 id="The Camera Model" class="header"><a href="#Camera-Basic Camera Types-The Camera Model">The Camera Model</a></h3></div>

<p>
Just like the Model-View matrix, the Camera matrix encodes information about the camera orientation. As we can see in the following diagram, the upper-left \(3 \times 3\) matrix corresponds to the camera axes:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/camera_model.png" alt="Camera Model" style="width:600px">
</p>

<ul>
<li>
The first column corresponds to the x-axis of the camera. We will call it <code>RightVector</code>.

</li><li>
The second column is the y-axis of the camera. This will be <code>UpVector</code>.

</li><li>
The third column determines the vector in which the camera can move back and forth. This is the z-axis of the camera and we will call it <code>CameraAxis</code>.

</li></ul>
<p>
Because the Camera matrix is the inverse of the Model-View matrix, the upper-left \(3 \times 3\) rotation matrix contained in the Camera matrix gives us the orientation of the camera axes in world space. This means that we can tell the orientation of our camera in world space just by looking at the columns of this \(3 \times 3\) rotation matrix.
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>