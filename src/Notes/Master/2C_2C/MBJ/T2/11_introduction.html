<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../src/style/custom.css">
    <title>Introduction</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="index.html">Back</a>
</p>

<div id="Introduction"><h1 id="Introduction" class="header"><a href="#Introduction">Introduction</a></h1></div>

<hr>

<p>
As a new example, consider a study in which students' scores of a standardized test such as the SAT are collected from five different senior high schools in a given year. It is inappropriate to use \(Y_{ij}\) as the random variable for the SAT score of student \(i = 1, 2, \cdots, n_j\) in school \(j = 1, \cdots, 5\).
</p>

<p>
Within school \(j\), one assumes that SAT scores are i.i.d. from a Normal data model with a mean and standard deviation depending on the school:
</p>

\begin{align}
Y_{ij} \sim \text{Normal}(\mu_j, \sigma_j)
\end{align}

<div id="Introduction-Separate estimates?"><h2 id="Separate estimates?" class="header"><a href="#Introduction-Separate estimates?">Separate estimates?</a></h2></div>

<p>
One approach for handling this group estimation problem is find separate estimates for each school. One focuses on the observations in school \(j\), \(\{Y_{1j}, \cdots, Y_{n_jj}\}\), choose a prior distribution \(\pi(\mu_j, \sigma_j)\) for the mean and the standard deviation parameters.
</p>

<p>
This "separate estimates" approach may be reasonable, especially if the researcher thinks the means and the standard deviations from the five Normal models are completely unrelated to each other. That is, oneâ€™s prior beliefs about the parameters of the SAT score distribution in one school are unrelated to the prior beliefs about the distribution parameters in another school.
</p>

<div id="Introduction-Combined estimates?"><h2 id="Combined estimates?" class="header"><a href="#Introduction-Combined estimates?">Combined estimates?</a></h2></div>

<p>
Another way to handle this group estimation problem is to ignore the fact that there is a grouping variable and estimate the parameters in the combined sample. In our school example, one ignores the school variable and simply assumes that the SAT scores \(Y_i\)'s are distributed from a single Normal population with mean \(\mu\) and standard deviation \(\sigma\) where \(i = 1, \cdots, n\) is the total number of students from all five schools. Using this approach, one is effectively ignoring any differences between the five schools.
</p>

<div id="Introduction-A two-stage prior"><h2 id="A two-stage prior" class="header"><a href="#Introduction-A two-stage prior">A two-stage prior</a></h2></div>

<p>
Is there an alternative approach that compromises between the separate and combined estimate methods?
</p>

<p>
For simplicity of discussion it is assumed the standard deviation \(\sigma_j\) of the \(j\)th school is known. Consider the collection of five mean parameters, \(\{\mu_1, \mu_2, \mu_3, \mu_4, \mu_5\}\) representing the means of the five schools' SAT scores. One believes that the \(\mu_j\)'s are distinct, because each \(\mu_j\) depends on the characteristics of school \(j\). One wishes to construct a prior distribution for the five mean parameters that reflects the belief that \(\{\mu_1, \mu_2, \mu_3, \mu_4, \mu_5\}\) are related or similar in size.
</p>

<p>
The prior belief in similarity of the means is constructed in two stages:
</p>

<ol>
<li>
[Stage 1] The prior distribution for the \(j\)th mean \(\mu_j\) is Normal, where the mean and standard deviation parameters are shared among all \(\mu_j\):
\begin{align}
\mu_j | \mu, \tau \sim \text{Normal}(\mu, \tau), j = 1, \cdots, 5
\end{align}

</li><li>
[Stage 2] In Stage 1, the parameters \(\mu\) and \(\tau\) are unknown. So this stage assigns the parameters a prior density \(\pi\) (hyperprior):
\begin{align}
\mu, \tau \sim \pi(\mu, \tau)
\end{align}

</li></ol>
<p>
Stage 1 indicates that the \(\mu_j\)'s a priori are related and thus come from the same distribution.
</p>

<p>
If one considers the limit of the Stage 1 prior as the standard deviation \(\tau\) approaches zero, the group means \(\mu_j\) will be identical. Then one is in the combined groups' situation where one is pooling the SAT data to learn about a single population. 
</p>

<p>
At the other extreme, if one allows the standard deviation \(\tau\) of the Stage 1 prior to approach infinity, then one is saying that the group means are unrelated and that leads to the separate estimates situation.
</p>

<p>
Since \(\mu\) and \(\tau\) are parameters in the prior distribution, they are called hyperparameters. Learning about \(\mu\) and \(\tau\) provides information about the population of \(\mu_j\). In Bayesian inference, one learns about \(\mu_j\) and \(\tau\) by specifying a hyperprior distribution and performing inference based on the posterior distribution.
</p>

<p>
 It will be seen that the hierarchical model posterior estimates for one school borrows information from other schools. This process is often called partial pooling information among groups.
</p>
 
<p>
 From the structural point of view, due to the two stages of the model, this approach is called hierarchical or multilevel modeling. In essence, hierarchical modeling takes into account information from multiple levels, acknowledging differences and similarities among groups. In the posterior analysis, one learns simultaneously about each group and learns about the population of groups by pooling information across groups.
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>