<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style.css">
    <title>Bayesian analysis of conjugate hierarchical models</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="index.html">Back</a>
</p>

<div id="Bayesian analysis of conjugate hierarchical models"><h1 id="Bayesian analysis of conjugate hierarchical models" class="header"><a href="#Bayesian analysis of conjugate hierarchical models">Bayesian analysis of conjugate hierarchical models</a></h1></div>

<hr>

<div id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions"><h2 id="Analytic derivation of conditional and marginal distributions" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions">Analytic derivation of conditional and marginal distributions</a></h2></div>

<p>
Hierarchical models involve multiple levels of parameters and dependencies between them, making the analysis more intricate. The following steps are necessary to disentangle the relationships between parameters at different levels of the hierarchy and to estimate their distributions accurately.
</p>

<ul>
<li>
<span id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions-Joint Posterior Density"></span><strong id="Joint Posterior Density">Joint Posterior Density</strong>: Combines the prior information (hyperprior distribution \(p(\phi)\)), the population distribution (\(p(\theta|\phi)\)), and the likelihood function \(p(y|\theta)\) to form the joint posterior distribution.
\begin{align}
p(\theta, \phi|y) \propto p(y|\theta)p(\theta|\phi)p(\phi)
\end{align}

</li><li>
<span id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions-Conditional Posterior Density of the parameters"></span><strong id="Conditional Posterior Density of the parameters">Conditional Posterior Density of the parameters</strong>: Calculates the posterior distribution of \(\theta\) given the hyperparameters \(\phi\), allows us to understan how parameters interact and influence each other. This is usually done using <a href="https://es.wikipedia.org/wiki/Prior_conjugada">a priori conjugate distributions</a>.
\begin{align}
p(\theta|\phi, y) 
\end{align}

</li><li>
<span id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions-Hyperparameter Estimation"></span><strong id="Hyperparameter Estimation">Hyperparameter Estimation</strong>: estimating \(\phi\) through the Bayesian paradigm helps in updating our knowledge about the higher-level parameters based on the observed data. This step can be perfomed by integrating the joint posterior distribution over \(\theta\) in to be able to marginalize \(\phi\) conditionally on \(y\).
\begin{align}
p(\phi|y) = \int p(\theta, \phi|y)d\theta
\end{align}

</li></ul>
<p>
For many standard models the marginal posterior distribution of \(\phi\) can be computed algebraically using the conditional probability formula:
</p>

\begin{align}
p(\phi|y) = \frac{p(\theta, \phi|y)}{p(\theta|\phi, y)}
\end{align}

<div id="Bayesian analysis of conjugate hierarchical models-Drawing simulations from the posterior distribution"><h2 id="Drawing simulations from the posterior distribution" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Drawing simulations from the posterior distribution">Drawing simulations from the posterior distribution</a></h2></div>

<p>
The following strategy is useful for simulating a draw from the joint posterior distribution \(p(\theta, \phi|y)\)
</p>

<ol>
<li>
Draw the vector of hyperparameters, \(\phi\), from its marginal posterior distribution, \(p(\phi|y)\).

</li><li>
Draw the parameter vector \(\theta\) from its conditional posterior distribution, \(p(\theta|\phi, y)\).  For the examples we consider in this chapter, the factorization \(p(\theta|\phi, y) = \prod_j p(\theta_j|\phi, y)\) holds.

</li><li>
If desired, draw predictive values \(\tilde{y}\) from the posterior predictive distribution.

</li></ol>
<p>
The above steps are performed \(L\) times in order to obtain a set of \(L\) draws. From the joint posterior simulations of \(\theta\) and \(\tilde{y}\), we can compute the posterior distribution of any estimand or predictive quantity of interest.
</p>

<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors"><h2 id="Application to the model for rat tumors" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors">Application to the model for rat tumors</a></h2></div>

<p>
The data from experiments \(j = 1, \cdots, J\), \(J = 71\), are assumed to follow independent binomial distributions:
</p>

\begin{align}
y_j \sim Bin(n_j, \theta_j)
\end{align}

<p>
This models the probability of getting exactly \(\theta_j\) successes in \(n_j\) independent Bernoulli trials.
</p>

<p>
with the number of rats \(n_j\) unknown. The parameters \(\theta_j\) are assumed to be independent samples from a beta distribution:
</p>

\begin{align}
\theta_j \sim Beta(\alpha, \beta)
\end{align}

<p>
  and we shall assign a noninformative hyperprior distribution to reflect our ignorance about the unknown hyperparameters \(\alpha, \beta\). We defer the choice of noninformative hyperprior distribution, a relatively arbitrary and unimportant part of this particular analysis, until we inspect the integrability of the posterior density.
</p>

<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions"><h3 id="Joint, conditional, and marginal posterior distributions" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions">Joint, conditional, and marginal posterior distributions</a></h3></div>

<p>
The <span id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions-joint posterior distribution"></span><strong id="joint posterior distribution">joint posterior distribution</strong> of all the parameters is:
</p>

\begin{align}
p(\theta, \alpha, \beta|y) \propto p(\alpha, \beta)p(\theta|\alpha,\beta)p(y|\theta, \alpha, \beta)
\end{align}

<p>
where \(p(\alpha, \beta)\) is the hyperprior distribution (\(p(\phi)\)).
</p>

<p>
Then \(p(\theta|\alpha,\beta)\) is the population distribution (\(p(\theta|\phi)\)). The pdf of \(x \sim Beta(\alpha, \beta)\), ignoring the normalization constant, <a href="https://en.wikipedia.org/wiki/Beta_distribution">is given by</a>:
</p>

\begin{align}
p(\theta|\alpha, \beta) \propto \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha - 1} (1- x)^{\beta - 1}
\end{align}

<p>
For \(j = 1, \cdots, J\) i.i.d \(\theta_j \sim Beta(\alpha, \beta)\):
</p>

\begin{align}
p(\theta|\alpha, \beta) \propto \prod_{j=1}^J \theta_j^{\alpha - 1} (1- \theta_j)^{\beta - 1}
\end{align}

<p>
And \(p(y|\theta, \alpha, \beta)\)  is the likelihood (\(p(y|\theta)\)). The pdf of \(x \sim Bin(n, p)\) <a href="https://en.wikipedia.org/wiki/Binomial_distribution">is given by</a>:
</p>

\begin{align}
p(x = k|n, p) \propto p^k (1 - p)^{n - k}
\end{align}

<p>
For \(j = 1, \cdots, J\) i.i.d \(y_j \sim \Bin(n_j, \theta_j)\):
</p>

\begin{align}
p(y_j|n_j, \theta_j) \propto \theta_j^{y_j} (1 - \theta_j)^{n_j - y_j}
\end{align}

<p>
Therefore we obtain:
</p>

\begin{align}
\propto p(\alpha, \beta) \left(\prod_{j=1}^J \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) + \Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1}\right) \left(\prod_{j=1}^J \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}\right)
\end{align}

<p>
The <span id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions-conditional posterior density of"></span><strong id="conditional posterior density of">conditional posterior density of</strong> \(\theta\) given the hyperparameters is defined using a <a href="https://compcogsci-3016.djnavarro.net/technote_betabinomial.pdf">Beta-binomial conjugate prior (page 7)</a>, therefore if:
</p>

\begin{align}
y_i|n_j, \theta_j \sim Bin(n_j, \theta_j)
\end{align}

\begin{align}
\theta_j|\alpha,\beta \sim Beta(\alpha, \beta)
\end{align}

<p>
then
</p>

\begin{align}
\theta_j|\alpha, \beta, y_j, n_j \sim Beta(\alpha + y_j, \beta + n_j - y_j)
\end{align}

<p>
which gives us the following <a href="https://en.wikipedia.org/wiki/Beta_distribution">pdf for a Beta distribution</a> of i.i.d \(\theta\):
</p>

\begin{align}
p(\theta|\alpha, \beta, y) = \prod_{j=1}^J \frac{\Gamma(\alpha + y_j + \beta + n_j - y_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}
\end{align}

\begin{align}
= \prod_{j=1}^J \frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}
\end{align}

<p>
We can determine the <span id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions-marginal posterior distribution of the hyperparameters"></span><strong id="marginal posterior distribution of the hyperparameters">marginal posterior distribution of the hyperparameters</strong> \((\alpha, \beta)\) by substituting on the previous equations on the following formula:
</p>

\begin{align}
p(\phi|y) = \frac{p(\theta, \phi|y)}{p(\theta|\phi, y)}
\end{align}

<p>
where \(\phi = (\alpha, \beta)\), so:
</p>

\begin{align}
p(\alpha, \beta|y) = \frac{p(\theta, \alpha, \beta|y)}{p(\theta|\alpha, \beta, y)}
\end{align}

\begin{align}
= \frac{p(\alpha, \beta) \left(\prod_{j=1}^J \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) + \Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1}\right) \left(\prod_{j=1}^J \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}\right)}{\prod_{j=1}^J \frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}
\end{align}

\begin{align}
= p(\alpha, \beta) \frac{\prod_{j=1}^J \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) + \Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1} \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}}{\prod_{j=1}^J \frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}
\end{align}

\begin{align}
= p(\alpha, \beta) \prod_{j=1}^J \frac{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) + \Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1} \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}}{\frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}
\end{align}

\begin{align}
= p(\alpha, \beta) \prod_{j=1}^J \left(\frac{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) + \Gamma(\beta)}}{\frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}}\frac{\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1} \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}}{\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}\right)
\end{align}
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>