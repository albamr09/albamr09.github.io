<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style.css">
    <title>Marco general para la combinacion de clasificadores</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Marco general para la combinacion de clasificadores"><h1 id="Marco general para la combinacion de clasificadores" class="header"><a href="#Marco general para la combinacion de clasificadores">Marco general para la combinacion de clasificadores</a></h1></div>

<hr>

<p>
The task is seen as a problem of finding a combination function which accepts \(N\)-dimensional score vectors from each of the \(M\) classifiers, then producing a single final classification score representing the selected class.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/classifier_combination.png" alt="Classifier Combination" style="width:450px;height:400px">
</p>

<p>
Given the \(N\) possible classes \(\{\omega_1, \omega_2, \cdots, \omega_N\}\) and a pattern \(Z\) (that is a data sample), let \(x_k\) be the measurement vector (the numerical attributes of \(Z\)) used by the \(k\)th classifier (different classifiers may use different attributes to discriminate). The probability density function of the measurement vector is represented by:
</p>

\begin{align}
p(x_k|\omega_n)
\end{align}

<p>
while the prior probability of the occurrence of the class is denoted by \(p(\omega_n)\). The Bayesian framework aims to determine the class label for the pattern \(Z\) by considering the information provided by all \(M\) classifiers. The final decision is based on the aposteriori probability, which is the probability of the pattern belonging to a specific class \(j\) given the measurement vectors from all classifiers \(x_1, x_2, \cdots, x_M\).
</p>

<p>
So the pattern \(Z\) is assigned to class \(\omega_j\) which produces the maximum a posterior probability, that is:
</p>

\begin{align}
\theta = w_j
\end{align}

<p>
si 
</p>

\begin{align}
p(\theta = \omega_j|x_1, x_2, \cdots, x_M) = max_{k} p(\theta = \omega_k | x_1, x_2, \cdots, x_M)
\end{align}

<p>
where the aposteriori distribution is computed as follows:
</p>

\begin{align}
p(\theta = \omega_k | x_1, x_2, \cdots, x_M) = \frac{p(x_1, x_2, \cdots, x_M|\theta = \omega_k)p(\theta=\omega_k)}{p(x_1, x_2, \cdots, x_M)}
\end{align}

<p>
Thus, it is necessary to compute the aposteriori probability of various hypotheses by considering all input observations to the classifiers concurrently. This requires the knowledge of the joint pdf, \(p(x_1, \cdots, x_M|\theta = \omega_k)\) for all of the \(M\) classifiers which is obviously impractical.
</p>

<p>
To simplify the above expression, it can be assumed that each classifier provides independently a decision support obtained from \(x_k\).
</p>

\begin{align}
p(\theta = \omega_j|x_1, x_2, \cdots, x_M) = \frac{p(x_1, x_2, \cdots, x_M|\theta = \omega_j)p(\theta=\omega_j)}{p(x_1, x_2, \cdots, x_M)}
\end{align}
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>