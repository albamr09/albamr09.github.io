<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style.css">
    <title>Boltzmann Based Networks</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="index.html">Back</a>
</p>

<div id="Boltzmann Based Networks"><h1 id="Boltzmann Based Networks" class="header"><a href="#Boltzmann Based Networks">Boltzmann Based Networks</a></h1></div>

<hr>

<div id="Boltzmann Based Networks-Boltzmann Machines"><h2 id="Boltzmann Machines" class="header"><a href="#Boltzmann Based Networks-Boltzmann Machines">Boltzmann Machines</a></h2></div>

<p>
They are fully connected artificial neural networks, but they are based on <span id="Boltzmann Based Networks-Boltzmann Machines-stochastic neurons"></span><strong id="stochastic neurons">stochastic neurons</strong>. The working of Boltzmann Machine is mainly inspired by the <span id="Boltzmann Based Networks-Boltzmann Machines-Boltzmann Distribution"></span><strong id="Boltzmann Distribution">Boltzmann Distribution</strong> which says that the current state of the system depends on the energy of the system and the temperature at which it is currently operating. These neurons output \(1\) with some probability, given by the following equation:
</p>

\begin{align}
p(s_i^{\text{next step}} = 1) \sigma\left(\frac{\sum_{j=1}^N w_{i,j}s_j + b_i}{T}\right)
\end{align}

<p>
Where:
</p>

<ul>
<li>
\(s_j\) is the \(j\)th neuron's state (\(0\) or \(1\)).

</li><li>
\(w_{i,j}\) is the connection weight between the \(i\)th and \(j\)th neurons. Note that \(w_{i,i}\) = 0.

</li><li>
\(b_i\)  is the ith neuron’s bias term.

</li><li>
\(N\) is the number of neurons in the network.

</li><li>
\(T\) is a number called the network’s temperature; the higher the temperature, the more random the output.

</li><li>
\(\sigma\) is the logistic function. 

</li></ul>
<p>
Hence to implement these as Neural Networks, we use the <span id="Boltzmann Based Networks-Boltzmann Machines-Energy Models"></span><strong id="Energy Models">Energy Models</strong>. The energy term was equivalent to the deviation from the actual answer. The higher the energy, the more the deviation. It has been thus important to train the model until it reaches a low-energy point.
</p>

<p>
The nodes in Boltzmann Machines are simply categorized as visible and hidden nodes. The visible nodes take in the input. The same nodes which take in the input will return back the reconstructed input as the output.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/boltzmann_machine.png" alt="Boltzmann Machine" style="width:550px;height:300px">
</p>

<p>
The energy function of the Boltzmann machine is defined as follows:
</p>

\begin{aligned}
E(v, h) = - \sum_{i} v_ib_i - \sum_k h_kb_k - \sum_{i, j}v_iv_jw_{i,j} \sum_{i,k}v_ih_kw_{i, k} - \sum_{k,l}h_kh_kw_{k,l}
\end{aligned}

<p>
Where \(v\) are the visible units, \(h\) as the hidden units \(b\) is the bias and \(w_{i, j}\) are the weights between units \(i\) and \(j\).
</p>

<p>
The probability of a joint configuration over both the visible unit and the hidden unit is as follows:
</p>

\begin{aligned}
p(v,h) = \frac{e^{-E(v,h)}}{\sum_{m, n} e^{-E(m, n)}}
\end{aligned}

<p>
And, for example, the probability distribution of visible units is obtained by marginalizing out hidden units:
</p>

\begin{aligned}
p(v) = \frac{\sum_h e^{-E(v,h)}}{\sum_{m, n} e^{-E(m, n)}}
\end{aligned}

<p>
This can now be utilized to sample visible units.
</p>

<p>
Training a Boltzmann machine means finding the parameters that will make the network approximate the training set’s probability distribution. So we have to obtain the parameters tha maximize the likelihood of the observed data. The traning algorithm runs as described:
</p>

<ul>
<li>
Obtain the log likelihood function of visible units, by marginalizing the hidden units:
\begin{align}
l(v|w) = \log p(v|w) = \log \sum_h e^{-E_{v, h}} - \log \sum_{m, n} e^{-E_{m, n}}
\end{align}

</li><li>
Take the derivative of the log likelihood function as a function of \(w\):
\begin{align}
\frac{\delta l(v|w)}{\delta w} = \frac{\delta \log \sum_h e^{-E_{v, h}}}{\delta \sum_h e^{-E_{v, h}}} \cdot \frac{\delta \sum_h e^{-E_{v, h}}}{\delta w} - \frac{\delta \log \sum_h e^{-E_{v, h}}}{\delta \sum_{m,n} e^{-E_{m, n}}} \cdot \frac{\delta \sum_̣{m,n} e^{-E_{m, n}}}{\delta w}
\end{align}
\begin{align}
= \frac{1}{\sum_h e^{-E_{v, h}}} \cdot \sum_h \frac{\delta e^{-E_{v,h}}}{\delta w} - \frac{1}{\sum_{m,n} e^{-E_{m, n}}} \cdot \sum_{m,n} \frac{\delta e^{-E_{m,m}}}{\delta w}
\end{align}
\begin{align}
= \frac{1}{\sum_h e^{-E_{v, h}}} \cdot \sum_h -e^{-E_{v,h}} \frac{\delta E_{v,h}}{\delta w} - \frac{1}{\sum_{m,n} e^{-E_{m, n}}} \cdot \sum_{m,n} -e^{E_{m,m}} \frac{\delta E_{m,m}}{\delta w}
\end{align}
\begin{align}
= -\sum_h \frac{e^{-E_{v,h}}}{\sum_h e^{-E_{v, h}}} \frac{\delta E_{v,h}}{\delta w} + \sum_{m,n} \frac{e^{E_{m,m}}}{\sum_{m,n} e^{-E_{m, n}}} \frac{\delta E_{m,m}}{\delta w}
\end{align}

</li></ul>
<p>
We know that:
</p>

\begin{align}
p(h|v) = \frac{p(v, h)}{p(v)} = \frac{\frac{e^{-E_{v, h}}}{\sum_{m,n} e^{-E_{m, n}}}}{\frac{\sum_h e^{-E_{v, h}}}{\sum_{m,n} e^{-E_{m, n}}}}
\end{align}

<p>
By removing both \(\sum_{m,n} e^{-E_{m, n}}\), we obtain:
</p>

\begin{align}
 = \frac{e^{-E_{v, h}}}{\sum_h e^{-E_{v, h}}}
\end{align}

<p>
Such that:
</p>

\begin{align}
= -\sum_h p(h|v) \frac{\delta E_{v,h}}{\delta w} + \sum_{m,n} p(m,n) \frac{\delta E_{m,m}}{\delta w}
\end{align}

<p>
And by de definition of the expected value \(\mathbb{E}(x) = \sum_x x p(x)\):
</p>

\begin{align}
= - \mathbb{E}_{p(h|v)}[\frac{\delta E_{v,h}}{\delta w}] + \mathbb{E}_̣{p(m,n)}[\frac{\delta E_{m,m}}{\delta w}] 
\end{align}

<p>
Computing these expectations is in general an <span id="Boltzmann Based Networks-Boltzmann Machines-intractable problem"></span><strong id="intractable problem">intractable problem</strong>. he general approach for solving this problem is to use <a href="https://towardsdatascience.com/monte-carlo-methods-and-simulations-explained-in-real-life-modeling-insomnia-f49685b321d0">Markov chain Monte Carlo</a> (MCMC) to approximate these quantities:
</p>

\begin{align}
\frac{\delta l(v|w)}{\delta w} = - &lt;s_i, s_j&gt;_{p(h_{data}|v_{data})} + &lt;s_i, s_j&gt;_{p(h_{model}|v_{model})}
\end{align}

<p>
Here \(&lt;\cdot, \cdot&gt;\) denotes the expectation.
</p>

<div id="Boltzmann Based Networks-Restricted Boltzmann Machines"><h2 id="Restricted Boltzmann Machines" class="header"><a href="#Boltzmann Based Networks-Restricted Boltzmann Machines">Restricted Boltzmann Machines</a></h2></div>

<p>
An RBM is a Boltzmann machine that only has connections between visible and hidden units.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/rbm_structure.png" alt="Restricted Boltzmann Machine" style="width:650px;height:350px">
</p>

<p>
The energy function of the RBM is defined as follows:
</p>

\begin{align}
E(v, h) = - \sum_i v_ib_i - \sum_k h_kb_k - \sum_{i,k} v_i h_k w_{i,k}
\end{align}

<div id="Boltzmann Based Networks-Restricted Boltzmann Machines-Contrastive Divergence"><h3 id="Contrastive Divergence" class="header"><a href="#Boltzmann Based Networks-Restricted Boltzmann Machines-Contrastive Divergence">Contrastive Divergence</a></h3></div>

<p>
This is a very efficient training algorithm for Boltzmann machines. Here is how it works:
</p>

<ol>
<li>
For each training instance \(x\), the algorithm starts by feeding it to the network by setting

</li></ol>
<p>
the state of the visible units to \(x_1, \cdots, x_n\).
</p>
<ol>
<li>
Compute the state of the hidden units by applying. 

</li></ol>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>