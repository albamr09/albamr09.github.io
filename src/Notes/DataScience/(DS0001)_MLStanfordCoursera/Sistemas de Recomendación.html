<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style.css">
    <title>Sistemas de Recomendación</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="index.html">Back</a>
</p>

<div id="Sistemas de Recomendación"><h1 id="Sistemas de Recomendación" class="header"><a href="#Sistemas de Recomendación">Sistemas de Recomendación</a></h1></div>

<hr>

<p>
Dados los parámetros:
</p>

<ul>
<li>
\(n_\mu\): número de usuarios

</li><li>
\(n_m\): número de ítems valorables

</li><li>
\(r(i,j)\): marcador de si el ítem ha sido valorado, tal que:
\begin{align}
r(i, j) = \begin{cases} 
1, &amp; \text{ si el usuario j ha valorado el ítem i} \\
0, &amp; \text{ en cualquier otro caso}
\end{cases}
\end{align}

</li><li>
\(y^{(i, j)}\): valoración del usuario \(j\) al ítem \(i\).

</li></ul>
<p>
El objetivo de un sistema de recomendación es predecir los valores de las valoraciones donde \(r(i, j) \neq 1\) (es decir predecir las valoraciones de usuarios hacia ítems que no han valorado con anteioridad)
</p>


<div id="Sistemas de Recomendación-Content Based Recommendations"><h2 id="Content Based Recommendations" class="header"><a href="#Sistemas de Recomendación-Content Based Recommendations">Content Based Recommendations</a></h2></div>

<ol>
<li>
Cada ítem está definido por \(n\) características.

</li><li>
Para cada usuario \(j\), debemos obtener \(\theta^{(j)} \in \mathbb{R}^{n+1}\), de tal manera que para predecir la valoración de \(x^{(i)} \rightarrow h_\theta(x^{(i)}) = (\theta^{(j)})^T x^{(i)}\)

</li></ol>
<div id="Sistemas de Recomendación-Content Based Recommendations-Función de coste"><h3 id="Función de coste" class="header"><a href="#Sistemas de Recomendación-Content Based Recommendations-Función de coste">Función de coste</a></h3></div>

<p>
Sea \(m^{(j)}\) el número de ítems valorados por el usuario \(j\), entonces la función de coste se define como:
</p>

\begin{align}
J(\Theta) = \frac{1}{2m^{(j)}}\sum_{j=1}^{n_\mu} \sum_{i; r(i, j) = 1} ((\theta^{(j)})^T x^{(i)} - y^{(i, j)})^2 + \frac{\lambda}{2m^{(j)}} \sum_{k=1}^{n_\mu} \theta^{(j)}_k
\end{align}

<p>
donde \(\Theta = \{\theta_1, \cdots, \theta_{n_\mu}\}\)
</p>

<p>
Es decir queremos minimizar la "distancia" entre lo predicho \((\theta^{(j)})^T x^{(i)}\) para el ítem (que ha sido valorado, por lo tanto \(r(i, j) = 1\)) y el usuario \(i\) y la valoración real \(y^{(i, j)}\).
</p>

<div id="Sistemas de Recomendación-Content Based Recommendations-Descenso Gradiente"><h3 id="Descenso Gradiente" class="header"><a href="#Sistemas de Recomendación-Content Based Recommendations-Descenso Gradiente">Descenso Gradiente</a></h3></div>

<p>
Lo que queremos es minimizar el coste, por lo tanto, calculamos \(\frac{\delta J(\Theta)}{\delta \theta_j}\) para obtener el vector en dirección al mayor incremento en la función, seguidamente, utilizar su opuesto, obtenemos el vector que apunta a la dirección de menor incremento. Es decir, aplicamos descenso gradiente como sigue:
</p>

<p>
Para \(k = 0\):
</p>

\begin{align}
\theta_k^{(j)} = \theta_k^{(j)} - \alpha \left(\sum_{i; r(i,j)=1} (\theta^{(j)})^Tx^{(i)} - y^{(i,j)}x^{(i)}_k \right)
\end{align}

<p>
Para \(k \neq 0\):
</p>

\begin{align}
\theta_k^{(j)} = \theta_k^{(j)} - \alpha \left(\sum_{i; r(i,j)=1} (\theta^{(j)})^Tx^{(i)} - y^{(i,j)}x^{(i)}_k + \lambda \theta_k^{(j)} \right)
\end{align}

<div id="Sistemas de Recomendación-Collaborative Filtering"><h2 id="Collaborative Filtering" class="header"><a href="#Sistemas de Recomendación-Collaborative Filtering">Collaborative Filtering</a></h2></div>

<p>
Collaborative filtering consiste en calcular las características de cada usuario (ejemplo \(x^{(i)}\)) en función de los pesos \(\theta^{(j)}\). Una vez hecho esto se calculan los pesos óptimos que que minimizan la función de coste y volvemos a obtener las características de cada usuario en función de estes nuevos pesos.
</p>

<p>
Este proceso se describe más formalmente a continuación:
</p>

<div id="Sistemas de Recomendación-Collaborative Filtering-Problema de Optimización"><h3 id="Problema de Optimización" class="header"><a href="#Sistemas de Recomendación-Collaborative Filtering-Problema de Optimización">Problema de Optimización</a></h3></div>

<p>
El problema de optimización se describe como sigue:
</p>

<p>
Dados \(\theta^{(1)}, \cdots, \theta^{n_\mu}\):
</p>

<p>
Para un ejemplo \(x^{(i)}\)
</p>
\begin{align}
\underset{x^{(i)}}{\min{}} \frac{1}{2} \sum_{j:r(i,j)=1} ((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{k=1}^n (x_k^{(i)})^2
\end{align}

<p>
Para todos los ejemplos del conjunto \(x^{0}, \cdots, x^{(n_m)}\):
</p>
\begin{align}
\underset{x^{(1)}, \cdots, x^{(n_m)}}{\min{}} \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1} ((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m}\sum_{k=1}^n (x_k^{(i)})^2
\end{align}

<p>
Es decir queremos minimizar la "distancia" entre lo predicho \((\theta^{(j)})^T x^{(i)}\) para el ítem (que ha sido valorado, por lo tanto \(r(i, j) = 1\)) y el usuario \(i\) y la valoración real \(y^{(i, j)}\). Además como queremos obtener los valores de \(x\) que minimizan el coste, los añadimos como coste a problema de optimización para evitar overfitting.
</p>

<div id="Sistemas de Recomendación-Collaborative Filtering-Algoritmo"><h3 id="Algoritmo" class="header"><a href="#Sistemas de Recomendación-Collaborative Filtering-Algoritmo">Algoritmo</a></h3></div>

<p>
El algoritmo consta de los siguientes pasos:
</p>

<ol>
<li>
Inicializar \(x^{(1)}, \cdots, x^{(m)}\) y \(\theta^{(1)}, \cdots, \theta^{(n_\mu)}\) de forma aleatoria.

</li><li>
Calcular \(X\) a partir de \(\Theta\)

</li><li>
Calcular \(\Theta\) a partir de \(X\)

</li><li>
Volvemos al paso 2.

</li></ol>
<p>
Es decir, queremos obtener \(X\) y \(\Theta\) que optimice el siguiente problema:
</p>

\begin{align}
\underset{x^{(1)}, \cdots, x^{(n_m)}, \theta^{(1)}, \cdots, \theta^{(n_\mu)}}{\min{}} \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1} ((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m}\sum_{k=1}^n (x_k^{(i)})^2 + \frac{\lambda}{2} \sum_{i=1}^{n_\mu}\sum_{k=1}^n (\theta_k^{(i)})^2
\end{align}

<p>
Observa que, como estamos optimizando tanto \(\theta\) como \(x\), entonces los añadimos como coste a la función de optimización para evitar overfitting:
</p>

<ul>
<li>
\(\frac{\lambda}{2} \sum_{i=1}^{n_m}\sum_{k=1}^n (x_k^{(i)})^2\)

</li><li>
\(\frac{\lambda}{2} \sum_{i=1}^{n_\mu}\sum_{k=1}^n (\theta_k^{(i)})^2\)

</li></ul>
<p>
Para aplicar la optimización utilizamos descenso gradiente: primero en función de \(x\) y después en función de \(\theta\):
</p>

\begin{align}
x^{(i)}_k = x^{(i)}_k - \alpha \left( \sum_{j:r(i, j)=1} ((\theta^{(j)})^T x^{(i)} - y^{(i, j)}) \theta_k^{(j)} + \lambda x^{(i)}_k\right)
\end{align}

\begin{align}
\theta^{(j)}_k = \theta^{(j)}_k - \alpha \left( \sum_{i:r(i, j)=1} ((\theta^{(j)})^T x^{(i)} - y^{(i, j)}) x_k^{(i)} + \lambda \theta^{(j)}_k\right)
\end{align}

<div id="Sistemas de Recomendación-Collaborative Filtering-Buscar ítems Relacionados"><h3 id="Buscar ítems Relacionados" class="header"><a href="#Sistemas de Recomendación-Collaborative Filtering-Buscar ítems Relacionados">Buscar ítems Relacionados</a></h3></div>

<p>
Si \(||x^{(i)} - x^{(j)}\)|| es un valor pequeño entonces los ítems \(i\) y \(j\) son similares.
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>