<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../src/style/custom.css">
    <title>Particle Filter</title>
  <link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"><script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Particle Filter"><h1 id="Particle Filter" class="header"><a href="#Particle Filter">Particle Filter</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="Particle Filter.html#Intro">Intro</a>

</li><li>
<a href="Particle Filter.html#Particle%20Set">Particle Set</a>

</li><li>
<a href="Particle Filter.html#Particle%20Generation">Particle Generation</a>

<ul>
<li>
<a href="Particle Filter.html#Gaussian%20Sampling">Gaussian Sampling</a>

</li><li>
<a href="Particle Filter.html#Importance%20Sampling%20Principle">Importance Sampling Principle</a>

</li></ul>
</li><li>
<a href="Particle Filter.html#Characteristics">Characteristics</a>

</li><li>
<a href="Particle Filter.html#Algorithm">Algorithm</a>

</li><li>
<a href="Particle Filter.html#Summary">Summary</a>

</li><li>
<a href="Particle Filter.html#Monte%20Carlo%20Localization">Monte Carlo Localization</a>

<ul>
<li>
<a href="Particle Filter.html#Structure">Structure</a>

</li><li>
<a href="Particle Filter.html#Particle%20Filter%20Algorithm%20for%20Localization">Particle Filter Algorithm for Localization</a>

</li><li>
<a href="Particle Filter.html#Example">Example</a>

</li></ul>
</li><li>
<a href="Particle Filter.html#Resampling%20Techniques">Resampling Techniques</a>

<ul>
<li>
<a href="Particle Filter.html#Roulette%20wheel">Roulette wheel</a>

</li><li>
<a href="Particle Filter.html#Low%20Variance%20Resampling">Low Variance Resampling</a>

<ul>
<li>
<a href="Particle Filter.html#Algorithm">Algorithm</a>

</li></ul>
</li></ul>
</li></ul>
<hr>

<div id="Particle Filter-Intro"><h2 id="Intro" class="header"><a href="#Particle Filter-Intro">Intro</a></h2></div>

<p>
With particle filters we are not restricting ourselves with parametric probability distributions like we do for example with Kalman Filters where we use Gaussian distributions.
</p>

<p>
As usual, we suppose we are given a map, and instead of using one parametric from we use non-parametric samples as a hypothesis of where the system might be.
</p>

<p>
So, we are going to leave behind Gaussian distributions to describe the estimate:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/gaussian_filters.png" alt="Gaussian Filters" style="transform:translate(50%,0)">
</p>

<p>
And we are going to model our estimate using an arbitrary distribution:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/flexible_distribution.png" alt="Flexible Distribution" style="transform:translate(50%,0)">
</p>

<p>
It turns out that we can describe this kind of distribution using samples:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/flexible_distribution_with_samples.png" alt="Describe Distribution with Samples" style="transform:translate(50%, 0)">
</p>

<p>
As you can see, the amount of samples in the areas where the density of the probability distribution is higher is also higher and vice versa.
</p>

<p>
Basically we have samples distributed over a state space, so imagine each sample signifies a little bit of probability mass, so we only need to count how many samples fall into a certain region to asses the probability that the system is in that region.
</p>

<p>
Also, we can weight our samples, so the larger the weight the larger the probability mass associated with that sample (taking into account that the sum of the weight have to amount to one). The weighting of the samples allows us to use less samples to represent the same probability distribution:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/weighted_samples.png" alt="Weigting the samples" style="transform:translate(50%,0)">
</p>

<p>
Note that by using samples we are computing an approximation of the probability function. And we use this weighted samples to estimate our belief. Some examples are:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/particle_approximation.png" alt="Examples of particle approximation" style="transform:translate(50%, 0)">
</p>

<p>
We use the particles to approximate the probability function, where the more particles fall into a region, the higher the probability of the region.
</p>

<div id="Particle Filter-Particle Set"><h2 id="Particle Set" class="header"><a href="#Particle Filter-Particle Set">Particle Set</a></h2></div>

<p>
We represent the sample set or particle set as follows:
</p>

\[
\mathcal{X} = \{\langle x^{[j]}, w^{[j]}\rangle\}_{j=1\cdots J}
\]

<p>
Where:
</p>

<ul>
<li>
There are \(J\) samples

</li><li>
\(x^{[j]}\) represents the hypothesis (i.e. the state of the system)

</li><li>
\(w^{[j]}\) represents the normalized weight assigned to jth particle

</li></ul>
<p>
The sum or integration over the particles represent the posterior (i.e. the probability function):
</p>

\[
p(x) = \sum_{j=1}^J w^{[j]} \delta_{x^{[j]}} (x)
\]

<p>
Where \(\delta\) is the Dirac function. Note that \(\int \delta(x) dx = 1\)
</p>

<div id="Particle Filter-Particle Generation"><h2 id="Particle Generation" class="header"><a href="#Particle Filter-Particle Generation">Particle Generation</a></h2></div>

<div id="Particle Filter-Particle Generation-Gaussian Sampling"><h3 id="Gaussian Sampling" class="header"><a href="#Particle Filter-Particle Generation-Gaussian Sampling">Gaussian Sampling</a></h3></div>

<p>
Note that closed form sampling is only possible for a few distributions, for example:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/sample_gaussian.png" alt="Gaussian Closed Form Samping" style="transform:translate(50%,0)">
</p>

<p>
For a Gaussian distribution to obtain an approximation from sampling, we would sample by summing \(12\) times a random (uniformly drawn) number \(x \in [-\sigma, \sigma]\), where \(\sigma\) represents the standard deviation, and divide the sum by \(\frac{1}{2}\). Then you would draw samples that are approximately close to a Gaussian distribution.
</p>

<div id="Particle Filter-Particle Generation-Importance Sampling Principle"><h3 id="Importance Sampling Principle" class="header"><a href="#Particle Filter-Particle Generation-Importance Sampling Principle">Importance Sampling Principle</a></h3></div>

<p>
But, how can we approximate for another probability distribution functions? It turns out we can do this by sampling from a different probability function that the actual probability function and then compensating for the mistakes that we have done by drawing from this "mistaken" probability function. To do this we apply the Importance Sampling Principle which tells us:
</p>

<ul>
<li>
We can use a different distribution (proposal distribution) \(\pi\) to generate samples from the target (real) distribution \(f\).

</li><li>
We need to account for the differences between \(\pi\) and \(f\) using a weight, given by \(\omega = \frac{f(x)}{\pi{x}}\)

</li><li>
We need to assert the following pre-condition: \(f(x) &gt; 0 \rightarrow \pi(x) &gt; 0\)

</li></ul>
<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/importance_sampling_principle.png" alt="Importance Sampling Principle" style="transform:translate(50%,0)">
</p>

<p>
You can see that the weights are larger where the difference between the proposal and the target function is bigger. Observe on the right side of the graph that we have drawn a low number of samples because our proposal probability function tells us the us the density on that region is low. However the target function shows a high probability in that same region, so by computing the difference between the proposal and the target function we assign bigger weights to those few particles. 
</p>

<div id="Particle Filter-Characteristics"><h2 id="Characteristics" class="header"><a href="#Particle Filter-Characteristics">Characteristics</a></h2></div>

<ul>
<li>
It is a recursive Bayes Filter

</li><li>
Uses a non-parametric approach

</li><li>
Models the distribution using samples and so the model need not be linear.

</li><li>
The prediction step consists of drawing samples from the proposal function (takes the motion into account)

</li><li>
The correction step consists of weighting the samples by the ration between the target function and the proposal function (takes the observation into account)

</li><li>
The more particles we use to approximate the probability function the better the estimate is.

</li></ul>
<div id="Particle Filter-Algorithm"><h2 id="Algorithm" class="header"><a href="#Particle Filter-Algorithm">Algorithm</a></h2></div>

<p>
The algorithm is composed of the following three steps:
</p>

<ul>
<li>
(Prediction Step) Sample the particles using the proposal distribution (this signifies: where could my system be?). Because we can choose the proposal function, what we do in this step is sampling from the motion model:
\[
x_t^{[j]} \sim proposal(x_t|\cdots)
\]

</li><li>
(Correction Step) Compute the importance weights to compensate from the mistakes made by sampling from the proposal distribution. If we derive the following expression, we obtain that the weights are given by the observation model:
\[
w_t^{[j]} = \frac{target(x_t^{j})}{proposal(x_t^{j})}
\]

</li><li>
Resampling: draw with replacement \(J\) samples \(i\) with probability \(w_t^{[i]}\). 

</li></ul>
<p>
So now we have a resampled set of samples where we update the weights by dividing the by \(1/J\) so they are normalized. What we do is generate a new set of samples where we replace the weight by the frequency. 
</p>

<p>
We do this because we work with a finite number of samples, so it could be the case that some particles have a very low probability and thus contribute very little to approximating the probability function. So it is better to eliminate those samples and replace them with a sample that is located in an area with high probability.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/particle_filter_algorithm.png" alt="Particle Filter Algorithm" style="transform:translate(50%,0)">
</p>

<ul>
<li>
We start with a empty sample set for the prediction step \(\hat{\mathcal{X}}_t\) and for the correction step \(\mathcal{X}_t\).

</li><li>
(Prediction step) For \(j=1\cdots J\): 

<ul>
<li>
Sample particle \(x^{[j]}_t\) from the proposal distribution \(\pi(x_t)\), this distribution can be defined by the user, and corresponds to the belief at time \(t-1\) and constrained to the control command at time \(t\), \(u_t\).

</li><li>
Compute the weight by obtaining the difference between the proposal distribution and the target distribution. This results in using the observation model

</li><li>
Save the pair \(x_t^{[j]}\), \(w_t^{[j]}\) to the prediction sample set \(\hat{\mathcal{X}}_t\).

</li></ul>
</li><li>
(Correction step) For \(j=1\cdots J\): 

<ul>
<li>
Draw a particle \(X_t^{[j]}\) with replacement from the prediction sample set with probability proportional to the weight of the sample \(w_t^{[j]}\).

</li><li>
Add the particle to the correction sample set \(\mathcal{X}_t\)

</li></ul>
</li><li>
Return the resampled sample set \(\mathcal{X}_t\)

</li></ul>
<div id="Particle Filter-Summary"><h2 id="Summary" class="header"><a href="#Particle Filter-Summary">Summary</a></h2></div>

<p>
What the particle filter does is:
</p>

<ul>
<li>
It takes each particle as a pose hypothesis that says "This is where the system is at time \(t\)".

</li><li>
Then it adds weight to each particle signifying how much that pose hypothesis conforms to the given observation, and tells us how likely the hypothesis is.

</li><li>
If we do this with \(N\) particles what we obtain is a belief, that is, a set of possibilities of where we are which describe my probability distribution.

</li></ul>
<div id="Particle Filter-Monte Carlo Localization"><h2 id="Monte Carlo Localization" class="header"><a href="#Particle Filter-Monte Carlo Localization">Monte Carlo Localization</a></h2></div>

<p>
Monte Carlo Localization refers to the estimation the location and orientation of the system using a particle filter.
</p>

<p>
For example:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/localization_with_particle_filter.png" alt="Example of Monte Carlo Localization" style="transform:translate(50%,0)">
</p>

<p>
With a particle filter, our belief shows where the robot is located by having a bigger density of particles right under where the robot is.
</p>

<p>
Another example is the following, where we start with all the particles scattered over the map that means the particles are sampled from a uniform distribution so every point in space is equally likely to be the location of the robot. 
</p>

<p>
Once the robot drives around and obtains new measurements the probability mass concentrates on places where the robot is more likely to be in given the motion commands and the observations. 
</p>

<p>
Eventually the system converges and you end up with a unimodal distribution that is similar to a Gaussian distribution.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/example_monte_carlo_map.png" alt="Another Monte Carlo Localization Example" style="transform:translate(50%,0)">
</p>

<div id="Particle Filter-Monte Carlo Localization-Structure"><h3 id="Structure" class="header"><a href="#Particle Filter-Monte Carlo Localization-Structure">Structure</a></h3></div>

<ul>
<li>
Each particle represents a pose hypothesis

</li><li>
We represent the proposal probability function by drawing from the motion model. Because we are sampling from the motion distribution what we do is increasing the uncertainty about the motion at time \(t\) and thus account for the noise present in each motion.
\[
x_t^{[j]} \sim p(x_t|x_{t-1}, u_t)
\]

</li><li>
We apply the correction via the observation model. So the weight of each particle is proportional to the likelihood of an observation \(z_t\) given i know where I am \(x_t\) and the map of the environment \(m\). This result is dependent of the choice made previously of sampling from the motion model.
\[
w_t^{[j]} = \frac{target}{proposal} \propto p(z_t|x_t,m)
\]

</li></ul>
<div id="Particle Filter-Monte Carlo Localization-Particle Filter Algorithm for Localization"><h3 id="Particle Filter Algorithm for Localization" class="header"><a href="#Particle Filter-Monte Carlo Localization-Particle Filter Algorithm for Localization">Particle Filter Algorithm for Localization</a></h3></div>

<p>
We modify slightly our particle filter algorithm to use it for localization:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/particle_filter_algorithm_localization.png" alt="Particle Filter Algorithm for Localization" style="transform:translate(50%,0)">
</p>

<ul>
<li>
We sample from the motion model \(p(x_t|u_t, x^{[j]}_{t-1})\) instead from the generic proposal function \(\pi(x_t)\)

</li><li>
We compute the weights with \(w_t^{[j]} = \frac{target}{proposal} \propto p(z_t|x_t,m)\).

</li></ul>
<div id="Particle Filter-Monte Carlo Localization-Example"><h3 id="Example" class="header"><a href="#Particle Filter-Monte Carlo Localization-Example">Example</a></h3></div>

<p>
First we start with a uniform distribution, and we sample from that distribution, obtaining \(J\) particles distributed over the space with the same probability. 
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/monte_carlo_localization_prediction.png" alt="Prediction step" style="transform:translate(50%,0)">
</p>

<p>
Then we obtain an observation, and in the weighting step we increase the weight of the samples with are more likely given the observation. In this case the samples in front of doors, while the rest of the particles get a lower weight.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/monte_carlo_localization_correction.png" alt="Correction step" style="transform:translate(50%,0)">
</p>

<p>
Then we apply resampling to replace weight by frequencies (the probability mass of a particle is bigger if this particle has been resampled several times, which means it weight was bigger than the rest of the samples). In the following picture the resampling step is executed along with the motion step (so the probability function is offsetted):
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/monte_carlo_resampling.png" alt="Resampling step" style="transform:translate(50%,0)">
</p>

<p>
Because the prediction/motion was already performed before, now we obtain another observation:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/monte_carlo_second_correction.png" alt="Second Correction Step" style="transform:translate(50%,0)">
</p>

<p>
When we obtain the weights, two things happen. First, and as before, the particles (pose hypothesis) more likely to be correct given the observation obtain a larger weight. Second, because the is a bigger number of particles in front of the second door the density in this area is bigger than in the areas in front of the other doors. Another resampling and prediction step:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/monte_carlo_second_resampling.png" alt="Second Resampling Step" style="transform:translate(50%,0)">
</p>

<div id="Particle Filter-Resampling Techniques"><h2 id="Resampling Techniques" class="header"><a href="#Particle Filter-Resampling Techniques">Resampling Techniques</a></h2></div>

<div id="Particle Filter-Resampling Techniques-Roulette wheel"><h3 id="Roulette wheel" class="header"><a href="#Particle Filter-Resampling Techniques-Roulette wheel">Roulette wheel</a></h3></div>

<p>
First we create a roulette wheel where each field represents a particle, and the bigger the weight associated with that particle the bigger the field is:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/wheel_roulette.png" alt="Wheel Roulette" style="transform:translate(30vw,0)">
</p>

<p>
The idea is that, we normalize the weights, and each time we draw a number between zero and one, which will "point" to a weight.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/wheen_resampling.png" alt="Wheel Resampling" style="transform:translate(20vw,0)">
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/wheel_resampling_1.png" alt="Wheel Resampling" style="transform:translate(30vw,0)">
</p>

<p>
However this method can lead to suboptimal solutions. Suppose that for some reason each time we end up with uniform weight, so that no particle is more likely than any other. Then, with the wheel roulette we will duplicate some particles and remove some others. However this does not make sense, because every particle had the same weight.
</p>

<p>
Thus we introduce the lower variance resampling.
</p>

<div id="Particle Filter-Resampling Techniques-Low Variance Resampling"><h3 id="Low Variance Resampling" class="header"><a href="#Particle Filter-Resampling Techniques-Low Variance Resampling">Low Variance Resampling</a></h3></div>

<p>
Here, the idea is using \(J\) arrows instead of only one, where the arrows are at the same angular distance from each other. So in order to sample what we do is, we simply turn the arrows, and where all the arrows end up, that is the samples we choose.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/low_variance_resampling.png" alt="Low Variance Resampling" style="transform:translate(30vw,0)">
</p>

<p>
This solution is faster, with time complexity equal to \(O(J)\) compared to the wheel roulette's \(O(J \log J)\), and resolves the suboptimal solution problem presented earlier.
</p>

<div id="Particle Filter-Resampling Techniques-Low Variance Resampling-Algorithm"><h4 id="Algorithm" class="header"><a href="#Particle Filter-Resampling Techniques-Low Variance Resampling-Algorithm">Algorithm</a></h4></div>

<ul>
<li>
First we draw a random number between \(0\) and \(\frac{1}{J}\)

</li><li>
Then we pick \(J-1\) particles by advancing in the array in steps of \(\frac{1}{J}\)

</li></ul>
<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/low_variance_resampling_array.png" alt="Low Variance Resampling" style="transform:translate(25vw,0)">
</p>

<p>
To efficiently implement this what we do is, in each element of the array we store the cummulative weight up until that point:
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/low_variance_resampling_cummulative.png" alt="Low Variance Resampling" style="transform:translate(25vw,0)">
</p>

<p>
So, we draw a random number between \(0\) and \(\frac{1}{J}\), if that number is bigger than the weight accumulated up until weight \(i\), then we move to the next one, else if it is less we sample the particle \(i\). And then we advance \(\frac{1}{J}\).
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Robotics/OnlineTrainingMobileRobotics/ParticleFilter/low_variance_resampling_algorithm.png" alt="Low Variance Resampling Algorithm" style="transform:translate(25vw,0)">
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="jQuery library"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/fuse.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>