<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/custom.css">
    <title>Metropolis and Metropolis-Hastings Algorithms</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms"><h1 id="Metropolis and Metropolis-Hastings Algorithms" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms">Metropolis and Metropolis-Hastings Algorithms</a></h1></div>

<hr>

<p>
The Metropolis-Hastings algorithm is a general term for a family of Markov chain simulation methods that are useful for sampling from Bayesian posterior distributions. We have already seen the Gibbs sampler in the previous section; it can be viewed as a special case of Metropolis-Hastings.
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm"><h2 id="The Metropolis algorithm" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm">The Metropolis algorithm</a></h2></div>

<p>
The Metropolis algorithm is an adaptation of a random walk with an acceptance/rejection rule to converge to the specified target distribution. The algorithm proceeds as follows.
</p>

<ol>
<li>
Draw a starting point \(\theta_0\), for which \(p(\theta_0|y) &gt; 0\), from a starting distribution \(p_0(\theta)\). The starting distribution might be based on an approximation or we may simply choose starting values dispersed around a crude approximate estimate.

</li><li>
For \(t = 1, 2, \cdots\):

<ul>
<li>
Sample a proposal \(\theta^*\) from a jumping distribution (or proposal distribution) at time \(t\), \(J_t(\theta^*|\theta^{t-1})\). For the Metropolis algorithm (but not the Metropolis-Hastings algorithm, as discussed later in this section), the jumping distribution must be symmetric.

</li><li>
Calculate the ratio of the densities:
\begin{align}
r = \frac{p(\theta^*|y)}{p(\theta^{t- 1}|y)}
\end{align}

</li><li>
Set:
\begin{align}
\theta^t = \begin{cases}
\theta^* &amp; \text{ with probability } \min(r, 1) \\
\theta^{t-1} \text{ otherwise }
\end{cases}
\end{align}

</li></ul>
</li></ol>
<p>
The acceptance/rejection rule of the Metropolis algorithm can be stated as follows: 
</p>

<ul>
<li>
If the jump increases the posterior density, set \(\theta^t = \theta^*\); 

</li><li>
If the jump decreases the posterior density, set \(\theta^t = \theta^*\) with probability equal to the density ratio, \(r\), otherwise set \(\theta_t = \theta^{t - 1}\) (with probability \(1 - r\)). 

</li></ul>
<p>
The Metropolis algorithm can thus be viewed as a stochastic version of a stepwise mode-finding algorithm, always accepting steps that increase the density but only sometimes accepting downward steps.
</p>

<p>
To use the algorithm, we need to calculate the ratio \(r\) for every pair of \((\theta, \theta^*)\), and we also need to choose \(\theta\) from the jumping distribution \(J_t(\theta^*|\theta)\) for all \(\theta\) and \(t\). Additionally, we need to generate a random number for step (\(c\)) in the process.
</p>

<p>
Even if the jump isn't accepted and \(\theta_t\) equals \(\theta_{t-1}\), it still counts as a step in the algorithm.
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm-Example: Bivariate Unit Normal Density with Normal Jumping Kernel"><h3 id="Example: Bivariate Unit Normal Density with Normal Jumping Kernel" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm-Example: Bivariate Unit Normal Density with Normal Jumping Kernel">Example: Bivariate Unit Normal Density with Normal Jumping Kernel</a></h3></div>

<p>
For simplicity, we illustrate the Metropolis algorithm with the simple example of the bivariate unit normal distribution. The target density is the bivariate unit normal, \(p(\theta|y) = \text{N}(\theta|0, I)\). The jumping distribution is also bivariate normal, centered at the current iteration and scaled to \(\frac{1}{5}\) the size: \(J_t(\theta^*|\theta^{t−1}) = \text{N}(\theta^*|\theta^{t−1}, 0.22\cdotI)\). 
</p>

<p>
At each step, it is easy to calculate the density ratio:
</p>

\[
r = \frac{\text{N}(\theta^*|0, I)}{\text{N}(\theta^{t-1}|0, I)}
\]

<p>
It is clear from the form of the normal distribution that the jumping rule is symmetric. <a href="01_gibbs_sampler.html#Introduction">Figure 11.1</a> displays five simulation runs starting from different points. We have purposely set the scale of this jumping algorithm to be too small, relative to the target distribution, so that the algorithm will run inefficiently and its random-walk aspect will be obvious in the figure.
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-Why does the Metropolis Algorithm Work?"><h2 id="Why does the Metropolis Algorithm Work?" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-Why does the Metropolis Algorithm Work?">Why does the Metropolis Algorithm Work?</a></h2></div>

<p>
The proof that the sequence of iterations \(\theta_1, \theta_2, \cdots\) converges to the target distribution has two steps:
</p>

<ol>
<li>
It is shown that the simulated sequence is a Markov chain with a unique stationary distribution.

</li><li>
It is shown that the stationary distribution equals the target distribution.

</li></ol>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>