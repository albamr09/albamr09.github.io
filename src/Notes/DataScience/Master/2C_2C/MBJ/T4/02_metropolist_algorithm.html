<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/custom.css">
    <title>Metropolis and Metropolis-Hastings Algorithms</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms"><h1 id="Metropolis and Metropolis-Hastings Algorithms" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms">Metropolis and Metropolis-Hastings Algorithms</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="02_metropolist_algorithm.html#The%20Metropolis%20algorithm">The Metropolis algorithm</a>

<ul>
<li>
<a href="02_metropolist_algorithm.html#Example%3A%20Bivariate%20Unit%20Normal%20Density%20with%20Normal%20Jumping%20Kernel">Example  Bivariate Unit Normal Density with Normal Jumping Kernel</a>

</li></ul>
</li><li>
<a href="02_metropolist_algorithm.html#Why%20does%20the%20Metropolis%20Algorithm%20Work%3F">Why does the Metropolis Algorithm Work</a>

</li><li>
<a href="02_metropolist_algorithm.html#The%20Metropolis-Hastings%20Algorithm">The Metropolis-Hastings Algorithm</a>

</li><li>
<a href="02_metropolist_algorithm.html#Relation%20Between%20the%20Jumping%20Rule%20and%20Efficiency%20of%20Simulations">Relation Between the Jumping Rule and Efficiency of Simulations</a>

</li></ul>
<hr>


<p>
The Metropolis-Hastings algorithm is a general term for a family of Markov chain simulation methods that are useful for sampling from Bayesian posterior distributions. We have already seen the Gibbs sampler in the previous section; it can be viewed as a special case of Metropolis-Hastings.
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm"><h2 id="The Metropolis algorithm" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm">The Metropolis algorithm</a></h2></div>

<p>
The Metropolis algorithm is an adaptation of a random walk with an acceptance/rejection rule to converge to the specified target distribution. The algorithm proceeds as follows.
</p>

<ol>
<li>
Draw a starting point \(\theta_0\), for which \(p(\theta_0|y) &gt; 0\), from a starting distribution \(p_0(\theta)\). The starting distribution might be based on an approximation or we may simply choose starting values dispersed around a crude approximate estimate.

</li><li>
For \(t = 1, 2, \cdots\):

<ul>
<li>
Sample a proposal \(\theta^*\) from a jumping distribution (or proposal distribution) at time \(t\), \(J_t(\theta^*|\theta^{t-1})\). For the Metropolis algorithm (but not the Metropolis-Hastings algorithm, as discussed later in this section), the jumping distribution must be symmetric.

</li><li>
Calculate the ratio of the densities:
\begin{align}
r = \frac{p(\theta^*|y)}{p(\theta^{t- 1}|y)}
\end{align}

</li><li>
Set:
\begin{align}
\theta^t = \begin{cases}
\theta^* &amp; \text{ with probability } \min(r, 1) \\
\theta^{t-1} \text{ otherwise }
\end{cases}
\end{align}

</li></ul>
</li></ol>
<p>
The acceptance/rejection rule of the Metropolis algorithm can be stated as follows: 
</p>

<ul>
<li>
If the jump increases the posterior density, set \(\theta^t = \theta^*\); 

</li><li>
If the jump decreases the posterior density, set \(\theta^t = \theta^*\) with probability equal to the density ratio, \(r\), otherwise set \(\theta_t = \theta^{t - 1}\) (with probability \(1 - r\)). 

</li></ul>
<p>
The Metropolis algorithm can thus be viewed as a stochastic version of a stepwise mode-finding algorithm, always accepting steps that increase the density but only sometimes accepting downward steps.
</p>

<p>
To use the algorithm, we need to calculate the ratio \(r\) for every pair of \((\theta, \theta^*)\), and we also need to choose \(\theta\) from the jumping distribution \(J_t(\theta^*|\theta)\) for all \(\theta\) and \(t\). Additionally, we need to generate a random number for step (\(c\)) in the process.
</p>

<p>
Even if the jump isn't accepted and \(\theta_t\) equals \(\theta_{t-1}\), it still counts as a step in the algorithm.
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm-Example: Bivariate Unit Normal Density with Normal Jumping Kernel"><h3 id="Example: Bivariate Unit Normal Density with Normal Jumping Kernel" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-The Metropolis algorithm-Example: Bivariate Unit Normal Density with Normal Jumping Kernel">Example: Bivariate Unit Normal Density with Normal Jumping Kernel</a></h3></div>

<p>
For simplicity, we illustrate the Metropolis algorithm with the simple example of the bivariate unit normal distribution. The target density is the bivariate unit normal, \(p(\theta|y) = \text{N}(\theta|0, I)\). The jumping distribution is also bivariate normal, centered at the current iteration and scaled to \(\frac{1}{5}\) the size: \(J_t(\theta^*|\theta^{t−1}) = \text{N}(\theta^*|\theta^{t−1}, 0.22\cdot I)\). 
</p>

<p>
At each step, it is easy to calculate the density ratio:
</p>

\[
r = \frac{\text{N}(\theta^*|0, I)}{\text{N}(\theta^{t-1}|0, I)}
\]

<p>
It is clear from the form of the normal distribution that the jumping rule is symmetric. <a href="01_gibbs_sampler.html#Introduction">Figure 11.1</a> displays five simulation runs starting from different points. We have purposely set the scale of this jumping algorithm to be too small, relative to the target distribution, so that the algorithm will run inefficiently and its random-walk aspect will be obvious in the figure.
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-Why does the Metropolis Algorithm Work?"><h2 id="Why does the Metropolis Algorithm Work?" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-Why does the Metropolis Algorithm Work?">Why does the Metropolis Algorithm Work?</a></h2></div>

<p>
The proof that the sequence of iterations \(\theta_1, \theta_2, \cdots\) converges to the target distribution has two steps:
</p>

<ol>
<li>
It is shown that the simulated sequence is a Markov chain with a unique stationary distribution.

</li><li>
It is shown that the stationary distribution equals the target distribution.

</li></ol>
<p>
Except for trivial exceptions, the latter two conditions hold for a random walk on any proper distribution, and irreducibility holds as long as the jumping distributions Jt is eventually be able to jump to all states with positive probability.
</p>

<ol>
<li>
To show (1) consider starting the algorithm at time \(t − 1\) with a draw \(\theta^{t−1}\) from the target distribution \(p(\theta|y)\). Now consider any two such points \(\theta_a\) and \(\theta_b\), drawn from \(p(\theta|y)\) and labeled so that \(p(\theta_b|y) \geq p(\theta_a|y)\). The unconditional probability density of a transition from \(\theta_a\) to \(\theta_b\) is:
\begin{align}
p(\theta^{t - 1} = \theta_a, \theta^t = \theta_b) = p(\theta_a|y)J_t(\theta_b|\theta_a)
\end{align}

</li></ol>
<p>
where the acceptance probability is \(1\) because of our labeling of \(a\) and \(b\), and the unconditional probability density of a transition from \(\theta_b\) to \(\theta_a\) is:
</p>

\begin{align}
p(\theta^t = \theta_a, \theta^{t-1} = \theta_b) = p(\theta_b|y)J_t(\theta_a|\theta_b) \left(\frac{p(\theta_a|y)}{p(\theta_b|y)}\right)
\end{align}

\begin{align}
= p(\theta_b|y)J_t(\theta_a|\theta_b)
\end{align}

<p>
which is the same as the probability of a transition from \(\theta_a\) to \(\theta_b\), since we have required that \(J_t(\cdot|\cdot)\) be symmetric.
</p>

<p>
Since their joint distribution is symmetric, \(\theta^t\) and \(\theta^{t−1}\) have the same marginal distributions, and so \(p(\theta|y)\) is the stationary distribution of the Markov chain of \(\theta\).
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-The Metropolis-Hastings Algorithm"><h2 id="The Metropolis-Hastings Algorithm" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-The Metropolis-Hastings Algorithm">The Metropolis-Hastings Algorithm</a></h2></div>

<p>
The Metropolis-Hastings algorithm generalizes the basic Metropolis algorithm presented above in two ways. 
</p>

<ol>
<li>
The jumping rules \(J_t\) need no longer be symmetric.

</li><li>
To correct for the asymmetry in the jumping rule the ratio \(r\) is replaced by a ratio of ratios:
\begin{align}
r = \frac{\frac{p(\theta^*|y)}{J_t(\theta^*|\theta^{t-1})}}{\frac{p(\theta^{t-1}|y)}{J_t(\theta^{t-1}|\theta^*)}}
\end{align}

</li></ol>
<p>
Allowing asymmetric jumping rules can be useful in increasing the speed of the random walk.
</p>

<div id="Metropolis and Metropolis-Hastings Algorithms-Relation Between the Jumping Rule and Efficiency of Simulations"><h2 id="Relation Between the Jumping Rule and Efficiency of Simulations" class="header"><a href="#Metropolis and Metropolis-Hastings Algorithms-Relation Between the Jumping Rule and Efficiency of Simulations">Relation Between the Jumping Rule and Efficiency of Simulations</a></h2></div>

<p>
The ideal Metropolis-Hastings jumping rule is simply to sample the proposal, \(\theta^*\), from the target distribution; such that our jumping distribution is equal to the target distribution, \(J(\theta^*|\theta) ≡ p(\theta^*|y)\). Then the ratio \(r\) is always exactly \(1\), so we always choose the new sampled \(\theta^*\) to update \(\theta^t\) instead of remaining with \(\theta^{t-1}\).
</p>

<p>
A good jumping distribution has the following properties:
</p>

<ol>
<li>
For any \(\theta\), it is easy to sample from \(J(\theta^*|\theta)\)

</li><li>
It is easy to compute the ratio \(r\)

</li><li>
Each jump goes a reasonable distance in the parameter space (otherwise the random walk moves too slowly).

</li><li>
The jumps are not rejected too frequently (otherwise the random walk wastes too much time standing still).

</li></ol>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>