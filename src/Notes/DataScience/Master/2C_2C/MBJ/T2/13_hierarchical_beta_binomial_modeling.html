<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/custom.css">
    <title>Hierarchical Beta-Binomial Modeling</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Hierarchical Beta-Binomial Modeling"><h1 id="Hierarchical Beta-Binomial Modeling" class="header"><a href="#Hierarchical Beta-Binomial Modeling">Hierarchical Beta-Binomial Modeling</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="13_hierarchical_beta_binomial_modeling.html#Example%3A%20Deaths%20after%20heart%20attack">Example  Deaths after heart attack</a>

</li><li>
<a href="13_hierarchical_beta_binomial_modeling.html#A%20Hierarchical%20Beta-Binomial%20Model">A Hierarchical Beta-Binomial Model</a>

<ul>
<li>
<a href="13_hierarchical_beta_binomial_modeling.html#Graphical%20Representation">Graphical Representation</a>

</li></ul>
</li><li>
<a href="13_hierarchical_beta_binomial_modeling.html#Inference%20through%20MCMC">Inference through MCMC</a>

<ul>
<li>
<a href="13_hierarchical_beta_binomial_modeling.html#Second-stage%20prior">Second-stage prior</a>

</li><li>
<a href="13_hierarchical_beta_binomial_modeling.html#MCMC%20diagnostics%20and%20summarization">MCMC diagnostics and summarization</a>

</li></ul>
</li></ul>
<hr>

<div id="Hierarchical Beta-Binomial Modeling-Example: Deaths after heart attack"><h2 id="Example: Deaths after heart attack" class="header"><a href="#Hierarchical Beta-Binomial Modeling-Example: Deaths after heart attack">Example: Deaths after heart attack</a></h2></div>

<p>
The New York State (NYS) Department of Health collects and releases data on mortality after a heart attack. We focus on 13 hospitals in Manhattan, New York City, with the goal of learning about the percentages of resulted deaths from heart attack for hospitals in this sample.
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/heart_attack_data.png" alt="Data" style="width:600px;height:450px">
</p>

<div id="Hierarchical Beta-Binomial Modeling-A Hierarchical Beta-Binomial Model"><h2 id="A Hierarchical Beta-Binomial Model" class="header"><a href="#Hierarchical Beta-Binomial Modeling-A Hierarchical Beta-Binomial Model">A Hierarchical Beta-Binomial Model</a></h2></div>

<p>
Treating “cases” as trials and “deaths” as successes, the Binomial sampling model is a natural choice for this data, and the objective is to learn about the death probability \(p\) of the hospitals.
</p>

<p>
If one creates thirteen separate Binomial sampling models, one for each hospital, and conducts separate inferences, one loses the ability to use potential information about the death rate from hospital \(i\) when making inference about that of a different hospital \(j\). Since these are all hospitals in Manhattan, New York City, they may share attributes in common related to death rates from heart attack.
</p>

<p>
Therefore, one builds a hierarchical model based on a common Beta distribution that generalizes the Beta-Binomial conjugate model described in <a href="https://bayesball.github.io/BOOK/proportion.html">Chapter 7</a>.
</p>

<p>
Let \(Y_i\) denote the number of resulted deaths from heart attack, \(n_i\) the number of heart attack cases, and \(p_i\) the death rate for hospital \(i\). So the sampling and first stage of the prior of our model is written as follows:
</p>

<ul>
<li>
Sampling for \(i = 1, \cdots, 13\):
\begin{align}
Y_i \sim \text{Binomial}(n_i, p_i)
\end{align}

</li></ul>
 
<ul>
<li>
Prior for \(p_i\), \(i = 1, \cdots, 13\):
\begin{align}
p_i \sim \text{Beta}(a, b)
\end{align}

</li></ul>
<p>
Note that the hyperparameters \(a\) and \(b\) are shared among all hospitals. If \(a\) and \(b\) are known values, then the posterior inference for \(p_i\) of hospital \(i\) is simply another Beta distribution by conjugacy (refer to <a href="https://compcogsci-3016.djnavarro.net/technote_betabinomial.pdf">Beta-binomial conjugate prior (page 7)</a>):
</p>

\begin{align}
p_i | y_i \sim \text{Beta}(a + y_i, b + n_i - y_i)
\end{align}

<p>
In the general situation where the hyperparameters \(a\) and \(b\) are unknown, a second stage of the prior \(\pi(a, b)\) needs to specified for these hyperparameters, such that the model is now defined as:
</p>

<ul>
<li>
Sampling for \(i = 1, \cdots, 13\):
\begin{align}
Y_i \sim \text{Binomial}(n_i, p_i)
\end{align}

</li></ul>
 
<ul>
<li>
Prior for \(p_i\), Stage 1: \(i = 1, \cdots, 13\):
\begin{align}
p_i \sim \text{Beta}(a, b)
\end{align}

</li></ul>
 
<ul>
<li>
Prior for \(p_i\), Stage 2: the hyperprior:
\begin{align}
a, b \sim \pi(a, b)
\end{align}

</li></ul>
<p>
When we start analyzing the New York State heart attack death rate dataset, the specification of this hyperprior distribution \(\pi(a, b)\) will be described.
</p>

<div id="Hierarchical Beta-Binomial Modeling-A Hierarchical Beta-Binomial Model-Graphical Representation"><h3 id="Graphical Representation" class="header"><a href="#Hierarchical Beta-Binomial Modeling-A Hierarchical Beta-Binomial Model-Graphical Representation">Graphical Representation</a></h3></div>

<p>
One sees that the upper section of the graph represents the sampling density, with the arrow directing from \(p_i\) to \(Y_i\). Here the start of the arrow is the parameter and the end of the arrow is the random variable. The lower section of the graph represents the prior, with arrows directing from \(a\) and \(b\) to \(p_i\). 
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/beta_binomial_hierarchical_model.png" alt="Graphical Representation of the Beta-Binomial Hierarchical Model" style="width:400px;height:200px">
</p>

<div id="Hierarchical Beta-Binomial Modeling-Inference through MCMC"><h2 id="Inference through MCMC" class="header"><a href="#Hierarchical Beta-Binomial Modeling-Inference through MCMC">Inference through MCMC</a></h2></div>

<div id="Hierarchical Beta-Binomial Modeling-Inference through MCMC-Second-stage prior"><h3 id="Second-stage prior" class="header"><a href="#Hierarchical Beta-Binomial Modeling-Inference through MCMC-Second-stage prior">Second-stage prior</a></h3></div>

<p>
For a \(\text{Beta}(a, b)\) prior distribution for a proportion \(p\), one considers the parameter \(a\) as the prior count of “successes”, the parameter \(b\) as the prior count of "failures", and the sum \(a + b\) represents the prior sample size. Also the expectation is given by \(\frac{a}{a + b}\). From these facts a more natural parametrization of the hyperprior distribution \(\pi(a, b)\) is \(\pi(\mu, \eta)\) where \(\mu = \frac{a}{a + b}\) is the hyperprior mean and \(\eta = a + b\) is the hyperprior sample size. Therefore:
</p>

\begin{align}
\mu, \eta \sim \pi(\mu, \eta)
\end{align}

<p>
where \(a = \mu\eta\) and \(b = (1 - \mu)\eta\).
</p>

<p>
Assume \(\mu\) and \(\eta\) are independent which means that one's beliefs about the prior mean are independent of the beliefs about the prior sample size. The hyperprior expectation \(\mu\) is the mean measure for \(p_i\), the average death rate across \(13\) hospitals. If one has little prior knowledge about the expectation \(\mu\), one assigns this parameter a Uniform prior which is equivalent to a \(\text{Beta}(1, 1)\) prior.
</p>

<p>
To motivate the prior choice for the hyperparameter sample size \(\eta\), consider the case where the hyperparameter values are known. If \(y^*\) and \(n^*\) are respectively the number of deaths and number of cases for one hospital, then the posterior mean of death rate parameter \(p^*\) is given by (refer to the Beta-binomial conjugate definition):
</p>

\begin{align}
\mathbb{E}[p^*|y^*] = \frac{y^* + \mu\eta}{n^* + \eta}
\end{align}

<p>
With a little algebra, the posterior mean is rewritten as
</p>

\begin{align}
\mathbb{E}[p^*|y^*] = (1 - \lambda)\frac{y^*}{n^*} + \lambda\mu
\end{align}

<p>
where \(\lambda\) is the shrinkage fraction:
</p>

\begin{align}
\lambda = \frac{\eta}{n^* + \eta}
\end{align}

<p>
The parameter \(\lambda\) falls in the interval \((0, 1)\) and represents the degree of shrinkage of the posterior mean away from the sample proportion \(\frac{y^*}{n^*}\) towards the prior mean \(\mu\).
</p>

<p>
Suppose one believes a priori that, for a representative sample size \(n^*\), the shrinkage \(\lambda\) is Uniformly distributed on \((0, 1)\). By performing a transformation, this implies that the prior density for the prior sample size \(\eta\) has the form:
</p>

\begin{align}
\pi(\eta) = \frac{n^*}{(n^* + \eta)^2}, \eta &gt; 0
\end{align}

<p>
Equivalently, the logarithm of \(\eta\), \(\theta = \log(\eta)\), has a Logistic distribution with location \(\log(n^*)\) and scale \(1\). We represent this distribution as \(Logistic(\log(n^*), 1)\), with pdf:
</p>

\begin{align}
\pi(\theta) = \frac{e^{-(\theta - \log(n^*))}}{(1 + e^{-(\theta - \log(n^*))})^2}
\end{align}

<p>
With this specification of the hyperparameter distribution, one writes down the complete hierarchical model as follows:
</p>
 
<ul>
<li>
Sampling for \(i = 1, \cdots, 13\):
\begin{align}
Y_i \sim \text{Binomial}(n_i, p_i)
\end{align}

</li></ul>
 
<ul>
<li>
Prior for \(p_i\), Stage 1: \(i = 1, \cdots, 13\):
\begin{align}
p_i \sim \text{Beta}(a, b)
\end{align}

</li></ul>
 
<ul>
<li>
Prior for \(p_i\), Stage 2: the hyperpriors:
\begin{align}
\mu, \eta \sim \pi(\mu, \eta)
\end{align}
\begin{align}
\log \eta \sim \text{Logistic}(\log n^*, 1)
\end{align}

</li></ul>
<p>
where \(a = \mu\eta\) and \(b = (1 - \mu)\eta\)
</p>

<div id="Hierarchical Beta-Binomial Modeling-Inference through MCMC-MCMC diagnostics and summarization"><h3 id="MCMC diagnostics and summarization" class="header"><a href="#Hierarchical Beta-Binomial Modeling-Inference through MCMC-MCMC diagnostics and summarization">MCMC diagnostics and summarization</a></h3></div>

<p>
After the diagnostics are performed, one reports posterior summaries of the parameters:
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/beta_binomial_MCMC_summary.png" alt="MCMC Summary" style="width:500px;height:400px;">
</p>

<p>
From the posterior output, one evaluates the effect of information pooling in the hierarchical model. See Figure 10.6 displays a shrinkage plot showing how the sample proportions are shrunk towards the overall death rate. 
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/beta_binomial_shrinkage.png" alt="MCMC Shrinkage" style="width:550px;height:400px;">
</p>

<p>
To compare the posterior densities of the different \(p_i\), one displays the density estimates in a single graph as in the following figure:
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/beta_binomial_posterior_densities.png" alt="Posterior Density Comparison" style="width:400px;height:400px;">
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>