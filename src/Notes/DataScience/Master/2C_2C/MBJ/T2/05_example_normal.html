<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/custom.css">
    <title>Example: parallel experiments in eight schools</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Example: parallel experiments in eight schools"><h1 id="Example: parallel experiments in eight schools" class="header"><a href="#Example: parallel experiments in eight schools">Example: parallel experiments in eight schools</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="05_example_normal.html#Inferences based on nonhierarchical models and their problems">Inferences based on nonhierarchical models and their problems</a>

</li><li>
<a href="05_example_normal.html#Posterior simulation under the hierarchical model">Posterior simulation under the hierarchical model</a>

</li><li>
<a href="05_example_normal.html#Discussion">Discussion</a>

</li></ul>
<hr>

<p>
A study was performed for the Educational Testing Service to analyze the effects of special coaching programs on test scores in each of eigth schools. The outcome variable in each study was the score on a special administration of the SAT-V. The scores can vary between \(200\) and \(800\), with mean about \(500\) and standard deviation about \(100\). Also, there was no prior reason to believe that any of the eight programs was more effective than any other or that some were more similar in effect to each other than to any other.
</p>

<p>
The results of the experiments are summarized in:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_example_results.png" alt="Example Results" style="width:500px;height:250px;">
</p>

<div id="Example: parallel experiments in eight schools-Inferences based on nonhierarchical models and their problems"><h2 id="Inferences based on nonhierarchical models and their problems" class="header"><a href="#Example: parallel experiments in eight schools-Inferences based on nonhierarchical models and their problems">Inferences based on nonhierarchical models and their problems</a></h2></div>

<p>
Before fitting the hierarchical Bayesian model, we first consider two simpler nonhierarchical methods—estimating the effects from the eight experiments independently (separate estimates), and complete pooling—and discuss why neither of these approaches is adequate for this example.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_hierarchical_modeling_comparison.png" alt="Model Comparison" style="width:500px;height:450px;">
</p>

<p>
Consider \(\theta_1\), the effect in school \(A\). The effect in school \(A\) is estimated as \(28.4\) with a standard error of \(14.9\) under the separate analysis, versus a pooled estimate of \(7.7\) with a standard error of \(4.1\) under
the common-effect model.
</p>

<p>
<span id="Example: parallel experiments in eight schools-Inferences based on nonhierarchical models and their problems-Note"></span><strong id="Note">Note</strong>: given a Normal distribution (symmetrical with respect to it mean) the probability that an estimate takes a value under the mean is \(\frac{1}{2}\) (cumulative density function), as the \(\mu\) serves as the midpoint of a Normal distribution such that half the area for the normal curve is contained under \([0, \mu]\).
</p>

<p>
The separate analyses of the eight schools imply the following posterior statement: 'the probability is \(\frac{1}{2}\) that the true effect in \(A\) is more than \(28.4\)' a doubtful statement, considering the results for the other seven schools. On the other hand, the pooled model implies the following statement: 'the probability is \(\frac{1}{2}\) that the true effect in A is less than \(7.7\),' which seems an inaccurate summary of our knowledge. As in the theoretical discussion of the previous section, neither estimate is fully satisfactory, and we would like a compromise that combines information from all eight experiments without assuming all the \(\theta_j\)'s to be equal. The Bayesian analysis under the hierarchical model provides exactly that.
</p>

<div id="Example: parallel experiments in eight schools-Posterior simulation under the hierarchical model"><h2 id="Posterior simulation under the hierarchical model" class="header"><a href="#Example: parallel experiments in eight schools-Posterior simulation under the hierarchical model">Posterior simulation under the hierarchical model</a></h2></div>

<p>
Consequently, we compute the posterior distribution of \(\theta_1, \cdots, \theta_8\), based on the normal model presented in <a href="04_normal_model.html">Section 4</a>. We draw from the posterior distribution for the Bayesian model by simulating the random variables \(\tau\), \(\mu\), and \(\theta\), in that order, from their posterior distribution, as discussed at the end of the previous section. The sampling standard deviations, \(\sigma_j\), are assumed known and equal to the values in Table 5.2, and we assume independent uniform prior densities on \(\mu\) and \(\tau\).
</p>

<p>
The marginal posterior density function, \(p(\tau|y)\) from, is plotted in the next figure:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_example_margina_posterior_density.png" alt="Normal Posterior Density" style="width:900px;height:350px;">
</p>

<p>
Values of \(\tau\) near zero are mos plausible. In the normal hierarchical model, however, we learn a great deal by considering the conditional posterior distributions given \(\tau\) (and averaged over \(\mu\)), that is \(\mathbb{E}[\theta_j|\tau, y]\), averaging over \(\mu\). This is displayed on the following image:
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_example_conditional_posterior.png" alt="Conditional Posterior Density" style="width:800px;height:350px;">
</p>

<p>
Comparing with the previous figure, which has the same scale on the horizontal axis, we see that for most of the likely values of \(\tau\), that is for \(\tau \approx 0\) the estimated effects for all the groups are relatively close together (when \(\tau = 0\) you would guess they are clustered on the same point). However, as \(\tau\) becomes larger, corresponding to more variability among schools, the estimates become more like the raw values shown on the first figure of this section.
</p>

<p>
The lines in the following figure show the conditional standard deviations, \(sd(\theta_j|\tau, y)\), as a function of \(\tau\). As \(\tau\) increases, the population distribution allows the eight effects to be more different from each other, and hence the posterior uncertainty in each individual \(\tau_j\) increases, approaching the standard deviations shown in the raw data in the limit of \(\tau \rightarrow \infty\). 
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_example_conditional_parameter_std.png" alt="Conditional Parameters' Standard Deviations" style="width:800px;height:350px;">
</p>

<p>
Contrary to what we saw with separate estimates and pooled estimates, for the likely values of \(\tau\) (see figure for \(p(\tau|y)\)), the estimates in all schools are substantially less than \(28\) points. For example, even at \(\tau = 0\), the probability that the effect in school A is less than \(28\) points is \(\Phi[(28 − 14.5)/9.1] = 93\%\), where \(\Phi\) is the standard normal cumulative distribution function.
</p>

<p>
Of substantial importance, we do not obtain an accurate summary of the data if we condition on the posterior mode of \(\tau\) as it ignores the uncertainty associated with \(\tau\) as conveyed by the full posterior distribution. In Bayesian statistics, the posterior distribution encapsulates both the most likely values of parameters as well as the uncertainty or variability in those estimates.
</p>

<p>
By only considering the mode (the peak or maximum) of the posterior distribution and neglecting its shape and spread, we may miss out on valuable information about the range of plausible values for τ and the associated uncertainty.
</p>

<div id="Example: parallel experiments in eight schools-Discussion"><h2 id="Discussion" class="header"><a href="#Example: parallel experiments in eight schools-Discussion">Discussion</a></h2></div>

<p>
Table 5.3 summarizes the \(200\) simulated effect estimates for all eight schools.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_example_simulation.png" alt="Simlated Effects (theta parameter)" style="width:600px;height:250px;">
</p>

<p>
The Bayesian probability that the effect in school A is as large as \(28\) points is less than \(10\%\), which is substantially less than the \(50\%\) probability based on the separate estimate for school A.
</p>

<p>
As an illustration of the simulation-based posterior results, \(200\) simulations of school A's effect are shown in Figure 5.8a.
</p>

<p>
<img src="https://albamr09.github.io/public/assets/normal_example_effects_simulation.png" alt="Simlated Effects" style="width:600px;height:250px;">
</p>

<p>
Having simulated the parameter \(\theta\), it is easy to ask more complicated questions of this model. For example, what is the posterior distribution of \(\max(\theta_j)\), the effect of the most successful of the eight coaching programs? Figure 5.8b displays a histogram of \(200\) values from this posterior distribution and shows that only \(22\) draws are larger than \(28.4\). For another example, we can estimate \(Pr(\theta_1 &gt; \theta_3|y)\), the posterior probability that the coaching program is more effective in school A than in school C, by the proportion of simulated draws of \(\theta\) for which \(\theta_1 &gt; \theta_3\); the result is \(\frac{141}{200} = 0.705\).
</p>

<p>
To sum up, the Bayesian analysis of this example not only allows straightforward inferences about many parameters that may be of interest, but the hierarchical model is flexible enough to adapt to the data, thereby providing posterior inferences that account for the partial pooling as well as the uncertainty in the hyperparameters.
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>