<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/custom.css">
    <title>Bayesian analysis of conjugate hierarchical models</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Bayesian analysis of conjugate hierarchical models"><h1 id="Bayesian analysis of conjugate hierarchical models" class="header"><a href="#Bayesian analysis of conjugate hierarchical models">Bayesian analysis of conjugate hierarchical models</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="03.html#Analytic%20derivation%20of%20conditional%20and%20marginal%20distributions">Analytic derivation of conditional and marginal distributions</a>

</li><li>
<a href="03.html#Drawing%20simulations%20from%20the%20posterior%20distribution">Drawing simulations from the posterior distribution</a>

</li><li>
<a href="03.html#Application%20to%20the%20model%20for%20rat%20tumors">Application to the model for rat tumors</a>

<ul>
<li>
<a href="03.html#Joint%2C%20conditional%2C%20and%20marginal%20posterior%20distributions">Joint  conditional  and marginal posterior distributions</a>

</li><li>
<a href="03.html#Choosing%20a%20standard%20parameterization%20and%20setting%20up%20a%20%27noninformative%27%20hyperprior%20distribution">Choosing a standard parameterization and setting up a  noninformative  hyperprior distribution</a>

</li><li>
<a href="03.html#Computing%20the%20marginal%20posterior%20density%20of%20the%20hyperparameters">Computing the marginal posterior density of the hyperparameters</a>

</li><li>
<a href="03.html#Sampling%20from%20the%20joint%20posterior%20distribution%20of%20parameters%20and%20hyperparameters">Sampling from the joint posterior distribution of parameters and hyperparameters</a>

</li><li>
<a href="03.html#Displaying%20the%20results">Displaying the results</a>

</li></ul>
</li></ul>
<hr>

<div id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions"><h2 id="Analytic derivation of conditional and marginal distributions" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions">Analytic derivation of conditional and marginal distributions</a></h2></div>

<p>
Hierarchical models involve multiple levels of parameters and dependencies between them, making the analysis more intricate. The following steps are necessary to disentangle the relationships between parameters at different levels of the hierarchy and to estimate their distributions accurately.
</p>

<ul>
<li>
<span id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions-Joint Posterior Density"></span><strong id="Joint Posterior Density">Joint Posterior Density</strong>: Combines the prior information (hyperprior distribution \(p(\phi)\)), the population distribution (\(p(\theta|\phi)\)), and the likelihood function \(p(y|\theta)\) to form the joint posterior distribution.
\begin{align}
p(\theta, \phi|y) \propto p(y|\theta)p(\theta|\phi)p(\phi)
\end{align}

</li><li>
<span id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions-Conditional Posterior Density of the parameters"></span><strong id="Conditional Posterior Density of the parameters">Conditional Posterior Density of the parameters</strong>: Calculates the posterior distribution of \(\theta\) given the hyperparameters \(\phi\), allows us to understan how parameters interact and influence each other. This is usually done using <a href="https://es.wikipedia.org/wiki/Prior_conjugada">a priori conjugate distributions</a>.
\begin{align}
p(\theta|\phi, y) 
\end{align}

</li><li>
<span id="Bayesian analysis of conjugate hierarchical models-Analytic derivation of conditional and marginal distributions-Hyperparameter Estimation"></span><strong id="Hyperparameter Estimation">Hyperparameter Estimation</strong>: estimating \(\phi\) through the Bayesian paradigm helps in updating our knowledge about the higher-level parameters based on the observed data. This step can be perfomed by integrating the joint posterior distribution over \(\theta\) in to be able to marginalize \(\phi\) conditionally on \(y\).
\begin{align}
p(\phi|y) = \int p(\theta, \phi|y)d\theta
\end{align}

</li></ul>
<p>
For many standard models the marginal posterior distribution of \(\phi\) can be computed algebraically using the conditional probability formula:
</p>

\begin{align}
p(\phi|y) = \frac{p(\theta, \phi|y)}{p(\theta|\phi, y)}
\end{align}

<div id="Bayesian analysis of conjugate hierarchical models-Drawing simulations from the posterior distribution"><h2 id="Drawing simulations from the posterior distribution" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Drawing simulations from the posterior distribution">Drawing simulations from the posterior distribution</a></h2></div>

<p>
The following strategy is useful for simulating a draw from the joint posterior distribution \(p(\theta, \phi|y)\)
</p>

<ol>
<li>
Draw the vector of hyperparameters, \(\phi\), from its marginal posterior distribution, \(p(\phi|y)\).

</li><li>
Draw the parameter vector \(\theta\) from its conditional posterior distribution, \(p(\theta|\phi, y)\).  For the examples we consider in this chapter, the factorization \(p(\theta|\phi, y) = \prod_j p(\theta_j|\phi, y)\) holds.

</li><li>
If desired, draw predictive values \(\tilde{y}\) from the posterior predictive distribution.

</li></ol>
<p>
The above steps are performed \(L\) times in order to obtain a set of \(L\) draws. From the joint posterior simulations of \(\theta\) and \(\tilde{y}\), we can compute the posterior distribution of any estimand or predictive quantity of interest.
</p>

<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors"><h2 id="Application to the model for rat tumors" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors">Application to the model for rat tumors</a></h2></div>

<p>
The data from experiments \(j = 1, \cdots, J\), \(J = 71\), are assumed to follow independent binomial distributions:
</p>

\begin{align}
y_j \sim Bin(n_j, \theta_j)
\end{align}

<p>
This models the probability of getting exactly \(\theta_j\) successes in \(n_j\) independent Bernoulli trials.
</p>

<p>
with the number of rats \(n_j\) unknown. The parameters \(\theta_j\) are assumed to be independent samples from a beta distribution:
</p>

\begin{align}
\theta_j \sim Beta(\alpha, \beta)
\end{align}

<p>
  and we shall assign a noninformative hyperprior distribution to reflect our ignorance about the unknown hyperparameters \(\alpha, \beta\). We defer the choice of noninformative hyperprior distribution, a relatively arbitrary and unimportant part of this particular analysis, until we inspect the integrability of the posterior density.
</p>

<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions"><h3 id="Joint, conditional, and marginal posterior distributions" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions">Joint, conditional, and marginal posterior distributions</a></h3></div>

<p>
The <span id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions-joint posterior distribution"></span><strong id="joint posterior distribution">joint posterior distribution</strong> of all the parameters is:
</p>

\begin{align}
p(\theta, \alpha, \beta|y) \propto p(\alpha, \beta)p(\theta|\alpha,\beta)p(y|\theta, \alpha, \beta)
\end{align}

<p>
where \(p(\alpha, \beta)\) is the hyperprior distribution (\(p(\phi)\)).
</p>

<p>
Then \(p(\theta|\alpha,\beta)\) is the population distribution (\(p(\theta|\phi)\)). The pdf of \(x \sim Beta(\alpha, \beta)\), ignoring the normalization constant, <a href="https://en.wikipedia.org/wiki/Beta_distribution">is given by</a>:
</p>

\begin{align}
p(\theta|\alpha, \beta) \propto \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha - 1} (1- x)^{\beta - 1}
\end{align}

<p>
For \(j = 1, \cdots, J\) i.i.d \(\theta_j \sim Beta(\alpha, \beta)\):
</p>

\begin{align}
p(\theta|\alpha, \beta) \propto \prod_{j=1}^J \theta_j^{\alpha - 1} (1- \theta_j)^{\beta - 1}
\end{align}

<p>
And \(p(y|\theta, \alpha, \beta)\)  is the likelihood (\(p(y|\theta)\)). The pdf of \(x \sim Bin(n, p)\) <a href="https://en.wikipedia.org/wiki/Binomial_distribution">is given by</a>:
</p>

\begin{align}
p(x = k|n, p) \propto p^k (1 - p)^{n - k}
\end{align}

<p>
For \(j = 1, \cdots, J\) i.i.d \(y_j \sim Bin(n_j, \theta_j)\):
</p>

\begin{align}
p(y_j|n_j, \theta_j) \propto \theta_j^{y_j} (1 - \theta_j)^{n_j - y_j}
\end{align}

<p>
Therefore we obtain:
</p>

\begin{align}
\propto p(\alpha, \beta) \left(\prod_{j=1}^J \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1}\right) \left(\prod_{j=1}^J \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}\right)
\end{align}

<p>
The <span id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions-conditional posterior density of"></span><strong id="conditional posterior density of">conditional posterior density of</strong> \(\theta\) given the hyperparameters is defined using a <a href="https://compcogsci-3016.djnavarro.net/technote_betabinomial.pdf">Beta-binomial conjugate prior (page 7)</a>, therefore if:
</p>

\begin{align}
y_i|n_j, \theta_j \sim Bin(n_j, \theta_j)
\end{align}

\begin{align}
\theta_j|\alpha,\beta \sim Beta(\alpha, \beta)
\end{align}

<p>
then
</p>

\begin{align}
\theta_j|\alpha, \beta, y_j, n_j \sim Beta(\alpha + y_j, \beta + n_j - y_j)
\end{align}

<p>
which gives us the following <a href="https://en.wikipedia.org/wiki/Beta_distribution">pdf for a Beta distribution</a> of i.i.d \(\theta\):
</p>

\begin{align}
p(\theta|\alpha, \beta, y) = \prod_{j=1}^J \frac{\Gamma(\alpha + y_j + \beta + n_j - y_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}
\end{align}

\begin{align}
= \prod_{j=1}^J \frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}
\end{align}

<p>
We can determine the <span id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Joint, conditional, and marginal posterior distributions-marginal posterior distribution of the hyperparameters"></span><strong id="marginal posterior distribution of the hyperparameters">marginal posterior distribution of the hyperparameters</strong> \((\alpha, \beta)\) by substituting on the previous equations on the following formula:
</p>

\begin{align}
p(\phi|y) = \frac{p(\theta, \phi|y)}{p(\theta|\phi, y)}
\end{align}

<p>
where \(\phi = (\alpha, \beta)\), so:
</p>

\begin{align}
p(\alpha, \beta|y) = \frac{p(\theta, \alpha, \beta|y)}{p(\theta|\alpha, \beta, y)}
\end{align}

\begin{align}
\propto \frac{p(\alpha, \beta) \left(\prod_{j=1}^J \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1}\right) \left(\prod_{j=1}^J \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}\right)}{\prod_{j=1}^J \frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}
\end{align}

\begin{align}
\propto p(\alpha, \beta) \frac{\prod_{j=1}^J \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1} \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}}{\prod_{j=1}^J \frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}
\end{align}

\begin{align}
\propto p(\alpha, \beta) \prod_{j=1}^J \frac{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1} \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}}{\frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}
\end{align}

\begin{align}
\propto p(\alpha, \beta) \prod_{j=1}^J \left(\frac{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}}{\frac{\Gamma(\alpha + \beta + n_j)}{\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}}\frac{\theta_j^{\alpha - 1}(1 - \theta_j)^{\beta - 1} \theta_j^{y_j}(1 - \theta_j)^{n_j - y_j}}{\theta_j^{\alpha + y_j - 1}(1-\theta_j)^{\beta + n_j - y_j - 1}}\right)
\end{align}

\begin{align}
\propto p(\alpha, \beta) \prod_{j=1}^J \left(\frac{\Gamma(\alpha + \beta)\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}{\Gamma(\alpha)\Gamma(\beta)\Gamma(\alpha + \beta + n_j)}\theta_j^{\alpha - 1 + y_j - \alpha - y_j + 1}(1-\theta_j)^{\beta - 1 + n_j - y_j - \beta - n_j + y_j + 1}\right)
\end{align}

\begin{align}
\propto p(\alpha, \beta) \prod_{j=1}^J \left(\frac{\Gamma(\alpha + \beta)\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}{\Gamma(\alpha)\Gamma(\beta)\Gamma(\alpha + \beta + n_j)}\theta_j^{0}(1-\theta_j)^{0}\right)
\end{align}

\begin{align}
\propto p(\alpha, \beta) \prod_{j=1}^J \frac{\Gamma(\alpha + \beta)\Gamma(\alpha + y_j)\Gamma(\beta + n_j - y_j)}{\Gamma(\alpha)\Gamma(\beta)\Gamma(\alpha + \beta + n_j)}
\end{align}

<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Choosing a standard parameterization and setting up a 'noninformative' hyperprior distribution"><h3 id="Choosing a standard parameterization and setting up a 'noninformative' hyperprior distribution" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Choosing a standard parameterization and setting up a 'noninformative' hyperprior distribution">Choosing a standard parameterization and setting up a 'noninformative' hyperprior distribution</a></h3></div>

<p>
Because we have no immediately available information about the distribution of tumor rates in populations of rats, we seek a relatively diffuse hyperprior distribution for \((\alpha, \beta)\).
</p>

<p>
By reparameterizing the hyperparameters, we transform them into a space that may have more intuitive or meaningful interpretations. In this case, \(logit(\frac{\alpha}{\alpha + \beta}) = \log(\frac{\alpha}{\beta})\) represents the log-odds of \(\alpha\) relative to the total of \(\alpha\) and \(\beta\), providing a clear interpretation of the prior mean in the beta distribution for \(\theta\). Similarly, \(\log(\alpha + \beta)\) captures the logarithm of the "sample size," influencing the precision or spread of the distribution.
</p>

<p>
Also the logit transformation helps stabilize the numerical computations, especially when dealing with probabilities or proportions that are bounded between 0 and 1. By working in the logit space, we avoid issues related to extreme values or boundaries that can arise in the original parameter space. And transforming the hyperparameters can facilitate the specification of appropriate prior distributions.
</p>

<p>
One reasonable choice of diffuse hyperprior density is uniform on \((\frac{\alpha}{\alpha + \beta}, (\alpha + \beta)^{−1/2})\), which when multiplied by the appropriate Jacobian yields the following densities on the original scale,
</p>

\begin{align}
p(\alpha, \beta) \propto (\alpha + \beta)^{-5/2}
\end{align}

<p>
and on the natural transformed scale:
</p>

\begin{align}
p(\log(\frac{\alpha}{\beta}), \log(\alpha + \beta)) \propto \alpha\beta(\alpha + \beta)^{-5/2}
\end{align}

<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Computing the marginal posterior density of the hyperparameters"><h3 id="Computing the marginal posterior density of the hyperparameters" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Computing the marginal posterior density of the hyperparameters">Computing the marginal posterior density of the hyperparameters</a></h3></div>

<p>
Now that we have established a full probability model for data and parameters, we compute the marginal posterior distribution of the hyperparameters.
</p>

<p>
The next figure shows a contour plot of the unnormalized marginal posterior density on a grid of values of \((\log(\frac{\alpha}{\beta}), \log(\alpha + \beta))\)
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/assets/marginal_contour_plot.png/marginal_contour_plot.png" alt="Contour plot of the marginal posterior distribution" style="width:550px;height:300px">
To create the plot, we first compute the logarithm of the density function of \(p(\alpha, \beta|y)\) with prior density \(p(\alpha, \beta) \propto (\alpha + \beta)^{-5/2}\), multiplying by the Jacobian to obtain the density \(p(\log(\frac{\alpha}{\beta}), \log(\alpha + \beta)|y)\)
</p>

<p>
The most obvious features of the contour plot are (1) the mode is not far from the point estimate (as we would expect), and (2) important parts of the marginal posterior distribution lie outside the range of the graph.
</p>

<p>
We recompute the previous pdf in a different range \((\log(\frac{\alpha}{\beta}), \log(\alpha + \beta)) \in [-2.3, -1.3] \times [1, 5]\).
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/assets/marginal_contour_plot_1.png/marginal_contour_plot_1.png" alt="Contour plot of the marginal posterior distribution" style="width:550px;height:300px">
</p>

<p>
Figure \(5.3b\) displays \(1000\) random draws from the numerically computed posterior distribution. 
The graphs show that the marginal posterior distribution of the hyperparameters, under this transformation, is approximately symmetric about the mode, roughly \((−1.75, 2.8)\). This corresponds to approximate values of \((\alpha, \beta) = (2.4, 14.0)\), which differs somewhat from the crude estimate obtained earlier.
</p>

<p>
Having computed the relative posterior density at a grid that covers the effective range of \((\alpha, \beta)\), we normalize by approximating the distribution as a step function over the grid
and setting the total probability in the grid to \(1\).
</p>

<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Sampling from the joint posterior distribution of parameters and hyperparameters"><h3 id="Sampling from the joint posterior distribution of parameters and hyperparameters" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Sampling from the joint posterior distribution of parameters and hyperparameters">Sampling from the joint posterior distribution of parameters and hyperparameters</a></h3></div>

<p>
We draw \(1000\) random samples from the joint posterior distribution of \((\alpha, \beta, \theta_1, \cdots, \theta_J)\), as follows.
</p>

<ol>
<li>
Simulate \(1000\) draws of \((\log(\frac{\alpha}{\beta}), \log(\alpha + \beta))\) from their posterior distribution using the same discrete-grid sampling procedure used to draw \((\alpha, \beta)\) for Figure \(3.3b\).

</li><li>
For \(l = 1, \cdots, 1000\):

<ol>
<li>
Transform the \(l\)th draw of \((\log(\frac{\alpha}{\beta}), \log(\alpha + \beta))\) to the scale \((\alpha, \beta)\) to yield a draw of the hyperparameters from their marginal posterior distribution. 

</li><li>
For each \(j = 1, \cdots, J\), sample \(\theta_j\) from its conditional posterior distribution, \(\theta_j|\alpha, \beta, y \sim Beta(\alpha + y_j, \beta + n_j − y_j)\).

</li></ol>
</li></ol>
<div id="Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Displaying the results"><h3 id="Displaying the results" class="header"><a href="#Bayesian analysis of conjugate hierarchical models-Application to the model for rat tumors-Displaying the results">Displaying the results</a></h3></div>

<p>
Figure \(5.4\) shows posterior medians and \(95\%\) intervals for the \(\theta_j\)’s, computed by simulation.
</p>

<p>
<img src="https://albamr09.github.io/public/DataScience/Master/2C_2C/MBJ/T2/assets/posterior_values_simulation.png/posterior_values_simulation.png" alt="Posterior Values' Simulation" style="width:550px;height:300px">
</p>

<p>
The results are superficially similar to what would be obtained based on a point estimate of the hyperparameters, which makes sense in this example, because of the fairly large number of experiments. But key differences remain, notably that posterior variability is higher in the full Bayesian analysis, reflecting posterior uncertainty in the hyperparameters.
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>