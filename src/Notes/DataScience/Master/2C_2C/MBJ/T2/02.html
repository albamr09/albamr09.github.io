<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/custom.css">
    <title>Exchangeability and hierarchical models</title>
  <script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"><link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Exchangeability and hierarchical models"><h1 id="Exchangeability and hierarchical models" class="header"><a href="#Exchangeability and hierarchical models">Exchangeability and hierarchical models</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="02.html#Exchangeability">Exchangeability</a>

<ul>
<li>
<a href="02.html#Example">Example</a>

</li></ul>
</li><li>
<a href="02.html#Exchangeability%20when%20additional%20information%20is%20available%20on%20the%20units">Exchangeability when additional information is available on the units</a>

<ul>
<li>
<a href="02.html#Example">Example</a>

<ul>
<li>
<a href="02.html#Assumptions">Assumptions</a>

</li><li>
<a href="02.html#Model%20Formulation">Model Formulation</a>

</li><li>
<a href="02.html#Bayesian%20Inference">Bayesian Inference</a>

</li></ul>
</li></ul>
</li><li>
<a href="02.html#Objections%20to%20exchangeable%20models">Objections to exchangeable models</a>

</li><li>
<a href="02.html#The%20full%20Bayesian%20Treatment%20of%20the%20hierarchical%20model">The full Bayesian Treatment of the hierarchical model</a>

</li><li>
<a href="02.html#Posterior%20predictive%20distributions">Posterior predictive distributions</a>

</li></ul>
<hr>


<p>
Let \(E\) be a set of experiments, such that \(E_j = {y_i, \theta_j}, j = 1, \cdots, J\) where \(y_i\) are the vector data, \(\theta_j\) are the vector parameters and \(p(y_j|\theta_j)\) is the likelihood function.
</p>

<div id="Exchangeability and hierarchical models-Exchangeability"><h2 id="Exchangeability" class="header"><a href="#Exchangeability and hierarchical models-Exchangeability">Exchangeability</a></h2></div>

<p>
When we have no additional data on the parameters, we assume exchangeability between them, such that \(p(\theta_1, \cdots, \theta_J)\) is invariant to permutation of the indexes.
</p>

<p>
The simplest form of an exchangeable distribution has each of the parameters \(\theta_j\) as an <span id="Exchangeability and hierarchical models-Exchangeability-independent"></span><strong id="independent">independent</strong> sample from a prior distribution governed by some unknown parameter vector \(\phi\); thus:
</p>

\begin{align}
p(\theta|\phi) = \prod_{j = 1}^J p(\theta_j|\phi)
\end{align}

<p>
In general, \(\phi\) is unknown, so our distribution for \(\theta\) must average over our uncertainty in \(\phi\):
</p>

\begin{align}
p(\theta) = \int_{\phi} p(\theta|\phi)p(\phi) d \phi
\end{align}

\begin{align}
= \int_{\phi} \left(\prod_{j = 1}^J p(\theta_j|\phi)\right) p(\phi) d \phi
\end{align}

<p>
This form, the mixture of independent identical distributions, is usually all that we need to
capture exchangeability in practice.
</p>

<div id="Exchangeability and hierarchical models-Exchangeability-Example"><h3 id="Example" class="header"><a href="#Exchangeability and hierarchical models-Exchangeability-Example">Example</a></h3></div>

<p>
We use a nonhierarchical example with exchangeability at the level of \(y\) rather than \(\theta\).
</p>

<p>
In this example, eight states in the United States were selected, and the divorce rate per \(1000\) population in each state in \(1981\) was recorded. Since you have no information to distinguish any of the eight states from the others, you must model them exchangeably.
</p>

<p>
However, you can't assign an exchangeable prior to the set of eight diverse states when there's specific information about one of them. For example, if we know that Nevada differentiates itself from the others because it divorce rate is known to be unusually high, that lets us know before even seeing the data (observed values), that there's a strong reason to believe that Nevada's divorce rate is higher than the other states. 
</p>

<p>
This means that in a Bayesian analysis, the prior distribution should reflect this belief, assigning more probability mass to Nevada having a higher divorce rate in comparison to the other states. 
</p>

<div id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units"><h2 id="Exchangeability when additional information is available on the units" class="header"><a href="#Exchangeability and hierarchical models-Exchangeability when additional information is available on the units">Exchangeability when additional information is available on the units</a></h2></div>

<p>
Sometimes obervations are partially or conditionally exchangeable. For example, when:
</p>

<ul>
<li>
In the case where observations can be grouped, a hierarchical model can be created. In this context, each group has unknown properties. The assumption of exchangeability allows for the use of a common prior distribution for these group properties, meaning that any group can be considered as a random sample of the same underlying population.

</li><li>
If \(y_i\) has additional information \(x_i\) so that \(y_i\) are not exchangeable but \((y_i, x_i)\) still are exchangeable, then we can make a joint model for \((y_i, x_i)\) or a conditional model for \(y_i|x_i\).

</li></ul>
<p>
In general, the usual way to model exchangeability with covariates is through conditional independence:
</p>

\begin{align}
p(\theta_1, \cdots, \theta_J) = \int \left[ p(\theta_j|\phi,x_j)\right]p(\phi, x) d\phi
\end{align}

<p>
whith \(x = [x_1, \cdots, x_J]\)
</p>

<div id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example"><h3 id="Example" class="header"><a href="#Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example">Example</a></h3></div>

<p>
Let's consider an example in the field of education where we want to analyze the test scores of students from different schools. We can view the test scores as observations that can be grouped by schools. 
</p>

<p>
Let \(y_{ij}\) be the test score of the student \(i\) in school \(j\), where \(i = 1, 2, \cdots, n_j\) and \(j = 1, 2, \cdots, J\) and \(n_j\) are the number of students at school \(j\).
</p>

<div id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Assumptions"><h4 id="Assumptions" class="header"><a href="#Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Assumptions">Assumptions</a></h4></div>

<ul>
<li>
Each school \(j\) has an unknown mean test score \(\mu_j\).

</li><li>
The mean test scores \(\mu_j\) are assumed to follow a common distribution.

</li><li>
*Exchangeability: The test scores within each school are exchangeable, implying that any school could be considered a random sample from the overall population of schools.

</li><li>
<span id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Assumptions-Common prior distribution"></span><strong id="Common prior distribution">Common prior distribution</strong>: we assume a common prior distribution for the group mean test scores \(\mu_j\) across schools.

</li></ul>
<div id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Model Formulation"><h4 id="Model Formulation" class="header"><a href="#Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Model Formulation">Model Formulation</a></h4></div>

<p>
<span id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Model Formulation-Likelihood"></span><strong id="Likelihood">Likelihood</strong>: The likelihood of the test scores given the group mean and variance
</p>

\begin{align}
p(y_{ij}|\mu_j, \sigma^2)
\end{align}

<p>
<span id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Model Formulation-Prior"></span><strong id="Prior">Prior</strong>: Common prior distribution for the group mean test scores
</p>

\begin{align}
p(\mu_j|\theta) \sim \mathcal{N}(\theta, \tau^2)
\end{align}

<p>
where \(\theta\) represents the overall mean test score and \(\tau\) is the variance parameter.
</p>

<p>
<span id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Model Formulation-Hyperprior"></span><strong id="Hyperprior">Hyperprior</strong>: Prior distribution for the overall test score
</p>

\begin{align}
p(\theta) \sim \mathcal{N}(\mu_0, \sigma_0^2)
\end{align}

<p>
where \(\mu_0\) is the prior mean and \(\sigma_0^2\) is the prior variance.
</p>

<div id="Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Bayesian Inference"><h4 id="Bayesian Inference" class="header"><a href="#Exchangeability and hierarchical models-Exchangeability when additional information is available on the units-Example-Bayesian Inference">Bayesian Inference</a></h4></div>

<p>
The posterior distribution of the group mean test scores and the overall mean test score can be obtained using Bayesian inference techniques, such as Markov Chain Monte Carlo (MCMC) sampling.
</p>

<div id="Exchangeability and hierarchical models-Objections to exchangeable models"><h2 id="Objections to exchangeable models" class="header"><a href="#Exchangeability and hierarchical models-Objections to exchangeable models">Objections to exchangeable models</a></h2></div>

<p>
In statistical applications, it is common to raise objections to the assumption that different data or experiments are exchangeable. For example experiments may which may have been conducted at different times, with different subjects, and likely in different places.
</p>

<p>
Despite these differences, the text suggests that it might be acceptable to consider the data as if they were from the same distribution due to model ignorance.
</p>

<div id="Exchangeability and hierarchical models-The full Bayesian Treatment of the hierarchical model"><h2 id="The full Bayesian Treatment of the hierarchical model" class="header"><a href="#Exchangeability and hierarchical models-The full Bayesian Treatment of the hierarchical model">The full Bayesian Treatment of the hierarchical model</a></h2></div>

<p>
The true 'hierarchical' part of the models is that some parameters are not known and thus have their own prior distributions, denoted as \(p(\phi)\). The Bayesian posterior distribution is of the vector \((\phi, \theta)\). The joint prior distribution is:
</p>

\begin{align}
p(\phi, \theta) = p(\phi)p(\theta|\phi)
\end{align}

<p>
and the joint posterior distribution (after seeing the data \(y\)) is:
</p>

\begin{align}
p(\phi, \theta|y) \propto p(\phi, \theta)p(y|\phi, \theta)
\end{align}

<p>
Given that \(p(y|\phi, \theta)\) depends only on \(\theta\):
</p>

\begin{align}
= p(\phi, \theta)p(y|\theta)
\end{align}

<p>
In order to create a joint probability distribution for \((\phi, \theta)\), we must assign a prior distribution to \(\phi\).
</p>

<p>
It is often practical to start with a simple, relatively noninformative, prior distribution on \(\phi\) and seek to add more prior information if there remains too much variation in the posterior distribution.
</p>

<div id="Exchangeability and hierarchical models-Posterior predictive distributions"><h2 id="Posterior predictive distributions" class="header"><a href="#Exchangeability and hierarchical models-Posterior predictive distributions">Posterior predictive distributions</a></h2></div>

<p>
Hierarchical models are characterized both by parameters \(\theta\) and hyperparameters, \(\phi\), that parametrize the prior distribution over \(\theta\).
</p>

<p>
There are two posterior predictive distributions that might be of interest:
</p>

<ul>
<li>
The distribution of future observations \(\tilde{y}\) corresponding to an existing \(j\) "group" described by \(\theta_j\).

</li><li>
The distribution of future observations \(\tilde{y}\) corresponding to future \(\theta_j\) (a "new group"), denoted by \(\tilde{\theta}\), drawn from the superpopulation \(p(\theta|\phi)\).

</li></ul>
<p>
In the rat tumor example, future observations can be (1) additional rats from an existing experiment, or (2) results from a future experiment (explained by a different set of parameters \(\theta\)). 
For (1) the posterior predictive draws \(\tilde{y}\) are based on the posterior draws of \(\theta_j\) (\(p(\theta_j|y)\)) for the existing experiment.
</p>

<p>
For (2) one must first draw \(\tilde{\theta}\) for the new experiment from the population distribution, given the posterior draws of \(\phi\), and then draw \(\tilde{y}\) given the simulated \(\tilde{\theta}\).
</p>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/flexsearch.bundle.js" id="flexsearch" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>