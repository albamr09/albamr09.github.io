<html><head>
    <!-- Normal styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/index.css">
    <!-- Custom styling from vimwiki -->
    <link rel="Stylesheet" type="text/css" href="../../../../../../../src/style/custom.css">
    <title>Programación MapReduce</title>
  <link rel="icon" type="image/svg+xml" href="https://albamr09.github.io/public/icon.svg" data-description="Page icon"><script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=es6" id="latex_script" data-description="Support for latex"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" data-description="Support for latex"></script><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/search.css" data-description="Styling for search"><link rel="Stylesheet" type="text/css" href="https://albamr09.github.io/src/style/atom-one-light.min.css" data-description="Code highlight"></head>
  <body>
    <a href="https://albamr09.github.io/" style="
        color: white;
        font-weight: bold;
        text-decoration: none;
        padding: 3px 6px;
        border-radius: 3px;
        background-color: #1e90ff;
        text-transform: uppercase;
      ">Index</a>
    <form id="search_form" class="search-form">
      <input required="" type="search" id="search_term" class="searchTerm">
      <button type="submit" class="searchButton">Search</button>
    </form>
    <div id="search-background" class="search-background">
      <div id="search-result" class="search-result-hide"></div>
      <div id="search-form-modal" class="search-form-modal">
        <form id="search-form-in-modal">
          <input required="" type="search" id="search-input-in-modal" class="search-input-in-modal" placeholder="Search whatever...">
          <button type="submit" class="searchButton">Search</button>
        </form>
      </div>
    </div>
    <hr>
    <div class="content">
<p>
<a href="../index.html">Back</a>
</p>

<div id="Programación MapReduce"><h1 id="Programación MapReduce" class="header"><a href="#Programación MapReduce">Programación MapReduce</a></h1></div>

<hr>

<div id="Contents" class="toc"><h2 id="Contents" class="header"><a href="#Contents">Contents</a></h2></div>
<ul>
<li>
<a href="03_mapreduce.html#El%20paradigma%20de%20programaci%F3n%20MapReduce%3A%20Hadoop%20Streaming">El paradigma de programaci n MapReduce  Hadoop Streaming</a>

<ul>
<li>
<a href="03_mapreduce.html#%BFQu%E9%20es%20MapReduce%3F">Qu  es MapReduce</a>

</li><li>
<a href="03_mapreduce.html#Fases%20de%20Map%20Reduce">Fases de Map Reduce</a>

</li><li>
<a href="03_mapreduce.html#Hadoop%20Streaming">Hadoop Streaming</a>

</li><li>
<a href="03_mapreduce.html#Ejemplo%20Pr%E1ctico%20de%20MapReduce">Ejemplo Pr ctico de MapReduce</a>

</li><li>
<a href="03_mapreduce.html#Optimizaci%F3n%3A%20Combiners%20y%20Partitioner">Optimizaci n  Combiners y Partitioner</a>

</li></ul>
</li><li>
<a href="03_mapreduce.html#Programaci%F3n%20MapReduce%20con%20lenguajes%20de%20alto%20nivel%3A%20Hive">Programaci n MapReduce con lenguajes de alto nivel  Hive</a>

<ul>
<li>
<a href="03_mapreduce.html#Introducci%F3n%20a%20Apache%20Hive">Introducci n a Apache Hive</a>

</li><li>
<a href="03_mapreduce.html#Arquitectura%20de%20Apache%20Hive">Arquitectura de Apache Hive</a>

<ul>
<li>
<a href="03_mapreduce.html#Cliente">Cliente</a>

</li><li>
<a href="03_mapreduce.html#Cat%E1logo%20Centralizado%3A%20Metastore">Cat logo Centralizado  Metastore</a>

</li><li>
<a href="03_mapreduce.html#Driver%20de%20Gesti%F3n">Driver de Gesti n</a>

</li><li>
<a href="03_mapreduce.html#HiveQL%20Parser">HiveQL Parser</a>

</li><li>
<a href="03_mapreduce.html#Optimizador%20y%20Planificador%20de%20Consultas">Optimizador y Planificador de Consultas</a>

</li><li>
<a href="03_mapreduce.html#Motor%20de%20Ejecuci%F3n">Motor de Ejecuci n</a>

</li><li>
<a href="03_mapreduce.html#Almacenamiento%20de%20Datos">Almacenamiento de Datos</a>

</li></ul>
</li><li>
<a href="03_mapreduce.html#Estructura%20Interna">Estructura Interna</a>

<ul>
<li>
<a href="03_mapreduce.html#Tipos%20de%20Datos">Tipos de Datos</a>

</li><li>
<a href="03_mapreduce.html#Estructura%20de%20Datos">Estructura de Datos</a>

<ul>
<li>
<a href="03_mapreduce.html#Tablas">Tablas</a>

</li></ul>
</li><li>
<a href="03_mapreduce.html#Particiones">Particiones</a>

</li><li>
<a href="03_mapreduce.html#Buckets">Buckets</a>

</li></ul>
</li></ul>
</li></ul>
<hr>

<div id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming"><h2 id="El paradigma de programación MapReduce: Hadoop Streaming" class="header"><a href="#Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming">El paradigma de programación MapReduce: Hadoop Streaming</a></h2></div>

<div id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-¿Qué es MapReduce?"><h3 id="¿Qué es MapReduce?" class="header"><a href="#Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-¿Qué es MapReduce?">¿Qué es MapReduce?</a></h3></div>

<p>
El flujo de procesamiento de MapReduce se divide en dos etapas: <span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-¿Qué es MapReduce?-Map"></span><strong id="Map">Map</strong> y <span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-¿Qué es MapReduce?-Reduce"></span><strong id="Reduce">Reduce</strong> las cuales se ejecutan de manera distribuida en distintos nodos de procesamiento mientras que un proceso central denominado <span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-¿Qué es MapReduce?-Job Tracker"></span><strong id="Job Tracker">Job Tracker</strong> controla su ejecución.
</p>

<div id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Fases de Map Reduce"><h3 id="Fases de Map Reduce" class="header"><a href="#Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Fases de Map Reduce">Fases de Map Reduce</a></h3></div>

<ol>
<li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Fases de Map Reduce-Map"></span><strong id="Map">Map</strong>: Los datos de entrada se subdividen en bloques independientes que son procesados de forma paralela por los mappers. Normalmente Hadoop intenta ejecutar los mappers en los nodos donde se encuentran los datos sobre los que va a trabajar (<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Fases de Map Reduce-data locality"></span><strong id="data locality">data locality</strong>). Esto reduce los tiempos de acceso a los datos y la necesidad de transferencia de datos entre nodos.

</li><li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Fases de Map Reduce-Shuffle &amp; sort"></span><strong id="Shuffle &amp; sort">Shuffle &amp; sort</strong>: los datos intermedios de los mappers se ordenan. Este proceso comienza mientras las tareas map están en progreso, a medida que van terminando. No es necesario esperar a que todas terminen.

</li><li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Fases de Map Reduce-Reduce"></span><strong id="Reduce">Reduce</strong>: comienza cuando todos los datos han sido ordenados en <span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Fases de Map Reduce-Shuffle &amp; sort"></span><strong id="Shuffle &amp; sort">Shuffle &amp; sort</strong>. Recibe como entrada estes datos ordenados estructurados como pares clave valor agrupados por clave. Cada reducer toma los valores asociados a una clave y los agrega/procesa y devuelve el resultado como salida que se puede almacenar en HDFS o en otro sistema.

</li><li>
Generalmente se concatenan varias fases de mapper-reducer para completar una tarea.

</li></ol>
<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/map_reduce.png" alt="Map Reduce">
</p>

<div id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Hadoop Streaming"><h3 id="Hadoop Streaming" class="header"><a href="#Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Hadoop Streaming">Hadoop Streaming</a></h3></div>

<p>
Hadoop Streaming se trata de una utilidad que permite ejecutar aplicaciones en Hadoop escritas en cualquier lenguaje, a pesar de que Hadoop este escrito en Java. Este proporciona un interfaz de entrada y de salida (stdin/stdout) que es consumida por las aplicaciones, tal que existe una pasarela de datos que actúa como comunicación entre Hadoop y la aplicación.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/hadoop_streaming.png">
</p>

<p>
En la imagen anterior se muestra el flujo de un trabajo MapReduce.
</p>

<ol>
<li>
Se leen los datos de entrada y se produce una lista de pares clave-valor.

</li><li>
Se proporcionan los datos en este formato a un mapper externo a través del canal estándar de entrada.

</li><li>
Se devuelve el resultado de los mapper en el mismo formato a través del canal estándar de salida.

</li><li>
Se proporcionan los datos procesados por los mapper al reducer externo a través de la entrada estándar.

</li><li>
Se devuelve el resultado del reducer a través de stdout.

</li><li>
Finalmente se almacena el resultado del reducer, bien en HDFS o en otro sistema externo.

</li></ol>
<p>
Como podemos ver en todas las fases del proceso de mantiene siempre la estructura de pares clave-valor.
</p>

<div id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Ejemplo Práctico de MapReduce"><h3 id="Ejemplo Práctico de MapReduce" class="header"><a href="#Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Ejemplo Práctico de MapReduce">Ejemplo Práctico de MapReduce</a></h3></div>

<p>
Para ejemplificar MapReduce planteamos el siguiente problema: queremos obtener la frecuencia de cada palabra en un documento.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/map_reduce_example_1.png" alt="MapReduce Example">
</p>

<ul>
<li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Ejemplo Práctico de MapReduce-Map"></span><strong id="Map">Map</strong>: dividimos el proceso en dos mappers (idealmente cada proceso mapper se debería de ejecutar en el nodo en el cual se encuentra el bloque de datos). Estes se encargan de obtener la frecuencia de las palabras en la "porción de texto" sobre el que trabajan.

</li></ul>
<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/map_reduce_example_2.png" alt="MapReduce Example">
</p>

<ul>
<li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Ejemplo Práctico de MapReduce-Shuffle &amp; Sort"></span><strong id="Shuffle &amp; Sort">Shuffle &amp; Sort</strong>: se ordenan y se agrupan los valores por la clave, donde la clave en nuestro caso es la palabra y el valor su frecuencia.

</li></ul>
<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/map_reduce_example_3.png" alt="MapReduce Example">
</p>

<ul>
<li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Ejemplo Práctico de MapReduce-Reduce"></span><strong id="Reduce">Reduce</strong>: se ejecuta un reducer por cada clave presente en el resultado, que agrupa (en nuestro caso suma) los valores bajo cada clave, es decir las frecuencias asociadas a la palabra.

</li></ul>
<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/map_reduce_example_4.png" alt="MapReduce Example">
</p>

<div id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Optimización: Combiners y Partitioner"><h3 id="Optimización: Combiners y Partitioner" class="header"><a href="#Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Optimización: Combiners y Partitioner">Optimización: Combiners y Partitioner</a></h3></div>

<p>
MapReduce cuenta con dos componentes para optimizar el procesamiento denominados <span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Optimización: Combiners y Partitioner-combiners"></span><strong id="combiners">combiners</strong> y <span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Optimización: Combiners y Partitioner-partitioners"></span><strong id="partitioners">partitioners</strong>.
</p>

<ol>
<li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Optimización: Combiners y Partitioner-Combiners"></span><strong id="Combiners">Combiners</strong>: agrupan los resultados de cada mapper antes de llegar a la frase de shuffle and sort con el objetivo de reducir el tamaño de los datos que se le proporcionan al reducer.

</li><li>
<span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Optimización: Combiners y Partitioner-Partitioners"></span><strong id="Partitioners">Partitioners</strong>: se utilizan para determinar cómo se distribuyen los datos a cada reducer. Por defecto Hadoop distribuye la carga de trabajo de manera uniforme entre los reducers, pero se puede personalizar utilizando los <span id="Programación MapReduce-El paradigma de programación MapReduce: Hadoop Streaming-Optimización: Combiners y Partitioner-partitioners"></span><strong id="partitioners">partitioners</strong>.

</li></ol>
<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive"><h2 id="Programación MapReduce con lenguajes de alto nivel: Hive" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive">Programación MapReduce con lenguajes de alto nivel: Hive</a></h2></div>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Introducción a Apache Hive"><h3 id="Introducción a Apache Hive" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Introducción a Apache Hive">Introducción a Apache Hive</a></h3></div>

<p>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Introducción a Apache Hive-Hive"></span><strong id="Hive">Hive</strong> fue creado por Facebook en el año 2007. Se trata de una abstracción sobre Hadoop, que permite utilizar su lenguaje de consulta, <span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Introducción a Apache Hive-HiveQL"></span><strong id="HiveQL">HiveQL</strong>, para generar de manera automática programas MapReduce.
</p>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive"><h3 id="Arquitectura de Apache Hive" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive">Arquitectura de Apache Hive</a></h3></div>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Cliente"><h4 id="Cliente" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Cliente">Cliente</a></h4></div>

<p>
Existen varias maneras de interactuar con Hive:
</p>

<ul>
<li>
Interfaz Web

</li><li>
Su interfaz de línea de comandos (CLI), Beeline

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Cliente-HiveServer"></span><strong id="HiveServer">HiveServer</strong>: un servidor Thrift de Hive que permite acceder a través de JDBC, ODBC o Thrift API.

</li></ul>
<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Catálogo Centralizado: Metastore"><h4 id="Catálogo Centralizado: Metastore" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Catálogo Centralizado: Metastore">Catálogo Centralizado: Metastore</a></h4></div>

<p>
Hive almacena los metadatos (esquemas de las tablas, tipos de datos, etc) en un catálogo centralizado denominado <span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Catálogo Centralizado: Metastore-Metastore"></span><strong id="Metastore">Metastore</strong>, que se trata de una base de datos relacional. Existen tres tipos de configuraciones:
</p>

<ul>
<li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Catálogo Centralizado: Metastore-Embedded Metastore"></span><strong id="Embedded Metastore">Embedded Metastore</strong>: se integra el código en el mismo proceso que el programa Hive y la base de datos. Generalmente utilizado en entornos de prueba.

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Catálogo Centralizado: Metastore-Local Metastore"></span><strong id="Local Metastore">Local Metastore</strong>: se ejecuta de manera local pero en un proceso distinto.

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Catálogo Centralizado: Metastore-Remote Metastore"></span><strong id="Remote Metastore">Remote Metastore</strong>: se configura en remote, tal que se desliga el metastore del resto de procesos. Generalmente se utiliza en entornos de producción.

</li></ul>
<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Driver de Gestión"><h4 id="Driver de Gestión" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Driver de Gestión">Driver de Gestión</a></h4></div>

<p>
Es el encargado de gestionar una consulta HiveQL durante todo su ciclo de vida.
</p>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-HiveQL Parser"><h4 id="HiveQL Parser" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-HiveQL Parser">HiveQL Parser</a></h4></div>

<p>
Se encarga de transformar las consultas en HiveQL a programas MapReduce.
</p>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Optimizador y Planificador de Consultas"><h4 id="Optimizador y Planificador de Consultas" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Optimizador y Planificador de Consultas">Optimizador y Planificador de Consultas</a></h4></div>

<ul>
<li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Optimizador y Planificador de Consultas-Optimizador de Consultas"></span><strong id="Optimizador de Consultas">Optimizador de Consultas</strong>: reorganiza la consulta para poder optimizarla mediante técnicas como el filtrado anticipado.

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Optimizador y Planificador de Consultas-Planificador de Consultas"></span><strong id="Planificador de Consultas">Planificador de Consultas</strong>: decide cómo y cuándo se ejecutan las consultas.

</li></ul>
<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Motor de Ejecución"><h4 id="Motor de Ejecución" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Motor de Ejecución">Motor de Ejecución</a></h4></div>

<p>
Se encarga de ejecutar la tarea de consulta de forma distribuida y paralela en los nodos del cluster de Hadoop.
</p>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Almacenamiento de Datos"><h4 id="Almacenamiento de Datos" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Arquitectura de Apache Hive-Almacenamiento de Datos">Almacenamiento de Datos</a></h4></div>

<p>
Los datos deben estar almacenados en HDFS y generalmente se almacenan en un formato aceptado por bases de datos relacionalales (p.ej. csv) o formatos que se integran con Hive como Parquet o Avro.
</p>

<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/hive_architecture.png" alt="Hive Architecture">
</p>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna"><h3 id="Estructura Interna" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna">Estructura Interna</a></h3></div>

<p>
Hive impone sobre HDFS una estructura propia que llamaremos esquema o Schema, la cual es almacenada en su propia base de datos (metastore).
</p>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos"><h4 id="Tipos de Datos" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos">Tipos de Datos</a></h4></div>

<p>
Hive soporta tipos de datos primitivos: <span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos-STRING"></span><strong id="STRING">STRING</strong>, <span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos-INT"></span><strong id="INT">INT</strong>, <span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos-BOOLEAN"></span><strong id="BOOLEAN">BOOLEAN</strong> y otros tipos de datos como <span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos-DATE"></span><strong id="DATE">DATE</strong>, así como tipos de datos compuestos: 
</p>

<ul>
<li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos-ARRAY"></span><strong id="ARRAY">ARRAY</strong>: son grupos de elementos del mismo tipo.

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos-MAP"></span><strong id="MAP">MAP</strong>: define elementos clave-valor: <code>{1: "flor, 2: "hoja", 3: "perro", 4: "gato}</code>

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Tipos de Datos-STRUCT"></span><strong id="STRUCT">STRUCT</strong>: permite crear objetos: <code>{"animal": "perro", "tipo": "mamífero", "numero_patas": 4}</code>

</li></ul>
<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Estructura de Datos"><h4 id="Estructura de Datos" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Estructura de Datos">Estructura de Datos</a></h4></div>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Estructura de Datos-Tablas"><h5 id="Tablas" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Estructura de Datos-Tablas">Tablas</a></h5></div>

<p>
Las tablas están compuestas por filas y columnas y tienen esquemas bien definidos, pero tienen una estructura lógica que se corresponde con una carpeta en HDFS. Existen dos tipos de tablas:
</p>

<ul>
<li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Estructura de Datos-Tablas-Tabla Interna (o gestionada)"></span><strong id="Tabla Interna (o gestionada)">Tabla Interna (o gestionada)</strong>: son tablas gestionadas por Hive. Cuando se crea una tabla interna automáticamente se crea un carpeta en HDFS y Hive controla tanto la tabla como sus datos. Si esta tabla se borra también se borra la carpeta en HDFS.
<pre> -- creación tabla interna
CREATE TABLE libros (
     id INT,
     titulo STRING,
     autor STRING,
     categoria STRING);
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;
</pre>

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Estructura de Datos-Tablas-Tabla externa"></span><strong id="Tabla externa">Tabla externa</strong>: se trata de una tabla populada con datos ya existentes en HDFS. Su estructura se define en la Metastore y si borramos la tabla no se borra su contenido en HDFS. Esta opción es útil cuando compartimos datos entre distintas herramientas.
<pre>-- creación tabla externa
CREATE EXTERNAL TABLE libros_externa (
     id INT,
     titulo STRING,
     autor STRING,
     categoria STRING);
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/curso-bigdata/externa/libros';
</pre>

</li></ul>
<p>
En la tabla anterior se indica la ubicación de los datos utilizando <code>LOCATION</code>. El término <code>STORED AS</code> indica el formato del fichero en el que residen los datos.
</p>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Particiones"><h4 id="Particiones" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Particiones">Particiones</a></h4></div>

<p>
Las <span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Particiones-particiones"></span><strong id="particiones">particiones</strong> son subdivisiones en una tabla Hive que permite la optimización de las consultas eliminando valores irrelevantes. Las subdivisiones se realizan en base a los valores de las columnas, por ejemplo si tenemos una variable nominal se podría particionar la tabla según las distintas categorías. Existen dos tipos de particiones:
</p>

<ul>
<li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Particiones-Particiones estáticas"></span><strong id="Particiones estáticas">Particiones estáticas</strong>: son definidas por parte del usuario pero no cambian en el tiempo.

</li><li>
<span id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Particiones-Particiones dinámicas"></span><strong id="Particiones dinámicas">Particiones dinámicas</strong>: Hive se ocupa de crear automáticamente las particiones basándose en los valores de la columna especificada.

</li></ul>
<p>
<img src="https://albamr09.github.io/public/images/DataScience/Master/3C_1C/ICPDM/hive_partitions.png" alt="Hive Partitions">
</p>

<pre>-- creación tabla con particiones
CREATE TABLE libros_particion (
     id INT,
     titulo STRING,
     autor STRING,
)
PARTITIONED BY (categoria STRING);

-- insertar datos
INSERT INTO TABLE libros_particion PARTITION (categoria=Fantástico) VALUES
 (1, 'Harry Potter y la Piedra Filosofal', 'J.K. Rowling');
 (2, 'Harry Potter y la Cámara Secreta', 'J.K. Rowling');
-- etc
</pre>

<div id="Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Buckets"><h4 id="Buckets" class="header"><a href="#Programación MapReduce-Programación MapReduce con lenguajes de alto nivel: Hive-Estructura Interna-Buckets">Buckets</a></h4></div>

<p>
Los buckets son otra técnica de división de datos, estes están identificados mediante un par 'clave, valor' que distribuye los datos según una función hash. El objetivo principal para utilizar buckets es optimizar las consultas, sobre todo cuando estas son de tipo JOIN o unión.
</p>

<p>
Podemos realizar los buckets bien de forma dinámica o estática. La diferencia radica en la elección de la columna que especifiquemos en la cláusula <code>CLUSTERED BY</code>.
</p>

<pre>-- creación tabla con buckets
CREATE TABLE prestamos (
     id INT,
     libro_id INT,
     fecha_prestamo STRING,
     socio_id INT,
)
CLUSTERED BY (libro_id) INTO 5 BUCKETS;   
</pre>
</div>
  

<script type="text/javascript" src="https://albamr09.github.io/src/lib/highlight.min.js" id="js_highlight" data-description="Support sytax highlighting on code"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/zepto.min.js" id="zepto" data-description="jQuery library"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/search.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" src="https://albamr09.github.io/src/lib/fuse.js" id="search" data-description="Library to perform search"></script><script type="text/javascript" id="search" data-description="Entrypoint for hightlihgting">
  $("pre").each(function (index, item) {
    $(item).html("<code>" + $(item).html() + "</code>");
  });
  hljs.highlightAll();
</script></body></html>